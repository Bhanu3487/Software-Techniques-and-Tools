old_file_path,new_file_path,commit_SHA,parent_commit_SHA,commit_message,diff_myers,diff_histogram,matches
minimal-notebook/setup-scripts/setup-julia-packages.bash,minimal-notebook/setup-scripts/setup-julia-packages.bash,98d700d84df9d0dec35a2647ee0338df3161f590,095717cb5793a31d3ad994985c0f376f9fc58370,Unify julia scripts style,"diff --git a/minimal-notebook/setup-scripts/setup-julia-packages.bash b/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 70ab730a..0be05426 100755
--- a/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -1,8 +1,9 @@
 #!/bin/bash
+set -exuo pipefail
 # Requirements:
 # - Run as non-root user
+# - The JULIA_PKGDIR environment variable is set
 # - Julia is already set up, with the setup-julia.bash command
-set -exuo pipefail
 
 # Install base Julia packages
 julia -e '","diff --git a/minimal-notebook/setup-scripts/setup-julia-packages.bash b/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 70ab730a..0be05426 100755
--- a/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -1,8 +1,9 @@
 #!/bin/bash
+set -exuo pipefail
 # Requirements:
 # - Run as non-root user
+# - The JULIA_PKGDIR environment variable is set
 # - Julia is already set up, with the setup-julia.bash command
-set -exuo pipefail
 
 # Install base Julia packages
 julia -e '",Yes
minimal-notebook/setup-scripts/setup-julia.bash,minimal-notebook/setup-scripts/setup-julia.bash,98d700d84df9d0dec35a2647ee0338df3161f590,095717cb5793a31d3ad994985c0f376f9fc58370,Unify julia scripts style,"diff --git a/minimal-notebook/setup-scripts/setup-julia.bash b/minimal-notebook/setup-scripts/setup-julia.bash
index 95a76581..3aab076e 100755
--- a/minimal-notebook/setup-scripts/setup-julia.bash
+++ b/minimal-notebook/setup-scripts/setup-julia.bash
@@ -1,7 +1,7 @@
 #!/bin/bash
 set -exuo pipefail
 # Requirements:
-# - This script is run as the root user
+# - Run as the root user
 # - The JULIA_PKGDIR environment variable is set
 
 # Default julia version to install if env var is not set","diff --git a/minimal-notebook/setup-scripts/setup-julia.bash b/minimal-notebook/setup-scripts/setup-julia.bash
index 95a76581..3aab076e 100755
--- a/minimal-notebook/setup-scripts/setup-julia.bash
+++ b/minimal-notebook/setup-scripts/setup-julia.bash
@@ -1,7 +1,7 @@
 #!/bin/bash
 set -exuo pipefail
 # Requirements:
-# - This script is run as the root user
+# - Run as the root user
 # - The JULIA_PKGDIR environment variable is set
 
 # Default julia version to install if env var is not set",Yes
.github/actions/load-image/action.yml,.github/actions/load-image/action.yml,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,98d700d84df9d0dec35a2647ee0338df3161f590,Refactor handling of artifacts (#1930),"diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index 6ce7c65b..55fa8c97 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -18,13 +18,12 @@ runs:
       uses: actions/download-artifact@v3
       with:
         name: ${{ inputs.image }}-${{ inputs.platform }}
-        path: /tmp/
+        path: /tmp/jupyter/images/
     - name: Load downloaded image to docker 📥
       run: |
-        docker load --input /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
+        docker load --input /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
         docker image ls --all
       shell: bash
     - name: Delete the file 🗑️
-      run: rm -f /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
+      run: rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
       shell: bash
-      if: always()","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index 6ce7c65b..55fa8c97 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -18,13 +18,12 @@ runs:
       uses: actions/download-artifact@v3
       with:
         name: ${{ inputs.image }}-${{ inputs.platform }}
-        path: /tmp/
+        path: /tmp/jupyter/images/
     - name: Load downloaded image to docker 📥
       run: |
-        docker load --input /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
+        docker load --input /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
         docker image ls --all
       shell: bash
     - name: Delete the file 🗑️
-      run: rm -f /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
+      run: rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
       shell: bash
-      if: always()",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,98d700d84df9d0dec35a2647ee0338df3161f590,Refactor handling of artifacts (#1930),"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 880c4fd7..d3c7f26a 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -44,9 +44,7 @@ jobs:
           docker kill $(docker ps --quiet) || true
           docker rm $(docker ps --all --quiet) || true
           docker system prune --all --force
-          rm -rf /tmp/tags/
-          rm -rf /tmp/hist_lines/
-          rm -rf /tmp/manifests/
+          rm -rf /tmp/jupyter/
         shell: bash
 
       - name: Load parent built image to Docker 📥
@@ -70,44 +68,39 @@ jobs:
 
       - name: Write tags file 🏷
         run: |
-          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/tags/ --owner ${{ env.OWNER }}
+          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
-          path: /tmp/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
+          path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
           retention-days: 3
 
       - name: Write manifest and build history file 🏷
-        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/hist_lines/ --manifest-dir /tmp/manifests/ --owner ${{ env.OWNER }}
+        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
-          path: /tmp/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
+          path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
-          path: /tmp/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
+          path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
           retention-days: 3
 
       - name: Save image as a tar for later use 💾
-        run: docker save ${{ env.OWNER }}/${{ inputs.image }} -o /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
+        run: |
+          mkdir -p /tmp/jupyter/images/
+          docker save ${{ env.OWNER }}/${{ inputs.image }} -o /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
         shell: bash
       - name: Upload image as artifact 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
-          path: /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
+          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
           retention-days: 3
-
-      # Self-hosted runners share a state (whole VM) between runs
-      - name: Cleanup artifacts 🗑️
-        run: |
-          rm -f /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
-        shell: bash
-        if: always()","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 880c4fd7..d3c7f26a 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -44,9 +44,7 @@ jobs:
           docker kill $(docker ps --quiet) || true
           docker rm $(docker ps --all --quiet) || true
           docker system prune --all --force
-          rm -rf /tmp/tags/
-          rm -rf /tmp/hist_lines/
-          rm -rf /tmp/manifests/
+          rm -rf /tmp/jupyter/
         shell: bash
 
       - name: Load parent built image to Docker 📥
@@ -70,44 +68,39 @@ jobs:
 
       - name: Write tags file 🏷
         run: |
-          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/tags/ --owner ${{ env.OWNER }}
+          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
-          path: /tmp/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
+          path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
           retention-days: 3
 
       - name: Write manifest and build history file 🏷
-        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/hist_lines/ --manifest-dir /tmp/manifests/ --owner ${{ env.OWNER }}
+        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
-          path: /tmp/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
+          path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
-          path: /tmp/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
+          path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
           retention-days: 3
 
       - name: Save image as a tar for later use 💾
-        run: docker save ${{ env.OWNER }}/${{ inputs.image }} -o /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
+        run: |
+          mkdir -p /tmp/jupyter/images/
+          docker save ${{ env.OWNER }}/${{ inputs.image }} -o /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
         shell: bash
       - name: Upload image as artifact 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
-          path: /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
+          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
           retention-days: 3
-
-      # Self-hosted runners share a state (whole VM) between runs
-      - name: Cleanup artifacts 🗑️
-        run: |
-          rm -f /tmp/${{ inputs.image }}-${{ inputs.platform }}.tar
-        shell: bash
-        if: always()",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,98d700d84df9d0dec35a2647ee0338df3161f590,Refactor handling of artifacts (#1930),"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index d977b889..7287b0cf 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -32,12 +32,12 @@ jobs:
         uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-x86_64-tags
-          path: /tmp/tags/
+          path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
         uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-aarch64-tags
-          path: /tmp/tags/
+          path: /tmp/jupyter/tags/
 
       # Docker might be stuck when pulling images
       # https://github.com/docker/for-mac/issues/2083
@@ -57,5 +57,5 @@ jobs:
 
       - name: Merge tags for the images 🔀
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
-        run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/tags/
+        run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/
         shell: bash","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index d977b889..7287b0cf 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -32,12 +32,12 @@ jobs:
         uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-x86_64-tags
-          path: /tmp/tags/
+          path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
         uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-aarch64-tags
-          path: /tmp/tags/
+          path: /tmp/jupyter/tags/
 
       # Docker might be stuck when pulling images
       # https://github.com/docker/for-mac/issues/2083
@@ -57,5 +57,5 @@ jobs:
 
       - name: Merge tags for the images 🔀
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
-        run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/tags/
+        run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/
         shell: bash",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,98d700d84df9d0dec35a2647ee0338df3161f590,Refactor handling of artifacts (#1930),"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index bd0baa0f..75e4a732 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -48,9 +48,9 @@ jobs:
         uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
-          path: /tmp/tags/
+          path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
-        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/tags/ --platform ${{ inputs.platform }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --owner ${{ env.OWNER }}
 
       - name: Push Images to Docker Hub 📤
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index bd0baa0f..75e4a732 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -48,9 +48,9 @@ jobs:
         uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
-          path: /tmp/tags/
+          path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
-        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/tags/ --platform ${{ inputs.platform }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --owner ${{ env.OWNER }}
 
       - name: Push Images to Docker Hub 📤
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,98d700d84df9d0dec35a2647ee0338df3161f590,Refactor handling of artifacts (#1930),"diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 9ae75dc8..d5747c64 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -20,12 +20,12 @@ jobs:
       - name: Download all manifests and history lines 📥
         uses: ./.github/actions/download-manifests
         with:
-          histLineDir: /tmp/hist_lines/
-          manifestDir: /tmp/manifests/
+          histLineDir: /tmp/jupyter/hist_lines/
+          manifestDir: /tmp/jupyter/manifests/
       - name: Display structure of downloaded files 🔍️
         run: |
-          ls -R /tmp/hist_lines/
-          ls -R /tmp/manifests/
+          ls -R /tmp/jupyter/hist_lines/
+          ls -R /tmp/jupyter/manifests/
         shell: bash
 
       - name: Checkout Wiki Repo 📃
@@ -35,7 +35,7 @@ jobs:
           path: wiki/
 
       - name: Update wiki page 🏷
-        run: python3 -m tagging.update_wiki_page --wiki-dir wiki/ --hist-line-dir /tmp/hist_lines/ --manifest-dir /tmp/manifests/
+        run: python3 -m tagging.update_wiki_page --wiki-dir wiki/ --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/
         shell: bash
 
       - name: Push Wiki to GitHub 📤","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 9ae75dc8..d5747c64 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -20,12 +20,12 @@ jobs:
       - name: Download all manifests and history lines 📥
         uses: ./.github/actions/download-manifests
         with:
-          histLineDir: /tmp/hist_lines/
-          manifestDir: /tmp/manifests/
+          histLineDir: /tmp/jupyter/hist_lines/
+          manifestDir: /tmp/jupyter/manifests/
       - name: Display structure of downloaded files 🔍️
         run: |
-          ls -R /tmp/hist_lines/
-          ls -R /tmp/manifests/
+          ls -R /tmp/jupyter/hist_lines/
+          ls -R /tmp/jupyter/manifests/
         shell: bash
 
       - name: Checkout Wiki Repo 📃
@@ -35,7 +35,7 @@ jobs:
           path: wiki/
 
       - name: Update wiki page 🏷
-        run: python3 -m tagging.update_wiki_page --wiki-dir wiki/ --hist-line-dir /tmp/hist_lines/ --manifest-dir /tmp/manifests/
+        run: python3 -m tagging.update_wiki_page --wiki-dir wiki/ --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/
         shell: bash
 
       - name: Push Wiki to GitHub 📤",Yes
Makefile,Makefile,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,98d700d84df9d0dec35a2647ee0338df3161f590,Refactor handling of artifacts (#1930),"diff --git a/Makefile b/Makefile
index 8a71110a..c1a33edb 100644
--- a/Makefile
+++ b/Makefile
@@ -69,7 +69,7 @@ linkcheck-docs: ## check broken links
 
 hook/%: ## run post-build hooks for an image
 	python3 -m tagging.tag_image --short-image-name ""$(notdir $@)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/hist_lines/ --manifest-dir /tmp/manifests/ --owner ""$(OWNER)""
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images","diff --git a/Makefile b/Makefile
index 8a71110a..c1a33edb 100644
--- a/Makefile
+++ b/Makefile
@@ -69,7 +69,7 @@ linkcheck-docs: ## check broken links
 
 hook/%: ## run post-build hooks for an image
 	python3 -m tagging.tag_image --short-image-name ""$(notdir $@)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/hist_lines/ --manifest-dir /tmp/manifests/ --owner ""$(OWNER)""
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images",Yes
tests/base-notebook/test_npm_package_manager.py,tests/base-notebook/test_npm_package_manager.py,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,"Add run_command script in tests (#1931)

* Add run_command script in tests

* Fix

* Add timeout back","diff --git a/tests/base-notebook/test_npm_package_manager.py b/tests/base-notebook/test_npm_package_manager.py
index 4d94dfbb..8bcba8c3 100644
--- a/tests/base-notebook/test_npm_package_manager.py
+++ b/tests/base-notebook/test_npm_package_manager.py
@@ -1,14 +1,10 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 
-import logging
-
 from tests.conftest import TrackedContainer
-from tests.package_helper import run_package_manager
-
-LOGGER = logging.getLogger(__name__)
+from tests.run_command import run_command
 
 
 def test_npm_package_manager(container: TrackedContainer) -> None:
     """"""Test that npm is installed and runs.""""""
-    run_package_manager(container, ""npm"", ""--version"")
+    run_command(container, ""npm --version"")","diff --git a/tests/base-notebook/test_npm_package_manager.py b/tests/base-notebook/test_npm_package_manager.py
index 4d94dfbb..8bcba8c3 100644
--- a/tests/base-notebook/test_npm_package_manager.py
+++ b/tests/base-notebook/test_npm_package_manager.py
@@ -1,14 +1,10 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 
-import logging
-
 from tests.conftest import TrackedContainer
-from tests.package_helper import run_package_manager
-
-LOGGER = logging.getLogger(__name__)
+from tests.run_command import run_command
 
 
 def test_npm_package_manager(container: TrackedContainer) -> None:
     """"""Test that npm is installed and runs.""""""
-    run_package_manager(container, ""npm"", ""--version"")
+    run_command(container, ""npm --version"")",Yes
tests/datascience-notebook/test_julia.py,tests/datascience-notebook/test_julia.py,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,"Add run_command script in tests (#1931)

* Add run_command script in tests

* Fix

* Add timeout back","diff --git a/tests/datascience-notebook/test_julia.py b/tests/datascience-notebook/test_julia.py
deleted file mode 100644
index 5ed9d1dc..00000000
--- a/tests/datascience-notebook/test_julia.py
+++ /dev/null
@@ -1,18 +0,0 @@
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
-import logging
-
-from tests.conftest import TrackedContainer
-
-LOGGER = logging.getLogger(__name__)
-
-
-def test_julia(container: TrackedContainer) -> None:
-    """"""Basic julia test""""""
-    LOGGER.info(""Test that julia is correctly installed ..."")
-    logs = container.run_and_wait(
-        timeout=5,
-        tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", ""julia --version""],
-    )
-    LOGGER.debug(logs)","diff --git a/tests/datascience-notebook/test_julia.py b/tests/datascience-notebook/test_julia.py
deleted file mode 100644
index 5ed9d1dc..00000000
--- a/tests/datascience-notebook/test_julia.py
+++ /dev/null
@@ -1,18 +0,0 @@
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
-import logging
-
-from tests.conftest import TrackedContainer
-
-LOGGER = logging.getLogger(__name__)
-
-
-def test_julia(container: TrackedContainer) -> None:
-    """"""Basic julia test""""""
-    LOGGER.info(""Test that julia is correctly installed ..."")
-    logs = container.run_and_wait(
-        timeout=5,
-        tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", ""julia --version""],
-    )
-    LOGGER.debug(logs)",Yes
,tests/datascience-notebook/test_julia_datascience.py,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,"Add run_command script in tests (#1931)

* Add run_command script in tests

* Fix

* Add timeout back","diff --git a/tests/datascience-notebook/test_julia_datascience.py b/tests/datascience-notebook/test_julia_datascience.py
new file mode 100644
index 00000000..3b1a55b6
--- /dev/null
+++ b/tests/datascience-notebook/test_julia_datascience.py
@@ -0,0 +1,8 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+from tests.conftest import TrackedContainer
+from tests.run_command import run_command
+
+
+def test_julia(container: TrackedContainer) -> None:
+    run_command(container, ""julia --version"")","diff --git a/tests/datascience-notebook/test_julia_datascience.py b/tests/datascience-notebook/test_julia_datascience.py
new file mode 100644
index 00000000..3b1a55b6
--- /dev/null
+++ b/tests/datascience-notebook/test_julia_datascience.py
@@ -0,0 +1,8 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+from tests.conftest import TrackedContainer
+from tests.run_command import run_command
+
+
+def test_julia(container: TrackedContainer) -> None:
+    run_command(container, ""julia --version"")",Yes
tests/docker-stacks-foundation/test_package_managers.py,tests/docker-stacks-foundation/test_package_managers.py,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,"Add run_command script in tests (#1931)

* Add run_command script in tests

* Fix

* Add timeout back","diff --git a/tests/docker-stacks-foundation/test_package_managers.py b/tests/docker-stacks-foundation/test_package_managers.py
index 9e8dd5b9..29e0b649 100644
--- a/tests/docker-stacks-foundation/test_package_managers.py
+++ b/tests/docker-stacks-foundation/test_package_managers.py
@@ -1,27 +1,22 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
-import logging
-
 import pytest  # type: ignore
 
 from tests.conftest import TrackedContainer
-from tests.package_helper import run_package_manager
-
-LOGGER = logging.getLogger(__name__)
+from tests.run_command import run_command
 
 
 @pytest.mark.parametrize(
-    ""package_manager, version_arg"",
+    ""package_manager_command"",
     [
-        (""apt"", ""--version""),
-        (""conda"", ""--version""),
-        (""mamba"", ""--version""),
-        (""pip"", ""--version""),
+        ""apt --version"",
+        ""conda --version"",
+        ""mamba --version"",
+        ""pip --version"",
     ],
 )
 def test_package_manager(
-    container: TrackedContainer, package_manager: str, version_arg: str
+    container: TrackedContainer, package_manager_command: str
 ) -> None:
     """"""Test that package managers are installed and run.""""""
-    run_package_manager(container, package_manager, version_arg)
+    run_command(container, package_manager_command)","diff --git a/tests/docker-stacks-foundation/test_package_managers.py b/tests/docker-stacks-foundation/test_package_managers.py
index 9e8dd5b9..29e0b649 100644
--- a/tests/docker-stacks-foundation/test_package_managers.py
+++ b/tests/docker-stacks-foundation/test_package_managers.py
@@ -1,27 +1,22 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
-import logging
-
 import pytest  # type: ignore
 
 from tests.conftest import TrackedContainer
-from tests.package_helper import run_package_manager
-
-LOGGER = logging.getLogger(__name__)
+from tests.run_command import run_command
 
 
 @pytest.mark.parametrize(
-    ""package_manager, version_arg"",
+    ""package_manager_command"",
     [
-        (""apt"", ""--version""),
-        (""conda"", ""--version""),
-        (""mamba"", ""--version""),
-        (""pip"", ""--version""),
+        ""apt --version"",
+        ""conda --version"",
+        ""mamba --version"",
+        ""pip --version"",
     ],
 )
 def test_package_manager(
-    container: TrackedContainer, package_manager: str, version_arg: str
+    container: TrackedContainer, package_manager_command: str
 ) -> None:
     """"""Test that package managers are installed and run.""""""
-    run_package_manager(container, package_manager, version_arg)
+    run_command(container, package_manager_command)",Yes
,tests/julia-notebook/test_julia.py,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,"Add run_command script in tests (#1931)

* Add run_command script in tests

* Fix

* Add timeout back","diff --git a/tests/julia-notebook/test_julia.py b/tests/julia-notebook/test_julia.py
new file mode 100644
index 00000000..3b1a55b6
--- /dev/null
+++ b/tests/julia-notebook/test_julia.py
@@ -0,0 +1,8 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+from tests.conftest import TrackedContainer
+from tests.run_command import run_command
+
+
+def test_julia(container: TrackedContainer) -> None:
+    run_command(container, ""julia --version"")","diff --git a/tests/julia-notebook/test_julia.py b/tests/julia-notebook/test_julia.py
new file mode 100644
index 00000000..3b1a55b6
--- /dev/null
+++ b/tests/julia-notebook/test_julia.py
@@ -0,0 +1,8 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+from tests.conftest import TrackedContainer
+from tests.run_command import run_command
+
+
+def test_julia(container: TrackedContainer) -> None:
+    run_command(container, ""julia --version"")",Yes
tests/julia-notebook/test_julia_exists.py,tests/julia-notebook/test_julia_exists.py,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,"Add run_command script in tests (#1931)

* Add run_command script in tests

* Fix

* Add timeout back","diff --git a/tests/julia-notebook/test_julia_exists.py b/tests/julia-notebook/test_julia_exists.py
deleted file mode 100644
index 5ed9d1dc..00000000
--- a/tests/julia-notebook/test_julia_exists.py
+++ /dev/null
@@ -1,18 +0,0 @@
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
-import logging
-
-from tests.conftest import TrackedContainer
-
-LOGGER = logging.getLogger(__name__)
-
-
-def test_julia(container: TrackedContainer) -> None:
-    """"""Basic julia test""""""
-    LOGGER.info(""Test that julia is correctly installed ..."")
-    logs = container.run_and_wait(
-        timeout=5,
-        tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", ""julia --version""],
-    )
-    LOGGER.debug(logs)","diff --git a/tests/julia-notebook/test_julia_exists.py b/tests/julia-notebook/test_julia_exists.py
deleted file mode 100644
index 5ed9d1dc..00000000
--- a/tests/julia-notebook/test_julia_exists.py
+++ /dev/null
@@ -1,18 +0,0 @@
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
-import logging
-
-from tests.conftest import TrackedContainer
-
-LOGGER = logging.getLogger(__name__)
-
-
-def test_julia(container: TrackedContainer) -> None:
-    """"""Basic julia test""""""
-    LOGGER.info(""Test that julia is correctly installed ..."")
-    logs = container.run_and_wait(
-        timeout=5,
-        tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", ""julia --version""],
-    )
-    LOGGER.debug(logs)",Yes
tests/package_helper.py,tests/package_helper.py,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,"Add run_command script in tests (#1931)

* Add run_command script in tests

* Fix

* Add timeout back","diff --git a/tests/package_helper.py b/tests/package_helper.py
index c9fa09f2..7524fe0a 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -37,21 +37,6 @@ from tests.conftest import TrackedContainer
 LOGGER = logging.getLogger(__name__)
 
 
-def run_package_manager(
-    container: TrackedContainer, package_manager: str, version_arg: str
-) -> None:
-    """"""Runs the given package manager with its version argument.""""""
-
-    LOGGER.info(
-        f""Test that the package manager {package_manager} is working properly ...""
-    )
-    container.run_and_wait(
-        timeout=5,
-        tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", f""{package_manager} {version_arg}""],
-    )
-
-
 class CondaPackageHelper:
     """"""Conda package helper permitting to get information about packages""""""","diff --git a/tests/package_helper.py b/tests/package_helper.py
index c9fa09f2..7524fe0a 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -37,21 +37,6 @@ from tests.conftest import TrackedContainer
 LOGGER = logging.getLogger(__name__)
 
 
-def run_package_manager(
-    container: TrackedContainer, package_manager: str, version_arg: str
-) -> None:
-    """"""Runs the given package manager with its version argument.""""""
-
-    LOGGER.info(
-        f""Test that the package manager {package_manager} is working properly ...""
-    )
-    container.run_and_wait(
-        timeout=5,
-        tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", f""{package_manager} {version_arg}""],
-    )
-
-
 class CondaPackageHelper:
     """"""Conda package helper permitting to get information about packages""""""",Yes
tests/pyspark-notebook/test_spark.py,tests/pyspark-notebook/test_spark.py,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,"Add run_command script in tests (#1931)

* Add run_command script in tests

* Fix

* Add timeout back","diff --git a/tests/pyspark-notebook/test_spark.py b/tests/pyspark-notebook/test_spark.py
index eb721bc1..211432f0 100644
--- a/tests/pyspark-notebook/test_spark.py
+++ b/tests/pyspark-notebook/test_spark.py
@@ -3,16 +3,12 @@
 import logging
 
 from tests.conftest import TrackedContainer
+from tests.run_command import run_command
 
 LOGGER = logging.getLogger(__name__)
 
 
 def test_spark_shell(container: TrackedContainer) -> None:
     """"""Checking if Spark (spark-shell) is running properly""""""
-    logs = container.run_and_wait(
-        timeout=60,
-        tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", 'spark-shell <<< ""1+1""'],
-    )
-
+    logs = run_command(container, 'spark-shell <<< ""1+1""', timeout=60)
     assert ""res0: Int = 2"" in logs, ""spark-shell does not work""","diff --git a/tests/pyspark-notebook/test_spark.py b/tests/pyspark-notebook/test_spark.py
index eb721bc1..211432f0 100644
--- a/tests/pyspark-notebook/test_spark.py
+++ b/tests/pyspark-notebook/test_spark.py
@@ -3,16 +3,12 @@
 import logging
 
 from tests.conftest import TrackedContainer
+from tests.run_command import run_command
 
 LOGGER = logging.getLogger(__name__)
 
 
 def test_spark_shell(container: TrackedContainer) -> None:
     """"""Checking if Spark (spark-shell) is running properly""""""
-    logs = container.run_and_wait(
-        timeout=60,
-        tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", 'spark-shell <<< ""1+1""'],
-    )
-
+    logs = run_command(container, 'spark-shell <<< ""1+1""', timeout=60)
     assert ""res0: Int = 2"" in logs, ""spark-shell does not work""",Yes
,tests/run_command.py,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,28c5a1bf1dd5f357071c2e775bf7c48ed816e42f,"Add run_command script in tests (#1931)

* Add run_command script in tests

* Fix

* Add timeout back","diff --git a/tests/run_command.py b/tests/run_command.py
new file mode 100644
index 00000000..40f343d0
--- /dev/null
+++ b/tests/run_command.py
@@ -0,0 +1,22 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import logging
+
+from tests.conftest import TrackedContainer
+
+LOGGER = logging.getLogger(__name__)
+
+
+def run_command(
+    container: TrackedContainer,
+    command: str,
+    timeout: int = 5,
+) -> str:
+    """"""Runs the given package manager with its version argument.""""""
+
+    LOGGER.info(f""Test that the command '{command}' is working properly ..."")
+    return container.run_and_wait(
+        timeout=timeout,
+        tty=True,
+        command=[""start.sh"", ""bash"", ""-c"", command],
+    )","diff --git a/tests/run_command.py b/tests/run_command.py
new file mode 100644
index 00000000..40f343d0
--- /dev/null
+++ b/tests/run_command.py
@@ -0,0 +1,22 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import logging
+
+from tests.conftest import TrackedContainer
+
+LOGGER = logging.getLogger(__name__)
+
+
+def run_command(
+    container: TrackedContainer,
+    command: str,
+    timeout: int = 5,
+) -> str:
+    """"""Runs the given package manager with its version argument.""""""
+
+    LOGGER.info(f""Test that the command '{command}' is working properly ..."")
+    return container.run_and_wait(
+        timeout=timeout,
+        tty=True,
+        command=[""start.sh"", ""bash"", ""-c"", command],
+    )",Yes
tests/R_mimetype_check.py,tests/R_mimetype_check.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/R_mimetype_check.py b/tests/R_mimetype_check.py
index cc09d134..4cfe7267 100644
--- a/tests/R_mimetype_check.py
+++ b/tests/R_mimetype_check.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 
 from tests.conftest import TrackedContainer","diff --git a/tests/R_mimetype_check.py b/tests/R_mimetype_check.py
index cc09d134..4cfe7267 100644
--- a/tests/R_mimetype_check.py
+++ b/tests/R_mimetype_check.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 
 from tests.conftest import TrackedContainer",Yes
tests/all-spark-notebook/test_spark_notebooks.py,tests/all-spark-notebook/test_spark_notebooks.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index 37aa2edb..b49b1cb2 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 from pathlib import Path","diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index 37aa2edb..b49b1cb2 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 from pathlib import Path",Yes
tests/base-notebook/test_healthcheck.py,tests/base-notebook/test_healthcheck.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index ac61e974..3c779803 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 import time
 from typing import Optional","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index ac61e974..3c779803 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 import time
 from typing import Optional",Yes
tests/base-notebook/test_notebook.py,tests/base-notebook/test_notebook.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/base-notebook/test_notebook.py b/tests/base-notebook/test_notebook.py
index c8288997..29c2bec7 100644
--- a/tests/base-notebook/test_notebook.py
+++ b/tests/base-notebook/test_notebook.py
@@ -1,7 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
-
 import requests
 
 from tests.conftest import TrackedContainer, find_free_port","diff --git a/tests/base-notebook/test_notebook.py b/tests/base-notebook/test_notebook.py
index c8288997..29c2bec7 100644
--- a/tests/base-notebook/test_notebook.py
+++ b/tests/base-notebook/test_notebook.py
@@ -1,7 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
-
 import requests
 
 from tests.conftest import TrackedContainer, find_free_port",Yes
tests/base-notebook/test_npm_package_manager.py,tests/base-notebook/test_npm_package_manager.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/base-notebook/test_npm_package_manager.py b/tests/base-notebook/test_npm_package_manager.py
index 8bcba8c3..14f50957 100644
--- a/tests/base-notebook/test_npm_package_manager.py
+++ b/tests/base-notebook/test_npm_package_manager.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 from tests.conftest import TrackedContainer
 from tests.run_command import run_command","diff --git a/tests/base-notebook/test_npm_package_manager.py b/tests/base-notebook/test_npm_package_manager.py
index 8bcba8c3..14f50957 100644
--- a/tests/base-notebook/test_npm_package_manager.py
+++ b/tests/base-notebook/test_npm_package_manager.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 from tests.conftest import TrackedContainer
 from tests.run_command import run_command",Yes
tests/base-notebook/test_pandoc.py,tests/base-notebook/test_pandoc.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/base-notebook/test_pandoc.py b/tests/base-notebook/test_pandoc.py
index fa4fac9c..f5cce325 100644
--- a/tests/base-notebook/test_pandoc.py
+++ b/tests/base-notebook/test_pandoc.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 
 from tests.conftest import TrackedContainer","diff --git a/tests/base-notebook/test_pandoc.py b/tests/base-notebook/test_pandoc.py
index fa4fac9c..f5cce325 100644
--- a/tests/base-notebook/test_pandoc.py
+++ b/tests/base-notebook/test_pandoc.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 
 from tests.conftest import TrackedContainer",Yes
tests/base-notebook/test_start_container.py,tests/base-notebook/test_start_container.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index b3d69610..14418288 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 import time
 from typing import Optional","diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index b3d69610..14418288 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 import time
 from typing import Optional",Yes
tests/datascience-notebook/test_mimetypes.py,tests/datascience-notebook/test_mimetypes.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/datascience-notebook/test_mimetypes.py b/tests/datascience-notebook/test_mimetypes.py
index a2ac55cf..4fd86473 100644
--- a/tests/datascience-notebook/test_mimetypes.py
+++ b/tests/datascience-notebook/test_mimetypes.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 from tests.conftest import TrackedContainer
 from tests.R_mimetype_check import check_r_mimetypes","diff --git a/tests/datascience-notebook/test_mimetypes.py b/tests/datascience-notebook/test_mimetypes.py
index a2ac55cf..4fd86473 100644
--- a/tests/datascience-notebook/test_mimetypes.py
+++ b/tests/datascience-notebook/test_mimetypes.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 from tests.conftest import TrackedContainer
 from tests.R_mimetype_check import check_r_mimetypes",Yes
tests/docker-stacks-foundation/test_outdated.py,tests/docker-stacks-foundation/test_outdated.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/docker-stacks-foundation/test_outdated.py b/tests/docker-stacks-foundation/test_outdated.py
index 72f6b3d0..6de18d3d 100644
--- a/tests/docker-stacks-foundation/test_outdated.py
+++ b/tests/docker-stacks-foundation/test_outdated.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 
 import pytest  # type: ignore","diff --git a/tests/docker-stacks-foundation/test_outdated.py b/tests/docker-stacks-foundation/test_outdated.py
index 72f6b3d0..6de18d3d 100644
--- a/tests/docker-stacks-foundation/test_outdated.py
+++ b/tests/docker-stacks-foundation/test_outdated.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 
 import pytest  # type: ignore",Yes
tests/docker-stacks-foundation/test_units.py,tests/docker-stacks-foundation/test_units.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/docker-stacks-foundation/test_units.py b/tests/docker-stacks-foundation/test_units.py
index e709fc0c..85d07862 100644
--- a/tests/docker-stacks-foundation/test_units.py
+++ b/tests/docker-stacks-foundation/test_units.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 
 from tests.conftest import TrackedContainer","diff --git a/tests/docker-stacks-foundation/test_units.py b/tests/docker-stacks-foundation/test_units.py
index e709fc0c..85d07862 100644
--- a/tests/docker-stacks-foundation/test_units.py
+++ b/tests/docker-stacks-foundation/test_units.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 
 from tests.conftest import TrackedContainer",Yes
tests/minimal-notebook/test_nbconvert.py,tests/minimal-notebook/test_nbconvert.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/minimal-notebook/test_nbconvert.py b/tests/minimal-notebook/test_nbconvert.py
index dabeba4d..33954cb0 100644
--- a/tests/minimal-notebook/test_nbconvert.py
+++ b/tests/minimal-notebook/test_nbconvert.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 from pathlib import Path","diff --git a/tests/minimal-notebook/test_nbconvert.py b/tests/minimal-notebook/test_nbconvert.py
index dabeba4d..33954cb0 100644
--- a/tests/minimal-notebook/test_nbconvert.py
+++ b/tests/minimal-notebook/test_nbconvert.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 from pathlib import Path",Yes
tests/pyspark-notebook/units/unit_pandas_version.py,tests/pyspark-notebook/units/unit_pandas_version.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/pyspark-notebook/units/unit_pandas_version.py b/tests/pyspark-notebook/units/unit_pandas_version.py
index 5f650a3b..1728effa 100644
--- a/tests/pyspark-notebook/units/unit_pandas_version.py
+++ b/tests/pyspark-notebook/units/unit_pandas_version.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import pandas
 
 assert pandas.__version__ == ""1.5.3""","diff --git a/tests/pyspark-notebook/units/unit_pandas_version.py b/tests/pyspark-notebook/units/unit_pandas_version.py
index 5f650a3b..1728effa 100644
--- a/tests/pyspark-notebook/units/unit_pandas_version.py
+++ b/tests/pyspark-notebook/units/unit_pandas_version.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import pandas
 
 assert pandas.__version__ == ""1.5.3""",Yes
tests/pyspark-notebook/units/unit_spark.py,tests/pyspark-notebook/units/unit_spark.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/pyspark-notebook/units/unit_spark.py b/tests/pyspark-notebook/units/unit_spark.py
index 80b47d43..b6413fa4 100644
--- a/tests/pyspark-notebook/units/unit_spark.py
+++ b/tests/pyspark-notebook/units/unit_spark.py
@@ -1,4 +1,3 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import pyspark  # noqa: F401","diff --git a/tests/pyspark-notebook/units/unit_spark.py b/tests/pyspark-notebook/units/unit_spark.py
index 80b47d43..b6413fa4 100644
--- a/tests/pyspark-notebook/units/unit_spark.py
+++ b/tests/pyspark-notebook/units/unit_spark.py
@@ -1,4 +1,3 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import pyspark  # noqa: F401",Yes
tests/r-notebook/test_R_mimetypes.py,tests/r-notebook/test_R_mimetypes.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/r-notebook/test_R_mimetypes.py b/tests/r-notebook/test_R_mimetypes.py
index a2ac55cf..4fd86473 100644
--- a/tests/r-notebook/test_R_mimetypes.py
+++ b/tests/r-notebook/test_R_mimetypes.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 from tests.conftest import TrackedContainer
 from tests.R_mimetype_check import check_r_mimetypes","diff --git a/tests/r-notebook/test_R_mimetypes.py b/tests/r-notebook/test_R_mimetypes.py
index a2ac55cf..4fd86473 100644
--- a/tests/r-notebook/test_R_mimetypes.py
+++ b/tests/r-notebook/test_R_mimetypes.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 from tests.conftest import TrackedContainer
 from tests.R_mimetype_check import check_r_mimetypes",Yes
tests/scipy-notebook/test_cython.py,tests/scipy-notebook/test_cython.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/scipy-notebook/test_cython.py b/tests/scipy-notebook/test_cython.py
index bf1c0ab5..839d83a1 100644
--- a/tests/scipy-notebook/test_cython.py
+++ b/tests/scipy-notebook/test_cython.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 from pathlib import Path
 
 from tests.conftest import TrackedContainer","diff --git a/tests/scipy-notebook/test_cython.py b/tests/scipy-notebook/test_cython.py
index bf1c0ab5..839d83a1 100644
--- a/tests/scipy-notebook/test_cython.py
+++ b/tests/scipy-notebook/test_cython.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 from pathlib import Path
 
 from tests.conftest import TrackedContainer",Yes
tests/scipy-notebook/test_matplotlib.py,tests/scipy-notebook/test_matplotlib.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/scipy-notebook/test_matplotlib.py b/tests/scipy-notebook/test_matplotlib.py
index b8807f8f..27c6d3c3 100644
--- a/tests/scipy-notebook/test_matplotlib.py
+++ b/tests/scipy-notebook/test_matplotlib.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 from pathlib import Path","diff --git a/tests/scipy-notebook/test_matplotlib.py b/tests/scipy-notebook/test_matplotlib.py
index b8807f8f..27c6d3c3 100644
--- a/tests/scipy-notebook/test_matplotlib.py
+++ b/tests/scipy-notebook/test_matplotlib.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import logging
 from pathlib import Path",Yes
tests/scipy-notebook/units/unit_pandas.py,tests/scipy-notebook/units/unit_pandas.py,c44f6e9476867f252ca77a75f58cf6c243607101,2343fdba34b1959f7b6cd06c7ee3e61ae4d303f2,Remove extra line in some test files,"diff --git a/tests/scipy-notebook/units/unit_pandas.py b/tests/scipy-notebook/units/unit_pandas.py
index fc998225..2190a0b5 100644
--- a/tests/scipy-notebook/units/unit_pandas.py
+++ b/tests/scipy-notebook/units/unit_pandas.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import numpy as np
 import pandas as pd","diff --git a/tests/scipy-notebook/units/unit_pandas.py b/tests/scipy-notebook/units/unit_pandas.py
index fc998225..2190a0b5 100644
--- a/tests/scipy-notebook/units/unit_pandas.py
+++ b/tests/scipy-notebook/units/unit_pandas.py
@@ -1,6 +1,5 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-
 import numpy as np
 import pandas as pd",Yes
.github/actions/load-image/action.yml,.github/actions/load-image/action.yml,2df2eeca933121d6153d9dd299c6d879a52f184f,c44f6e9476867f252ca77a75f58cf6c243607101,Compress images to improve download/upload speed (#1932),"diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index 55fa8c97..a28ffe17 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -21,9 +21,6 @@ runs:
         path: /tmp/jupyter/images/
     - name: Load downloaded image to docker 📥
       run: |
-        docker load --input /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
+        zstd --uncompress --stdout --rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst | docker load
         docker image ls --all
       shell: bash
-    - name: Delete the file 🗑️
-      run: rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
-      shell: bash","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index 55fa8c97..a28ffe17 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -21,9 +21,6 @@ runs:
         path: /tmp/jupyter/images/
     - name: Load downloaded image to docker 📥
       run: |
-        docker load --input /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
+        zstd --uncompress --stdout --rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst | docker load
         docker image ls --all
       shell: bash
-    - name: Delete the file 🗑️
-      run: rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
-      shell: bash",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,2df2eeca933121d6153d9dd299c6d879a52f184f,c44f6e9476867f252ca77a75f58cf6c243607101,Compress images to improve download/upload speed (#1932),"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index d3c7f26a..c53d85e6 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -96,11 +96,11 @@ jobs:
       - name: Save image as a tar for later use 💾
         run: |
           mkdir -p /tmp/jupyter/images/
-          docker save ${{ env.OWNER }}/${{ inputs.image }} -o /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
+          docker save ${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
-          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
+          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
           retention-days: 3","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index d3c7f26a..c53d85e6 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -96,11 +96,11 @@ jobs:
       - name: Save image as a tar for later use 💾
         run: |
           mkdir -p /tmp/jupyter/images/
-          docker save ${{ env.OWNER }}/${{ inputs.image }} -o /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
+          docker save ${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
         uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
-          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar
+          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
           retention-days: 3",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,d71917f3c0405a44aeafea94589374a2f31cd358,2df2eeca933121d6153d9dd299c6d879a52f184f,"[pre-commit.ci] pre-commit autoupdate (#1933)

updates:
- [github.com/asottile/pyupgrade: v3.6.0 → v3.8.0](https://github.com/asottile/pyupgrade/compare/v3.6.0...v3.8.0)
- [github.com/pre-commit/mirrors-mypy: v1.3.0 → v1.4.1](https://github.com/pre-commit/mirrors-mypy/compare/v1.3.0...v1.4.1)
- [github.com/igorshubovych/markdownlint-cli: v0.34.0 → v0.35.0](https://github.com/igorshubovych/markdownlint-cli/compare/v0.34.0...v0.35.0)
- [github.com/asottile/blacken-docs: 1.13.0 → 1.14.0](https://github.com/asottile/blacken-docs/compare/1.13.0...1.14.0)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 34df15e0..cc1e4bfe 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.6.0
+    rev: v3.8.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.3.0
+    rev: v1.4.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -102,7 +102,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.34.0
+    rev: v0.35.0
     hooks:
       - id: markdownlint
         args: [""--fix""]
@@ -127,7 +127,7 @@ repos:
 
   # Run black on python code blocks in documentation files.
   - repo: https://github.com/asottile/blacken-docs
-    rev: 1.13.0
+    rev: 1.14.0
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 34df15e0..cc1e4bfe 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.6.0
+    rev: v3.8.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.3.0
+    rev: v1.4.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -102,7 +102,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.34.0
+    rev: v0.35.0
     hooks:
       - id: markdownlint
         args: [""--fix""]
@@ -127,7 +127,7 @@ repos:
 
   # Run black on python code blocks in documentation files.
   - repo: https://github.com/asottile/blacken-docs
-    rev: 1.13.0
+    rev: 1.14.0
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if",Yes
mypy.ini,mypy.ini,0b8b444cf114a8fa2e65ab6e4cc13d328352649b,d71917f3c0405a44aeafea94589374a2f31cd358,Change mypy website url,"diff --git a/mypy.ini b/mypy.ini
index 4373ba9a..f35b2e18 100644
--- a/mypy.ini
+++ b/mypy.ini
@@ -1,7 +1,7 @@
 # Mypy is an optional static type checker for Python that aims to combine
 # the benefits of dynamic (or ""duck"") typing and static typing.
 #
-# Documentation: http://www.mypy-lang.org
+# Documentation: https://www.mypy-lang.org
 # Project: https://github.com/python/mypy
 # Config reference: https://mypy.readthedocs.io/en/stable/config_file.html
 #","diff --git a/mypy.ini b/mypy.ini
index 4373ba9a..f35b2e18 100644
--- a/mypy.ini
+++ b/mypy.ini
@@ -1,7 +1,7 @@
 # Mypy is an optional static type checker for Python that aims to combine
 # the benefits of dynamic (or ""duck"") typing and static typing.
 #
-# Documentation: http://www.mypy-lang.org
+# Documentation: https://www.mypy-lang.org
 # Project: https://github.com/python/mypy
 # Config reference: https://mypy.readthedocs.io/en/stable/config_file.html
 #",Yes
docs/_static/using/troubleshooting/vscode-jupyter-settings.png,docs/_static/using/troubleshooting/vscode-jupyter-settings.png,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,0b8b444cf114a8fa2e65ab6e4cc13d328352649b,Improve docs about VSCode jupyter settings,"diff --git a/docs/_static/using/troubleshooting/vscode-jupyter-settings.png b/docs/_static/using/troubleshooting/vscode-jupyter-settings.png
index 177c3855..6c60389a 100644
Binary files a/docs/_static/using/troubleshooting/vscode-jupyter-settings.png and b/docs/_static/using/troubleshooting/vscode-jupyter-settings.png differ","diff --git a/docs/_static/using/troubleshooting/vscode-jupyter-settings.png b/docs/_static/using/troubleshooting/vscode-jupyter-settings.png
index 177c3855..6c60389a 100644
Binary files a/docs/_static/using/troubleshooting/vscode-jupyter-settings.png and b/docs/_static/using/troubleshooting/vscode-jupyter-settings.png differ",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,0b8b444cf114a8fa2e65ab6e4cc13d328352649b,Improve docs about VSCode jupyter settings,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index bcab93f2..2f3c0e93 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -308,9 +308,9 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
 
    Alternatively - you might want to ensure that the `Jupyter: Auto Start` setting is turned off to avoid this issue in the future.
 
-   You can achieve this from the `Preferences > Jupyter` menu in VScode:
+   You can achieve this from the `Settings > Jupyter` menu in VScode:
 
-   ![VSCode Preferences UI - Jupyter: Disable Jupyter Auto Start checkbox unchecked](../_static/using/troubleshooting/vscode-jupyter-settings.png)
+   ![VSCode Settings UI - Jupyter: Disable Jupyter Auto Start checkbox checked](../_static/using/troubleshooting/vscode-jupyter-settings.png)
 
 3. **Route container to unused local port**","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index bcab93f2..2f3c0e93 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -308,9 +308,9 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
 
    Alternatively - you might want to ensure that the `Jupyter: Auto Start` setting is turned off to avoid this issue in the future.
 
-   You can achieve this from the `Preferences > Jupyter` menu in VScode:
+   You can achieve this from the `Settings > Jupyter` menu in VScode:
 
-   ![VSCode Preferences UI - Jupyter: Disable Jupyter Auto Start checkbox unchecked](../_static/using/troubleshooting/vscode-jupyter-settings.png)
+   ![VSCode Settings UI - Jupyter: Disable Jupyter Auto Start checkbox checked](../_static/using/troubleshooting/vscode-jupyter-settings.png)
 
 3. **Route container to unused local port**",Yes
docs/_static/docker-github-settings.png,docs/_static/contributing/stacks/docker-github-settings.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/docker-github-settings.png b/docs/_static/contributing/stacks/docker-github-settings.png
new file mode 100644
index 00000000..8a07fe0c
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-github-settings.png differ","diff --git a/docs/_static/contributing/stacks/docker-github-settings.png b/docs/_static/contributing/stacks/docker-github-settings.png
new file mode 100644
index 00000000..8a07fe0c
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-github-settings.png differ",Yes
docs/_static/docker-org-create-token.png,docs/_static/contributing/stacks/docker-org-create-token.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/docker-org-create-token.png b/docs/_static/contributing/stacks/docker-org-create-token.png
new file mode 100644
index 00000000..ae016331
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-org-create-token.png differ","diff --git a/docs/_static/contributing/stacks/docker-org-create-token.png b/docs/_static/contributing/stacks/docker-org-create-token.png
new file mode 100644
index 00000000..ae016331
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-org-create-token.png differ",Yes
docs/_static/docker-org-security.png,docs/_static/contributing/stacks/docker-org-security.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/docker-org-security.png b/docs/_static/contributing/stacks/docker-org-security.png
new file mode 100644
index 00000000..2dfa2a78
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-org-security.png differ","diff --git a/docs/_static/contributing/stacks/docker-org-security.png b/docs/_static/contributing/stacks/docker-org-security.png
new file mode 100644
index 00000000..2dfa2a78
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-org-security.png differ",Yes
docs/_static/docker-org-select.png,docs/_static/contributing/stacks/docker-org-select.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/docker-org-select.png b/docs/_static/contributing/stacks/docker-org-select.png
new file mode 100644
index 00000000..3d2a2b8c
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-org-select.png differ","diff --git a/docs/_static/contributing/stacks/docker-org-select.png b/docs/_static/contributing/stacks/docker-org-select.png
new file mode 100644
index 00000000..3d2a2b8c
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-org-select.png differ",Yes
docs/_static/docker-repo-name.png,docs/_static/contributing/stacks/docker-repo-name.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/docker-repo-name.png b/docs/_static/contributing/stacks/docker-repo-name.png
new file mode 100644
index 00000000..b4088f9d
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-repo-name.png differ","diff --git a/docs/_static/contributing/stacks/docker-repo-name.png b/docs/_static/contributing/stacks/docker-repo-name.png
new file mode 100644
index 00000000..b4088f9d
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-repo-name.png differ",Yes
docs/_static/github-actions-tab.png,docs/_static/contributing/stacks/github-actions-tab.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/github-actions-tab.png b/docs/_static/contributing/stacks/github-actions-tab.png
new file mode 100644
index 00000000..932e3c04
Binary files /dev/null and b/docs/_static/contributing/stacks/github-actions-tab.png differ","diff --git a/docs/_static/contributing/stacks/github-actions-tab.png b/docs/_static/contributing/stacks/github-actions-tab.png
new file mode 100644
index 00000000..932e3c04
Binary files /dev/null and b/docs/_static/contributing/stacks/github-actions-tab.png differ",Yes
docs/_static/github-actions-workflow.png,docs/_static/contributing/stacks/github-actions-workflow.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/github-actions-workflow.png b/docs/_static/contributing/stacks/github-actions-workflow.png
new file mode 100644
index 00000000..1af7c512
Binary files /dev/null and b/docs/_static/contributing/stacks/github-actions-workflow.png differ","diff --git a/docs/_static/contributing/stacks/github-actions-workflow.png b/docs/_static/contributing/stacks/github-actions-workflow.png
new file mode 100644
index 00000000..1af7c512
Binary files /dev/null and b/docs/_static/contributing/stacks/github-actions-workflow.png differ",Yes
docs/_static/github-create-secrets.png,docs/_static/contributing/stacks/github-create-secrets.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/github-create-secrets.png b/docs/_static/contributing/stacks/github-create-secrets.png
new file mode 100644
index 00000000..3d1e35a4
Binary files /dev/null and b/docs/_static/contributing/stacks/github-create-secrets.png differ","diff --git a/docs/_static/contributing/stacks/github-create-secrets.png b/docs/_static/contributing/stacks/github-create-secrets.png
new file mode 100644
index 00000000..3d1e35a4
Binary files /dev/null and b/docs/_static/contributing/stacks/github-create-secrets.png differ",Yes
docs/_static/github-secret-token.png,docs/_static/contributing/stacks/github-secret-token.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/github-secret-token.png b/docs/_static/contributing/stacks/github-secret-token.png
new file mode 100644
index 00000000..68cb72c4
Binary files /dev/null and b/docs/_static/contributing/stacks/github-secret-token.png differ","diff --git a/docs/_static/contributing/stacks/github-secret-token.png b/docs/_static/contributing/stacks/github-secret-token.png
new file mode 100644
index 00000000..68cb72c4
Binary files /dev/null and b/docs/_static/contributing/stacks/github-secret-token.png differ",Yes
docs/_static/github-secrets-completed.png,docs/_static/contributing/stacks/github-secrets-completed.png,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/_static/contributing/stacks/github-secrets-completed.png b/docs/_static/contributing/stacks/github-secrets-completed.png
new file mode 100644
index 00000000..c26cfd42
Binary files /dev/null and b/docs/_static/contributing/stacks/github-secrets-completed.png differ","diff --git a/docs/_static/contributing/stacks/github-secrets-completed.png b/docs/_static/contributing/stacks/github-secrets-completed.png
new file mode 100644
index 00000000..c26cfd42
Binary files /dev/null and b/docs/_static/contributing/stacks/github-secrets-completed.png differ",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,042161a94f59b9a63cb48d2205f87639b319cc4d,e5879f20f1e6db5e9b8ea144a158498ec38f7d88,Put static files in correct folder,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index d93a6950..da3f7a8a 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -89,11 +89,11 @@ The cookiecutter template comes with a `.github/workflows/docker.yml` file, whic
 
 2. Commit your changes and push them to GitHub.
 3. Head back to your repository and click on the **Actions** tab.
-   ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/github-actions-tab.png)
+   ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
    From there, you can click on the workflows on the left-hand side of the screen.
 4. In the next screen, you will see information about the workflow run and duration.
    If you click the button with the workflow name again, you will see the logs for the workflow steps.
-   ![GitHub Actions page showing the ""Build Docker Images"" workflow](../_static/github-actions-workflow.png)
+   ![GitHub Actions page showing the ""Build Docker Images"" workflow](../_static/contributing/stacks/github-actions-workflow.png)
 
 ## Configuring Docker Hub
 
@@ -102,21 +102,21 @@ you merge a GitHub pull request to the main branch of your project.
 
 1. Visit [https://hub.docker.com/](https://hub.docker.com/) and log in.
 2. Select the account or organization matching the one you entered when prompted with `stack_org` by the cookiecutter.
-   ![DockerHub page zoomed into the user's settings and accounts menu.](../_static/docker-org-select.png)
+   ![DockerHub page zoomed into the user's settings and accounts menu.](../_static/contributing/stacks/docker-org-select.png)
 3. Scroll to the bottom of the page and click **Create repository**.
 4. Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
-   ![DockerHub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/docker-repo-name.png)
+   ![DockerHub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
 5. Enter a description for your image.
 6. Click **GitHub** under the **Build Settings** and follow the prompts to connect your account if it is not already connected.
 7. Select the GitHub organization and repository containing your image definition from the dropdowns.
-   ![Dockerhub - Create Repository page focusing on the ""Select Repository"" dropdown menu](../_static/docker-github-settings.png)
+   ![Dockerhub - Create Repository page focusing on the ""Select Repository"" dropdown menu](../_static/contributing/stacks/docker-github-settings.png)
 8. Click the **Create and Build** button.
 9. Click on your avatar in the top-right corner and select Account settings.
-   ![DockerHub page zoomed into the user's settings and accounts menu](../_static/docker-org-select.png)
+   ![DockerHub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-org-select.png)
 10. Click on **Security** and then click on the **New Access Token** button.
-    ![DockerHub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/docker-org-security.png)
+    ![DockerHub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/contributing/stacks/docker-org-security.png)
 11. Enter a meaningful name for your token and click on **Create**
-    ![DockerHub - New Access Token page with the name field set to ""my-jupyter-docker-token""](../_static/docker-org-create-token.png)
+    ![DockerHub - New Access Token page with the name field set to ""my-jupyter-docker-token""](../_static/contributing/stacks/docker-org-create-token.png)
 12. Copy the personal access token displayed on the next screen.
 
     ```{note}
@@ -124,13 +124,13 @@ you merge a GitHub pull request to the main branch of your project.
     ```
 
 13. Head back to your GitHub repository and click on the **Settings tab**.
-    ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/github-create-secrets.png)
+    ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/contributing/stacks/github-create-secrets.png)
 14. Click on the **Secrets** section and then on the **New repository secret** button in the top right corner (see image above).
 15. Create a **DOCKERHUB_TOKEN** secret and paste the Personal Access Token from DockerHub in the **value** field.
-    ![GitHub - Actions/New secret page with the Name field set to ""DOCKERHUB_TOKEN""](../_static/github-secret-token.png)
+    ![GitHub - Actions/New secret page with the Name field set to ""DOCKERHUB_TOKEN""](../_static/contributing/stacks/github-secret-token.png)
 16. Repeat the above step but creating a **DOCKERHUB_USERNAME** and replacing the _value_ field with your DockerHub username.
     Once you have completed these steps, your repository secrets section should look something like this:
-    ![GitHub - Repository secrets page showing the existing ""DOCKERHUB_TOKEN"" and ""DOCKERHUB_USERNAME"" secrets](../_static/github-secrets-completed.png)
+    ![GitHub - Repository secrets page showing the existing ""DOCKERHUB_TOKEN"" and ""DOCKERHUB_USERNAME"" secrets](../_static/contributing/stacks/github-secrets-completed.png)
 
 ## Defining Your Image","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index d93a6950..da3f7a8a 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -89,11 +89,11 @@ The cookiecutter template comes with a `.github/workflows/docker.yml` file, whic
 
 2. Commit your changes and push them to GitHub.
 3. Head back to your repository and click on the **Actions** tab.
-   ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/github-actions-tab.png)
+   ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
    From there, you can click on the workflows on the left-hand side of the screen.
 4. In the next screen, you will see information about the workflow run and duration.
    If you click the button with the workflow name again, you will see the logs for the workflow steps.
-   ![GitHub Actions page showing the ""Build Docker Images"" workflow](../_static/github-actions-workflow.png)
+   ![GitHub Actions page showing the ""Build Docker Images"" workflow](../_static/contributing/stacks/github-actions-workflow.png)
 
 ## Configuring Docker Hub
 
@@ -102,21 +102,21 @@ you merge a GitHub pull request to the main branch of your project.
 
 1. Visit [https://hub.docker.com/](https://hub.docker.com/) and log in.
 2. Select the account or organization matching the one you entered when prompted with `stack_org` by the cookiecutter.
-   ![DockerHub page zoomed into the user's settings and accounts menu.](../_static/docker-org-select.png)
+   ![DockerHub page zoomed into the user's settings and accounts menu.](../_static/contributing/stacks/docker-org-select.png)
 3. Scroll to the bottom of the page and click **Create repository**.
 4. Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
-   ![DockerHub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/docker-repo-name.png)
+   ![DockerHub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
 5. Enter a description for your image.
 6. Click **GitHub** under the **Build Settings** and follow the prompts to connect your account if it is not already connected.
 7. Select the GitHub organization and repository containing your image definition from the dropdowns.
-   ![Dockerhub - Create Repository page focusing on the ""Select Repository"" dropdown menu](../_static/docker-github-settings.png)
+   ![Dockerhub - Create Repository page focusing on the ""Select Repository"" dropdown menu](../_static/contributing/stacks/docker-github-settings.png)
 8. Click the **Create and Build** button.
 9. Click on your avatar in the top-right corner and select Account settings.
-   ![DockerHub page zoomed into the user's settings and accounts menu](../_static/docker-org-select.png)
+   ![DockerHub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-org-select.png)
 10. Click on **Security** and then click on the **New Access Token** button.
-    ![DockerHub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/docker-org-security.png)
+    ![DockerHub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/contributing/stacks/docker-org-security.png)
 11. Enter a meaningful name for your token and click on **Create**
-    ![DockerHub - New Access Token page with the name field set to ""my-jupyter-docker-token""](../_static/docker-org-create-token.png)
+    ![DockerHub - New Access Token page with the name field set to ""my-jupyter-docker-token""](../_static/contributing/stacks/docker-org-create-token.png)
 12. Copy the personal access token displayed on the next screen.
 
     ```{note}
@@ -124,13 +124,13 @@ you merge a GitHub pull request to the main branch of your project.
     ```
 
 13. Head back to your GitHub repository and click on the **Settings tab**.
-    ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/github-create-secrets.png)
+    ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/contributing/stacks/github-create-secrets.png)
 14. Click on the **Secrets** section and then on the **New repository secret** button in the top right corner (see image above).
 15. Create a **DOCKERHUB_TOKEN** secret and paste the Personal Access Token from DockerHub in the **value** field.
-    ![GitHub - Actions/New secret page with the Name field set to ""DOCKERHUB_TOKEN""](../_static/github-secret-token.png)
+    ![GitHub - Actions/New secret page with the Name field set to ""DOCKERHUB_TOKEN""](../_static/contributing/stacks/github-secret-token.png)
 16. Repeat the above step but creating a **DOCKERHUB_USERNAME** and replacing the _value_ field with your DockerHub username.
     Once you have completed these steps, your repository secrets section should look something like this:
-    ![GitHub - Repository secrets page showing the existing ""DOCKERHUB_TOKEN"" and ""DOCKERHUB_USERNAME"" secrets](../_static/github-secrets-completed.png)
+    ![GitHub - Repository secrets page showing the existing ""DOCKERHUB_TOKEN"" and ""DOCKERHUB_USERNAME"" secrets](../_static/contributing/stacks/github-secrets-completed.png)
 
 ## Defining Your Image",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,b345aa508dc17c0c2ba4bc652ba1cb2351968434,042161a94f59b9a63cb48d2205f87639b319cc4d,Fix text,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 2f3c0e93..2419d33f 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -306,7 +306,7 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
 
 2. **Turn off Jupyter auto-start in VSCode**
 
-   Alternatively - you might want to ensure that the `Jupyter: Auto Start` setting is turned off to avoid this issue in the future.
+   Alternatively - you might want to ensure that the `Jupyter: Disable Auto Start` setting is turned on to avoid this issue in the future.
 
    You can achieve this from the `Settings > Jupyter` menu in VScode:","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 2f3c0e93..2419d33f 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -306,7 +306,7 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
 
 2. **Turn off Jupyter auto-start in VSCode**
 
-   Alternatively - you might want to ensure that the `Jupyter: Auto Start` setting is turned off to avoid this issue in the future.
+   Alternatively - you might want to ensure that the `Jupyter: Disable Auto Start` setting is turned on to avoid this issue in the future.
 
    You can achieve this from the `Settings > Jupyter` menu in VScode:",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,a10fc2bdd0c9f58d39d4797c5e0e48af02aad107,b345aa508dc17c0c2ba4bc652ba1cb2351968434,Update maintaining recipes,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index ce37a24c..10ab1835 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -10,7 +10,8 @@ To build new images and publish them to the Docker Hub registry, do the followin
 
    ```{note}
    GitHub Actions are pretty reliable, so please investigate if some error occurs.
-   Building Docker images in PRs is the same after merging to the main branch, except there is an additional `push` step.
+   Building Docker images in PRs is the same as building them in default branch,
+   except single-platform images are pushed to Docker Hub and then tags are merged for `x86_64` and `aarch64`.
    ```
 
 4. Avoid merging another PR to the main branch until all pending builds are complete.
@@ -40,29 +41,25 @@ Pushing the `Run Workflow` button will trigger this process.
 In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
 ```
 
-When there's a new stack definition, do the following before merging the PR with the new stack:
+When there's a new stack definition, check before merging the PR:
 
-1. Ensure the PR includes an update to the stack overview diagram
+1. PR includes an update to the stack overview diagram
    [in the documentation](https://github.com/jupyter/docker-stacks/blob/main/docs/using/selecting.md#image-relationships).
    The image links to the [blockdiag source](http://interactive.blockdiag.com/) used to create it.
-2. Ensure the PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
-3. Ensure necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
-4. Create a new repository in the `jupyter` org on Docker Hub named after the stack folder in the
-   git repo.
-5. Grant the `stacks` team permission to write to the repo.
+2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
+3. Necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
+4. A new repository is created in the `jupyter` org on Docker Hub
+   and it's named after the stack folder in the git repo.
+5. Grant the `stacks` team permission to write to this repo.
 
 ## Adding a New Maintainer Account
 
-1. Visit <https://hub.docker.com/app/jupyter/team/stacks/users>
+1. Visit <https://hub.docker.com/orgs/jupyter/teams/stacks/members>
 2. Add the maintainer's Docker Hub username.
 3. Visit <https://github.com/orgs/jupyter/teams/docker-image-maintainers/members>
 4. Add the maintainer's GitHub username.
 
-## Pushing a Build Manually
+## Restarting a failed build
 
-If an automated build in GitHub Actions has got you down, do the following to push a build manually:
-
-1. Clone this repository.
-2. Check out the git SHA you want to build and publish.
-3. `docker login` with your Docker Hub credentials.
-4. Run `make push-all`.
+If an automated build in GitHub Actions has got you down, you can restart failed steps on GitHub.
+You can also download the artifacts and investigate them for any issues.","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index ce37a24c..10ab1835 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -10,7 +10,8 @@ To build new images and publish them to the Docker Hub registry, do the followin
 
    ```{note}
    GitHub Actions are pretty reliable, so please investigate if some error occurs.
-   Building Docker images in PRs is the same after merging to the main branch, except there is an additional `push` step.
+   Building Docker images in PRs is the same as building them in default branch,
+   except single-platform images are pushed to Docker Hub and then tags are merged for `x86_64` and `aarch64`.
    ```
 
 4. Avoid merging another PR to the main branch until all pending builds are complete.
@@ -40,29 +41,25 @@ Pushing the `Run Workflow` button will trigger this process.
 In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
 ```
 
-When there's a new stack definition, do the following before merging the PR with the new stack:
+When there's a new stack definition, check before merging the PR:
 
-1. Ensure the PR includes an update to the stack overview diagram
+1. PR includes an update to the stack overview diagram
    [in the documentation](https://github.com/jupyter/docker-stacks/blob/main/docs/using/selecting.md#image-relationships).
    The image links to the [blockdiag source](http://interactive.blockdiag.com/) used to create it.
-2. Ensure the PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
-3. Ensure necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
-4. Create a new repository in the `jupyter` org on Docker Hub named after the stack folder in the
-   git repo.
-5. Grant the `stacks` team permission to write to the repo.
+2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
+3. Necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
+4. A new repository is created in the `jupyter` org on Docker Hub
+   and it's named after the stack folder in the git repo.
+5. Grant the `stacks` team permission to write to this repo.
 
 ## Adding a New Maintainer Account
 
-1. Visit <https://hub.docker.com/app/jupyter/team/stacks/users>
+1. Visit <https://hub.docker.com/orgs/jupyter/teams/stacks/members>
 2. Add the maintainer's Docker Hub username.
 3. Visit <https://github.com/orgs/jupyter/teams/docker-image-maintainers/members>
 4. Add the maintainer's GitHub username.
 
-## Pushing a Build Manually
+## Restarting a failed build
 
-If an automated build in GitHub Actions has got you down, do the following to push a build manually:
-
-1. Clone this repository.
-2. Check out the git SHA you want to build and publish.
-3. `docker login` with your Docker Hub credentials.
-4. Run `make push-all`.
+If an automated build in GitHub Actions has got you down, you can restart failed steps on GitHub.
+You can also download the artifacts and investigate them for any issues.",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,51109c93aa6ffd5d3133b32646ad53dd6de3760f,a10fc2bdd0c9f58d39d4797c5e0e48af02aad107,Add newlines to Community Stacks to make images look better,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index da3f7a8a..d9acf978 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -89,10 +89,13 @@ The cookiecutter template comes with a `.github/workflows/docker.yml` file, whic
 
 2. Commit your changes and push them to GitHub.
 3. Head back to your repository and click on the **Actions** tab.
-   ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
    From there, you can click on the workflows on the left-hand side of the screen.
+
+   ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
+
 4. In the next screen, you will see information about the workflow run and duration.
    If you click the button with the workflow name again, you will see the logs for the workflow steps.
+
    ![GitHub Actions page showing the ""Build Docker Images"" workflow](../_static/contributing/stacks/github-actions-workflow.png)
 
 ## Configuring Docker Hub
@@ -102,21 +105,33 @@ you merge a GitHub pull request to the main branch of your project.
 
 1. Visit [https://hub.docker.com/](https://hub.docker.com/) and log in.
 2. Select the account or organization matching the one you entered when prompted with `stack_org` by the cookiecutter.
+
    ![DockerHub page zoomed into the user's settings and accounts menu.](../_static/contributing/stacks/docker-org-select.png)
+
 3. Scroll to the bottom of the page and click **Create repository**.
 4. Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
+
    ![DockerHub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
+
 5. Enter a description for your image.
 6. Click **GitHub** under the **Build Settings** and follow the prompts to connect your account if it is not already connected.
 7. Select the GitHub organization and repository containing your image definition from the dropdowns.
+
    ![Dockerhub - Create Repository page focusing on the ""Select Repository"" dropdown menu](../_static/contributing/stacks/docker-github-settings.png)
+
 8. Click the **Create and Build** button.
 9. Click on your avatar in the top-right corner and select Account settings.
+
    ![DockerHub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-org-select.png)
+
 10. Click on **Security** and then click on the **New Access Token** button.
+
     ![DockerHub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/contributing/stacks/docker-org-security.png)
+
 11. Enter a meaningful name for your token and click on **Create**
+
     ![DockerHub - New Access Token page with the name field set to ""my-jupyter-docker-token""](../_static/contributing/stacks/docker-org-create-token.png)
+
 12. Copy the personal access token displayed on the next screen.
 
     ```{note}
@@ -124,12 +139,17 @@ you merge a GitHub pull request to the main branch of your project.
     ```
 
 13. Head back to your GitHub repository and click on the **Settings tab**.
+
     ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/contributing/stacks/github-create-secrets.png)
+
 14. Click on the **Secrets** section and then on the **New repository secret** button in the top right corner (see image above).
 15. Create a **DOCKERHUB_TOKEN** secret and paste the Personal Access Token from DockerHub in the **value** field.
+
     ![GitHub - Actions/New secret page with the Name field set to ""DOCKERHUB_TOKEN""](../_static/contributing/stacks/github-secret-token.png)
+
 16. Repeat the above step but creating a **DOCKERHUB_USERNAME** and replacing the _value_ field with your DockerHub username.
     Once you have completed these steps, your repository secrets section should look something like this:
+
     ![GitHub - Repository secrets page showing the existing ""DOCKERHUB_TOKEN"" and ""DOCKERHUB_USERNAME"" secrets](../_static/contributing/stacks/github-secrets-completed.png)
 
 ## Defining Your Image","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index da3f7a8a..d9acf978 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -89,10 +89,13 @@ The cookiecutter template comes with a `.github/workflows/docker.yml` file, whic
 
 2. Commit your changes and push them to GitHub.
 3. Head back to your repository and click on the **Actions** tab.
-   ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
    From there, you can click on the workflows on the left-hand side of the screen.
+
+   ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
+
 4. In the next screen, you will see information about the workflow run and duration.
    If you click the button with the workflow name again, you will see the logs for the workflow steps.
+
    ![GitHub Actions page showing the ""Build Docker Images"" workflow](../_static/contributing/stacks/github-actions-workflow.png)
 
 ## Configuring Docker Hub
@@ -102,21 +105,33 @@ you merge a GitHub pull request to the main branch of your project.
 
 1. Visit [https://hub.docker.com/](https://hub.docker.com/) and log in.
 2. Select the account or organization matching the one you entered when prompted with `stack_org` by the cookiecutter.
+
    ![DockerHub page zoomed into the user's settings and accounts menu.](../_static/contributing/stacks/docker-org-select.png)
+
 3. Scroll to the bottom of the page and click **Create repository**.
 4. Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
+
    ![DockerHub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
+
 5. Enter a description for your image.
 6. Click **GitHub** under the **Build Settings** and follow the prompts to connect your account if it is not already connected.
 7. Select the GitHub organization and repository containing your image definition from the dropdowns.
+
    ![Dockerhub - Create Repository page focusing on the ""Select Repository"" dropdown menu](../_static/contributing/stacks/docker-github-settings.png)
+
 8. Click the **Create and Build** button.
 9. Click on your avatar in the top-right corner and select Account settings.
+
    ![DockerHub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-org-select.png)
+
 10. Click on **Security** and then click on the **New Access Token** button.
+
     ![DockerHub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/contributing/stacks/docker-org-security.png)
+
 11. Enter a meaningful name for your token and click on **Create**
+
     ![DockerHub - New Access Token page with the name field set to ""my-jupyter-docker-token""](../_static/contributing/stacks/docker-org-create-token.png)
+
 12. Copy the personal access token displayed on the next screen.
 
     ```{note}
@@ -124,12 +139,17 @@ you merge a GitHub pull request to the main branch of your project.
     ```
 
 13. Head back to your GitHub repository and click on the **Settings tab**.
+
     ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/contributing/stacks/github-create-secrets.png)
+
 14. Click on the **Secrets** section and then on the **New repository secret** button in the top right corner (see image above).
 15. Create a **DOCKERHUB_TOKEN** secret and paste the Personal Access Token from DockerHub in the **value** field.
+
     ![GitHub - Actions/New secret page with the Name field set to ""DOCKERHUB_TOKEN""](../_static/contributing/stacks/github-secret-token.png)
+
 16. Repeat the above step but creating a **DOCKERHUB_USERNAME** and replacing the _value_ field with your DockerHub username.
     Once you have completed these steps, your repository secrets section should look something like this:
+
     ![GitHub - Repository secrets page showing the existing ""DOCKERHUB_TOKEN"" and ""DOCKERHUB_USERNAME"" secrets](../_static/contributing/stacks/github-secrets-completed.png)
 
 ## Defining Your Image",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,127004aec4eb4c5675576544dd85589a5c042772,51109c93aa6ffd5d3133b32646ad53dd6de3760f,Add an example of adding a new image,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 10ab1835..b95dd513 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -41,6 +41,8 @@ Pushing the `Run Workflow` button will trigger this process.
 In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
 ```
 
+You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1926/files).
+
 When there's a new stack definition, check before merging the PR:
 
 1. PR includes an update to the stack overview diagram","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 10ab1835..b95dd513 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -41,6 +41,8 @@ Pushing the `Run Workflow` button will trigger this process.
 In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
 ```
 
+You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1926/files).
+
 When there's a new stack definition, check before merging the PR:
 
 1. PR includes an update to the stack overview diagram",Yes
docs/using/selecting.md,docs/using/selecting.md,39582f7099f439832235d81af4282f6fea8fe87a,127004aec4eb4c5675576544dd85589a5c042772,"Install Pluto.jl and jupyter-pluto-proxy (#1929)

* Install Pluto.jl and jupyter-pluto-proxy

[Pluto.jl](https://plutojl.org/) is an alternative reactive notebook
frontend focused specifically on Julia. I think shipping this
by default in the julia-enabled images helps serve the Julia
community better, particularly when used with JupyterHub.

For context, I am working with the Julia users of the
[Jupyter Meets the Earth](https://jupytearth.org/) project, and
trying to understand how to best serve their needs on a JupyterHub.
We currently maintain a massive image that 'has everything', but
I'm trying to instead work upstream wherever possible so everyone
working in these subfields can benefit. Meeting Julia users where
they are at seems a useful path forward here.

* Add note about Pluto.jl to selecting.md

* Default to replacing - with _ in package imports

* Add jupyter-pluto-proxy to package import mapping

* Add Pluto.jl to datascience-notebook image

* Add test for pluto proxy starting correctly

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update test_packages.py

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index f93aad70..7083dcbb 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -118,6 +118,8 @@ It contains:
 - Everything in `jupyter/minimal-notebook` and its ancestor images
 - The [Julia Programming Language](https://julialang.org/)
 - [IJulia](https://github.com/JuliaLang/IJulia.jl) to support Julia code in Jupyter notebook
+- [Pluto.jl](https://plutojl.org/) reactive Julia notebook interface, made accessible with [jupyter-pluto-proxy](https://github.com/yuvipanda/jupyter-pluto-proxy)
+- [HDF5](https://github.com/JuliaIO/HDF5.jl) package
 
 ### jupyter/scipy-notebook
 
@@ -188,6 +190,7 @@ communities.
 - [rpy2](https://rpy2.github.io/doc/latest/html/index.html) package
 - The [Julia](https://julialang.org/) compiler and base environment
 - [IJulia](https://github.com/JuliaLang/IJulia.jl) to support Julia code in Jupyter notebooks
+- [Pluto.jl](https://plutojl.org/) reactive Julia notebook interface, made accessible with [jupyter-pluto-proxy](https://github.com/yuvipanda/jupyter-pluto-proxy)
 - [HDF5](https://github.com/JuliaIO/HDF5.jl) package
 
 ### jupyter/pyspark-notebook","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index f93aad70..7083dcbb 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -118,6 +118,8 @@ It contains:
 - Everything in `jupyter/minimal-notebook` and its ancestor images
 - The [Julia Programming Language](https://julialang.org/)
 - [IJulia](https://github.com/JuliaLang/IJulia.jl) to support Julia code in Jupyter notebook
+- [Pluto.jl](https://plutojl.org/) reactive Julia notebook interface, made accessible with [jupyter-pluto-proxy](https://github.com/yuvipanda/jupyter-pluto-proxy)
+- [HDF5](https://github.com/JuliaIO/HDF5.jl) package
 
 ### jupyter/scipy-notebook
 
@@ -188,6 +190,7 @@ communities.
 - [rpy2](https://rpy2.github.io/doc/latest/html/index.html) package
 - The [Julia](https://julialang.org/) compiler and base environment
 - [IJulia](https://github.com/JuliaLang/IJulia.jl) to support Julia code in Jupyter notebooks
+- [Pluto.jl](https://plutojl.org/) reactive Julia notebook interface, made accessible with [jupyter-pluto-proxy](https://github.com/yuvipanda/jupyter-pluto-proxy)
 - [HDF5](https://github.com/JuliaIO/HDF5.jl) package
 
 ### jupyter/pyspark-notebook",Yes
minimal-notebook/setup-scripts/setup-julia-packages.bash,minimal-notebook/setup-scripts/setup-julia-packages.bash,39582f7099f439832235d81af4282f6fea8fe87a,127004aec4eb4c5675576544dd85589a5c042772,"Install Pluto.jl and jupyter-pluto-proxy (#1929)

* Install Pluto.jl and jupyter-pluto-proxy

[Pluto.jl](https://plutojl.org/) is an alternative reactive notebook
frontend focused specifically on Julia. I think shipping this
by default in the julia-enabled images helps serve the Julia
community better, particularly when used with JupyterHub.

For context, I am working with the Julia users of the
[Jupyter Meets the Earth](https://jupytearth.org/) project, and
trying to understand how to best serve their needs on a JupyterHub.
We currently maintain a massive image that 'has everything', but
I'm trying to instead work upstream wherever possible so everyone
working in these subfields can benefit. Meeting Julia users where
they are at seems a useful path forward here.

* Add note about Pluto.jl to selecting.md

* Default to replacing - with _ in package imports

* Add jupyter-pluto-proxy to package import mapping

* Add Pluto.jl to datascience-notebook image

* Add test for pluto proxy starting correctly

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update test_packages.py

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/minimal-notebook/setup-scripts/setup-julia-packages.bash b/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 0be05426..faeee01e 100755
--- a/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -11,7 +11,8 @@ import Pkg;
 Pkg.update();
 Pkg.add([
     ""HDF5"",
-    ""IJulia""
+    ""IJulia"",
+    ""Pluto""
 ]);
 Pkg.precompile();
 '
@@ -23,3 +24,10 @@ mv ""${HOME}/.local/share/jupyter/kernels/julia""* ""${CONDA_DIR}/share/jupyter/ker
 chmod -R go+rx ""${CONDA_DIR}/share/jupyter""
 rm -rf ""${HOME}/.local""
 fix-permissions ""${JULIA_PKGDIR}"" ""${CONDA_DIR}/share/jupyter""
+
+# Install jupyter-pluto-proxy to get Pluto to work on JupyterHub
+mamba install --yes \
+    'jupyter-pluto-proxy' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/minimal-notebook/setup-scripts/setup-julia-packages.bash b/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 0be05426..faeee01e 100755
--- a/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -11,7 +11,8 @@ import Pkg;
 Pkg.update();
 Pkg.add([
     ""HDF5"",
-    ""IJulia""
+    ""IJulia"",
+    ""Pluto""
 ]);
 Pkg.precompile();
 '
@@ -23,3 +24,10 @@ mv ""${HOME}/.local/share/jupyter/kernels/julia""* ""${CONDA_DIR}/share/jupyter/ker
 chmod -R go+rx ""${CONDA_DIR}/share/jupyter""
 rm -rf ""${HOME}/.local""
 fix-permissions ""${JULIA_PKGDIR}"" ""${CONDA_DIR}/share/jupyter""
+
+# Install jupyter-pluto-proxy to get Pluto to work on JupyterHub
+mamba install --yes \
+    'jupyter-pluto-proxy' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
tests/base-notebook/test_packages.py,tests/base-notebook/test_packages.py,39582f7099f439832235d81af4282f6fea8fe87a,127004aec4eb4c5675576544dd85589a5c042772,"Install Pluto.jl and jupyter-pluto-proxy (#1929)

* Install Pluto.jl and jupyter-pluto-proxy

[Pluto.jl](https://plutojl.org/) is an alternative reactive notebook
frontend focused specifically on Julia. I think shipping this
by default in the julia-enabled images helps serve the Julia
community better, particularly when used with JupyterHub.

For context, I am working with the Julia users of the
[Jupyter Meets the Earth](https://jupytearth.org/) project, and
trying to understand how to best serve their needs on a JupyterHub.
We currently maintain a massive image that 'has everything', but
I'm trying to instead work upstream wherever possible so everyone
working in these subfields can benefit. Meeting Julia users where
they are at seems a useful path forward here.

* Add note about Pluto.jl to selecting.md

* Default to replacing - with _ in package imports

* Add jupyter-pluto-proxy to package import mapping

* Add Pluto.jl to datascience-notebook image

* Add test for pluto proxy starting correctly

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update test_packages.py

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index f6f9c085..b56d6120 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -52,6 +52,7 @@ LOGGER = logging.getLogger(__name__)
 PACKAGE_MAPPING = {
     # Python
     ""beautifulsoup4"": ""bs4"",
+    ""jupyter-pluto-proxy"": ""jupyter_pluto_proxy"",
     ""matplotlib-base"": ""matplotlib"",
     ""pytables"": ""tables"",
     ""scikit-image"": ""skimage"",","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index f6f9c085..b56d6120 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -52,6 +52,7 @@ LOGGER = logging.getLogger(__name__)
 PACKAGE_MAPPING = {
     # Python
     ""beautifulsoup4"": ""bs4"",
+    ""jupyter-pluto-proxy"": ""jupyter_pluto_proxy"",
     ""matplotlib-base"": ""matplotlib"",
     ""pytables"": ""tables"",
     ""scikit-image"": ""skimage"",",Yes
,tests/datascience-notebook/test_julia_starts.py,39582f7099f439832235d81af4282f6fea8fe87a,127004aec4eb4c5675576544dd85589a5c042772,"Install Pluto.jl and jupyter-pluto-proxy (#1929)

* Install Pluto.jl and jupyter-pluto-proxy

[Pluto.jl](https://plutojl.org/) is an alternative reactive notebook
frontend focused specifically on Julia. I think shipping this
by default in the julia-enabled images helps serve the Julia
community better, particularly when used with JupyterHub.

For context, I am working with the Julia users of the
[Jupyter Meets the Earth](https://jupytearth.org/) project, and
trying to understand how to best serve their needs on a JupyterHub.
We currently maintain a massive image that 'has everything', but
I'm trying to instead work upstream wherever possible so everyone
working in these subfields can benefit. Meeting Julia users where
they are at seems a useful path forward here.

* Add note about Pluto.jl to selecting.md

* Default to replacing - with _ in package imports

* Add jupyter-pluto-proxy to package import mapping

* Add Pluto.jl to datascience-notebook image

* Add test for pluto proxy starting correctly

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update test_packages.py

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/datascience-notebook/test_julia_starts.py b/tests/datascience-notebook/test_julia_starts.py
new file mode 100644
index 00000000..a0d59b39
--- /dev/null
+++ b/tests/datascience-notebook/test_julia_starts.py
@@ -0,0 +1,32 @@
+import logging
+import secrets
+import time
+
+import requests
+
+from tests.conftest import TrackedContainer, find_free_port
+
+LOGGER = logging.getLogger(__name__)
+
+
+def test_pluto_proxy(
+    container: TrackedContainer, http_client: requests.Session
+) -> None:
+    """"""Pluto proxy starts Pluto correctly""""""
+    host_port = find_free_port()
+    token = secrets.token_hex()
+    container.run_detached(
+        command=[
+            ""start.sh"",
+            ""jupyter"",
+            ""lab"",
+            ""--port=8888"",
+            f""--LabApp.token={token}"",
+        ],
+        ports={""8888/tcp"": host_port},
+    )
+    # Give the server a bit of time to start
+    time.sleep(3)
+    resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
+    resp.raise_for_status()
+    assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""","diff --git a/tests/datascience-notebook/test_julia_starts.py b/tests/datascience-notebook/test_julia_starts.py
new file mode 100644
index 00000000..a0d59b39
--- /dev/null
+++ b/tests/datascience-notebook/test_julia_starts.py
@@ -0,0 +1,32 @@
+import logging
+import secrets
+import time
+
+import requests
+
+from tests.conftest import TrackedContainer, find_free_port
+
+LOGGER = logging.getLogger(__name__)
+
+
+def test_pluto_proxy(
+    container: TrackedContainer, http_client: requests.Session
+) -> None:
+    """"""Pluto proxy starts Pluto correctly""""""
+    host_port = find_free_port()
+    token = secrets.token_hex()
+    container.run_detached(
+        command=[
+            ""start.sh"",
+            ""jupyter"",
+            ""lab"",
+            ""--port=8888"",
+            f""--LabApp.token={token}"",
+        ],
+        ports={""8888/tcp"": host_port},
+    )
+    # Give the server a bit of time to start
+    time.sleep(3)
+    resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
+    resp.raise_for_status()
+    assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""",Yes
,tests/julia-notebook/test_pluto.py,39582f7099f439832235d81af4282f6fea8fe87a,127004aec4eb4c5675576544dd85589a5c042772,"Install Pluto.jl and jupyter-pluto-proxy (#1929)

* Install Pluto.jl and jupyter-pluto-proxy

[Pluto.jl](https://plutojl.org/) is an alternative reactive notebook
frontend focused specifically on Julia. I think shipping this
by default in the julia-enabled images helps serve the Julia
community better, particularly when used with JupyterHub.

For context, I am working with the Julia users of the
[Jupyter Meets the Earth](https://jupytearth.org/) project, and
trying to understand how to best serve their needs on a JupyterHub.
We currently maintain a massive image that 'has everything', but
I'm trying to instead work upstream wherever possible so everyone
working in these subfields can benefit. Meeting Julia users where
they are at seems a useful path forward here.

* Add note about Pluto.jl to selecting.md

* Default to replacing - with _ in package imports

* Add jupyter-pluto-proxy to package import mapping

* Add Pluto.jl to datascience-notebook image

* Add test for pluto proxy starting correctly

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update test_packages.py

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/julia-notebook/test_pluto.py b/tests/julia-notebook/test_pluto.py
new file mode 100644
index 00000000..a0d59b39
--- /dev/null
+++ b/tests/julia-notebook/test_pluto.py
@@ -0,0 +1,32 @@
+import logging
+import secrets
+import time
+
+import requests
+
+from tests.conftest import TrackedContainer, find_free_port
+
+LOGGER = logging.getLogger(__name__)
+
+
+def test_pluto_proxy(
+    container: TrackedContainer, http_client: requests.Session
+) -> None:
+    """"""Pluto proxy starts Pluto correctly""""""
+    host_port = find_free_port()
+    token = secrets.token_hex()
+    container.run_detached(
+        command=[
+            ""start.sh"",
+            ""jupyter"",
+            ""lab"",
+            ""--port=8888"",
+            f""--LabApp.token={token}"",
+        ],
+        ports={""8888/tcp"": host_port},
+    )
+    # Give the server a bit of time to start
+    time.sleep(3)
+    resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
+    resp.raise_for_status()
+    assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""","diff --git a/tests/julia-notebook/test_pluto.py b/tests/julia-notebook/test_pluto.py
new file mode 100644
index 00000000..a0d59b39
--- /dev/null
+++ b/tests/julia-notebook/test_pluto.py
@@ -0,0 +1,32 @@
+import logging
+import secrets
+import time
+
+import requests
+
+from tests.conftest import TrackedContainer, find_free_port
+
+LOGGER = logging.getLogger(__name__)
+
+
+def test_pluto_proxy(
+    container: TrackedContainer, http_client: requests.Session
+) -> None:
+    """"""Pluto proxy starts Pluto correctly""""""
+    host_port = find_free_port()
+    token = secrets.token_hex()
+    container.run_detached(
+        command=[
+            ""start.sh"",
+            ""jupyter"",
+            ""lab"",
+            ""--port=8888"",
+            f""--LabApp.token={token}"",
+        ],
+        ports={""8888/tcp"": host_port},
+    )
+    # Give the server a bit of time to start
+    time.sleep(3)
+    resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
+    resp.raise_for_status()
+    assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""",Yes
,tests/datascience-notebook/test_pluto_datascience.py,2edc0fe21403ea9ba87038bf79a51799533daaa7,39582f7099f439832235d81af4282f6fea8fe87a,Put pluto test in one common file (#1934),"diff --git a/tests/datascience-notebook/test_pluto_datascience.py b/tests/datascience-notebook/test_pluto_datascience.py
new file mode 100644
index 00000000..27c4aaf0
--- /dev/null
+++ b/tests/datascience-notebook/test_pluto_datascience.py
@@ -0,0 +1,13 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import requests
+
+from tests.conftest import TrackedContainer
+from tests.pluto_check import check_pluto_proxy
+
+
+def test_pluto_proxy(
+    container: TrackedContainer, http_client: requests.Session
+) -> None:
+    """"""Pluto proxy starts Pluto correctly""""""
+    check_pluto_proxy(container, http_client)","diff --git a/tests/datascience-notebook/test_pluto_datascience.py b/tests/datascience-notebook/test_pluto_datascience.py
new file mode 100644
index 00000000..27c4aaf0
--- /dev/null
+++ b/tests/datascience-notebook/test_pluto_datascience.py
@@ -0,0 +1,13 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import requests
+
+from tests.conftest import TrackedContainer
+from tests.pluto_check import check_pluto_proxy
+
+
+def test_pluto_proxy(
+    container: TrackedContainer, http_client: requests.Session
+) -> None:
+    """"""Pluto proxy starts Pluto correctly""""""
+    check_pluto_proxy(container, http_client)",Yes
tests/julia-notebook/test_pluto.py,tests/julia-notebook/test_pluto.py,2edc0fe21403ea9ba87038bf79a51799533daaa7,39582f7099f439832235d81af4282f6fea8fe87a,Put pluto test in one common file (#1934),"diff --git a/tests/julia-notebook/test_pluto.py b/tests/julia-notebook/test_pluto.py
index a0d59b39..27c4aaf0 100644
--- a/tests/julia-notebook/test_pluto.py
+++ b/tests/julia-notebook/test_pluto.py
@@ -1,32 +1,13 @@
-import logging
-import secrets
-import time
-
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
 import requests
 
-from tests.conftest import TrackedContainer, find_free_port
-
-LOGGER = logging.getLogger(__name__)
+from tests.conftest import TrackedContainer
+from tests.pluto_check import check_pluto_proxy
 
 
 def test_pluto_proxy(
     container: TrackedContainer, http_client: requests.Session
 ) -> None:
     """"""Pluto proxy starts Pluto correctly""""""
-    host_port = find_free_port()
-    token = secrets.token_hex()
-    container.run_detached(
-        command=[
-            ""start.sh"",
-            ""jupyter"",
-            ""lab"",
-            ""--port=8888"",
-            f""--LabApp.token={token}"",
-        ],
-        ports={""8888/tcp"": host_port},
-    )
-    # Give the server a bit of time to start
-    time.sleep(3)
-    resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
-    resp.raise_for_status()
-    assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""
+    check_pluto_proxy(container, http_client)","diff --git a/tests/julia-notebook/test_pluto.py b/tests/julia-notebook/test_pluto.py
index a0d59b39..27c4aaf0 100644
--- a/tests/julia-notebook/test_pluto.py
+++ b/tests/julia-notebook/test_pluto.py
@@ -1,32 +1,13 @@
-import logging
-import secrets
-import time
-
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
 import requests
 
-from tests.conftest import TrackedContainer, find_free_port
-
-LOGGER = logging.getLogger(__name__)
+from tests.conftest import TrackedContainer
+from tests.pluto_check import check_pluto_proxy
 
 
 def test_pluto_proxy(
     container: TrackedContainer, http_client: requests.Session
 ) -> None:
     """"""Pluto proxy starts Pluto correctly""""""
-    host_port = find_free_port()
-    token = secrets.token_hex()
-    container.run_detached(
-        command=[
-            ""start.sh"",
-            ""jupyter"",
-            ""lab"",
-            ""--port=8888"",
-            f""--LabApp.token={token}"",
-        ],
-        ports={""8888/tcp"": host_port},
-    )
-    # Give the server a bit of time to start
-    time.sleep(3)
-    resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
-    resp.raise_for_status()
-    assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""
+    check_pluto_proxy(container, http_client)",Yes
tests/datascience-notebook/test_julia_starts.py,tests/pluto_check.py,2edc0fe21403ea9ba87038bf79a51799533daaa7,39582f7099f439832235d81af4282f6fea8fe87a,Put pluto test in one common file (#1934),"diff --git a/tests/pluto_check.py b/tests/pluto_check.py
new file mode 100644
index 00000000..8a39509c
--- /dev/null
+++ b/tests/pluto_check.py
@@ -0,0 +1,33 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import logging
+import secrets
+import time
+
+import requests
+
+from tests.conftest import TrackedContainer, find_free_port
+
+LOGGER = logging.getLogger(__name__)
+
+
+def check_pluto_proxy(
+    container: TrackedContainer, http_client: requests.Session
+) -> None:
+    host_port = find_free_port()
+    token = secrets.token_hex()
+    container.run_detached(
+        command=[
+            ""start.sh"",
+            ""jupyter"",
+            ""lab"",
+            ""--port=8888"",
+            f""--LabApp.token={token}"",
+        ],
+        ports={""8888/tcp"": host_port},
+    )
+    # Give the server a bit of time to start
+    time.sleep(3)
+    resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
+    resp.raise_for_status()
+    assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""","diff --git a/tests/pluto_check.py b/tests/pluto_check.py
new file mode 100644
index 00000000..8a39509c
--- /dev/null
+++ b/tests/pluto_check.py
@@ -0,0 +1,33 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import logging
+import secrets
+import time
+
+import requests
+
+from tests.conftest import TrackedContainer, find_free_port
+
+LOGGER = logging.getLogger(__name__)
+
+
+def check_pluto_proxy(
+    container: TrackedContainer, http_client: requests.Session
+) -> None:
+    host_port = find_free_port()
+    token = secrets.token_hex()
+    container.run_detached(
+        command=[
+            ""start.sh"",
+            ""jupyter"",
+            ""lab"",
+            ""--port=8888"",
+            f""--LabApp.token={token}"",
+        ],
+        ports={""8888/tcp"": host_port},
+    )
+    # Give the server a bit of time to start
+    time.sleep(3)
+    resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
+    resp.raise_for_status()
+    assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,819aa102303d65c749d63c2f55aab179f755772b,2edc0fe21403ea9ba87038bf79a51799533daaa7,Add tensorflow-notebook artifacts download,"diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 83aa93a1..c96fcd70 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -78,6 +78,11 @@ runs:
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      with:
+        name: tensorflow-notebook-aarch64-history_line
+        path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
@@ -164,6 +169,11 @@ runs:
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      with:
+        name: tensorflow-notebook-aarch64-manifest
+        path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 83aa93a1..c96fcd70 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -78,6 +78,11 @@ runs:
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      with:
+        name: tensorflow-notebook-aarch64-history_line
+        path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
@@ -164,6 +169,11 @@ runs:
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      with:
+        name: tensorflow-notebook-aarch64-manifest
+        path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:",Yes
Makefile,Makefile,4f92f2c6515b259ca8c11f2b10289409a3bde2de,819aa102303d65c749d63c2f55aab179f755772b,Fix image tagging in hook/% (#1938),"diff --git a/Makefile b/Makefile
index c1a33edb..8c7334a6 100644
--- a/Makefile
+++ b/Makefile
@@ -68,7 +68,8 @@ linkcheck-docs: ## check broken links
 
 
 hook/%: ## run post-build hooks for an image
-	python3 -m tagging.tag_image --short-image-name ""$(notdir $@)"" --owner ""$(OWNER)"" && \
+	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --owner ""$(OWNER)"" && \
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --owner ""$(OWNER)"" && \
 	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images","diff --git a/Makefile b/Makefile
index c1a33edb..8c7334a6 100644
--- a/Makefile
+++ b/Makefile
@@ -68,7 +68,8 @@ linkcheck-docs: ## check broken links
 
 
 hook/%: ## run post-build hooks for an image
-	python3 -m tagging.tag_image --short-image-name ""$(notdir $@)"" --owner ""$(OWNER)"" && \
+	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --owner ""$(OWNER)"" && \
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --owner ""$(OWNER)"" && \
 	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images",Yes
Makefile,Makefile,3d1dfb045378df107c60051fd4b4e96f80ac5d8c,4f92f2c6515b259ca8c11f2b10289409a3bde2de,Fix applying tags in local development (#1939),"diff --git a/Makefile b/Makefile
index 8c7334a6..8a8ce75b 100644
--- a/Makefile
+++ b/Makefile
@@ -69,8 +69,8 @@ linkcheck-docs: ## check broken links
 
 hook/%: ## run post-build hooks for an image
 	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --owner ""$(OWNER)"" && \
-	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)""
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)"" && \
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images","diff --git a/Makefile b/Makefile
index 8c7334a6..8a8ce75b 100644
--- a/Makefile
+++ b/Makefile
@@ -69,8 +69,8 @@ linkcheck-docs: ## check broken links
 
 hook/%: ## run post-build hooks for an image
 	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --owner ""$(OWNER)"" && \
-	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)""
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)"" && \
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images",Yes
tagging/apply_tags.py,tagging/apply_tags.py,3d1dfb045378df107c60051fd4b4e96f80ac5d8c,4f92f2c6515b259ca8c11f2b10289409a3bde2de,Fix applying tags in local development (#1939),"diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 04148216..64c391bd 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -7,6 +7,8 @@ from pathlib import Path
 
 import plumbum
 
+from tagging.get_platform import unify_aarch64
+
 docker = plumbum.local[""docker""]
 
 LOGGER = logging.getLogger(__name__)
@@ -55,7 +57,7 @@ if __name__ == ""__main__"":
         ""--platform"",
         required=True,
         type=str,
-        choices=[""x86_64"", ""aarch64""],
+        choices=[""x86_64"", ""aarch64"", ""arm64""],
         help=""Image platform"",
     )
     arg_parser.add_argument(
@@ -64,5 +66,6 @@ if __name__ == ""__main__"":
         help=""Owner of the image"",
     )
     args = arg_parser.parse_args()
+    args.platform = unify_aarch64(args.platform)
 
     apply_tags(args.short_image_name, args.owner, args.tags_dir, args.platform)","diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 04148216..64c391bd 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -7,6 +7,8 @@ from pathlib import Path
 
 import plumbum
 
+from tagging.get_platform import unify_aarch64
+
 docker = plumbum.local[""docker""]
 
 LOGGER = logging.getLogger(__name__)
@@ -55,7 +57,7 @@ if __name__ == ""__main__"":
         ""--platform"",
         required=True,
         type=str,
-        choices=[""x86_64"", ""aarch64""],
+        choices=[""x86_64"", ""aarch64"", ""arm64""],
         help=""Image platform"",
     )
     arg_parser.add_argument(
@@ -64,5 +66,6 @@ if __name__ == ""__main__"":
         help=""Owner of the image"",
     )
     args = arg_parser.parse_args()
+    args.platform = unify_aarch64(args.platform)
 
     apply_tags(args.short_image_name, args.owner, args.tags_dir, args.platform)",Yes
tagging/get_platform.py,tagging/get_platform.py,3d1dfb045378df107c60051fd4b4e96f80ac5d8c,4f92f2c6515b259ca8c11f2b10289409a3bde2de,Fix applying tags in local development (#1939),"diff --git a/tagging/get_platform.py b/tagging/get_platform.py
index 139e3697..187a2592 100644
--- a/tagging/get_platform.py
+++ b/tagging/get_platform.py
@@ -5,10 +5,14 @@ import platform
 ALL_PLATFORMS = {""x86_64"", ""aarch64""}
 
 
-def get_platform() -> str:
-    machine = platform.machine()
+def unify_aarch64(platform: str) -> str:
     return {
         ""aarch64"": ""aarch64"",
         ""arm64"": ""aarch64"",  # To support local building on aarch64 Macs
         ""x86_64"": ""x86_64"",
-    }[machine]
+    }[platform]
+
+
+def get_platform() -> str:
+    machine = platform.machine()
+    return unify_aarch64(machine)","diff --git a/tagging/get_platform.py b/tagging/get_platform.py
index 139e3697..187a2592 100644
--- a/tagging/get_platform.py
+++ b/tagging/get_platform.py
@@ -5,10 +5,14 @@ import platform
 ALL_PLATFORMS = {""x86_64"", ""aarch64""}
 
 
-def get_platform() -> str:
-    machine = platform.machine()
+def unify_aarch64(platform: str) -> str:
     return {
         ""aarch64"": ""aarch64"",
         ""arm64"": ""aarch64"",  # To support local building on aarch64 Macs
         ""x86_64"": ""x86_64"",
-    }[machine]
+    }[platform]
+
+
+def get_platform() -> str:
+    machine = platform.machine()
+    return unify_aarch64(machine)",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,f0d0871bd32e69c08780fdc35ee3b35f7f71239c,3d1dfb045378df107c60051fd4b4e96f80ac5d8c,Update prettier,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index cc1e4bfe..579af73e 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -52,7 +52,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.0.0-alpha.9-for-vscode
+    rev: v3.0.0
     hooks:
       - id: prettier","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index cc1e4bfe..579af73e 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -52,7 +52,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.0.0-alpha.9-for-vscode
+    rev: v3.0.0
     hooks:
       - id: prettier",Yes
.readthedocs.yaml,.readthedocs.yaml,8c74f0ba67dca235d8b9d44f233481d54dab5ab5,f0d0871bd32e69c08780fdc35ee3b35f7f71239c,Update rtd config,"diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index df3d6c32..3a772387 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -1,12 +1,10 @@
----
-# .readthedocs.yaml
-# Read the Docs configuration file
+# Read the Docs configuration file for Sphinx projects
 # See https://docs.readthedocs.io/en/stable/config-file/v2.html for details
 
 # Required
 version: 2
 
-# Set the version of Python and other tools you might need
+# Set the OS, Python version and other tools you might need
 build:
   os: ubuntu-22.04
   tools:
@@ -16,15 +14,17 @@ build:
     # rust: ""1.64""
     # golang: ""1.19""
 
-# Build documentation in the docs/ directory with Sphinx
+# Build documentation in the ""docs/"" directory with Sphinx
 sphinx:
   configuration: docs/conf.py
-
-# If using Sphinx, optionally build your docs in additional formats such as PDF
+# Optionally build your docs in additional formats such as PDF and ePub
 # formats:
 #    - pdf
+#    - epub
 
-# Optionally declare the Python requirements required to build your docs
+# Optional but recommended, declare the Python requirements required
+# to build your documentation
+# See https://docs.readthedocs.io/en/stable/guides/reproducible-builds.html
 python:
   install:
     - requirements: docs/requirements.txt","diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index df3d6c32..3a772387 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -1,12 +1,10 @@
----
-# .readthedocs.yaml
-# Read the Docs configuration file
+# Read the Docs configuration file for Sphinx projects
 # See https://docs.readthedocs.io/en/stable/config-file/v2.html for details
 
 # Required
 version: 2
 
-# Set the version of Python and other tools you might need
+# Set the OS, Python version and other tools you might need
 build:
   os: ubuntu-22.04
   tools:
@@ -16,15 +14,17 @@ build:
     # rust: ""1.64""
     # golang: ""1.19""
 
-# Build documentation in the docs/ directory with Sphinx
+# Build documentation in the ""docs/"" directory with Sphinx
 sphinx:
   configuration: docs/conf.py
-
-# If using Sphinx, optionally build your docs in additional formats such as PDF
+# Optionally build your docs in additional formats such as PDF and ePub
 # formats:
 #    - pdf
+#    - epub
 
-# Optionally declare the Python requirements required to build your docs
+# Optional but recommended, declare the Python requirements required
+# to build your documentation
+# See https://docs.readthedocs.io/en/stable/guides/reproducible-builds.html
 python:
   install:
     - requirements: docs/requirements.txt",Yes
Makefile,Makefile,29a1e3da6e7db834ff82c042c90dd56ac868d87b,8c74f0ba67dca235d8b9d44f233481d54dab5ab5,Makefile cleanup and check-outdated fix,"diff --git a/Makefile b/Makefile
index 8a8ce75b..483522a1 100644
--- a/Makefile
+++ b/Makefile
@@ -37,14 +37,15 @@ help:
 
 build/%: DOCKER_BUILD_ARGS?=
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag $(OWNER)/$(notdir $@):latest ./$(notdir $@) --build-arg OWNER=$(OWNER)
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(OWNER)/$(notdir $@):latest"" ""./$(notdir $@)"" --build-arg OWNER=""$(OWNER)""
 	@echo -n ""Built image size: ""
-	@docker images $(OWNER)/$(notdir $@):latest --format ""{{.Size}}""
+	@docker images ""$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks
 
 
-check-outdated/%: ## check the outdated mamba/conda packages in a stack and produce a report (experimental)
-	@TEST_IMAGE=""$(OWNER)/$(notdir $@)"" pytest tests/base-notebook/test_outdated.py
+
+check-outdated/%: ## check the outdated mamba/conda packages in a stack and produce a report
+	@TEST_IMAGE=""$(OWNER)/$(notdir $@)"" pytest tests/docker-stacks-foundation/test_outdated.py
 check-outdated-all: $(foreach I, $(ALL_IMAGES), check-outdated/$(I)) ## check all the stacks for outdated packages
 
 
@@ -61,7 +62,6 @@ cont-rm-all: ## remove all containers
 
 docs: ## build HTML documentation
 	sphinx-build -W --keep-going --color docs/ docs/_build/
-
 linkcheck-docs: ## check broken links
 	sphinx-build -W --keep-going --color -b linkcheck docs/ docs/_build/
 
@@ -97,21 +97,18 @@ pre-commit-install: ## set up the git hook scripts
 
 
 pull/%: ## pull a jupyter image
-	docker pull $(OWNER)/$(notdir $@)
+	docker pull ""$(OWNER)/$(notdir $@)""
 pull-all: $(foreach I, $(ALL_IMAGES), pull/$(I)) ## pull all images
-
-
 push/%: ## push all tags for a jupyter image
-	docker push --all-tags $(OWNER)/$(notdir $@)
+	docker push --all-tags ""$(OWNER)/$(notdir $@)""
 push-all: $(foreach I, $(ALL_IMAGES), push/$(I)) ## push all tagged images
 
 
 
 run-shell/%: ## run a bash in interactive mode in a stack
-	docker run -it --rm $(OWNER)/$(notdir $@) $(SHELL)
-
+	docker run -it --rm ""$(OWNER)/$(notdir $@)"" $(SHELL)
 run-sudo-shell/%: ## run a bash in interactive mode as root in a stack
-	docker run -it --rm --user root $(OWNER)/$(notdir $@) $(SHELL)
+	docker run -it --rm --user root ""$(OWNER)/$(notdir $@)"" $(SHELL)","diff --git a/Makefile b/Makefile
index 8a8ce75b..483522a1 100644
--- a/Makefile
+++ b/Makefile
@@ -37,14 +37,15 @@ help:
 
 build/%: DOCKER_BUILD_ARGS?=
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag $(OWNER)/$(notdir $@):latest ./$(notdir $@) --build-arg OWNER=$(OWNER)
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(OWNER)/$(notdir $@):latest"" ""./$(notdir $@)"" --build-arg OWNER=""$(OWNER)""
 	@echo -n ""Built image size: ""
-	@docker images $(OWNER)/$(notdir $@):latest --format ""{{.Size}}""
+	@docker images ""$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks
 
 
-check-outdated/%: ## check the outdated mamba/conda packages in a stack and produce a report (experimental)
-	@TEST_IMAGE=""$(OWNER)/$(notdir $@)"" pytest tests/base-notebook/test_outdated.py
+
+check-outdated/%: ## check the outdated mamba/conda packages in a stack and produce a report
+	@TEST_IMAGE=""$(OWNER)/$(notdir $@)"" pytest tests/docker-stacks-foundation/test_outdated.py
 check-outdated-all: $(foreach I, $(ALL_IMAGES), check-outdated/$(I)) ## check all the stacks for outdated packages
 
 
@@ -61,7 +62,6 @@ cont-rm-all: ## remove all containers
 
 docs: ## build HTML documentation
 	sphinx-build -W --keep-going --color docs/ docs/_build/
-
 linkcheck-docs: ## check broken links
 	sphinx-build -W --keep-going --color -b linkcheck docs/ docs/_build/
 
@@ -97,21 +97,18 @@ pre-commit-install: ## set up the git hook scripts
 
 
 pull/%: ## pull a jupyter image
-	docker pull $(OWNER)/$(notdir $@)
+	docker pull ""$(OWNER)/$(notdir $@)""
 pull-all: $(foreach I, $(ALL_IMAGES), pull/$(I)) ## pull all images
-
-
 push/%: ## push all tags for a jupyter image
-	docker push --all-tags $(OWNER)/$(notdir $@)
+	docker push --all-tags ""$(OWNER)/$(notdir $@)""
 push-all: $(foreach I, $(ALL_IMAGES), push/$(I)) ## push all tagged images
 
 
 
 run-shell/%: ## run a bash in interactive mode in a stack
-	docker run -it --rm $(OWNER)/$(notdir $@) $(SHELL)
-
+	docker run -it --rm ""$(OWNER)/$(notdir $@)"" $(SHELL)
 run-sudo-shell/%: ## run a bash in interactive mode as root in a stack
-	docker run -it --rm --user root $(OWNER)/$(notdir $@) $(SHELL)
+	docker run -it --rm --user root ""$(OWNER)/$(notdir $@)"" $(SHELL)",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,11071cb577e39c5eb5a65b2312cb301d8d94fd51,29a1e3da6e7db834ff82c042c90dd56ac868d87b,Fix docs,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 2419d33f..d1fe431f 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -306,7 +306,7 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
 
 2. **Turn off Jupyter auto-start in VSCode**
 
-   Alternatively - you might want to ensure that the `Jupyter: Disable Auto Start` setting is turned on to avoid this issue in the future.
+   Alternatively - you might want to ensure that the `Jupyter: Disable Jupyter Auto Start` setting is turned on to avoid this issue in the future.
 
    You can achieve this from the `Settings > Jupyter` menu in VScode:","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 2419d33f..d1fe431f 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -306,7 +306,7 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
 
 2. **Turn off Jupyter auto-start in VSCode**
 
-   Alternatively - you might want to ensure that the `Jupyter: Disable Auto Start` setting is turned on to avoid this issue in the future.
+   Alternatively - you might want to ensure that the `Jupyter: Disable Jupyter Auto Start` setting is turned on to avoid this issue in the future.
 
    You can achieve this from the `Settings > Jupyter` menu in VScode:",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,1b04ebe67d28dd6f054cd1e2ea2f9ca78901979f,11071cb577e39c5eb5a65b2312cb301d8d94fd51,One more docs fix,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index d1fe431f..8abaebd6 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -202,7 +202,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
   -v ""${PWD}""/<my-vol>:/home/jovyan/work
   ```
 
-  This example uses the syntax `$(PWD)`, which is replaced with the full path to the current directory at runtime. The destination
+  This example uses the syntax `${PWD}`, which is replaced with the full path to the current directory at runtime. The destination
   path should also be an absolute path starting with a `/` such as `/home/jovyan/work`.
 
 - You might want to consider using the Docker native `--user <UID>` and `--group-add users` flags instead of `-e NB_UID` and `-e NB_GID`:","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index d1fe431f..8abaebd6 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -202,7 +202,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
   -v ""${PWD}""/<my-vol>:/home/jovyan/work
   ```
 
-  This example uses the syntax `$(PWD)`, which is replaced with the full path to the current directory at runtime. The destination
+  This example uses the syntax `${PWD}`, which is replaced with the full path to the current directory at runtime. The destination
   path should also be an absolute path starting with a `/` such as `/home/jovyan/work`.
 
 - You might want to consider using the Docker native `--user <UID>` and `--group-add users` flags instead of `-e NB_UID` and `-e NB_GID`:",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,67029f17f03c54b600ec9d1100bfb730cc00fea4,1b04ebe67d28dd6f054cd1e2ea2f9ca78901979f,Always pull ubuntu:22.04 (#1940),"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index c53d85e6..c72f2046 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -54,6 +54,11 @@ jobs:
           image: ${{ inputs.parentImage }}
           platform: ${{ inputs.platform }}
 
+      - name: Pull ubuntu:22.04 image 📥
+        if: ${{ inputs.parentImage == '' }}
+        run: docker pull ubuntu:22.04
+        shell: bash
+
       - name: Build image 🛠
         run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} ${{ inputs.image }}/
         env:","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index c53d85e6..c72f2046 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -54,6 +54,11 @@ jobs:
           image: ${{ inputs.parentImage }}
           platform: ${{ inputs.platform }}
 
+      - name: Pull ubuntu:22.04 image 📥
+        if: ${{ inputs.parentImage == '' }}
+        run: docker pull ubuntu:22.04
+        shell: bash
+
       - name: Build image 🛠
         run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} ${{ inputs.image }}/
         env:",Yes
docs/using/specifics.md,docs/using/specifics.md,a7781fb90ad2a3fe8a38e4d3e26b8e2dab81cfc5,67029f17f03c54b600ec9d1100bfb730cc00fea4,More clear docs on building pyspark-notebook with different spark version,"diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 0eb84717..0155c294 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -39,7 +39,8 @@ ipython profile create
 
 ### Build an Image with a Different Version of Spark
 
-You can build a `pyspark-notebook` image (and also the downstream `all-spark-notebook` image) with a different version of Spark by overriding the default value of the following arguments at build time.
+You can build a `pyspark-notebook` image with a different version of Spark by overriding the default value of the following arguments at build time.
+If you want to build `all-spark-notebook` with a different version, you have to build `pyspark-notebook` first with the version you want and then build `all-spark-notebook` (which is inherited from `pyspark-notebook`).
 
 - Spark distribution is defined by the combination of Spark, Hadoop and Scala versions and verified by the package checksum,
   see [Download Apache Spark](https://spark.apache.org/downloads.html) and the [archive repo](https://archive.apache.org/dist/spark/) for more information.","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 0eb84717..0155c294 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -39,7 +39,8 @@ ipython profile create
 
 ### Build an Image with a Different Version of Spark
 
-You can build a `pyspark-notebook` image (and also the downstream `all-spark-notebook` image) with a different version of Spark by overriding the default value of the following arguments at build time.
+You can build a `pyspark-notebook` image with a different version of Spark by overriding the default value of the following arguments at build time.
+If you want to build `all-spark-notebook` with a different version, you have to build `pyspark-notebook` first with the version you want and then build `all-spark-notebook` (which is inherited from `pyspark-notebook`).
 
 - Spark distribution is defined by the combination of Spark, Hadoop and Scala versions and verified by the package checksum,
   see [Download Apache Spark](https://spark.apache.org/downloads.html) and the [archive repo](https://archive.apache.org/dist/spark/) for more information.",Yes
docs/using/specifics.md,docs/using/specifics.md,d60cf610fd213b6467cae00914f11c78b3a8e7c5,a7781fb90ad2a3fe8a38e4d3e26b8e2dab81cfc5,More clear docs,"diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 0155c294..53dc0e40 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -39,8 +39,8 @@ ipython profile create
 
 ### Build an Image with a Different Version of Spark
 
-You can build a `pyspark-notebook` image with a different version of Spark by overriding the default value of the following arguments at build time.
-If you want to build `all-spark-notebook` with a different version, you have to build `pyspark-notebook` first with the version you want and then build `all-spark-notebook` (which is inherited from `pyspark-notebook`).
+You can build a `pyspark-notebook` image with a different `Spark` version by overriding the default value of the following arguments at build time.
+`all-spark-notebook` is inherited from `pyspark-notebook`, so you have to first build `pyspark-notebook` and then `all-spark-notebook` to get the same version in `all-spark-notebook`.
 
 - Spark distribution is defined by the combination of Spark, Hadoop and Scala versions and verified by the package checksum,
   see [Download Apache Spark](https://spark.apache.org/downloads.html) and the [archive repo](https://archive.apache.org/dist/spark/) for more information.","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 0155c294..53dc0e40 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -39,8 +39,8 @@ ipython profile create
 
 ### Build an Image with a Different Version of Spark
 
-You can build a `pyspark-notebook` image with a different version of Spark by overriding the default value of the following arguments at build time.
-If you want to build `all-spark-notebook` with a different version, you have to build `pyspark-notebook` first with the version you want and then build `all-spark-notebook` (which is inherited from `pyspark-notebook`).
+You can build a `pyspark-notebook` image with a different `Spark` version by overriding the default value of the following arguments at build time.
+`all-spark-notebook` is inherited from `pyspark-notebook`, so you have to first build `pyspark-notebook` and then `all-spark-notebook` to get the same version in `all-spark-notebook`.
 
 - Spark distribution is defined by the combination of Spark, Hadoop and Scala versions and verified by the package checksum,
   see [Download Apache Spark](https://spark.apache.org/downloads.html) and the [archive repo](https://archive.apache.org/dist/spark/) for more information.",Yes
.github/dependabot.yml,.github/dependabot.yml,78ba661e89a85ab6cdb075df88b38fd1c397ddf2,d60cf610fd213b6467cae00914f11c78b3a8e7c5,Change dependabot url,"diff --git a/.github/dependabot.yml b/.github/dependabot.yml
index 136832b0..5296f1a4 100644
--- a/.github/dependabot.yml
+++ b/.github/dependabot.yml
@@ -1,7 +1,7 @@
 # To get started with Dependabot version updates, you'll need to specify which
 # package ecosystems to update and where the package manifests are located.
 # Please see the documentation for all configuration options:
-# https://docs.github.com/en/code-security/supply-chain-security/keeping-your-dependencies-updated-automatically/configuration-options-for-dependency-updates
+# https://docs.github.com/en/code-security/dependabot/dependabot-version-updates/configuration-options-for-the-dependabot.yml-file
 
 version: 2
 updates:","diff --git a/.github/dependabot.yml b/.github/dependabot.yml
index 136832b0..5296f1a4 100644
--- a/.github/dependabot.yml
+++ b/.github/dependabot.yml
@@ -1,7 +1,7 @@
 # To get started with Dependabot version updates, you'll need to specify which
 # package ecosystems to update and where the package manifests are located.
 # Please see the documentation for all configuration options:
-# https://docs.github.com/en/code-security/supply-chain-security/keeping-your-dependencies-updated-automatically/configuration-options-for-dependency-updates
+# https://docs.github.com/en/code-security/dependabot/dependabot-version-updates/configuration-options-for-the-dependabot.yml-file
 
 version: 2
 updates:",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,3c77c1073d07ae6d823123a71936e848e9b3ba42,78ba661e89a85ab6cdb075df88b38fd1c397ddf2,Update cookiecutter example,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index d9acf978..b783e0b5 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -8,7 +8,7 @@ Following these steps will:
 
 1. Set up a project on GitHub containing a Dockerfile based on any image we provide.
 2. Configure GitHub Actions to build and test your image when users submit pull requests to your repository.
-3. Configure Docker Hub to build and host your images for others to use.
+3. Configure Docker Hub to host your images for others to use.
 4. Update the [list of community stacks](../using/selecting.md#community-stacks) in this documentation to include your image.
 
 This approach mirrors how we build and share the core stack images.
@@ -16,7 +16,7 @@ Feel free to follow it or pave your own path using alternative services and buil
 
 ## Creating a Project
 
-First, install [cookiecutter](https://github.com/cookiecutter/cookiecutter) using _pip_ or _conda_:
+First, install [cookiecutter](https://github.com/cookiecutter/cookiecutter) using _pip_ or _mamba_:
 
 ```bash
 pip install cookiecutter  # or mamba install cookiecutter
@@ -36,13 +36,13 @@ stack_name [my-jupyter-stack]:
 ```
 
 Enter the user or organization name under which this stack will reside on Docker Hub.
-You must have access to manage this Docker Hub organization to push images here and set up automated builds.
+You must have access to manage this Docker Hub organization to push images here.
 
 ```text
 stack_org [my-project]:
 ```
 
-Select an image from the jupyter/docker-stacks project that will serve as the base for your new image.
+Select an image from the `jupyter/docker-stacks` project that will serve as the base for your new image.
 
 ```text
 stack_base_image [jupyter/base-notebook]:
@@ -54,6 +54,7 @@ Enter a longer description of the stack for your README.
 stack_description [my-jupyter-stack is a community-maintained Jupyter Docker Stack image]:
 ```
 
+Create a GitHub repository to store your project.
 Initialize your project as a Git repository and push it to GitHub.
 
 ```bash
@@ -68,23 +69,8 @@ git push -u origin main
 
 ## Configuring GitHub actions
 
-The cookiecutter template comes with a `.github/workflows/docker.yml` file, which allows you to use GitHub actions to build your Docker image whenever you or someone else submits a pull request.
-
-1. By default, the `.github/workflows/docker.yaml` file has the following triggers configuration:
-
-   ```yaml
-   on:
-   pull_request:
-     paths-ignore:
-       - ""*.md""
-   push:
-     branches:
-       - main
-     paths-ignore:
-       - ""*.md""
-   ```
-
-   This will trigger the CI pipeline whenever you push to your `main` branch and when any Pull Requests are made to your repository.
+1. By default, the `.github/workflows/docker.yaml` will trigger the CI pipeline whenever you push to your `main` branch
+   and when any Pull Requests are made to your repository.
    For more details on this configuration, visit the [GitHub actions documentation on triggers](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows).
 
 2. Commit your changes and push them to GitHub.","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index d9acf978..b783e0b5 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -8,7 +8,7 @@ Following these steps will:
 
 1. Set up a project on GitHub containing a Dockerfile based on any image we provide.
 2. Configure GitHub Actions to build and test your image when users submit pull requests to your repository.
-3. Configure Docker Hub to build and host your images for others to use.
+3. Configure Docker Hub to host your images for others to use.
 4. Update the [list of community stacks](../using/selecting.md#community-stacks) in this documentation to include your image.
 
 This approach mirrors how we build and share the core stack images.
@@ -16,7 +16,7 @@ Feel free to follow it or pave your own path using alternative services and buil
 
 ## Creating a Project
 
-First, install [cookiecutter](https://github.com/cookiecutter/cookiecutter) using _pip_ or _conda_:
+First, install [cookiecutter](https://github.com/cookiecutter/cookiecutter) using _pip_ or _mamba_:
 
 ```bash
 pip install cookiecutter  # or mamba install cookiecutter
@@ -36,13 +36,13 @@ stack_name [my-jupyter-stack]:
 ```
 
 Enter the user or organization name under which this stack will reside on Docker Hub.
-You must have access to manage this Docker Hub organization to push images here and set up automated builds.
+You must have access to manage this Docker Hub organization to push images here.
 
 ```text
 stack_org [my-project]:
 ```
 
-Select an image from the jupyter/docker-stacks project that will serve as the base for your new image.
+Select an image from the `jupyter/docker-stacks` project that will serve as the base for your new image.
 
 ```text
 stack_base_image [jupyter/base-notebook]:
@@ -54,6 +54,7 @@ Enter a longer description of the stack for your README.
 stack_description [my-jupyter-stack is a community-maintained Jupyter Docker Stack image]:
 ```
 
+Create a GitHub repository to store your project.
 Initialize your project as a Git repository and push it to GitHub.
 
 ```bash
@@ -68,23 +69,8 @@ git push -u origin main
 
 ## Configuring GitHub actions
 
-The cookiecutter template comes with a `.github/workflows/docker.yml` file, which allows you to use GitHub actions to build your Docker image whenever you or someone else submits a pull request.
-
-1. By default, the `.github/workflows/docker.yaml` file has the following triggers configuration:
-
-   ```yaml
-   on:
-   pull_request:
-     paths-ignore:
-       - ""*.md""
-   push:
-     branches:
-       - main
-     paths-ignore:
-       - ""*.md""
-   ```
-
-   This will trigger the CI pipeline whenever you push to your `main` branch and when any Pull Requests are made to your repository.
+1. By default, the `.github/workflows/docker.yaml` will trigger the CI pipeline whenever you push to your `main` branch
+   and when any Pull Requests are made to your repository.
    For more details on this configuration, visit the [GitHub actions documentation on triggers](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows).
 
 2. Commit your changes and push them to GitHub.",Yes
docs/_static/contributing/stacks/docker-github-settings.png,docs/_static/contributing/stacks/docker-github-settings.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/docker-github-settings.png b/docs/_static/contributing/stacks/docker-github-settings.png
deleted file mode 100644
index 8a07fe0c..00000000
Binary files a/docs/_static/contributing/stacks/docker-github-settings.png and /dev/null differ","diff --git a/docs/_static/contributing/stacks/docker-github-settings.png b/docs/_static/contributing/stacks/docker-github-settings.png
deleted file mode 100644
index 8a07fe0c..00000000
Binary files a/docs/_static/contributing/stacks/docker-github-settings.png and /dev/null differ",Yes
docs/_static/contributing/stacks/docker-org-create-token.png,docs/_static/contributing/stacks/docker-org-create-token.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/docker-org-create-token.png b/docs/_static/contributing/stacks/docker-org-create-token.png
index ae016331..21105bc2 100644
Binary files a/docs/_static/contributing/stacks/docker-org-create-token.png and b/docs/_static/contributing/stacks/docker-org-create-token.png differ","diff --git a/docs/_static/contributing/stacks/docker-org-create-token.png b/docs/_static/contributing/stacks/docker-org-create-token.png
index ae016331..21105bc2 100644
Binary files a/docs/_static/contributing/stacks/docker-org-create-token.png and b/docs/_static/contributing/stacks/docker-org-create-token.png differ",Yes
docs/_static/contributing/stacks/docker-org-security.png,docs/_static/contributing/stacks/docker-org-security.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/docker-org-security.png b/docs/_static/contributing/stacks/docker-org-security.png
index 2dfa2a78..831b3d54 100644
Binary files a/docs/_static/contributing/stacks/docker-org-security.png and b/docs/_static/contributing/stacks/docker-org-security.png differ","diff --git a/docs/_static/contributing/stacks/docker-org-security.png b/docs/_static/contributing/stacks/docker-org-security.png
index 2dfa2a78..831b3d54 100644
Binary files a/docs/_static/contributing/stacks/docker-org-security.png and b/docs/_static/contributing/stacks/docker-org-security.png differ",Yes
docs/_static/contributing/stacks/docker-org-select.png,docs/_static/contributing/stacks/docker-org-select.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/docker-org-select.png b/docs/_static/contributing/stacks/docker-org-select.png
deleted file mode 100644
index 3d2a2b8c..00000000
Binary files a/docs/_static/contributing/stacks/docker-org-select.png and /dev/null differ","diff --git a/docs/_static/contributing/stacks/docker-org-select.png b/docs/_static/contributing/stacks/docker-org-select.png
deleted file mode 100644
index 3d2a2b8c..00000000
Binary files a/docs/_static/contributing/stacks/docker-org-select.png and /dev/null differ",Yes
docs/_static/contributing/stacks/docker-repo-name.png,docs/_static/contributing/stacks/docker-repo-name.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/docker-repo-name.png b/docs/_static/contributing/stacks/docker-repo-name.png
index b4088f9d..baf24d5d 100644
Binary files a/docs/_static/contributing/stacks/docker-repo-name.png and b/docs/_static/contributing/stacks/docker-repo-name.png differ","diff --git a/docs/_static/contributing/stacks/docker-repo-name.png b/docs/_static/contributing/stacks/docker-repo-name.png
index b4088f9d..baf24d5d 100644
Binary files a/docs/_static/contributing/stacks/docker-repo-name.png and b/docs/_static/contributing/stacks/docker-repo-name.png differ",Yes
docs/_static/contributing/stacks/docker-user-dropdown.png,docs/_static/contributing/stacks/docker-user-dropdown.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/docker-user-dropdown.png b/docs/_static/contributing/stacks/docker-user-dropdown.png
new file mode 100644
index 00000000..1cc107e9
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-user-dropdown.png differ","diff --git a/docs/_static/contributing/stacks/docker-user-dropdown.png b/docs/_static/contributing/stacks/docker-user-dropdown.png
new file mode 100644
index 00000000..1cc107e9
Binary files /dev/null and b/docs/_static/contributing/stacks/docker-user-dropdown.png differ",Yes
docs/_static/contributing/stacks/github-actions-tab.png,docs/_static/contributing/stacks/github-actions-tab.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/github-actions-tab.png b/docs/_static/contributing/stacks/github-actions-tab.png
index 932e3c04..1c233629 100644
Binary files a/docs/_static/contributing/stacks/github-actions-tab.png and b/docs/_static/contributing/stacks/github-actions-tab.png differ","diff --git a/docs/_static/contributing/stacks/github-actions-tab.png b/docs/_static/contributing/stacks/github-actions-tab.png
index 932e3c04..1c233629 100644
Binary files a/docs/_static/contributing/stacks/github-actions-tab.png and b/docs/_static/contributing/stacks/github-actions-tab.png differ",Yes
docs/_static/contributing/stacks/github-actions-workflow.png,docs/_static/contributing/stacks/github-actions-workflow.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/github-actions-workflow.png b/docs/_static/contributing/stacks/github-actions-workflow.png
index 1af7c512..2dc4a9cf 100644
Binary files a/docs/_static/contributing/stacks/github-actions-workflow.png and b/docs/_static/contributing/stacks/github-actions-workflow.png differ","diff --git a/docs/_static/contributing/stacks/github-actions-workflow.png b/docs/_static/contributing/stacks/github-actions-workflow.png
index 1af7c512..2dc4a9cf 100644
Binary files a/docs/_static/contributing/stacks/github-actions-workflow.png and b/docs/_static/contributing/stacks/github-actions-workflow.png differ",Yes
docs/_static/contributing/stacks/github-create-secrets.png,docs/_static/contributing/stacks/github-create-secrets.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/github-create-secrets.png b/docs/_static/contributing/stacks/github-create-secrets.png
index 3d1e35a4..1336d0da 100644
Binary files a/docs/_static/contributing/stacks/github-create-secrets.png and b/docs/_static/contributing/stacks/github-create-secrets.png differ","diff --git a/docs/_static/contributing/stacks/github-create-secrets.png b/docs/_static/contributing/stacks/github-create-secrets.png
index 3d1e35a4..1336d0da 100644
Binary files a/docs/_static/contributing/stacks/github-create-secrets.png and b/docs/_static/contributing/stacks/github-create-secrets.png differ",Yes
docs/_static/contributing/stacks/github-secret-token.png,docs/_static/contributing/stacks/github-secret-token.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/github-secret-token.png b/docs/_static/contributing/stacks/github-secret-token.png
index 68cb72c4..5901c264 100644
Binary files a/docs/_static/contributing/stacks/github-secret-token.png and b/docs/_static/contributing/stacks/github-secret-token.png differ","diff --git a/docs/_static/contributing/stacks/github-secret-token.png b/docs/_static/contributing/stacks/github-secret-token.png
index 68cb72c4..5901c264 100644
Binary files a/docs/_static/contributing/stacks/github-secret-token.png and b/docs/_static/contributing/stacks/github-secret-token.png differ",Yes
docs/_static/contributing/stacks/github-secrets-completed.png,docs/_static/contributing/stacks/github-secrets-completed.png,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/_static/contributing/stacks/github-secrets-completed.png b/docs/_static/contributing/stacks/github-secrets-completed.png
deleted file mode 100644
index c26cfd42..00000000
Binary files a/docs/_static/contributing/stacks/github-secrets-completed.png and /dev/null differ","diff --git a/docs/_static/contributing/stacks/github-secrets-completed.png b/docs/_static/contributing/stacks/github-secrets-completed.png
deleted file mode 100644
index c26cfd42..00000000
Binary files a/docs/_static/contributing/stacks/github-secrets-completed.png and /dev/null differ",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,ab71f95be861c1851038fe3f836b1cc32452dabf,3c77c1073d07ae6d823123a71936e848e9b3ba42,Rewrite community stacks doc and update all the screenshots,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index b783e0b5..85644333 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -67,19 +67,22 @@ git remote add origin <url from github>
 git push -u origin main
 ```
 
-## Configuring GitHub actions
+## Exploring GitHub Actions
 
-1. By default, the `.github/workflows/docker.yaml` will trigger the CI pipeline whenever you push to your `main` branch
+1. By default, the newly `.github/workflows/docker.yaml` will trigger the CI pipeline whenever you push to your `main` branch
    and when any Pull Requests are made to your repository.
    For more details on this configuration, visit the [GitHub actions documentation on triggers](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows).
 
-2. Commit your changes and push them to GitHub.
-3. Head back to your repository and click on the **Actions** tab.
+2. Go to your repository and click on the **Actions** tab.
    From there, you can click on the workflows on the left-hand side of the screen.
 
    ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
 
-4. In the next screen, you will see information about the workflow run and duration.
+   ```{note}
+   First run is expected to fail, because we haven't yet added Docker credentials to push the image
+   ```
+
+3. In the next screen, you will see information about the workflow run and duration.
    If you click the button with the workflow name again, you will see the logs for the workflow steps.
 
    ![GitHub Actions page showing the ""Build Docker Images"" workflow](../_static/contributing/stacks/github-actions-workflow.png)
@@ -90,58 +93,44 @@ Now, configure Docker Hub to build your stack image and push it to the Docker Hu
 you merge a GitHub pull request to the main branch of your project.
 
 1. Visit [https://hub.docker.com/](https://hub.docker.com/) and log in.
-2. Select the account or organization matching the one you entered when prompted with `stack_org` by the cookiecutter.
-
-   ![DockerHub page zoomed into the user's settings and accounts menu.](../_static/contributing/stacks/docker-org-select.png)
-
-3. Scroll to the bottom of the page and click **Create repository**.
-4. Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
+2. Create a new repository - make sure to use the correct namespace (account or organization).
+   Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
 
-   ![DockerHub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
+   ![Docker Hub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
 
-5. Enter a description for your image.
-6. Click **GitHub** under the **Build Settings** and follow the prompts to connect your account if it is not already connected.
-7. Select the GitHub organization and repository containing your image definition from the dropdowns.
+3. Enter a description for your image.
+4. Click on your avatar in the top-right corner and select Account settings.
 
-   ![Dockerhub - Create Repository page focusing on the ""Select Repository"" dropdown menu](../_static/contributing/stacks/docker-github-settings.png)
+   ![Docker Hub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-user-dropdown.png)
 
-8. Click the **Create and Build** button.
-9. Click on your avatar in the top-right corner and select Account settings.
+5. Click on **Security** and then click on the **New Access Token** button.
 
-   ![DockerHub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-org-select.png)
+   ![Docker Hub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/contributing/stacks/docker-org-security.png)
 
-10. Click on **Security** and then click on the **New Access Token** button.
+6. Enter a meaningful name for your token and click on **Generate**
 
-    ![DockerHub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/contributing/stacks/docker-org-security.png)
+   ![Docker Hub - New Access Token page with the name field set to ""test-stack token""](../_static/contributing/stacks/docker-org-create-token.png)
 
-11. Enter a meaningful name for your token and click on **Create**
+7. Copy the personal access token displayed on the next screen.
 
-    ![DockerHub - New Access Token page with the name field set to ""my-jupyter-docker-token""](../_static/contributing/stacks/docker-org-create-token.png)
+   ```{note}
+   **You will not be able to see it again after you close the pop-up window**.
+   ```
 
-12. Copy the personal access token displayed on the next screen.
+8. Head back to your GitHub repository and click on the **Settings tab**.
+9. Click on the **Secrets and variables->Actions** section and then on the **New repository secret** button in the top right corner.
 
-    ```{note}
-    you will not be able to see it again after you close the pop-up window**.
-    ```
+   ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/contributing/stacks/github-create-secrets.png)
 
-13. Head back to your GitHub repository and click on the **Settings tab**.
-
-    ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/contributing/stacks/github-create-secrets.png)
-
-14. Click on the **Secrets** section and then on the **New repository secret** button in the top right corner (see image above).
-15. Create a **DOCKERHUB_TOKEN** secret and paste the Personal Access Token from DockerHub in the **value** field.
+10. Create a **DOCKERHUB_TOKEN** secret and paste the Personal Access Token from Docker Hub in the **value** field.
 
     ![GitHub - Actions/New secret page with the Name field set to ""DOCKERHUB_TOKEN""](../_static/contributing/stacks/github-secret-token.png)
 
-16. Repeat the above step but creating a **DOCKERHUB_USERNAME** and replacing the _value_ field with your DockerHub username.
-    Once you have completed these steps, your repository secrets section should look something like this:
-
-    ![GitHub - Repository secrets page showing the existing ""DOCKERHUB_TOKEN"" and ""DOCKERHUB_USERNAME"" secrets](../_static/contributing/stacks/github-secrets-completed.png)
+11. Now you're ready to go and you can restart a failed workflow.
 
 ## Defining Your Image
 
-Make edits to the Dockerfile in your project to add third-party libraries and configure Jupyter
-applications.
+Make edits to the Dockerfile in your project to add third-party libraries and configure Jupyter applications.
 Refer to the Dockerfiles for the core stacks (e.g., [jupyter/datascience-notebook](https://github.com/jupyter/docker-stacks/blob/main/datascience-notebook/Dockerfile))
 to get a feel for what's possible and the best practices.","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index b783e0b5..85644333 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -67,19 +67,22 @@ git remote add origin <url from github>
 git push -u origin main
 ```
 
-## Configuring GitHub actions
+## Exploring GitHub Actions
 
-1. By default, the `.github/workflows/docker.yaml` will trigger the CI pipeline whenever you push to your `main` branch
+1. By default, the newly `.github/workflows/docker.yaml` will trigger the CI pipeline whenever you push to your `main` branch
    and when any Pull Requests are made to your repository.
    For more details on this configuration, visit the [GitHub actions documentation on triggers](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows).
 
-2. Commit your changes and push them to GitHub.
-3. Head back to your repository and click on the **Actions** tab.
+2. Go to your repository and click on the **Actions** tab.
    From there, you can click on the workflows on the left-hand side of the screen.
 
    ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
 
-4. In the next screen, you will see information about the workflow run and duration.
+   ```{note}
+   First run is expected to fail, because we haven't yet added Docker credentials to push the image
+   ```
+
+3. In the next screen, you will see information about the workflow run and duration.
    If you click the button with the workflow name again, you will see the logs for the workflow steps.
 
    ![GitHub Actions page showing the ""Build Docker Images"" workflow](../_static/contributing/stacks/github-actions-workflow.png)
@@ -90,58 +93,44 @@ Now, configure Docker Hub to build your stack image and push it to the Docker Hu
 you merge a GitHub pull request to the main branch of your project.
 
 1. Visit [https://hub.docker.com/](https://hub.docker.com/) and log in.
-2. Select the account or organization matching the one you entered when prompted with `stack_org` by the cookiecutter.
+2. Create a new repository - make sure to use the correct namespace (account or organization).
+   Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
 
-   ![DockerHub page zoomed into the user's settings and accounts menu.](../_static/contributing/stacks/docker-org-select.png)
+   ![Docker Hub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
 
-3. Scroll to the bottom of the page and click **Create repository**.
-4. Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
+3. Enter a description for your image.
+4. Click on your avatar in the top-right corner and select Account settings.
 
-   ![DockerHub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
+   ![Docker Hub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-user-dropdown.png)
 
-5. Enter a description for your image.
-6. Click **GitHub** under the **Build Settings** and follow the prompts to connect your account if it is not already connected.
-7. Select the GitHub organization and repository containing your image definition from the dropdowns.
+5. Click on **Security** and then click on the **New Access Token** button.
 
-   ![Dockerhub - Create Repository page focusing on the ""Select Repository"" dropdown menu](../_static/contributing/stacks/docker-github-settings.png)
+   ![Docker Hub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/contributing/stacks/docker-org-security.png)
 
-8. Click the **Create and Build** button.
-9. Click on your avatar in the top-right corner and select Account settings.
+6. Enter a meaningful name for your token and click on **Generate**
 
-   ![DockerHub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-org-select.png)
+   ![Docker Hub - New Access Token page with the name field set to ""test-stack token""](../_static/contributing/stacks/docker-org-create-token.png)
 
-10. Click on **Security** and then click on the **New Access Token** button.
+7. Copy the personal access token displayed on the next screen.
 
-    ![DockerHub - Account page with the ""Security"" tab active and a rectangle highlighting the ""New Access Token"" button in the UI](../_static/contributing/stacks/docker-org-security.png)
+   ```{note}
+   **You will not be able to see it again after you close the pop-up window**.
+   ```
 
-11. Enter a meaningful name for your token and click on **Create**
+8. Head back to your GitHub repository and click on the **Settings tab**.
+9. Click on the **Secrets and variables->Actions** section and then on the **New repository secret** button in the top right corner.
 
-    ![DockerHub - New Access Token page with the name field set to ""my-jupyter-docker-token""](../_static/contributing/stacks/docker-org-create-token.png)
+   ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/contributing/stacks/github-create-secrets.png)
 
-12. Copy the personal access token displayed on the next screen.
-
-    ```{note}
-    you will not be able to see it again after you close the pop-up window**.
-    ```
-
-13. Head back to your GitHub repository and click on the **Settings tab**.
-
-    ![GitHub page with the ""Setting"" tab active and a rectangle highlighting the ""New repository secret"" button in the UI](../_static/contributing/stacks/github-create-secrets.png)
-
-14. Click on the **Secrets** section and then on the **New repository secret** button in the top right corner (see image above).
-15. Create a **DOCKERHUB_TOKEN** secret and paste the Personal Access Token from DockerHub in the **value** field.
+10. Create a **DOCKERHUB_TOKEN** secret and paste the Personal Access Token from Docker Hub in the **value** field.
 
     ![GitHub - Actions/New secret page with the Name field set to ""DOCKERHUB_TOKEN""](../_static/contributing/stacks/github-secret-token.png)
 
-16. Repeat the above step but creating a **DOCKERHUB_USERNAME** and replacing the _value_ field with your DockerHub username.
-    Once you have completed these steps, your repository secrets section should look something like this:
-
-    ![GitHub - Repository secrets page showing the existing ""DOCKERHUB_TOKEN"" and ""DOCKERHUB_USERNAME"" secrets](../_static/contributing/stacks/github-secrets-completed.png)
+11. Now you're ready to go and you can restart a failed workflow.
 
 ## Defining Your Image
 
-Make edits to the Dockerfile in your project to add third-party libraries and configure Jupyter
-applications.
+Make edits to the Dockerfile in your project to add third-party libraries and configure Jupyter applications.
 Refer to the Dockerfiles for the core stacks (e.g., [jupyter/datascience-notebook](https://github.com/jupyter/docker-stacks/blob/main/datascience-notebook/Dockerfile))
 to get a feel for what's possible and the best practices.",No
docs/contributing/stacks.md,docs/contributing/stacks.md,7cd3a776fe5963961364818796cbbda065ed5757,ab71f95be861c1851038fe3f836b1cc32452dabf,Fix docs to share an image,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 85644333..72085d85 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -143,8 +143,8 @@ Refer to Docker Hub to build the main branch that you can `docker pull`.
 
 Finally, if you'd like to add a link to your project to this documentation site, please do the following:
 
-1. Clone the [jupyter/docker-stacks](https://github.com/jupyter/docker-stacks) GitHub repository.
-2. Open the `docs/using/selecting.md` source file and locate the **Community Stacks** section.
+1. Fork the [jupyter/docker-stacks](https://github.com/jupyter/docker-stacks) GitHub repository.
+2. Open the `docs/using/selecting.md` source file and locate the **Community Stacks** section in your fork.
 3. Add a table entry with a link to your project, a binder link and a short description of what your Docker image contains.
 4. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)(PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 85644333..72085d85 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -143,8 +143,8 @@ Refer to Docker Hub to build the main branch that you can `docker pull`.
 
 Finally, if you'd like to add a link to your project to this documentation site, please do the following:
 
-1. Clone the [jupyter/docker-stacks](https://github.com/jupyter/docker-stacks) GitHub repository.
-2. Open the `docs/using/selecting.md` source file and locate the **Community Stacks** section.
+1. Fork the [jupyter/docker-stacks](https://github.com/jupyter/docker-stacks) GitHub repository.
+2. Open the `docs/using/selecting.md` source file and locate the **Community Stacks** section in your fork.
 3. Add a table entry with a link to your project, a binder link and a short description of what your Docker image contains.
 4. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)(PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.",Yes
.github/workflows/sphinx.yml,.github/workflows/sphinx.yml,141d72d9e602647584f8241c112a549a66cf3fa4,7cd3a776fe5963961364818796cbbda065ed5757,Run link checker twice to get less GitHub fails,"diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index 922d4076..ffc0259f 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -50,4 +50,4 @@ jobs:
         run: make docs
 
       - name: Check Documentation URLs 🔗
-        run: make linkcheck-docs
+        run: make linkcheck-docs || make linkcheck-docs","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index 922d4076..ffc0259f 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -50,4 +50,4 @@ jobs:
         run: make docs
 
       - name: Check Documentation URLs 🔗
-        run: make linkcheck-docs
+        run: make linkcheck-docs || make linkcheck-docs",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,8f03ac983827cbabb6a6f99a2aee7e59c8abd78e,141d72d9e602647584f8241c112a549a66cf3fa4,Add docker-stacks-foundation to issue template,"diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 3dc95c4f..778ca60c 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -23,6 +23,7 @@ body:
         - all-spark-notebook
         - base-notebook
         - datascience-notebook
+        - docker-stacks-foundation
         - julia-notebook
         - minimal-notebook
         - pyspark-notebook","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 3dc95c4f..778ca60c 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -23,6 +23,7 @@ body:
         - all-spark-notebook
         - base-notebook
         - datascience-notebook
+        - docker-stacks-foundation
         - julia-notebook
         - minimal-notebook
         - pyspark-notebook",Yes
.github/ISSUE_TEMPLATE/feature_request.yml,.github/ISSUE_TEMPLATE/feature_request.yml,8f03ac983827cbabb6a6f99a2aee7e59c8abd78e,141d72d9e602647584f8241c112a549a66cf3fa4,Add docker-stacks-foundation to issue template,"diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index 89242a2b..d6bd00cd 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -21,6 +21,7 @@ body:
         - all-spark-notebook
         - base-notebook
         - datascience-notebook
+        - docker-stacks-foundation
         - julia-notebook
         - minimal-notebook
         - pyspark-notebook","diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index 89242a2b..d6bd00cd 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -21,6 +21,7 @@ body:
         - all-spark-notebook
         - base-notebook
         - datascience-notebook
+        - docker-stacks-foundation
         - julia-notebook
         - minimal-notebook
         - pyspark-notebook",Yes
.github/ISSUE_TEMPLATE/feature_request.yml,.github/ISSUE_TEMPLATE/feature_request.yml,1dbb946c200628f5a42142fe8ba92ff4056dae5e,8f03ac983827cbabb6a6f99a2aee7e59c8abd78e,Small fix in issue template,"diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index d6bd00cd..2dc1d106 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -34,7 +34,7 @@ body:
 
   - type: textarea
     attributes:
-      label: What changes are you proposing?
+      label: What change(s) are you proposing?
       description: |
         Be concise and feel free to add supporting links or references.
       placeholder: |","diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index d6bd00cd..2dc1d106 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -34,7 +34,7 @@ body:
 
   - type: textarea
     attributes:
-      label: What changes are you proposing?
+      label: What change(s) are you proposing?
       description: |
         Be concise and feel free to add supporting links or references.
       placeholder: |",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,b94d9e074c4b46292f3e3a2e1cb490988e428bf0,1dbb946c200628f5a42142fe8ba92ff4056dae5e,Show all issues when creating bug report,"diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 778ca60c..a3aba057 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -10,7 +10,7 @@ body:
         Hi! Thanks for using the Jupyter Docker Stacks and taking some time to contribute to this project.
 
         We'd appreciate it if you could check out the [Troubleshooting common problems](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/troubleshooting.html) section in the documentation,
-        as well as [existing issues](https://github.com/jupyter/docker-stacks/issues) prior to submitting an issue to avoid duplication.
+        as well as [existing issues](https://github.com/jupyter/docker-stacks/issues?q=is%3Aissue) prior to submitting an issue to avoid duplication.
 
         Please answer the following sections to help us troubleshoot the problem.","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 778ca60c..a3aba057 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -10,7 +10,7 @@ body:
         Hi! Thanks for using the Jupyter Docker Stacks and taking some time to contribute to this project.
 
         We'd appreciate it if you could check out the [Troubleshooting common problems](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/troubleshooting.html) section in the documentation,
-        as well as [existing issues](https://github.com/jupyter/docker-stacks/issues) prior to submitting an issue to avoid duplication.
+        as well as [existing issues](https://github.com/jupyter/docker-stacks/issues?q=is%3Aissue) prior to submitting an issue to avoid duplication.
 
         Please answer the following sections to help us troubleshoot the problem.",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,ca6272c2be0309fd30b7d67ed01bb2a2a4ee42f1,b94d9e074c4b46292f3e3a2e1cb490988e428bf0,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 579af73e..aa5faab5 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.8.0
+    rev: v3.9.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.3.0
+    rev: 23.7.0
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -127,7 +127,7 @@ repos:
 
   # Run black on python code blocks in documentation files.
   - repo: https://github.com/asottile/blacken-docs
-    rev: 1.14.0
+    rev: 1.15.0
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 579af73e..aa5faab5 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.8.0
+    rev: v3.9.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.3.0
+    rev: 23.7.0
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -127,7 +127,7 @@ repos:
 
   # Run black on python code blocks in documentation files.
   - repo: https://github.com/asottile/blacken-docs
-    rev: 1.14.0
+    rev: 1.15.0
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if",Yes
base-notebook/Dockerfile,base-notebook/Dockerfile,b8d617dc0568d60f6583c42f989da51ec80e9af6,ca6272c2be0309fd30b7d67ed01bb2a2a4ee42f1,"Some fixes for Jupyter Notebook 7 (#1944)

* Some fixes for Jupyter Notebook 7

* Fix jupyter nbextension

* Remove explicit port setting","diff --git a/base-notebook/Dockerfile b/base-notebook/Dockerfile
index 0a097c6c..fafeb443 100644
--- a/base-notebook/Dockerfile
+++ b/base-notebook/Dockerfile
@@ -38,7 +38,8 @@ WORKDIR /tmp
 RUN mamba install --yes \
     'notebook' \
     'jupyterhub' \
-    'jupyterlab' && \
+    'jupyterlab' \
+    'nbclassic' && \
     jupyter notebook --generate-config && \
     mamba clean --all -f -y && \
     npm cache clean --force && \","diff --git a/base-notebook/Dockerfile b/base-notebook/Dockerfile
index 0a097c6c..fafeb443 100644
--- a/base-notebook/Dockerfile
+++ b/base-notebook/Dockerfile
@@ -38,7 +38,8 @@ WORKDIR /tmp
 RUN mamba install --yes \
     'notebook' \
     'jupyterhub' \
-    'jupyterlab' && \
+    'jupyterlab' \
+    'nbclassic' && \
     jupyter notebook --generate-config && \
     mamba clean --all -f -y && \
     npm cache clean --force && \",Yes
docs/using/recipes.md,docs/using/recipes.md,b8d617dc0568d60f6583c42f989da51ec80e9af6,ca6272c2be0309fd30b7d67ed01bb2a2a4ee42f1,"Some fixes for Jupyter Notebook 7 (#1944)

* Some fixes for Jupyter Notebook 7

* Fix jupyter nbextension

* Remove explicit port setting","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 71af470f..e99e4a62 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -486,7 +486,7 @@ docker run -it --rm \
     start.sh jupyter notebook --NotebookApp.token=''
 ```
 
-## Enable nbextension spellchecker for markdown (or any other nbextension)
+## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)
 
 NB: this works for classic notebooks only
 
@@ -499,7 +499,7 @@ USER ${NB_UID}
 RUN pip install --no-cache-dir jupyter_contrib_nbextensions && \
     jupyter contrib nbextension install --user && \
     # can modify or enable additional extensions here
-    jupyter nbextension enable spellchecker/main --user && \
+    jupyter nbclassic-extension enable spellchecker/main --user && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 71af470f..e99e4a62 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -486,7 +486,7 @@ docker run -it --rm \
     start.sh jupyter notebook --NotebookApp.token=''
 ```
 
-## Enable nbextension spellchecker for markdown (or any other nbextension)
+## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)
 
 NB: this works for classic notebooks only
 
@@ -499,7 +499,7 @@ USER ${NB_UID}
 RUN pip install --no-cache-dir jupyter_contrib_nbextensions && \
     jupyter contrib nbextension install --user && \
     # can modify or enable additional extensions here
-    jupyter nbextension enable spellchecker/main --user && \
+    jupyter nbclassic-extension enable spellchecker/main --user && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```",Yes
scipy-notebook/Dockerfile,scipy-notebook/Dockerfile,b8d617dc0568d60f6583c42f989da51ec80e9af6,ca6272c2be0309fd30b7d67ed01bb2a2a4ee42f1,"Some fixes for Jupyter Notebook 7 (#1944)

* Some fixes for Jupyter Notebook 7

* Fix jupyter nbextension

* Remove explicit port setting","diff --git a/scipy-notebook/Dockerfile b/scipy-notebook/Dockerfile
index c2c3bdb5..6338f42e 100644
--- a/scipy-notebook/Dockerfile
+++ b/scipy-notebook/Dockerfile
@@ -64,7 +64,7 @@ RUN mamba install --yes \
 # Install facets which does not have a pip or conda package at the moment
 WORKDIR /tmp
 RUN git clone https://github.com/PAIR-code/facets.git && \
-    jupyter nbextension install facets/facets-dist/ --sys-prefix && \
+    jupyter nbclassic-extension install facets/facets-dist/ --sys-prefix && \
     rm -rf /tmp/facets && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/scipy-notebook/Dockerfile b/scipy-notebook/Dockerfile
index c2c3bdb5..6338f42e 100644
--- a/scipy-notebook/Dockerfile
+++ b/scipy-notebook/Dockerfile
@@ -64,7 +64,7 @@ RUN mamba install --yes \
 # Install facets which does not have a pip or conda package at the moment
 WORKDIR /tmp
 RUN git clone https://github.com/PAIR-code/facets.git && \
-    jupyter nbextension install facets/facets-dist/ --sys-prefix && \
+    jupyter nbclassic-extension install facets/facets-dist/ --sys-prefix && \
     rm -rf /tmp/facets && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,076d1511387fe506f93e8b48a0ebb61ca5693fb8,b8d617dc0568d60f6583c42f989da51ec80e9af6,Add missing julia images needs,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index aa02bb82..d6eec499 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -288,6 +288,7 @@ jobs:
         aarch64-minimal,
         aarch64-scipy,
         aarch64-r,
+        aarch64-julia,
         aarch64-tensorflow,
         aarch64-datascience,
         aarch64-pyspark,
@@ -325,6 +326,7 @@ jobs:
         x86_64-minimal,
         x86_64-scipy,
         x86_64-r,
+        x86_64-julia,
         x86_64-tensorflow,
         x86_64-datascience,
         x86_64-pyspark,","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index aa02bb82..d6eec499 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -288,6 +288,7 @@ jobs:
         aarch64-minimal,
         aarch64-scipy,
         aarch64-r,
+        aarch64-julia,
         aarch64-tensorflow,
         aarch64-datascience,
         aarch64-pyspark,
@@ -325,6 +326,7 @@ jobs:
         x86_64-minimal,
         x86_64-scipy,
         x86_64-r,
+        x86_64-julia,
         x86_64-tensorflow,
         x86_64-datascience,
         x86_64-pyspark,",Yes
minimal-notebook/setup-scripts/setup-julia-packages.bash,minimal-notebook/setup-scripts/setup-julia-packages.bash,1688c06ea3daaaffbed1fd1612280e0ea721b2c1,076d1511387fe506f93e8b48a0ebb61ca5693fb8,Improve docs in setup-julia-packages.bash,"diff --git a/minimal-notebook/setup-scripts/setup-julia-packages.bash b/minimal-notebook/setup-scripts/setup-julia-packages.bash
index faeee01e..7cc0a45f 100755
--- a/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -17,9 +17,9 @@ Pkg.add([
 Pkg.precompile();
 '
 
-# Move the kernelspec out to the system share location. Avoids
-# problems with runtime UID change not taking effect properly on the
-# .local folder in the jovyan home dir.  move kernelspec out of home
+# Move the kernelspec out of ${HOME} to the system share location.
+# Avoids problems with runtime UID change not taking effect properly
+# on the .local folder in the jovyan home dir.
 mv ""${HOME}/.local/share/jupyter/kernels/julia""* ""${CONDA_DIR}/share/jupyter/kernels/""
 chmod -R go+rx ""${CONDA_DIR}/share/jupyter""
 rm -rf ""${HOME}/.local""","diff --git a/minimal-notebook/setup-scripts/setup-julia-packages.bash b/minimal-notebook/setup-scripts/setup-julia-packages.bash
index faeee01e..7cc0a45f 100755
--- a/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -17,9 +17,9 @@ Pkg.add([
 Pkg.precompile();
 '
 
-# Move the kernelspec out to the system share location. Avoids
-# problems with runtime UID change not taking effect properly on the
-# .local folder in the jovyan home dir.  move kernelspec out of home
+# Move the kernelspec out of ${HOME} to the system share location.
+# Avoids problems with runtime UID change not taking effect properly
+# on the .local folder in the jovyan home dir.
 mv ""${HOME}/.local/share/jupyter/kernels/julia""* ""${CONDA_DIR}/share/jupyter/kernels/""
 chmod -R go+rx ""${CONDA_DIR}/share/jupyter""
 rm -rf ""${HOME}/.local""",Yes
README.md,README.md,df6884ffaf3c3cfd80ceee42abeb6babe2be05e2,1688c06ea3daaaffbed1fd1612280e0ea721b2c1,Update tag example,"diff --git a/README.md b/README.md
index 0373b796..7d764bf9 100644
--- a/README.md
+++ b/README.md
@@ -26,11 +26,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-06-01
+docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-25
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -45,11 +45,11 @@ The container remains intact for restart after the Jupyter Server exits.
 
 **Example 2:**
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-06-01
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-25
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -117,7 +117,7 @@ This change is tracked in the issue [#1217](https://github.com/jupyter/docker-st
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-06-01`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-07-25`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images","diff --git a/README.md b/README.md
index 0373b796..7d764bf9 100644
--- a/README.md
+++ b/README.md
@@ -26,11 +26,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-06-01
+docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-25
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -45,11 +45,11 @@ The container remains intact for restart after the Jupyter Server exits.
 
 **Example 2:**
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-06-01
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-25
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -117,7 +117,7 @@ This change is tracked in the issue [#1217](https://github.com/jupyter/docker-st
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-06-01`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-07-25`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images",Yes
binder/Dockerfile,binder/Dockerfile,df6884ffaf3c3cfd80ceee42abeb6babe2be05e2,1688c06ea3daaaffbed1fd1612280e0ea721b2c1,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 4986e2f4..214a8008 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -3,7 +3,7 @@
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-06-01
+ARG BASE_CONTAINER=$OWNER/base-notebook:2023-07-25
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -12,6 +12,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-06-01""
+ENV TAG=""2023-07-25""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 4986e2f4..214a8008 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -3,7 +3,7 @@
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-06-01
+ARG BASE_CONTAINER=$OWNER/base-notebook:2023-07-25
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -12,6 +12,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-06-01""
+ENV TAG=""2023-07-25""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/recipes.md,docs/using/recipes.md,df6884ffaf3c3cfd80ceee42abeb6babe2be05e2,1688c06ea3daaaffbed1fd1612280e0ea721b2c1,Update tag example,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index e99e4a62..9b3d976d 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -29,7 +29,7 @@ Create a new Dockerfile like the one shown below.
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/datascience-notebook:2023-06-01
+FROM jupyter/datascience-notebook:2023-07-25
 # Install in the default python3 environment
 RUN pip install --no-cache-dir 'flake8==3.9.2' && \
     fix-permissions ""${CONDA_DIR}"" && \
@@ -48,7 +48,7 @@ Next, create a new Dockerfile like the one shown below.
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/datascience-notebook:2023-06-01
+FROM jupyter/datascience-notebook:2023-07-25
 # Install from the requirements.txt file
 COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
 RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
@@ -60,7 +60,7 @@ For conda, the Dockerfile is similar:
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/datascience-notebook:2023-06-01
+FROM jupyter/datascience-notebook:2023-07-25
 # Install from the requirements.txt file
 COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
 RUN mamba install --yes --file /tmp/requirements.txt && \
@@ -283,7 +283,7 @@ To use a specific version of JupyterHub, the version of `jupyterhub` in your ima
 version in the Hub itself.
 
 ```dockerfile
-FROM jupyter/base-notebook:2023-06-01
+FROM jupyter/base-notebook:2023-07-25
 RUN pip install --no-cache-dir jupyterhub==1.4.1 && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
@@ -474,7 +474,7 @@ For JupyterLab:
 
 ```bash
 docker run -it --rm \
-    jupyter/base-notebook:2023-06-01 \
+    jupyter/base-notebook:2023-07-25 \
     start.sh jupyter lab --LabApp.token=''
 ```
 
@@ -482,7 +482,7 @@ For jupyter classic:
 
 ```bash
 docker run -it --rm \
-    jupyter/base-notebook:2023-06-01 \
+    jupyter/base-notebook:2023-07-25 \
     start.sh jupyter notebook --NotebookApp.token=''
 ```
 
@@ -575,7 +575,7 @@ The example below is a Dockerfile to install the [ijavascript kernel](https://gi
 
 ```dockerfile
 # use one of the Jupyter Docker Stacks images
-FROM jupyter/scipy-notebook:2023-06-01
+FROM jupyter/scipy-notebook:2023-07-25
 
 # install ijavascript
 RUN npm install -g ijavascript","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index e99e4a62..9b3d976d 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -29,7 +29,7 @@ Create a new Dockerfile like the one shown below.
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/datascience-notebook:2023-06-01
+FROM jupyter/datascience-notebook:2023-07-25
 # Install in the default python3 environment
 RUN pip install --no-cache-dir 'flake8==3.9.2' && \
     fix-permissions ""${CONDA_DIR}"" && \
@@ -48,7 +48,7 @@ Next, create a new Dockerfile like the one shown below.
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/datascience-notebook:2023-06-01
+FROM jupyter/datascience-notebook:2023-07-25
 # Install from the requirements.txt file
 COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
 RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
@@ -60,7 +60,7 @@ For conda, the Dockerfile is similar:
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/datascience-notebook:2023-06-01
+FROM jupyter/datascience-notebook:2023-07-25
 # Install from the requirements.txt file
 COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
 RUN mamba install --yes --file /tmp/requirements.txt && \
@@ -283,7 +283,7 @@ To use a specific version of JupyterHub, the version of `jupyterhub` in your ima
 version in the Hub itself.
 
 ```dockerfile
-FROM jupyter/base-notebook:2023-06-01
+FROM jupyter/base-notebook:2023-07-25
 RUN pip install --no-cache-dir jupyterhub==1.4.1 && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
@@ -474,7 +474,7 @@ For JupyterLab:
 
 ```bash
 docker run -it --rm \
-    jupyter/base-notebook:2023-06-01 \
+    jupyter/base-notebook:2023-07-25 \
     start.sh jupyter lab --LabApp.token=''
 ```
 
@@ -482,7 +482,7 @@ For jupyter classic:
 
 ```bash
 docker run -it --rm \
-    jupyter/base-notebook:2023-06-01 \
+    jupyter/base-notebook:2023-07-25 \
     start.sh jupyter notebook --NotebookApp.token=''
 ```
 
@@ -575,7 +575,7 @@ The example below is a Dockerfile to install the [ijavascript kernel](https://gi
 
 ```dockerfile
 # use one of the Jupyter Docker Stacks images
-FROM jupyter/scipy-notebook:2023-06-01
+FROM jupyter/scipy-notebook:2023-07-25
 
 # install ijavascript
 RUN npm install -g ijavascript",Yes
docs/using/running.md,docs/using/running.md,df6884ffaf3c3cfd80ceee42abeb6babe2be05e2,1688c06ea3daaaffbed1fd1612280e0ea721b2c1,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index 1f330b54..125b5f02 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Notebook server and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the notebook server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-06-01
+docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-25
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the notebook server but leaves the container
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-06-01                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-07-25                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 **Example 2:**
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Notebook server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the notebook server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-06-01
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-25
 ```
 
 Pressing `Ctrl-C` twice shuts down the notebook server and immediately destroys the Docker container.
@@ -130,7 +130,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the notebook server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -139,7 +139,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-06-01
+    docker.io/jupyter/r-notebook:2023-07-25
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 1f330b54..125b5f02 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Notebook server and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the notebook server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-06-01
+docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-25
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the notebook server but leaves the container
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-06-01                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-07-25                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 **Example 2:**
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Notebook server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the notebook server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-06-01
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-25
 ```
 
 Pressing `Ctrl-C` twice shuts down the notebook server and immediately destroys the Docker container.
@@ -130,7 +130,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-06-01` from Docker Hub if it is not already present on the local host.
+This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the notebook server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -139,7 +139,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-06-01
+    docker.io/jupyter/r-notebook:2023-07-25
 ```
 
 ```{warning}",Yes
examples/docker-compose/README.md,examples/docker-compose/README.md,df6884ffaf3c3cfd80ceee42abeb6babe2be05e2,1688c06ea3daaaffbed1fd1612280e0ea721b2c1,Update tag example,"diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index b2ea9efb..5846aa7d 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -42,7 +42,7 @@ You can customize the docker-stack notebook image to deploy by modifying the `no
 For example, you can build and deploy a `jupyter/all-spark-notebook` by modifying the Dockerfile like so:
 
 ```dockerfile
-FROM jupyter/all-spark-notebook:2023-06-01
+FROM jupyter/all-spark-notebook:2023-07-25
 # Your RUN commands and so on
 ```","diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index b2ea9efb..5846aa7d 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -42,7 +42,7 @@ You can customize the docker-stack notebook image to deploy by modifying the `no
 For example, you can build and deploy a `jupyter/all-spark-notebook` by modifying the Dockerfile like so:
 
 ```dockerfile
-FROM jupyter/all-spark-notebook:2023-06-01
+FROM jupyter/all-spark-notebook:2023-07-25
 # Your RUN commands and so on
 ```",Yes
examples/docker-compose/notebook/Dockerfile,examples/docker-compose/notebook/Dockerfile,df6884ffaf3c3cfd80ceee42abeb6babe2be05e2,1688c06ea3daaaffbed1fd1612280e0ea721b2c1,Update tag example,"diff --git a/examples/docker-compose/notebook/Dockerfile b/examples/docker-compose/notebook/Dockerfile
index 6e2668cc..07846faa 100644
--- a/examples/docker-compose/notebook/Dockerfile
+++ b/examples/docker-compose/notebook/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook:2023-06-01
+FROM jupyter/minimal-notebook:2023-07-25
 
 USER root","diff --git a/examples/docker-compose/notebook/Dockerfile b/examples/docker-compose/notebook/Dockerfile
index 6e2668cc..07846faa 100644
--- a/examples/docker-compose/notebook/Dockerfile
+++ b/examples/docker-compose/notebook/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook:2023-06-01
+FROM jupyter/minimal-notebook:2023-07-25
 
 USER root",Yes
examples/make-deploy/Dockerfile,examples/make-deploy/Dockerfile,df6884ffaf3c3cfd80ceee42abeb6babe2be05e2,1688c06ea3daaaffbed1fd1612280e0ea721b2c1,Update tag example,"diff --git a/examples/make-deploy/Dockerfile b/examples/make-deploy/Dockerfile
index 6e2668cc..07846faa 100644
--- a/examples/make-deploy/Dockerfile
+++ b/examples/make-deploy/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook:2023-06-01
+FROM jupyter/minimal-notebook:2023-07-25
 
 USER root","diff --git a/examples/make-deploy/Dockerfile b/examples/make-deploy/Dockerfile
index 6e2668cc..07846faa 100644
--- a/examples/make-deploy/Dockerfile
+++ b/examples/make-deploy/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook:2023-06-01
+FROM jupyter/minimal-notebook:2023-07-25
 
 USER root",Yes
base-notebook/Dockerfile,base-notebook/Dockerfile,aedf3e788c32671c80abab22d53a4942039f8caf,df6884ffaf3c3cfd80ceee42abeb6babe2be05e2,"Remove jupyter_notebook_config.py (#1945)

* Remove jupyter_notebook_config.py

* Update Dockerfile","diff --git a/base-notebook/Dockerfile b/base-notebook/Dockerfile
index fafeb443..45260fe0 100644
--- a/base-notebook/Dockerfile
+++ b/base-notebook/Dockerfile
@@ -56,16 +56,11 @@ CMD [""start-notebook.sh""]
 
 # Copy local files as late as possible to avoid cache busting
 COPY start-notebook.sh start-singleuser.sh /usr/local/bin/
-# Currently need to have both jupyter_notebook_config and jupyter_server_config to support classic and lab
 COPY jupyter_server_config.py docker_healthcheck.py /etc/jupyter/
 
 # Fix permissions on /etc/jupyter as root
 USER root
-
-# Legacy for Jupyter Notebook Server, see: [#1205](https://github.com/jupyter/docker-stacks/issues/1205)
-RUN sed -re ""s/c.ServerApp/c.NotebookApp/g"" \
-    /etc/jupyter/jupyter_server_config.py > /etc/jupyter/jupyter_notebook_config.py && \
-    fix-permissions /etc/jupyter/
+RUN fix-permissions /etc/jupyter/
 
 # HEALTHCHECK documentation: https://docs.docker.com/engine/reference/builder/#healthcheck
 # This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server` and `retro` jupyter commands","diff --git a/base-notebook/Dockerfile b/base-notebook/Dockerfile
index fafeb443..45260fe0 100644
--- a/base-notebook/Dockerfile
+++ b/base-notebook/Dockerfile
@@ -56,16 +56,11 @@ CMD [""start-notebook.sh""]
 
 # Copy local files as late as possible to avoid cache busting
 COPY start-notebook.sh start-singleuser.sh /usr/local/bin/
-# Currently need to have both jupyter_notebook_config and jupyter_server_config to support classic and lab
 COPY jupyter_server_config.py docker_healthcheck.py /etc/jupyter/
 
 # Fix permissions on /etc/jupyter as root
 USER root
-
-# Legacy for Jupyter Notebook Server, see: [#1205](https://github.com/jupyter/docker-stacks/issues/1205)
-RUN sed -re ""s/c.ServerApp/c.NotebookApp/g"" \
-    /etc/jupyter/jupyter_server_config.py > /etc/jupyter/jupyter_notebook_config.py && \
-    fix-permissions /etc/jupyter/
+RUN fix-permissions /etc/jupyter/
 
 # HEALTHCHECK documentation: https://docs.docker.com/engine/reference/builder/#healthcheck
 # This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server` and `retro` jupyter commands",Yes
minimal-notebook/setup-scripts/setup-julia.bash,minimal-notebook/setup-scripts/setup-julia.bash,84352d06b40a13c11bdabdc73b0544971bfe7870,aedf3e788c32671c80abab22d53a4942039f8caf,Update julia version (#1946),"diff --git a/minimal-notebook/setup-scripts/setup-julia.bash b/minimal-notebook/setup-scripts/setup-julia.bash
index 3aab076e..29d2b172 100755
--- a/minimal-notebook/setup-scripts/setup-julia.bash
+++ b/minimal-notebook/setup-scripts/setup-julia.bash
@@ -6,7 +6,7 @@ set -exuo pipefail
 
 # Default julia version to install if env var is not set
 # Check https://julialang.org/downloads/
-JULIA_VERSION=""${JULIA_VERSION:-1.9.1}""
+JULIA_VERSION=""${JULIA_VERSION:-1.9.2}""
 
 # Figure out what architecture we are installing in
 JULIA_ARCH=$(uname -m)","diff --git a/minimal-notebook/setup-scripts/setup-julia.bash b/minimal-notebook/setup-scripts/setup-julia.bash
index 3aab076e..29d2b172 100755
--- a/minimal-notebook/setup-scripts/setup-julia.bash
+++ b/minimal-notebook/setup-scripts/setup-julia.bash
@@ -6,7 +6,7 @@ set -exuo pipefail
 
 # Default julia version to install if env var is not set
 # Check https://julialang.org/downloads/
-JULIA_VERSION=""${JULIA_VERSION:-1.9.1}""
+JULIA_VERSION=""${JULIA_VERSION:-1.9.2}""
 
 # Figure out what architecture we are installing in
 JULIA_ARCH=$(uname -m)",Yes
docs/using/selecting.md,docs/using/selecting.md,75ca54d55008a641b6896d8af65247233127ac90,84352d06b40a13c11bdabdc73b0544971bfe7870,Update selecting.md,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 7083dcbb..300f8f05 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -37,6 +37,8 @@ It contains:
 - `tini` as the container entry point
 - A `start.sh` script as the default command - useful for running alternative commands in the container as applications are added (e.g. `ipython`, `jupyter kernelgateway`, `jupyter lab`)
 - Options for a passwordless sudo
+- Common system libraries like `bzip2`, `ca-certificates`, `locales`
+- `wget` to download external files
 - No preinstalled scientific computing packages
 
 ### jupyter/base-notebook","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 7083dcbb..300f8f05 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -37,6 +37,8 @@ It contains:
 - `tini` as the container entry point
 - A `start.sh` script as the default command - useful for running alternative commands in the container as applications are added (e.g. `ipython`, `jupyter kernelgateway`, `jupyter lab`)
 - Options for a passwordless sudo
+- Common system libraries like `bzip2`, `ca-certificates`, `locales`
+- `wget` to download external files
 - No preinstalled scientific computing packages
 
 ### jupyter/base-notebook",Yes
docs/using/common.md,docs/using/common.md,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/docs/using/common.md b/docs/using/common.md
index 1161439e..790eb2d6 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -11,19 +11,19 @@ This page describes the options supported by the startup script and how to bypas
 You can pass [Jupyter server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.sh` script when launching the container.
 
 1. For example, to secure the Notebook server with a [custom password](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#preparing-a-hashed-password)
-   hashed using `jupyter_server.auth.security.passwd()` instead of the default token,
+   hashed using `jupyter_server.auth.passwd()` instead of the default token,
    you can run the following (this hash was generated for the `my-password` password):
 
    ```bash
    docker run -it --rm -p 8888:8888 jupyter/base-notebook \
-       start-notebook.sh --NotebookApp.password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
+       start-notebook.sh --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the notebook server, you can run the following:
 
    ```bash
    docker run  -it --rm -p 8888:8888 jupyter/base-notebook \
-       start-notebook.sh --NotebookApp.base_url=/customized/url/prefix/
+       start-notebook.sh --ServerApp.base_url=/customized/url/prefix/
    ```
 
 ## Docker Options
@@ -148,8 +148,8 @@ docker run -it --rm -p 8888:8888 \
     -v /some/host/folder:/etc/ssl/notebook \
     jupyter/base-notebook \
     start-notebook.sh \
-    --NotebookApp.keyfile=/etc/ssl/notebook/notebook.key \
-    --NotebookApp.certfile=/etc/ssl/notebook/notebook.crt
+    --ServerApp.keyfile=/etc/ssl/notebook/notebook.key \
+    --ServerApp.certfile=/etc/ssl/notebook/notebook.crt
 ```
 
 Alternatively, you may mount a single PEM file containing both the key and certificate.
@@ -160,7 +160,7 @@ docker run -it --rm -p 8888:8888 \
     -v /some/host/folder/notebook.pem:/etc/ssl/notebook.pem \
     jupyter/base-notebook \
     start-notebook.sh \
-    --NotebookApp.certfile=/etc/ssl/notebook.pem
+    --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
 
 In either case, Jupyter Notebook expects the key and certificate to be a **base64 encoded text file**.","diff --git a/docs/using/common.md b/docs/using/common.md
index 1161439e..790eb2d6 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -11,19 +11,19 @@ This page describes the options supported by the startup script and how to bypas
 You can pass [Jupyter server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.sh` script when launching the container.
 
 1. For example, to secure the Notebook server with a [custom password](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#preparing-a-hashed-password)
-   hashed using `jupyter_server.auth.security.passwd()` instead of the default token,
+   hashed using `jupyter_server.auth.passwd()` instead of the default token,
    you can run the following (this hash was generated for the `my-password` password):
 
    ```bash
    docker run -it --rm -p 8888:8888 jupyter/base-notebook \
-       start-notebook.sh --NotebookApp.password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
+       start-notebook.sh --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the notebook server, you can run the following:
 
    ```bash
    docker run  -it --rm -p 8888:8888 jupyter/base-notebook \
-       start-notebook.sh --NotebookApp.base_url=/customized/url/prefix/
+       start-notebook.sh --ServerApp.base_url=/customized/url/prefix/
    ```
 
 ## Docker Options
@@ -148,8 +148,8 @@ docker run -it --rm -p 8888:8888 \
     -v /some/host/folder:/etc/ssl/notebook \
     jupyter/base-notebook \
     start-notebook.sh \
-    --NotebookApp.keyfile=/etc/ssl/notebook/notebook.key \
-    --NotebookApp.certfile=/etc/ssl/notebook/notebook.crt
+    --ServerApp.keyfile=/etc/ssl/notebook/notebook.key \
+    --ServerApp.certfile=/etc/ssl/notebook/notebook.crt
 ```
 
 Alternatively, you may mount a single PEM file containing both the key and certificate.
@@ -160,7 +160,7 @@ docker run -it --rm -p 8888:8888 \
     -v /some/host/folder/notebook.pem:/etc/ssl/notebook.pem \
     jupyter/base-notebook \
     start-notebook.sh \
-    --NotebookApp.certfile=/etc/ssl/notebook.pem
+    --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
 
 In either case, Jupyter Notebook expects the key and certificate to be a **base64 encoded text file**.",Yes
docs/using/recipes.md,docs/using/recipes.md,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 9b3d976d..57de144a 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -475,15 +475,16 @@ For JupyterLab:
 ```bash
 docker run -it --rm \
     jupyter/base-notebook:2023-07-25 \
-    start.sh jupyter lab --LabApp.token=''
+    start-notebook.sh --IdentityProvider.token=''
 ```
 
-For jupyter classic:
+For Jupyter Notebook:
 
 ```bash
 docker run -it --rm \
+    -e DOCKER_STACKS_JUPYTER_CMD=notebook \
     jupyter/base-notebook:2023-07-25 \
-    start.sh jupyter notebook --NotebookApp.token=''
+    start-notebook.sh --IdentityProvider.token=''
 ```
 
 ## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 9b3d976d..57de144a 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -475,15 +475,16 @@ For JupyterLab:
 ```bash
 docker run -it --rm \
     jupyter/base-notebook:2023-07-25 \
-    start.sh jupyter lab --LabApp.token=''
+    start-notebook.sh --IdentityProvider.token=''
 ```
 
-For jupyter classic:
+For Jupyter Notebook:
 
 ```bash
 docker run -it --rm \
+    -e DOCKER_STACKS_JUPYTER_CMD=notebook \
     jupyter/base-notebook:2023-07-25 \
-    start.sh jupyter notebook --NotebookApp.token=''
+    start-notebook.sh --IdentityProvider.token=''
 ```
 
 ## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)",Yes
examples/docker-compose/notebook/letsencrypt-notebook.yml,examples/docker-compose/notebook/letsencrypt-notebook.yml,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/examples/docker-compose/notebook/letsencrypt-notebook.yml b/examples/docker-compose/notebook/letsencrypt-notebook.yml
index 1b7449f7..1c47c99e 100644
--- a/examples/docker-compose/notebook/letsencrypt-notebook.yml
+++ b/examples/docker-compose/notebook/letsencrypt-notebook.yml
@@ -19,8 +19,8 @@ services:
       PASSWORD: ${PASSWORD}
     command: >
       start-notebook.sh
-      --NotebookApp.certfile=/etc/letsencrypt/fullchain.pem
-      --NotebookApp.keyfile=/etc/letsencrypt/privkey.pem
+      --ServerApp.certfile=/etc/letsencrypt/fullchain.pem
+      --ServerApp.keyfile=/etc/letsencrypt/privkey.pem
 
 volumes:
   work:","diff --git a/examples/docker-compose/notebook/letsencrypt-notebook.yml b/examples/docker-compose/notebook/letsencrypt-notebook.yml
index 1b7449f7..1c47c99e 100644
--- a/examples/docker-compose/notebook/letsencrypt-notebook.yml
+++ b/examples/docker-compose/notebook/letsencrypt-notebook.yml
@@ -19,8 +19,8 @@ services:
       PASSWORD: ${PASSWORD}
     command: >
       start-notebook.sh
-      --NotebookApp.certfile=/etc/letsencrypt/fullchain.pem
-      --NotebookApp.keyfile=/etc/letsencrypt/privkey.pem
+      --ServerApp.certfile=/etc/letsencrypt/fullchain.pem
+      --ServerApp.keyfile=/etc/letsencrypt/privkey.pem
 
 volumes:
   work:",Yes
examples/make-deploy/letsencrypt.makefile,examples/make-deploy/letsencrypt.makefile,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/examples/make-deploy/letsencrypt.makefile b/examples/make-deploy/letsencrypt.makefile
index cb006388..3ef9b092 100644
--- a/examples/make-deploy/letsencrypt.makefile
+++ b/examples/make-deploy/letsencrypt.makefile
@@ -52,8 +52,8 @@ letsencrypt-notebook: DOCKER_ARGS:=-e USE_HTTPS=yes \
 	-e PASSWORD=$(PASSWORD) \
 	-v $(SECRETS_VOLUME):/etc/letsencrypt
 letsencrypt-notebook: ARGS:=\
-	--NotebookApp.certfile=/etc/letsencrypt/fullchain.pem \
-	--NotebookApp.keyfile=/etc/letsencrypt/privkey.pem
+	--ServerApp.certfile=/etc/letsencrypt/fullchain.pem \
+	--ServerApp.keyfile=/etc/letsencrypt/privkey.pem
 letsencrypt-notebook: check
 	@test -n ""$(PASSWORD)"" || \
 		(echo ""ERROR: PASSWORD not defined or blank""; exit 1)","diff --git a/examples/make-deploy/letsencrypt.makefile b/examples/make-deploy/letsencrypt.makefile
index cb006388..3ef9b092 100644
--- a/examples/make-deploy/letsencrypt.makefile
+++ b/examples/make-deploy/letsencrypt.makefile
@@ -52,8 +52,8 @@ letsencrypt-notebook: DOCKER_ARGS:=-e USE_HTTPS=yes \
 	-e PASSWORD=$(PASSWORD) \
 	-v $(SECRETS_VOLUME):/etc/letsencrypt
 letsencrypt-notebook: ARGS:=\
-	--NotebookApp.certfile=/etc/letsencrypt/fullchain.pem \
-	--NotebookApp.keyfile=/etc/letsencrypt/privkey.pem
+	--ServerApp.certfile=/etc/letsencrypt/fullchain.pem \
+	--ServerApp.keyfile=/etc/letsencrypt/privkey.pem
 letsencrypt-notebook: check
 	@test -n ""$(PASSWORD)"" || \
 		(echo ""ERROR: PASSWORD not defined or blank""; exit 1)",Yes
examples/openshift/templates.json,examples/openshift/templates.json,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/examples/openshift/templates.json b/examples/openshift/templates.json
index 0efd4ad2..6c48e129 100644
--- a/examples/openshift/templates.json
+++ b/examples/openshift/templates.json
@@ -38,7 +38,7 @@
         }
       },
       ""data"": {
-        ""jupyter_server_config.py"": ""import os\n\npassword = os.environ.get('JUPYTER_NOTEBOOK_PASSWORD')\n\nif password:\n    import notebook.auth\n    c.NotebookApp.password = notebook.auth.passwd(password)\n    del password\n    del os.environ['JUPYTER_NOTEBOOK_PASSWORD']\n\nimage_config_file = '/home/jovyan/.jupyter/jupyter_server_config.py'\n\nif os.path.exists(image_config_file):\n    with open(image_config_file) as fp:\n        exec(compile(fp.read(), image_config_file, 'exec'), globals())\n""
+        ""jupyter_server_config.py"": ""import os\n\npassword = os.environ.get('JUPYTER_NOTEBOOK_PASSWORD')\n\nif password:\n    from jupyter_server.auth import passwd\n    c.ServerApp.password = passwd(password)\n    del password\n    del os.environ['JUPYTER_NOTEBOOK_PASSWORD']\n\nimage_config_file = '/home/jovyan/.jupyter/jupyter_server_config.py'\n\nif os.path.exists(image_config_file):\n    with open(image_config_file) as fp:\n        exec(compile(fp.read(), image_config_file, 'exec'), globals())\n""
       }
     },
     {","diff --git a/examples/openshift/templates.json b/examples/openshift/templates.json
index 0efd4ad2..6c48e129 100644
--- a/examples/openshift/templates.json
+++ b/examples/openshift/templates.json
@@ -38,7 +38,7 @@
         }
       },
       ""data"": {
-        ""jupyter_server_config.py"": ""import os\n\npassword = os.environ.get('JUPYTER_NOTEBOOK_PASSWORD')\n\nif password:\n    import notebook.auth\n    c.NotebookApp.password = notebook.auth.passwd(password)\n    del password\n    del os.environ['JUPYTER_NOTEBOOK_PASSWORD']\n\nimage_config_file = '/home/jovyan/.jupyter/jupyter_server_config.py'\n\nif os.path.exists(image_config_file):\n    with open(image_config_file) as fp:\n        exec(compile(fp.read(), image_config_file, 'exec'), globals())\n""
+        ""jupyter_server_config.py"": ""import os\n\npassword = os.environ.get('JUPYTER_NOTEBOOK_PASSWORD')\n\nif password:\n    from jupyter_server.auth import passwd\n    c.ServerApp.password = passwd(password)\n    del password\n    del os.environ['JUPYTER_NOTEBOOK_PASSWORD']\n\nimage_config_file = '/home/jovyan/.jupyter/jupyter_server_config.py'\n\nif os.path.exists(image_config_file):\n    with open(image_config_file) as fp:\n        exec(compile(fp.read(), image_config_file, 'exec'), globals())\n""
       }
     },
     {",Yes
examples/source-to-image/templates.json,examples/source-to-image/templates.json,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/examples/source-to-image/templates.json b/examples/source-to-image/templates.json
index 3f6817af..e335fc68 100644
--- a/examples/source-to-image/templates.json
+++ b/examples/source-to-image/templates.json
@@ -221,7 +221,7 @@
             }
           },
           ""data"": {
-            ""jupyter_server_config.py"": ""import os\n\npassword = os.environ.get('JUPYTER_NOTEBOOK_PASSWORD')\n\nif password:\n    import notebook.auth\n    c.NotebookApp.password = notebook.auth.passwd(password)\n    del password\n    del os.environ['JUPYTER_NOTEBOOK_PASSWORD']\n\nimage_config_file = '/home/jovyan/.jupyter/jupyter_server_config.py'\n\nif os.path.exists(image_config_file):\n    with open(image_config_file) as fp:\n        exec(compile(fp.read(), image_config_file, 'exec'), globals())\n""
+            ""jupyter_server_config.py"": ""import os\n\npassword = os.environ.get('JUPYTER_NOTEBOOK_PASSWORD')\n\nif password:\n    from jupyter_server.auth import passwd\n    c.ServerApp.password = passwd(password)\n    del password\n    del os.environ['JUPYTER_NOTEBOOK_PASSWORD']\n\nimage_config_file = '/home/jovyan/.jupyter/jupyter_server_config.py'\n\nif os.path.exists(image_config_file):\n    with open(image_config_file) as fp:\n        exec(compile(fp.read(), image_config_file, 'exec'), globals())\n""
           }
         },
         {","diff --git a/examples/source-to-image/templates.json b/examples/source-to-image/templates.json
index 3f6817af..e335fc68 100644
--- a/examples/source-to-image/templates.json
+++ b/examples/source-to-image/templates.json
@@ -221,7 +221,7 @@
             }
           },
           ""data"": {
-            ""jupyter_server_config.py"": ""import os\n\npassword = os.environ.get('JUPYTER_NOTEBOOK_PASSWORD')\n\nif password:\n    import notebook.auth\n    c.NotebookApp.password = notebook.auth.passwd(password)\n    del password\n    del os.environ['JUPYTER_NOTEBOOK_PASSWORD']\n\nimage_config_file = '/home/jovyan/.jupyter/jupyter_server_config.py'\n\nif os.path.exists(image_config_file):\n    with open(image_config_file) as fp:\n        exec(compile(fp.read(), image_config_file, 'exec'), globals())\n""
+            ""jupyter_server_config.py"": ""import os\n\npassword = os.environ.get('JUPYTER_NOTEBOOK_PASSWORD')\n\nif password:\n    from jupyter_server.auth import passwd\n    c.ServerApp.password = passwd(password)\n    del password\n    del os.environ['JUPYTER_NOTEBOOK_PASSWORD']\n\nimage_config_file = '/home/jovyan/.jupyter/jupyter_server_config.py'\n\nif os.path.exists(image_config_file):\n    with open(image_config_file) as fp:\n        exec(compile(fp.read(), image_config_file, 'exec'), globals())\n""
           }
         },
         {",Yes
tests/base-notebook/test_container_options.py,tests/base-notebook/test_container_options.py,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 33a85622..6fa2e81f 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -16,7 +16,7 @@ def test_cli_args(container: TrackedContainer, http_client: requests.Session) ->
     (e.g., disabling token security)""""""
     host_port = find_free_port()
     running_container = container.run_detached(
-        command=[""start-notebook.sh"", ""--NotebookApp.token=''""],
+        command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
         ports={""8888/tcp"": host_port},
     )
     resp = http_client.get(f""http://localhost:{host_port}"")
@@ -103,7 +103,7 @@ def test_custom_internal_port(
     host_port = find_free_port()
     internal_port = env.get(""JUPYTER_PORT"", 8888)
     running_container = container.run_detached(
-        command=[""start-notebook.sh"", ""--NotebookApp.token=''""],
+        command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
         environment=env,
         ports={internal_port: host_port},
     )","diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 33a85622..6fa2e81f 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -16,7 +16,7 @@ def test_cli_args(container: TrackedContainer, http_client: requests.Session) ->
     (e.g., disabling token security)""""""
     host_port = find_free_port()
     running_container = container.run_detached(
-        command=[""start-notebook.sh"", ""--NotebookApp.token=''""],
+        command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
         ports={""8888/tcp"": host_port},
     )
     resp = http_client.get(f""http://localhost:{host_port}"")
@@ -103,7 +103,7 @@ def test_custom_internal_port(
     host_port = find_free_port()
     internal_port = env.get(""JUPYTER_PORT"", 8888)
     running_container = container.run_detached(
-        command=[""start-notebook.sh"", ""--NotebookApp.token=''""],
+        command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
         environment=env,
         ports={internal_port: host_port},
     )",Yes
tests/base-notebook/test_healthcheck.py,tests/base-notebook/test_healthcheck.py,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 3c779803..2b15faf6 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -22,23 +22,23 @@ LOGGER = logging.getLogger(__name__)
         ([""RESTARTABLE=yes""], None, None),
         ([""JUPYTER_PORT=8171""], None, None),
         ([""JUPYTER_PORT=8117"", ""DOCKER_STACKS_JUPYTER_CMD=notebook""], None, None),
-        (None, [""start-notebook.sh"", ""--NotebookApp.base_url=/test""], None),
-        (None, [""start-notebook.sh"", ""--NotebookApp.base_url=/test/""], None),
-        ([""GEN_CERT=1""], [""start-notebook.sh"", ""--NotebookApp.base_url=/test""], None),
+        (None, [""start-notebook.sh"", ""--ServerApp.base_url=/test""], None),
+        (None, [""start-notebook.sh"", ""--ServerApp.base_url=/test/""], None),
+        ([""GEN_CERT=1""], [""start-notebook.sh"", ""--ServerApp.base_url=/test""], None),
         (
             [""GEN_CERT=1"", ""JUPYTER_PORT=7891""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             None,
         ),
         ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, ""root""),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
     ],
@@ -75,12 +75,12 @@ def test_health(
         ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, None),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             None,
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             None,
         ),
     ],","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 3c779803..2b15faf6 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -22,23 +22,23 @@ LOGGER = logging.getLogger(__name__)
         ([""RESTARTABLE=yes""], None, None),
         ([""JUPYTER_PORT=8171""], None, None),
         ([""JUPYTER_PORT=8117"", ""DOCKER_STACKS_JUPYTER_CMD=notebook""], None, None),
-        (None, [""start-notebook.sh"", ""--NotebookApp.base_url=/test""], None),
-        (None, [""start-notebook.sh"", ""--NotebookApp.base_url=/test/""], None),
-        ([""GEN_CERT=1""], [""start-notebook.sh"", ""--NotebookApp.base_url=/test""], None),
+        (None, [""start-notebook.sh"", ""--ServerApp.base_url=/test""], None),
+        (None, [""start-notebook.sh"", ""--ServerApp.base_url=/test/""], None),
+        ([""GEN_CERT=1""], [""start-notebook.sh"", ""--ServerApp.base_url=/test""], None),
         (
             [""GEN_CERT=1"", ""JUPYTER_PORT=7891""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             None,
         ),
         ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, ""root""),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
     ],
@@ -75,12 +75,12 @@ def test_health(
         ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, None),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             None,
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
-            [""start-notebook.sh"", ""--NotebookApp.base_url=/test""],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
             None,
         ),
     ],",Yes
tests/base-notebook/test_start_container.py,tests/base-notebook/test_start_container.py,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index 14418288..556f4c2c 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -45,7 +45,6 @@ def test_start_notebook(
     running_container = container.run_detached(
         tty=True,
         environment=env,
-        command=[""start-notebook.sh""],
         ports={""8888/tcp"": host_port},
     )
     # sleeping some time to let the server start","diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index 14418288..556f4c2c 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -45,7 +45,6 @@ def test_start_notebook(
     running_container = container.run_detached(
         tty=True,
         environment=env,
-        command=[""start-notebook.sh""],
         ports={""8888/tcp"": host_port},
     )
     # sleeping some time to let the server start",Yes
tests/pluto_check.py,tests/pluto_check.py,bfe5f20914d0b049c10f65392ac7c9371f3406be,75ca54d55008a641b6896d8af65247233127ac90,Use correct ServerApp options in examples and tests (#1947),"diff --git a/tests/pluto_check.py b/tests/pluto_check.py
index 8a39509c..5fc269de 100644
--- a/tests/pluto_check.py
+++ b/tests/pluto_check.py
@@ -18,11 +18,8 @@ def check_pluto_proxy(
     token = secrets.token_hex()
     container.run_detached(
         command=[
-            ""start.sh"",
-            ""jupyter"",
-            ""lab"",
-            ""--port=8888"",
-            f""--LabApp.token={token}"",
+            ""start-notebook.sh"",
+            f""--IdentityProvider.token={token}"",
         ],
         ports={""8888/tcp"": host_port},
     )","diff --git a/tests/pluto_check.py b/tests/pluto_check.py
index 8a39509c..5fc269de 100644
--- a/tests/pluto_check.py
+++ b/tests/pluto_check.py
@@ -18,11 +18,8 @@ def check_pluto_proxy(
     token = secrets.token_hex()
     container.run_detached(
         command=[
-            ""start.sh"",
-            ""jupyter"",
-            ""lab"",
-            ""--port=8888"",
-            f""--LabApp.token={token}"",
+            ""start-notebook.sh"",
+            f""--IdentityProvider.token={token}"",
         ],
         ports={""8888/tcp"": host_port},
     )",Yes
tests/base-notebook/test_packages.py,tests/base-notebook/test_packages.py,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,bfe5f20914d0b049c10f65392ac7c9371f3406be,Temporarily disable tests using conda --json output,"diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index b56d6120..9f6fef90 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -168,6 +168,9 @@ def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     )
 
 
+@pytest.mark.skip(
+    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
+)
 def test_r_packages(
     package_helper: CondaPackageHelper, r_packages: Iterable[str]
 ) -> None:
@@ -181,6 +184,9 @@ def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     return map(get_package_import_name, filter(python_package_predicate, packages))
 
 
+@pytest.mark.skip(
+    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
+)
 def test_python_packages(
     package_helper: CondaPackageHelper,
     python_packages: Iterable[str],","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index b56d6120..9f6fef90 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -168,6 +168,9 @@ def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     )
 
 
+@pytest.mark.skip(
+    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
+)
 def test_r_packages(
     package_helper: CondaPackageHelper, r_packages: Iterable[str]
 ) -> None:
@@ -181,6 +184,9 @@ def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     return map(get_package_import_name, filter(python_package_predicate, packages))
 
 
+@pytest.mark.skip(
+    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
+)
 def test_python_packages(
     package_helper: CondaPackageHelper,
     python_packages: Iterable[str],",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index a3aba057..a76cbf52 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -97,7 +97,7 @@ body:
       description: |
         A clear and concise description of what the bug is.
       placeholder: |
-        Example: No output is visible in the notebook and the notebook server log contains messages about ...
+        Example: No output is visible in the notebook and the Server log contains messages about ...
     validations:
       required: true","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index a3aba057..a76cbf52 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -97,7 +97,7 @@ body:
       description: |
         A clear and concise description of what the bug is.
       placeholder: |
-        Example: No output is visible in the notebook and the notebook server log contains messages about ...
+        Example: No output is visible in the notebook and the Server log contains messages about ...
     validations:
       required: true",Yes
README.md,README.md,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/README.md b/README.md
index 7d764bf9..714c2dad 100644
--- a/README.md
+++ b/README.md
@@ -11,7 +11,7 @@ You can use a stack image to do any of the following (and more):
 
 - Start a personal Jupyter Server with the JupyterLab frontend (default)
 - Run JupyterLab for a team using JupyterHub
-- Start a personal Jupyter Notebook server in a local Docker container
+- Start a personal Jupyter Server with the Jupyter Notebook frontend in a local Docker container
 - Write your own project Dockerfile
 
 ## Quick Start
@@ -20,14 +20,14 @@ You can try a [relatively recent build of the jupyter/base-notebook image on myb
 by simply clicking the preceding link.
 Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
 know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use
-and want to launch a single Jupyter Server in a container.
+and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.
 
 **Example 1:**
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts a container running a Jupyter Server and exposes the container's internal port `8888` to port `10000` of the host machine:
+It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
 docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-25
@@ -41,12 +41,12 @@ where:
 - `hostname` is the name of the computer running Docker
 - `token` is the secret token printed in the console.
 
-The container remains intact for restart after the Jupyter Server exits.
+The container remains intact for restart after the Server exits.
 
 **Example 2:**
 
 This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts an _ephemeral_ container running a Jupyter Server and exposes the server on host port 10000.
+It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
 docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-25
@@ -83,18 +83,13 @@ We'd also like to invite members of the community to help with two maintainer ac
 Anyone in the community can jump in and help with these activities anytime.
 We will happily grant additional permissions (e.g., the ability to merge PRs) to anyone who shows an ongoing interest in working on the project.
 
-## Jupyter Notebook Deprecation Notice
+## Choosing Jupyter frontend
 
-Following [Jupyter Notebook notice](https://github.com/jupyter/notebook#notice), JupyterLab is now the default for all the Jupyter Docker stack images.
+JupyterLab is the default for all the Jupyter Docker Stacks images.
 It is still possible to switch back to Jupyter Notebook (or to launch a different startup command).
 You can achieve this by passing the environment variable `DOCKER_STACKS_JUPYTER_CMD=notebook` (or any other valid `jupyter` subcommand) at container startup;
 more information is available in the [documentation](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#alternative-commands).
 
-According to the Jupyter Notebook project status and its compatibility with JupyterLab,
-these Docker images may remove the classic Jupyter Notebook interface altogether in favor of another _classic-like_ UI built atop JupyterLab.
-
-This change is tracked in the issue [#1217](https://github.com/jupyter/docker-stacks/issues/1217); please check its content for more information.
-
 ## Alternatives
 
 - [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) - Turn git repositories into","diff --git a/README.md b/README.md
index 7d764bf9..714c2dad 100644
--- a/README.md
+++ b/README.md
@@ -11,7 +11,7 @@ You can use a stack image to do any of the following (and more):
 
 - Start a personal Jupyter Server with the JupyterLab frontend (default)
 - Run JupyterLab for a team using JupyterHub
-- Start a personal Jupyter Notebook server in a local Docker container
+- Start a personal Jupyter Server with the Jupyter Notebook frontend in a local Docker container
 - Write your own project Dockerfile
 
 ## Quick Start
@@ -20,14 +20,14 @@ You can try a [relatively recent build of the jupyter/base-notebook image on myb
 by simply clicking the preceding link.
 Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
 know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use
-and want to launch a single Jupyter Server in a container.
+and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.
 
 **Example 1:**
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts a container running a Jupyter Server and exposes the container's internal port `8888` to port `10000` of the host machine:
+It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
 docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-25
@@ -41,12 +41,12 @@ where:
 - `hostname` is the name of the computer running Docker
 - `token` is the secret token printed in the console.
 
-The container remains intact for restart after the Jupyter Server exits.
+The container remains intact for restart after the Server exits.
 
 **Example 2:**
 
 This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts an _ephemeral_ container running a Jupyter Server and exposes the server on host port 10000.
+It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
 docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-25
@@ -83,18 +83,13 @@ We'd also like to invite members of the community to help with two maintainer ac
 Anyone in the community can jump in and help with these activities anytime.
 We will happily grant additional permissions (e.g., the ability to merge PRs) to anyone who shows an ongoing interest in working on the project.
 
-## Jupyter Notebook Deprecation Notice
+## Choosing Jupyter frontend
 
-Following [Jupyter Notebook notice](https://github.com/jupyter/notebook#notice), JupyterLab is now the default for all the Jupyter Docker stack images.
+JupyterLab is the default for all the Jupyter Docker Stacks images.
 It is still possible to switch back to Jupyter Notebook (or to launch a different startup command).
 You can achieve this by passing the environment variable `DOCKER_STACKS_JUPYTER_CMD=notebook` (or any other valid `jupyter` subcommand) at container startup;
 more information is available in the [documentation](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#alternative-commands).
 
-According to the Jupyter Notebook project status and its compatibility with JupyterLab,
-these Docker images may remove the classic Jupyter Notebook interface altogether in favor of another _classic-like_ UI built atop JupyterLab.
-
-This change is tracked in the issue [#1217](https://github.com/jupyter/docker-stacks/issues/1217); please check its content for more information.
-
 ## Alternatives
 
 - [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) - Turn git repositories into",Yes
base-notebook/Dockerfile,base-notebook/Dockerfile,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/base-notebook/Dockerfile b/base-notebook/Dockerfile
index 45260fe0..5f47a5d4 100644
--- a/base-notebook/Dockerfile
+++ b/base-notebook/Dockerfile
@@ -12,7 +12,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for notebook server that starts but lacks all
+# Install all OS dependencies for Server that starts but lacks all
 # features (e.g., download as all possible file formats)
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
@@ -28,19 +28,19 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
-# Install Jupyter Notebook, Lab, and Hub
-# Generate a notebook server config
+# Install JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
+# Generate a Jupyter Server config
 # Cleanup temporary files
 # Correct permissions
 # Do all this in a single RUN command to avoid duplicating all of the
 # files across image layers when the permissions change
 WORKDIR /tmp
 RUN mamba install --yes \
+    'jupyterlab' \
     'notebook' \
     'jupyterhub' \
-    'jupyterlab' \
     'nbclassic' && \
-    jupyter notebook --generate-config && \
+    jupyter server --generate-config && \
     mamba clean --all -f -y && \
     npm cache clean --force && \
     jupyter lab clean && \","diff --git a/base-notebook/Dockerfile b/base-notebook/Dockerfile
index 45260fe0..5f47a5d4 100644
--- a/base-notebook/Dockerfile
+++ b/base-notebook/Dockerfile
@@ -12,7 +12,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for notebook server that starts but lacks all
+# Install all OS dependencies for Server that starts but lacks all
 # features (e.g., download as all possible file formats)
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
@@ -28,19 +28,19 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
-# Install Jupyter Notebook, Lab, and Hub
-# Generate a notebook server config
+# Install JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
+# Generate a Jupyter Server config
 # Cleanup temporary files
 # Correct permissions
 # Do all this in a single RUN command to avoid duplicating all of the
 # files across image layers when the permissions change
 WORKDIR /tmp
 RUN mamba install --yes \
+    'jupyterlab' \
     'notebook' \
     'jupyterhub' \
-    'jupyterlab' \
     'nbclassic' && \
-    jupyter notebook --generate-config && \
+    jupyter server --generate-config && \
     mamba clean --all -f -y && \
     npm cache clean --force && \
     jupyter lab clean && \",Yes
base-notebook/jupyter_server_config.py,base-notebook/jupyter_server_config.py,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/base-notebook/jupyter_server_config.py b/base-notebook/jupyter_server_config.py
index 679f96be..c4c50147 100644
--- a/base-notebook/jupyter_server_config.py
+++ b/base-notebook/jupyter_server_config.py
@@ -53,7 +53,6 @@ if ""GEN_CERT"" in os.environ:
     os.chmod(pem_file, stat.S_IRUSR | stat.S_IWUSR)
     c.ServerApp.certfile = pem_file
 
-# Change default umask for all subprocesses of the notebook server if set in
-# the environment
+# Change default umask for all subprocesses of the Server if set in the environment
 if ""NB_UMASK"" in os.environ:
     os.umask(int(os.environ[""NB_UMASK""], 8))","diff --git a/base-notebook/jupyter_server_config.py b/base-notebook/jupyter_server_config.py
index 679f96be..c4c50147 100644
--- a/base-notebook/jupyter_server_config.py
+++ b/base-notebook/jupyter_server_config.py
@@ -53,7 +53,6 @@ if ""GEN_CERT"" in os.environ:
     os.chmod(pem_file, stat.S_IRUSR | stat.S_IWUSR)
     c.ServerApp.certfile = pem_file
 
-# Change default umask for all subprocesses of the notebook server if set in
-# the environment
+# Change default umask for all subprocesses of the Server if set in the environment
 if ""NB_UMASK"" in os.environ:
     os.umask(int(os.environ[""NB_UMASK""], 8))",Yes
binder/README.ipynb,binder/README.ipynb,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/binder/README.ipynb b/binder/README.ipynb
index 4116a188..66630c9e 100644
--- a/binder/README.ipynb
+++ b/binder/README.ipynb
@@ -28,7 +28,7 @@
    ""cell_type"": ""markdown"",
    ""metadata"": {},
    ""source"": [
-    ""The notebook server is running as the following user.""
+    ""The Server is running as the following user.""
    ]
   },
   {
@@ -128,7 +128,7 @@
    ""name"": ""python"",
    ""nbconvert_exporter"": ""python"",
    ""pygments_lexer"": ""ipython3"",
-   ""version"": ""3.9.10""
+   ""version"": ""3.11.4""
   }
  },
  ""nbformat"": 4,","diff --git a/binder/README.ipynb b/binder/README.ipynb
index 4116a188..66630c9e 100644
--- a/binder/README.ipynb
+++ b/binder/README.ipynb
@@ -28,7 +28,7 @@
    ""cell_type"": ""markdown"",
    ""metadata"": {},
    ""source"": [
-    ""The notebook server is running as the following user.""
+    ""The Server is running as the following user.""
    ]
   },
   {
@@ -128,7 +128,7 @@
    ""name"": ""python"",
    ""nbconvert_exporter"": ""python"",
    ""pygments_lexer"": ""ipython3"",
-   ""version"": ""3.9.10""
+   ""version"": ""3.11.4""
   }
  },
  ""nbformat"": 4,",Yes
docker-stacks-foundation/Dockerfile,docker-stacks-foundation/Dockerfile,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/docker-stacks-foundation/Dockerfile b/docker-stacks-foundation/Dockerfile
index d87dad6d..e6868736 100644
--- a/docker-stacks-foundation/Dockerfile
+++ b/docker-stacks-foundation/Dockerfile
@@ -18,8 +18,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for notebook server that starts but lacks all
-# features (e.g., download as all possible file formats)
+# Install all OS dependencies for Server that starts
+# but lacks all features (e.g., download as all possible file formats)
 ENV DEBIAN_FRONTEND noninteractive
 RUN apt-get update --yes && \
     # - apt-get upgrade is run to patch known vulnerabilities in apt-get packages as","diff --git a/docker-stacks-foundation/Dockerfile b/docker-stacks-foundation/Dockerfile
index d87dad6d..e6868736 100644
--- a/docker-stacks-foundation/Dockerfile
+++ b/docker-stacks-foundation/Dockerfile
@@ -18,8 +18,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for notebook server that starts but lacks all
-# features (e.g., download as all possible file formats)
+# Install all OS dependencies for Server that starts
+# but lacks all features (e.g., download as all possible file formats)
 ENV DEBIAN_FRONTEND noninteractive
 RUN apt-get update --yes && \
     # - apt-get upgrade is run to patch known vulnerabilities in apt-get packages as",Yes
docs/contributing/features.md,docs/contributing/features.md,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 08c1331f..86c6289e 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -20,7 +20,7 @@ Please follow the process below to suggest a new feature for inclusion in one of
 Roughly speaking, we evaluate new features based on the following criteria:
 
 - **Usefulness to Jupyter users**: Is the feature generally applicable across domains? Does it work
-  with Jupyter Notebook, JupyterLab, JupyterHub, etc.?
+  with JupyterLab, Jupyter Notebook, JupyterHub, etc.?
 - **Fit with the image purpose**: Does the feature match the theme of the stack in which it will be
   added? Would it fit better in a new community stack?
 - **Complexity of build/runtime configuration**: How many lines of code does the feature require","diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 08c1331f..86c6289e 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -20,7 +20,7 @@ Please follow the process below to suggest a new feature for inclusion in one of
 Roughly speaking, we evaluate new features based on the following criteria:
 
 - **Usefulness to Jupyter users**: Is the feature generally applicable across domains? Does it work
-  with Jupyter Notebook, JupyterLab, JupyterHub, etc.?
+  with JupyterLab, Jupyter Notebook, JupyterHub, etc.?
 - **Fit with the image purpose**: Does the feature match the theme of the stack in which it will be
   added? Would it fit better in a new community stack?
 - **Complexity of build/runtime configuration**: How many lines of code does the feature require",Yes
docs/using/common.md,docs/using/common.md,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/docs/using/common.md b/docs/using/common.md
index 790eb2d6..6e04e5f8 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -1,6 +1,6 @@
 # Common Features
 
-Except for `jupyter/docker-stacks-foundation`, a container launched from any Jupyter Docker Stacks image runs a Jupyter Server with a JupyterLab frontend.
+Except for `jupyter/docker-stacks-foundation`, a container launched from any Jupyter Docker Stacks image runs a Jupyter Server with the JupyterLab frontend.
 The container does so by executing a `start-notebook.sh` script.
 This script configures the internal container environment and then runs `jupyter lab`, passing any command-line arguments received.
 
@@ -8,9 +8,9 @@ This page describes the options supported by the startup script and how to bypas
 
 ## Jupyter Server Options
 
-You can pass [Jupyter server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.sh` script when launching the container.
+You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.sh` script when launching the container.
 
-1. For example, to secure the Notebook server with a [custom password](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#preparing-a-hashed-password)
+1. For example, to secure the Jupyter Server with a [custom password](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#preparing-a-hashed-password)
    hashed using `jupyter_server.auth.passwd()` instead of the default token,
    you can run the following (this hash was generated for the `my-password` password):
 
@@ -19,7 +19,7 @@ You can pass [Jupyter server options](https://jupyter-server.readthedocs.io/en/l
        start-notebook.sh --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
-2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the notebook server, you can run the following:
+2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
    docker run  -it --rm -p 8888:8888 jupyter/base-notebook \
@@ -28,7 +28,7 @@ You can pass [Jupyter server options](https://jupyter-server.readthedocs.io/en/l
 
 ## Docker Options
 
-You may instruct the `start-notebook.sh` script to customize the container environment before launching the notebook server.
+You may instruct the `start-notebook.sh` script to customize the container environment before launching the Server.
 You do so by passing arguments to the `docker run` command.
 
 ### User-related configurations
@@ -133,7 +133,7 @@ or executables (`chmod +x`) to be run to the paths below:
 
 - `/usr/local/bin/start-notebook.d/` - handled **before** any of the standard options noted above are applied
 - `/usr/local/bin/before-notebook.d/` - handled **after** all the standard options noted above are applied
-  and ran right before the notebook server launches
+  and ran right before the Server launches
 
 See the `run-hooks` function in the [`jupyter/base-notebook start.sh`](https://github.com/jupyter/docker-stacks/blob/main/docker-stacks-foundation/start.sh)
 script for execution details.
@@ -163,7 +163,7 @@ docker run -it --rm -p 8888:8888 \
     --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
 
-In either case, Jupyter Notebook expects the key and certificate to be a **base64 encoded text file**.
+In either case, Jupyter Server expects the key and certificate to be a **base64 encoded text file**.
 The certificate file or PEM may contain one or more certificates (e.g., server, intermediate, and root).
 
 For additional information about using SSL, see the following:
@@ -174,7 +174,7 @@ For additional information about using SSL, see the following:
 - The [`jupyter_server_config.py`](https://github.com/jupyter/docker-stacks/blob/main/base-notebook/jupyter_server_config.py)
   file for how this Docker image generates a self-signed certificate.
 - The [Jupyter Server documentation](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#securing-a-jupyter-server)
-  for best practices about securing a public notebook server in general.
+  for best practices about securing a public Server in general.
 
 ## Alternative Commands
 
@@ -184,31 +184,32 @@ JupyterLab, built on top of Jupyter Server, is now the default for all the image
 However, switching back to the classic notebook or using a different startup command is still possible.
 You can achieve this by setting the environment variable `DOCKER_STACKS_JUPYTER_CMD` at container startup.
 The table below shows some options.
+Since `Jupyter Notebook v7` `jupyter-server` is used as a backend.
 
-| `DOCKER_STACKS_JUPYTER_CMD` | Backend          | Frontend         |
-| --------------------------- | ---------------- | ---------------- |
-| `lab` (default)             | Jupyter Server   | JupyterLab       |
-| `notebook`                  | Jupyter Notebook | Jupyter Notebook |
-| `nbclassic`                 | Jupyter Server   | Jupyter Notebook |
-| `server`                    | Jupyter Server   | None             |
-| `retro`\*                   | Jupyter Server   | RetroLab         |
+| `DOCKER_STACKS_JUPYTER_CMD` | Frontend         |
+| --------------------------- | ---------------- |
+| `lab` (default)             | JupyterLab       |
+| `notebook`                  | Jupyter Notebook |
+| `nbclassic`                 | NbClassic        |
+| `server`                    | None             |
+| `retro`\*                   | RetroLab         |
 
 Notes:
 
 - \*Not installed at this time, but it could be the case in the future or in a community stack.
-- Any other valid `jupyter` command that starts the Jupyter server can be used.
+- Any other valid `jupyter` subcommand that starts the Jupyter Application can be used.
 
 Example:
 
 ```bash
-# Run Jupyter Notebook on Jupyter Server
+# Run Jupyter Server with the Jupyter Notebook frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
     jupyter/base-notebook
 # Executing the command: jupyter notebook ...
 
-# Run Jupyter Notebook classic
+# Use Jupyter NBClassic frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=nbclassic \","diff --git a/docs/using/common.md b/docs/using/common.md
index 790eb2d6..6e04e5f8 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -1,6 +1,6 @@
 # Common Features
 
-Except for `jupyter/docker-stacks-foundation`, a container launched from any Jupyter Docker Stacks image runs a Jupyter Server with a JupyterLab frontend.
+Except for `jupyter/docker-stacks-foundation`, a container launched from any Jupyter Docker Stacks image runs a Jupyter Server with the JupyterLab frontend.
 The container does so by executing a `start-notebook.sh` script.
 This script configures the internal container environment and then runs `jupyter lab`, passing any command-line arguments received.
 
@@ -8,9 +8,9 @@ This page describes the options supported by the startup script and how to bypas
 
 ## Jupyter Server Options
 
-You can pass [Jupyter server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.sh` script when launching the container.
+You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.sh` script when launching the container.
 
-1. For example, to secure the Notebook server with a [custom password](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#preparing-a-hashed-password)
+1. For example, to secure the Jupyter Server with a [custom password](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#preparing-a-hashed-password)
    hashed using `jupyter_server.auth.passwd()` instead of the default token,
    you can run the following (this hash was generated for the `my-password` password):
 
@@ -19,7 +19,7 @@ You can pass [Jupyter server options](https://jupyter-server.readthedocs.io/en/l
        start-notebook.sh --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
-2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the notebook server, you can run the following:
+2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
    docker run  -it --rm -p 8888:8888 jupyter/base-notebook \
@@ -28,7 +28,7 @@ You can pass [Jupyter server options](https://jupyter-server.readthedocs.io/en/l
 
 ## Docker Options
 
-You may instruct the `start-notebook.sh` script to customize the container environment before launching the notebook server.
+You may instruct the `start-notebook.sh` script to customize the container environment before launching the Server.
 You do so by passing arguments to the `docker run` command.
 
 ### User-related configurations
@@ -133,7 +133,7 @@ or executables (`chmod +x`) to be run to the paths below:
 
 - `/usr/local/bin/start-notebook.d/` - handled **before** any of the standard options noted above are applied
 - `/usr/local/bin/before-notebook.d/` - handled **after** all the standard options noted above are applied
-  and ran right before the notebook server launches
+  and ran right before the Server launches
 
 See the `run-hooks` function in the [`jupyter/base-notebook start.sh`](https://github.com/jupyter/docker-stacks/blob/main/docker-stacks-foundation/start.sh)
 script for execution details.
@@ -163,7 +163,7 @@ docker run -it --rm -p 8888:8888 \
     --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
 
-In either case, Jupyter Notebook expects the key and certificate to be a **base64 encoded text file**.
+In either case, Jupyter Server expects the key and certificate to be a **base64 encoded text file**.
 The certificate file or PEM may contain one or more certificates (e.g., server, intermediate, and root).
 
 For additional information about using SSL, see the following:
@@ -174,7 +174,7 @@ For additional information about using SSL, see the following:
 - The [`jupyter_server_config.py`](https://github.com/jupyter/docker-stacks/blob/main/base-notebook/jupyter_server_config.py)
   file for how this Docker image generates a self-signed certificate.
 - The [Jupyter Server documentation](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#securing-a-jupyter-server)
-  for best practices about securing a public notebook server in general.
+  for best practices about securing a public Server in general.
 
 ## Alternative Commands
 
@@ -184,31 +184,32 @@ JupyterLab, built on top of Jupyter Server, is now the default for all the image
 However, switching back to the classic notebook or using a different startup command is still possible.
 You can achieve this by setting the environment variable `DOCKER_STACKS_JUPYTER_CMD` at container startup.
 The table below shows some options.
+Since `Jupyter Notebook v7` `jupyter-server` is used as a backend.
 
-| `DOCKER_STACKS_JUPYTER_CMD` | Backend          | Frontend         |
-| --------------------------- | ---------------- | ---------------- |
-| `lab` (default)             | Jupyter Server   | JupyterLab       |
-| `notebook`                  | Jupyter Notebook | Jupyter Notebook |
-| `nbclassic`                 | Jupyter Server   | Jupyter Notebook |
-| `server`                    | Jupyter Server   | None             |
-| `retro`\*                   | Jupyter Server   | RetroLab         |
+| `DOCKER_STACKS_JUPYTER_CMD` | Frontend         |
+| --------------------------- | ---------------- |
+| `lab` (default)             | JupyterLab       |
+| `notebook`                  | Jupyter Notebook |
+| `nbclassic`                 | NbClassic        |
+| `server`                    | None             |
+| `retro`\*                   | RetroLab         |
 
 Notes:
 
 - \*Not installed at this time, but it could be the case in the future or in a community stack.
-- Any other valid `jupyter` command that starts the Jupyter server can be used.
+- Any other valid `jupyter` subcommand that starts the Jupyter Application can be used.
 
 Example:
 
 ```bash
-# Run Jupyter Notebook on Jupyter Server
+# Run Jupyter Server with the Jupyter Notebook frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
     jupyter/base-notebook
 # Executing the command: jupyter notebook ...
 
-# Run Jupyter Notebook classic
+# Use Jupyter NBClassic frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=nbclassic \",Yes
docs/using/recipes.md,docs/using/recipes.md,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 57de144a..7dbaee25 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -145,7 +145,7 @@ docker run -it --rm \
 
 Ref: <https://github.com/jupyter/docker-stacks/issues/999>
 
-## Let's Encrypt a Notebook server
+## Let's Encrypt a Server
 
 See the README for a basic automation here
 <https://github.com/jupyter/docker-stacks/tree/main/examples/make-deploy>
@@ -461,14 +461,14 @@ USER ${NB_UID}
 
 Credit: [britishbadger](https://github.com/britishbadger) from [docker-stacks/issues/369](https://github.com/jupyter/docker-stacks/issues/369)
 
-## Run Jupyter Notebook/Lab inside an already secured environment (i.e., with no token)
+## Run Server inside an already secured environment (i.e., with no token)
 
 (Adapted from [issue 728](https://github.com/jupyter/docker-stacks/issues/728))
 
 The default security is very good.
 There are use cases, encouraged by containers, where the jupyter container and the system it runs within lie inside the security boundary.
 It is convenient to launch the server without a password or token in these use cases.
-In this case, you should use the `start.sh` script to launch the server with no token:
+In this case, you should use the `start-notebook.sh` script to launch the server with no token:
 
 For JupyterLab:","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 57de144a..7dbaee25 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -145,7 +145,7 @@ docker run -it --rm \
 
 Ref: <https://github.com/jupyter/docker-stacks/issues/999>
 
-## Let's Encrypt a Notebook server
+## Let's Encrypt a Server
 
 See the README for a basic automation here
 <https://github.com/jupyter/docker-stacks/tree/main/examples/make-deploy>
@@ -461,14 +461,14 @@ USER ${NB_UID}
 
 Credit: [britishbadger](https://github.com/britishbadger) from [docker-stacks/issues/369](https://github.com/jupyter/docker-stacks/issues/369)
 
-## Run Jupyter Notebook/Lab inside an already secured environment (i.e., with no token)
+## Run Server inside an already secured environment (i.e., with no token)
 
 (Adapted from [issue 728](https://github.com/jupyter/docker-stacks/issues/728))
 
 The default security is very good.
 There are use cases, encouraged by containers, where the jupyter container and the system it runs within lie inside the security boundary.
 It is convenient to launch the server without a password or token in these use cases.
-In this case, you should use the `start.sh` script to launch the server with no token:
+In this case, you should use the `start-notebook.sh` script to launch the server with no token:
 
 For JupyterLab:",Yes
docs/using/running.md,docs/using/running.md,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/docs/using/running.md b/docs/using/running.md
index 125b5f02..923bbbd1 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -16,8 +16,8 @@ The following are some common patterns.
 **Example 1:**
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts a container running a Jupyter Notebook server and exposes the server on host port 8888.
-The server logs appear in the terminal and include a URL to the notebook server.
+It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
+The server logs appear in the terminal and include a URL to the server.
 
 ```bash
 docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-25
@@ -33,7 +33,7 @@ docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-25
 #      or http://127.0.0.1:8888/lab?token=f31f2625f13d131f578fced0fc76b81d10f6c629e92c7099
 ```
 
-Pressing `Ctrl-C` twice shuts down the notebook server but leaves the container intact on disk for later restart or permanent deletion using commands like the following:
+Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on disk for later restart or permanent deletion using commands like the following:
 
 ```bash
 # list containers
@@ -54,14 +54,14 @@ docker rm 221331c047c4
 **Example 2:**
 
 This command pulls the `jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts a container running a Jupyter Notebook server and exposes the server on host port 10000.
-The server logs appear in the terminal and include a URL to the notebook server, but with the internal container port (8888) instead of the correct host port (10000).
+It then starts a container running Server and exposes the server on host port 10000.
+The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
 docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-25
 ```
 
-Pressing `Ctrl-C` twice shuts down the notebook server and immediately destroys the Docker container.
+Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
 New files and changes in `~/work` in the container will be preserved.
 Any other changes made in the container will be lost.
 
@@ -78,7 +78,7 @@ where:
 
 - `--detach`: will run the container in detached mode
 
-You can also use the following docker commands to see the port and notebook server token:
+You can also use the following docker commands to see the port and Jupyter Server token:
 
 ```bash
 # get the random host port assigned to the container port 8888
@@ -131,8 +131,8 @@ subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Si
 ```
 
 This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts a container running a Jupyter Server and exposes the server on host port 10000.
-The server logs appear in the terminal and include a URL to the notebook server, but with the internal container port (8888) instead of the correct host port (10000).
+It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
+The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
 podman run -it --rm -p 10000:8888 \
@@ -156,7 +156,7 @@ The `podman run` option `--userns=auto` will, for instance, not be possible to u
 The example could be improved by investigating more in detail which UIDs and GIDs need to be available in the container and then only map them.
 ```
 
-Pressing `Ctrl-C` twice shuts down the notebook server and immediately destroys the Docker container.
+Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
 New files and changes in `~/work` in the container will be preserved.
 Any other changes made in the container will be lost.","diff --git a/docs/using/running.md b/docs/using/running.md
index 125b5f02..923bbbd1 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -16,8 +16,8 @@ The following are some common patterns.
 **Example 1:**
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts a container running a Jupyter Notebook server and exposes the server on host port 8888.
-The server logs appear in the terminal and include a URL to the notebook server.
+It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
+The server logs appear in the terminal and include a URL to the server.
 
 ```bash
 docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-25
@@ -33,7 +33,7 @@ docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-25
 #      or http://127.0.0.1:8888/lab?token=f31f2625f13d131f578fced0fc76b81d10f6c629e92c7099
 ```
 
-Pressing `Ctrl-C` twice shuts down the notebook server but leaves the container intact on disk for later restart or permanent deletion using commands like the following:
+Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on disk for later restart or permanent deletion using commands like the following:
 
 ```bash
 # list containers
@@ -54,14 +54,14 @@ docker rm 221331c047c4
 **Example 2:**
 
 This command pulls the `jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts a container running a Jupyter Notebook server and exposes the server on host port 10000.
-The server logs appear in the terminal and include a URL to the notebook server, but with the internal container port (8888) instead of the correct host port (10000).
+It then starts a container running Server and exposes the server on host port 10000.
+The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
 docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-25
 ```
 
-Pressing `Ctrl-C` twice shuts down the notebook server and immediately destroys the Docker container.
+Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
 New files and changes in `~/work` in the container will be preserved.
 Any other changes made in the container will be lost.
 
@@ -78,7 +78,7 @@ where:
 
 - `--detach`: will run the container in detached mode
 
-You can also use the following docker commands to see the port and notebook server token:
+You can also use the following docker commands to see the port and Jupyter Server token:
 
 ```bash
 # get the random host port assigned to the container port 8888
@@ -131,8 +131,8 @@ subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Si
 ```
 
 This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
-It then starts a container running a Jupyter Server and exposes the server on host port 10000.
-The server logs appear in the terminal and include a URL to the notebook server, but with the internal container port (8888) instead of the correct host port (10000).
+It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
+The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
 podman run -it --rm -p 10000:8888 \
@@ -156,7 +156,7 @@ The `podman run` option `--userns=auto` will, for instance, not be possible to u
 The example could be improved by investigating more in detail which UIDs and GIDs need to be available in the container and then only map them.
 ```
 
-Pressing `Ctrl-C` twice shuts down the notebook server and immediately destroys the Docker container.
+Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
 New files and changes in `~/work` in the container will be preserved.
 Any other changes made in the container will be lost.",Yes
docs/using/selecting.md,docs/using/selecting.md,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 300f8f05..3723ba45 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -25,7 +25,7 @@ The following sections describe these images, including their contents, relation
 `jupyter/docker-stacks-foundation` is a small image supporting a majority of [options common across all core stacks](common.md).
 It is the basis for all other stacks on which Jupyter-related applications can be built
 (e.g., kernel-based containers, [nbclient](https://github.com/jupyter/nbclient) applications, etc.).
-As such, it does not contain application-level software like Jupyter Notebook server, Jupyter Lab or Jupyter Hub.
+As such, it does not contain application-level software like JupyterLab, Jupyter Notebook or JupyterHub.
 
 It contains:
 
@@ -47,13 +47,13 @@ It contains:
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/base-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/base-notebook/tags/)
 
-`jupyter/base-notebook` adds base Jupyter server applications like Notebook, Jupyter Lab and Jupyter Hub
+`jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
 and serves as the basis for all other stacks besides `jupyter/docker-stacks-foundation`.
 
 It contains:
 
 - Everything in `jupyter/docker-stacks-foundation`
-- Minimally functional Jupyter Notebook server (e.g., no LaTeX support for saving notebooks as PDFs)
+- Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
 - `notebook`, `jupyterhub` and `jupyterlab` packages
 - A `start-notebook.sh` script as the default command
 - A `start-singleuser.sh` script useful for launching containers in JupyterHub","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 300f8f05..3723ba45 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -25,7 +25,7 @@ The following sections describe these images, including their contents, relation
 `jupyter/docker-stacks-foundation` is a small image supporting a majority of [options common across all core stacks](common.md).
 It is the basis for all other stacks on which Jupyter-related applications can be built
 (e.g., kernel-based containers, [nbclient](https://github.com/jupyter/nbclient) applications, etc.).
-As such, it does not contain application-level software like Jupyter Notebook server, Jupyter Lab or Jupyter Hub.
+As such, it does not contain application-level software like JupyterLab, Jupyter Notebook or JupyterHub.
 
 It contains:
 
@@ -47,13 +47,13 @@ It contains:
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/base-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/base-notebook/tags/)
 
-`jupyter/base-notebook` adds base Jupyter server applications like Notebook, Jupyter Lab and Jupyter Hub
+`jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
 and serves as the basis for all other stacks besides `jupyter/docker-stacks-foundation`.
 
 It contains:
 
 - Everything in `jupyter/docker-stacks-foundation`
-- Minimally functional Jupyter Notebook server (e.g., no LaTeX support for saving notebooks as PDFs)
+- Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
 - `notebook`, `jupyterhub` and `jupyterlab` packages
 - A `start-notebook.sh` script as the default command
 - A `start-singleuser.sh` script useful for launching containers in JupyterHub",Yes
examples/docker-compose/README.md,examples/docker-compose/README.md,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index 5846aa7d..26a585f4 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -86,8 +86,8 @@ NAME=your-notebook PORT=9001 WORK_VOLUME=our-work notebook/up.sh
 
 ### How do I run over HTTPS?
 
-To run the notebook server with a self-signed certificate, pass the `--secure` option to the `up.sh` script.
-You must also provide a password, which will be used to secure the notebook server.
+To run the Jupyter Server with a self-signed certificate, pass the `--secure` option to the `up.sh` script.
+You must also provide a password, which will be used to secure the Jupyter Server.
 You can specify the password by setting the `PASSWORD` environment variable, or by passing it to the `up.sh` script.
 
 ```bash","diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index 5846aa7d..26a585f4 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -86,8 +86,8 @@ NAME=your-notebook PORT=9001 WORK_VOLUME=our-work notebook/up.sh
 
 ### How do I run over HTTPS?
 
-To run the notebook server with a self-signed certificate, pass the `--secure` option to the `up.sh` script.
-You must also provide a password, which will be used to secure the notebook server.
+To run the Jupyter Server with a self-signed certificate, pass the `--secure` option to the `up.sh` script.
+You must also provide a password, which will be used to secure the Jupyter Server.
 You can specify the password by setting the `PASSWORD` environment variable, or by passing it to the `up.sh` script.
 
 ```bash",Yes
examples/make-deploy/README.md,examples/make-deploy/README.md,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/examples/make-deploy/README.md b/examples/make-deploy/README.md
index d4fc70fe..0636612c 100644
--- a/examples/make-deploy/README.md
+++ b/examples/make-deploy/README.md
@@ -20,7 +20,7 @@ make virtualbox-vm NAME=dev
 eval $(docker-machine env dev)
 # pull a docker stack and build a local image from it
 make image
-# start a notebook server in a container
+# start a Server in a container
 make notebook
 ```","diff --git a/examples/make-deploy/README.md b/examples/make-deploy/README.md
index d4fc70fe..0636612c 100644
--- a/examples/make-deploy/README.md
+++ b/examples/make-deploy/README.md
@@ -20,7 +20,7 @@ make virtualbox-vm NAME=dev
 eval $(docker-machine env dev)
 # pull a docker stack and build a local image from it
 make image
-# start a notebook server in a container
+# start a Server in a container
 make notebook
 ```",Yes
minimal-notebook/Dockerfile,minimal-notebook/Dockerfile,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/minimal-notebook/Dockerfile b/minimal-notebook/Dockerfile
index a998d2a1..29f3bdda 100644
--- a/minimal-notebook/Dockerfile
+++ b/minimal-notebook/Dockerfile
@@ -12,7 +12,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for fully functional notebook server
+# Install all OS dependencies for fully functional Server
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     # Common useful utilities","diff --git a/minimal-notebook/Dockerfile b/minimal-notebook/Dockerfile
index a998d2a1..29f3bdda 100644
--- a/minimal-notebook/Dockerfile
+++ b/minimal-notebook/Dockerfile
@@ -12,7 +12,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for fully functional notebook server
+# Install all OS dependencies for fully functional Server
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     # Common useful utilities",Yes
tests/base-notebook/test_container_options.py,tests/base-notebook/test_container_options.py,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 6fa2e81f..5fa28d89 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -12,8 +12,7 @@ LOGGER = logging.getLogger(__name__)
 
 
 def test_cli_args(container: TrackedContainer, http_client: requests.Session) -> None:
-    """"""Container should respect notebook server command line args
-    (e.g., disabling token security)""""""
+    """"""Image should respect command line args (e.g., disabling token security)""""""
     host_port = find_free_port()
     running_container = container.run_detached(
         command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
@@ -59,7 +58,7 @@ def test_unsigned_ssl(
     container: TrackedContainer, http_client: requests.Session
 ) -> None:
     """"""Container should generate a self-signed SSL certificate
-    and notebook server should use it to enable HTTPS.
+    and Jupyter Server should use it to enable HTTPS.
     """"""
     host_port = find_free_port()
     running_container = container.run_detached(","diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 6fa2e81f..5fa28d89 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -12,8 +12,7 @@ LOGGER = logging.getLogger(__name__)
 
 
 def test_cli_args(container: TrackedContainer, http_client: requests.Session) -> None:
-    """"""Container should respect notebook server command line args
-    (e.g., disabling token security)""""""
+    """"""Image should respect command line args (e.g., disabling token security)""""""
     host_port = find_free_port()
     running_container = container.run_detached(
         command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
@@ -59,7 +58,7 @@ def test_unsigned_ssl(
     container: TrackedContainer, http_client: requests.Session
 ) -> None:
     """"""Container should generate a self-signed SSL certificate
-    and notebook server should use it to enable HTTPS.
+    and Jupyter Server should use it to enable HTTPS.
     """"""
     host_port = find_free_port()
     running_container = container.run_detached(",Yes
tests/base-notebook/test_notebook.py,tests/base-notebook/test_notebook.py,df06e241034cb28bc7ba5ae014395ff041dff9d4,7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9,"Improve wording in docs about Jupyter Notebook (#1949)

* Improve wording in docs about Jupyter Notebook

* Fixes

* Better naming

* Apply suggestions from code review","diff --git a/tests/base-notebook/test_notebook.py b/tests/base-notebook/test_notebook.py
index 29c2bec7..3985990e 100644
--- a/tests/base-notebook/test_notebook.py
+++ b/tests/base-notebook/test_notebook.py
@@ -8,7 +8,7 @@ from tests.conftest import TrackedContainer, find_free_port
 def test_secured_server(
     container: TrackedContainer, http_client: requests.Session
 ) -> None:
-    """"""Notebook server should eventually request user login.""""""
+    """"""Jupyter Server should eventually request user login.""""""
     host_port = find_free_port()
     container.run_detached(ports={""8888/tcp"": host_port})
     resp = http_client.get(f""http://localhost:{host_port}"")","diff --git a/tests/base-notebook/test_notebook.py b/tests/base-notebook/test_notebook.py
index 29c2bec7..3985990e 100644
--- a/tests/base-notebook/test_notebook.py
+++ b/tests/base-notebook/test_notebook.py
@@ -8,7 +8,7 @@ from tests.conftest import TrackedContainer, find_free_port
 def test_secured_server(
     container: TrackedContainer, http_client: requests.Session
 ) -> None:
-    """"""Notebook server should eventually request user login.""""""
+    """"""Jupyter Server should eventually request user login.""""""
     host_port = find_free_port()
     container.run_detached(ports={""8888/tcp"": host_port})
     resp = http_client.get(f""http://localhost:{host_port}"")",Yes
docs/using/recipes.md,docs/using/recipes.md,3ab837290e2c33e9aefdd6c538568d0b02512a9a,df06e241034cb28bc7ba5ae014395ff041dff9d4,"Update Microsoft SQL Server ODBC driver recipe (#1952)

* Update Microsoft SQL Server ODBC driver recipe

* Fix","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 7dbaee25..0062d672 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -588,7 +588,7 @@ RUN ijsinstall
 The following recipe demonstrates how to add functionality to read from and write to an instance of Microsoft SQL server in your notebook.
 
 ```dockerfile
-ARG BASE_IMAGE=jupyter/tensorflow-notebook
+ARG BASE_IMAGE=jupyter/base-notebook
 
 FROM $BASE_IMAGE
 
@@ -598,18 +598,25 @@ ENV MSSQL_DRIVER ""ODBC Driver 18 for SQL Server""
 ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
 
 RUN apt-get update --yes && \
-    apt-get install --yes --no-install-recommends gnupg2 && \
-    wget --progress=dot:giga https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor > /usr/share/keyrings/microsoft.gpg && \
-    apt-get purge --yes gnupg2 && \
-    echo ""deb [arch=amd64,armhf,arm64 signed-by=/usr/share/keyrings/microsoft.gpg] https://packages.microsoft.com/ubuntu/22.04/prod jammy main"" > /etc/apt/sources.list.d/microsoft.list && \
+    apt-get install --yes --no-install-recommends curl gnupg2 lsb-release && \
+    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
+    curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list && \
     apt-get update --yes && \
     ACCEPT_EULA=Y apt-get install --yes --no-install-recommends msodbcsql18 && \
+    # optional: for bcp and sqlcmd
+    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends mssql-tools18 && \
+    # optional: for unixODBC development headers
+    apt-get install -y unixodbc-dev && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}
 
-RUN pip install --no-cache-dir pyodbc
+RUN mamba install --yes \
+    'pyodbc' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
 ```
 
 You can now use `pyodbc` and `sqlalchemy` to interact with the database.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 7dbaee25..0062d672 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -588,7 +588,7 @@ RUN ijsinstall
 The following recipe demonstrates how to add functionality to read from and write to an instance of Microsoft SQL server in your notebook.
 
 ```dockerfile
-ARG BASE_IMAGE=jupyter/tensorflow-notebook
+ARG BASE_IMAGE=jupyter/base-notebook
 
 FROM $BASE_IMAGE
 
@@ -598,18 +598,25 @@ ENV MSSQL_DRIVER ""ODBC Driver 18 for SQL Server""
 ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
 
 RUN apt-get update --yes && \
-    apt-get install --yes --no-install-recommends gnupg2 && \
-    wget --progress=dot:giga https://packages.microsoft.com/keys/microsoft.asc | gpg --dearmor > /usr/share/keyrings/microsoft.gpg && \
-    apt-get purge --yes gnupg2 && \
-    echo ""deb [arch=amd64,armhf,arm64 signed-by=/usr/share/keyrings/microsoft.gpg] https://packages.microsoft.com/ubuntu/22.04/prod jammy main"" > /etc/apt/sources.list.d/microsoft.list && \
+    apt-get install --yes --no-install-recommends curl gnupg2 lsb-release && \
+    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
+    curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list && \
     apt-get update --yes && \
     ACCEPT_EULA=Y apt-get install --yes --no-install-recommends msodbcsql18 && \
+    # optional: for bcp and sqlcmd
+    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends mssql-tools18 && \
+    # optional: for unixODBC development headers
+    apt-get install -y unixodbc-dev && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}
 
-RUN pip install --no-cache-dir pyodbc
+RUN mamba install --yes \
+    'pyodbc' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
 ```
 
 You can now use `pyodbc` and `sqlalchemy` to interact with the database.",Yes
docs/using/recipes.md,docs/using/recipes.md,6d5d183acfbf4abfbb8283d7951807bae5d0152f,3ab837290e2c33e9aefdd6c538568d0b02512a9a,Update docs on using `mamba install` or `pip install`,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 0062d672..e934da30 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -17,59 +17,57 @@ For example:
 docker run -it --rm \
     --user root \
     -e GRANT_SUDO=yes \
-    jupyter/minimal-notebook
+    jupyter/base-notebook
 ```
 
 **You should only enable `sudo` if you trust the user and/or if the container is running on an isolated host.**
 See [Docker security documentation](https://docs.docker.com/engine/security/userns-remap/) for more information about running containers as `root`.
 
-## Using `mamba install` or `pip install` in a Child Docker image
+## Using `mamba install` (recommended) or `pip install` in a Child Docker image
 
 Create a new Dockerfile like the one shown below.
+To use a requirements.txt file, first, create your `requirements.txt` file with the listing of packages desired.
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/datascience-notebook:2023-07-25
-# Install in the default python3 environment
-RUN pip install --no-cache-dir 'flake8==3.9.2' && \
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'flake8' && \
+    mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
-```
-
-Then build a new image.
 
-```bash
-docker build --rm -t jupyter/my-datascience-notebook .
-```
-
-To use a requirements.txt file, first, create your `requirements.txt` file with the listing of
-packages desired.
-Next, create a new Dockerfile like the one shown below.
-
-```dockerfile
-# Start from a core stack version
-FROM jupyter/datascience-notebook:2023-07-25
 # Install from the requirements.txt file
 COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
-RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
+RUN mamba install --yes --file /tmp/requirements.txt && \
+    mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```
 
-For conda, the Dockerfile is similar:
+`pip` usage is similar:
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/datascience-notebook:2023-07-25
+FROM jupyter/base-notebook
+
+# Install in the default python3 environment
+RUN pip install --no-cache-dir 'flake8' && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
 # Install from the requirements.txt file
 COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
-RUN mamba install --yes --file /tmp/requirements.txt && \
-    mamba clean --all -f -y && \
+RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```
 
-Ref: [docker-stacks/commit/79169618d571506304934a7b29039085e77db78c](https://github.com/jupyter/docker-stacks/commit/79169618d571506304934a7b29039085e77db78c#r15960081)
+Then build a new image.
+
+```bash
+docker build --rm -t jupyter/my-custom-image .
+```
 
 ## Add a custom conda environment and Jupyter kernel","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 0062d672..e934da30 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -17,50 +17,26 @@ For example:
 docker run -it --rm \
     --user root \
     -e GRANT_SUDO=yes \
-    jupyter/minimal-notebook
+    jupyter/base-notebook
 ```
 
 **You should only enable `sudo` if you trust the user and/or if the container is running on an isolated host.**
 See [Docker security documentation](https://docs.docker.com/engine/security/userns-remap/) for more information about running containers as `root`.
 
-## Using `mamba install` or `pip install` in a Child Docker image
+## Using `mamba install` (recommended) or `pip install` in a Child Docker image
 
 Create a new Dockerfile like the one shown below.
+To use a requirements.txt file, first, create your `requirements.txt` file with the listing of packages desired.
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/datascience-notebook:2023-07-25
-# Install in the default python3 environment
-RUN pip install --no-cache-dir 'flake8==3.9.2' && \
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'flake8' && \
+    mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
-```
 
-Then build a new image.
-
-```bash
-docker build --rm -t jupyter/my-datascience-notebook .
-```
-
-To use a requirements.txt file, first, create your `requirements.txt` file with the listing of
-packages desired.
-Next, create a new Dockerfile like the one shown below.
-
-```dockerfile
-# Start from a core stack version
-FROM jupyter/datascience-notebook:2023-07-25
-# Install from the requirements.txt file
-COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
-RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-```
-
-For conda, the Dockerfile is similar:
-
-```dockerfile
-# Start from a core stack version
-FROM jupyter/datascience-notebook:2023-07-25
 # Install from the requirements.txt file
 COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
 RUN mamba install --yes --file /tmp/requirements.txt && \
@@ -69,7 +45,29 @@ RUN mamba install --yes --file /tmp/requirements.txt && \
     fix-permissions ""/home/${NB_USER}""
 ```
 
-Ref: [docker-stacks/commit/79169618d571506304934a7b29039085e77db78c](https://github.com/jupyter/docker-stacks/commit/79169618d571506304934a7b29039085e77db78c#r15960081)
+`pip` usage is similar:
+
+```dockerfile
+# Start from a core stack version
+FROM jupyter/base-notebook
+
+# Install in the default python3 environment
+RUN pip install --no-cache-dir 'flake8' && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Install from the requirements.txt file
+COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
+RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+```
+
+Then build a new image.
+
+```bash
+docker build --rm -t jupyter/my-custom-image .
+```
 
 ## Add a custom conda environment and Jupyter kernel",No
docs/using/faq.md,docs/using/faq.md,25c16a49b7aabca40993699ca35614059fad448d,6d5d183acfbf4abfbb8283d7951807bae5d0152f,Fix markdown reference in docs,"diff --git a/docs/using/faq.md b/docs/using/faq.md
index 6c4856e8..1d417190 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -4,7 +4,7 @@
 
 We have lots of users with different packages they want to use.
 Adding them all is impossible, so we have several images to choose from.
-[Choose the image](selecting.md), that is closest to your needs and feel free to [add your package on top of our images](recipes.md#using-mamba-install-or-pip-install-in-a-child-docker-image).
+[Choose the image](selecting.md), that is closest to your needs and feel free to [add your package on top of our images](recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
 
 ## Who is `jovyan`","diff --git a/docs/using/faq.md b/docs/using/faq.md
index 6c4856e8..1d417190 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -4,7 +4,7 @@
 
 We have lots of users with different packages they want to use.
 Adding them all is impossible, so we have several images to choose from.
-[Choose the image](selecting.md), that is closest to your needs and feel free to [add your package on top of our images](recipes.md#using-mamba-install-or-pip-install-in-a-child-docker-image).
+[Choose the image](selecting.md), that is closest to your needs and feel free to [add your package on top of our images](recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
 
 ## Who is `jovyan`",Yes
docs/using/recipes.md,docs/using/recipes.md,4ee1da08c14ea0d60ecd591ba52dabfc8964946e,25c16a49b7aabca40993699ca35614059fad448d,Do not use :latest tag,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index e934da30..952c412f 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -76,7 +76,7 @@ The instructions below permit adding a conda environment with a different Python
 
 ```dockerfile
 # Choose your desired base image
-FROM jupyter/minimal-notebook:latest
+FROM jupyter/minimal-notebook
 
 # name your environment and choose the python version
 ARG conda_env=python37
@@ -113,7 +113,7 @@ Create the Dockerfile as:
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/scipy-notebook:latest
+FROM jupyter/scipy-notebook
 
 # Install the Dask dashboard
 RUN pip install --no-cache-dir dask-labextension && \
@@ -130,7 +130,7 @@ ENTRYPOINT [""jupyter"", ""lab"", ""--ip=0.0.0.0"", ""--allow-root""]
 And build the image as:
 
 ```bash
-docker build --tag jupyter/scipy-dasklabextension:latest .
+docker build --tag jupyter/scipy-dasklabextension .
 ```
 
 Once built, run using the command:
@@ -138,7 +138,7 @@ Once built, run using the command:
 ```bash
 docker run -it --rm \
     -p 8888:8888 \
-    -p 8787:8787 jupyter/scipy-dasklabextension:latest
+    -p 8787:8787 jupyter/scipy-dasklabextension
 ```
 
 Ref: <https://github.com/jupyter/docker-stacks/issues/999>
@@ -216,7 +216,7 @@ You can use the following Dockerfile to inherit from one of our images to enable
 
 ```dockerfile
 # Choose your desired base image
-ARG BASE_CONTAINER=jupyter/datascience-notebook:latest
+ARG BASE_CONTAINER=jupyter/datascience-notebook
 FROM $BASE_CONTAINER
 
 USER root
@@ -491,7 +491,7 @@ NB: this works for classic notebooks only
 
 ```dockerfile
 # Update with your base image of choice
-FROM jupyter/minimal-notebook:latest
+FROM jupyter/minimal-notebook
 
 USER ${NB_UID}
 
@@ -511,7 +511,7 @@ Please note that the [Delta Lake](https://delta.io/) packages are only available
 By adding the properties to `spark-defaults.conf`, the user no longer needs to enable Delta support in each notebook.
 
 ```dockerfile
-FROM jupyter/pyspark-notebook:latest
+FROM jupyter/pyspark-notebook
 
 ARG DELTA_CORE_VERSION=""1.2.1""
 RUN pip install --no-cache-dir delta-spark==${DELTA_CORE_VERSION} && \
@@ -538,7 +538,7 @@ RUN echo ""from pyspark.sql import SparkSession"" > /tmp/init-delta.py && \
 The example below is a Dockerfile to load Source Han Sans with normal weight, usually used for the web.
 
 ```dockerfile
-FROM jupyter/scipy-notebook:latest
+FROM jupyter/scipy-notebook
 
 RUN PYV=$(ls ""${CONDA_DIR}/lib"" | grep ^python) && \
     MPL_DATA=""${CONDA_DIR}/lib/${PYV}/site-packages/matplotlib/mpl-data"" && \","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index e934da30..952c412f 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -76,7 +76,7 @@ The instructions below permit adding a conda environment with a different Python
 
 ```dockerfile
 # Choose your desired base image
-FROM jupyter/minimal-notebook:latest
+FROM jupyter/minimal-notebook
 
 # name your environment and choose the python version
 ARG conda_env=python37
@@ -113,7 +113,7 @@ Create the Dockerfile as:
 
 ```dockerfile
 # Start from a core stack version
-FROM jupyter/scipy-notebook:latest
+FROM jupyter/scipy-notebook
 
 # Install the Dask dashboard
 RUN pip install --no-cache-dir dask-labextension && \
@@ -130,7 +130,7 @@ ENTRYPOINT [""jupyter"", ""lab"", ""--ip=0.0.0.0"", ""--allow-root""]
 And build the image as:
 
 ```bash
-docker build --tag jupyter/scipy-dasklabextension:latest .
+docker build --tag jupyter/scipy-dasklabextension .
 ```
 
 Once built, run using the command:
@@ -138,7 +138,7 @@ Once built, run using the command:
 ```bash
 docker run -it --rm \
     -p 8888:8888 \
-    -p 8787:8787 jupyter/scipy-dasklabextension:latest
+    -p 8787:8787 jupyter/scipy-dasklabextension
 ```
 
 Ref: <https://github.com/jupyter/docker-stacks/issues/999>
@@ -216,7 +216,7 @@ You can use the following Dockerfile to inherit from one of our images to enable
 
 ```dockerfile
 # Choose your desired base image
-ARG BASE_CONTAINER=jupyter/datascience-notebook:latest
+ARG BASE_CONTAINER=jupyter/datascience-notebook
 FROM $BASE_CONTAINER
 
 USER root
@@ -491,7 +491,7 @@ NB: this works for classic notebooks only
 
 ```dockerfile
 # Update with your base image of choice
-FROM jupyter/minimal-notebook:latest
+FROM jupyter/minimal-notebook
 
 USER ${NB_UID}
 
@@ -511,7 +511,7 @@ Please note that the [Delta Lake](https://delta.io/) packages are only available
 By adding the properties to `spark-defaults.conf`, the user no longer needs to enable Delta support in each notebook.
 
 ```dockerfile
-FROM jupyter/pyspark-notebook:latest
+FROM jupyter/pyspark-notebook
 
 ARG DELTA_CORE_VERSION=""1.2.1""
 RUN pip install --no-cache-dir delta-spark==${DELTA_CORE_VERSION} && \
@@ -538,7 +538,7 @@ RUN echo ""from pyspark.sql import SparkSession"" > /tmp/init-delta.py && \
 The example below is a Dockerfile to load Source Han Sans with normal weight, usually used for the web.
 
 ```dockerfile
-FROM jupyter/scipy-notebook:latest
+FROM jupyter/scipy-notebook
 
 RUN PYV=$(ls ""${CONDA_DIR}/lib"" | grep ^python) && \
     MPL_DATA=""${CONDA_DIR}/lib/${PYV}/site-packages/matplotlib/mpl-data"" && \",Yes
docs/using/recipes.md,docs/using/recipes.md,d3ffd76092f66f871cce5b5d43cb897fbf1a4d7c,4ee1da08c14ea0d60ecd591ba52dabfc8964946e,Unify base image choice,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 952c412f..3096c2ae 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -29,7 +29,6 @@ Create a new Dockerfile like the one shown below.
 To use a requirements.txt file, first, create your `requirements.txt` file with the listing of packages desired.
 
 ```dockerfile
-# Start from a core stack version
 FROM jupyter/base-notebook
 
 RUN mamba install --yes 'flake8' && \
@@ -48,7 +47,6 @@ RUN mamba install --yes --file /tmp/requirements.txt && \
 `pip` usage is similar:
 
 ```dockerfile
-# Start from a core stack version
 FROM jupyter/base-notebook
 
 # Install in the default python3 environment
@@ -75,7 +73,6 @@ The default version of Python that ships with the image may not be the version y
 The instructions below permit adding a conda environment with a different Python version and making it accessible to Jupyter.
 
 ```dockerfile
-# Choose your desired base image
 FROM jupyter/minimal-notebook
 
 # name your environment and choose the python version
@@ -112,7 +109,6 @@ RUN ""${CONDA_DIR}/envs/${conda_env}/bin/python"" -m ipykernel install --user --na
 Create the Dockerfile as:
 
 ```dockerfile
-# Start from a core stack version
 FROM jupyter/scipy-notebook
 
 # Install the Dask dashboard
@@ -215,9 +211,7 @@ Most containers, including our Ubuntu base image, ship without manpages installe
 You can use the following Dockerfile to inherit from one of our images to enable manpages:
 
 ```dockerfile
-# Choose your desired base image
-ARG BASE_CONTAINER=jupyter/datascience-notebook
-FROM $BASE_CONTAINER
+FROM jupyter/datascience-notebookR
 
 USER root
 
@@ -281,7 +275,8 @@ To use a specific version of JupyterHub, the version of `jupyterhub` in your ima
 version in the Hub itself.
 
 ```dockerfile
-FROM jupyter/base-notebook:2023-07-25
+FROM jupyter/base-notebook
+
 RUN pip install --no-cache-dir jupyterhub==1.4.1 && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
@@ -472,7 +467,7 @@ For JupyterLab:
 
 ```bash
 docker run -it --rm \
-    jupyter/base-notebook:2023-07-25 \
+    jupyter/base-notebook \
     start-notebook.sh --IdentityProvider.token=''
 ```
 
@@ -481,7 +476,7 @@ For Jupyter Notebook:
 ```bash
 docker run -it --rm \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    jupyter/base-notebook:2023-07-25 \
+    jupyter/base-notebook \
     start-notebook.sh --IdentityProvider.token=''
 ```
 
@@ -490,7 +485,6 @@ docker run -it --rm \
 NB: this works for classic notebooks only
 
 ```dockerfile
-# Update with your base image of choice
 FROM jupyter/minimal-notebook
 
 USER ${NB_UID}
@@ -573,8 +567,7 @@ docker run -it --rm \
 The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
 
 ```dockerfile
-# use one of the Jupyter Docker Stacks images
-FROM jupyter/scipy-notebook:2023-07-25
+FROM jupyter/scipy-notebook
 
 # install ijavascript
 RUN npm install -g ijavascript
@@ -586,9 +579,7 @@ RUN ijsinstall
 The following recipe demonstrates how to add functionality to read from and write to an instance of Microsoft SQL server in your notebook.
 
 ```dockerfile
-ARG BASE_IMAGE=jupyter/base-notebook
-
-FROM $BASE_IMAGE
+FROM jupyter/base-notebook
 
 USER root","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 952c412f..3096c2ae 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -29,7 +29,6 @@ Create a new Dockerfile like the one shown below.
 To use a requirements.txt file, first, create your `requirements.txt` file with the listing of packages desired.
 
 ```dockerfile
-# Start from a core stack version
 FROM jupyter/base-notebook
 
 RUN mamba install --yes 'flake8' && \
@@ -48,7 +47,6 @@ RUN mamba install --yes --file /tmp/requirements.txt && \
 `pip` usage is similar:
 
 ```dockerfile
-# Start from a core stack version
 FROM jupyter/base-notebook
 
 # Install in the default python3 environment
@@ -75,7 +73,6 @@ The default version of Python that ships with the image may not be the version y
 The instructions below permit adding a conda environment with a different Python version and making it accessible to Jupyter.
 
 ```dockerfile
-# Choose your desired base image
 FROM jupyter/minimal-notebook
 
 # name your environment and choose the python version
@@ -112,7 +109,6 @@ RUN ""${CONDA_DIR}/envs/${conda_env}/bin/python"" -m ipykernel install --user --na
 Create the Dockerfile as:
 
 ```dockerfile
-# Start from a core stack version
 FROM jupyter/scipy-notebook
 
 # Install the Dask dashboard
@@ -215,9 +211,7 @@ Most containers, including our Ubuntu base image, ship without manpages installe
 You can use the following Dockerfile to inherit from one of our images to enable manpages:
 
 ```dockerfile
-# Choose your desired base image
-ARG BASE_CONTAINER=jupyter/datascience-notebook
-FROM $BASE_CONTAINER
+FROM jupyter/datascience-notebookR
 
 USER root
 
@@ -281,7 +275,8 @@ To use a specific version of JupyterHub, the version of `jupyterhub` in your ima
 version in the Hub itself.
 
 ```dockerfile
-FROM jupyter/base-notebook:2023-07-25
+FROM jupyter/base-notebook
+
 RUN pip install --no-cache-dir jupyterhub==1.4.1 && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
@@ -472,7 +467,7 @@ For JupyterLab:
 
 ```bash
 docker run -it --rm \
-    jupyter/base-notebook:2023-07-25 \
+    jupyter/base-notebook \
     start-notebook.sh --IdentityProvider.token=''
 ```
 
@@ -481,7 +476,7 @@ For Jupyter Notebook:
 ```bash
 docker run -it --rm \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    jupyter/base-notebook:2023-07-25 \
+    jupyter/base-notebook \
     start-notebook.sh --IdentityProvider.token=''
 ```
 
@@ -490,7 +485,6 @@ docker run -it --rm \
 NB: this works for classic notebooks only
 
 ```dockerfile
-# Update with your base image of choice
 FROM jupyter/minimal-notebook
 
 USER ${NB_UID}
@@ -573,8 +567,7 @@ docker run -it --rm \
 The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
 
 ```dockerfile
-# use one of the Jupyter Docker Stacks images
-FROM jupyter/scipy-notebook:2023-07-25
+FROM jupyter/scipy-notebook
 
 # install ijavascript
 RUN npm install -g ijavascript
@@ -586,9 +579,7 @@ RUN ijsinstall
 The following recipe demonstrates how to add functionality to read from and write to an instance of Microsoft SQL server in your notebook.
 
 ```dockerfile
-ARG BASE_IMAGE=jupyter/base-notebook
-
-FROM $BASE_IMAGE
+FROM jupyter/base-notebook
 
 USER root",Yes
docs/using/recipes.md,docs/using/recipes.md,5f839cd86b6316666ae41e2c53d764fffd97a06d,d3ffd76092f66f871cce5b5d43cb897fbf1a4d7c,Fix custom image name,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 3096c2ae..c895f659 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -64,7 +64,7 @@ RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
 Then build a new image.
 
 ```bash
-docker build --rm -t jupyter/my-custom-image .
+docker build --rm -t my-custom-image .
 ```
 
 ## Add a custom conda environment and Jupyter kernel","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 3096c2ae..c895f659 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -64,7 +64,7 @@ RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
 Then build a new image.
 
 ```bash
-docker build --rm -t jupyter/my-custom-image .
+docker build --rm -t my-custom-image .
 ```
 
 ## Add a custom conda environment and Jupyter kernel",Yes
docs/using/recipes.md,docs/using/recipes.md,88021e8b520801c0b64cf19bd178622a1df690bc,5f839cd86b6316666ae41e2c53d764fffd97a06d,Fix dask extension recipe,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index c895f659..c570e796 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -109,24 +109,21 @@ RUN ""${CONDA_DIR}/envs/${conda_env}/bin/python"" -m ipykernel install --user --na
 Create the Dockerfile as:
 
 ```dockerfile
-FROM jupyter/scipy-notebook
+FROM jupyter/base-notebook
 
 # Install the Dask dashboard
-RUN pip install --no-cache-dir dask-labextension && \
+RUN mamba install --yes 'dask-labextension' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Dask Scheduler & Bokeh ports
+# Dask Scheduler port
 EXPOSE 8787
-EXPOSE 8786
-
-ENTRYPOINT [""jupyter"", ""lab"", ""--ip=0.0.0.0"", ""--allow-root""]
 ```
 
 And build the image as:
 
 ```bash
-docker build --tag jupyter/scipy-dasklabextension .
+docker build --tag my-custom-image .
 ```
 
 Once built, run using the command:
@@ -134,11 +131,10 @@ Once built, run using the command:
 ```bash
 docker run -it --rm \
     -p 8888:8888 \
-    -p 8787:8787 jupyter/scipy-dasklabextension
+    -p 8787:8787 \
+    my-custom-image
 ```
 
-Ref: <https://github.com/jupyter/docker-stacks/issues/999>
-
 ## Let's Encrypt a Server
 
 See the README for a basic automation here","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index c895f659..c570e796 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -109,24 +109,21 @@ RUN ""${CONDA_DIR}/envs/${conda_env}/bin/python"" -m ipykernel install --user --na
 Create the Dockerfile as:
 
 ```dockerfile
-FROM jupyter/scipy-notebook
+FROM jupyter/base-notebook
 
 # Install the Dask dashboard
-RUN pip install --no-cache-dir dask-labextension && \
+RUN mamba install --yes 'dask-labextension' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Dask Scheduler & Bokeh ports
+# Dask Scheduler port
 EXPOSE 8787
-EXPOSE 8786
-
-ENTRYPOINT [""jupyter"", ""lab"", ""--ip=0.0.0.0"", ""--allow-root""]
 ```
 
 And build the image as:
 
 ```bash
-docker build --tag jupyter/scipy-dasklabextension .
+docker build --tag my-custom-image .
 ```
 
 Once built, run using the command:
@@ -134,11 +131,10 @@ Once built, run using the command:
 ```bash
 docker run -it --rm \
     -p 8888:8888 \
-    -p 8787:8787 jupyter/scipy-dasklabextension
+    -p 8787:8787 \
+    my-custom-image
 ```
 
-Ref: <https://github.com/jupyter/docker-stacks/issues/999>
-
 ## Let's Encrypt a Server
 
 See the README for a basic automation here",Yes
docs/using/recipes.md,docs/using/recipes.md,832dbb97c06a267aa990be4efd89af622b1b9124,88021e8b520801c0b64cf19bd178622a1df690bc,Update rise to suggest JupyterLab extension,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index c570e796..bf4ee113 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -143,22 +143,24 @@ which includes steps for requesting and renewing a Let's Encrypt certificate.
 
 Ref: <https://github.com/jupyter/docker-stacks/issues/78>
 
-## Slideshows with Jupyter and RISE
+## Slideshows with JupyterLab and RISE
 
-[RISE](https://github.com/damianavila/RISE) allows via an extension to create live slideshows of your
-notebooks, with no conversion, adding javascript Reveal.js:
+[RISE](https://github.com/jupyterlab-contrib/rise): ""Live"" Reveal.js JupyterLab Slideshow Extension.
 
-```bash
-# Add Live slideshows with RISE
-RUN mamba install --yes -c damianavila82 rise && \
+```{note}
+We're providing the recipe to install JupyterLab extension.
+You can find the original Jupyter Notebook extenstion [here](http://github.com/damianavila/RISE)
+```
+
+```dockerfile
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'jupyterlab_rise' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```
 
-Credit: [Paolo D.](https://github.com/pdonorio) based on
-[docker-stacks/issues/43](https://github.com/jupyter/docker-stacks/issues/43)
-
 ## xgboost
 
 You need to install conda-forge's gcc for Python xgboost to work correctly.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index c570e796..bf4ee113 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -143,22 +143,24 @@ which includes steps for requesting and renewing a Let's Encrypt certificate.
 
 Ref: <https://github.com/jupyter/docker-stacks/issues/78>
 
-## Slideshows with Jupyter and RISE
+## Slideshows with JupyterLab and RISE
 
-[RISE](https://github.com/damianavila/RISE) allows via an extension to create live slideshows of your
-notebooks, with no conversion, adding javascript Reveal.js:
+[RISE](https://github.com/jupyterlab-contrib/rise): ""Live"" Reveal.js JupyterLab Slideshow Extension.
 
-```bash
-# Add Live slideshows with RISE
-RUN mamba install --yes -c damianavila82 rise && \
+```{note}
+We're providing the recipe to install JupyterLab extension.
+You can find the original Jupyter Notebook extenstion [here](http://github.com/damianavila/RISE)
+```
+
+```dockerfile
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'jupyterlab_rise' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```
 
-Credit: [Paolo D.](https://github.com/pdonorio) based on
-[docker-stacks/issues/43](https://github.com/jupyter/docker-stacks/issues/43)
-
 ## xgboost
 
 You need to install conda-forge's gcc for Python xgboost to work correctly.",Yes
docs/using/recipes.md,docs/using/recipes.md,57d6c600d1b633bda5763d05fba92f5af84b4b4c,832dbb97c06a267aa990be4efd89af622b1b9124,Unify pip installation style,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index bf4ee113..e6abc1f3 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -167,12 +167,12 @@ You need to install conda-forge's gcc for Python xgboost to work correctly.
 Otherwise, you'll get an exception about libgomp.so.1 missing GOMP_4.0.
 
 ```bash
-mamba install --yes gcc && \
+mamba install --yes 'gcc' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-pip install --no-cache-dir xgboost && \
+pip install --no-cache-dir 'xgboost' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
@@ -275,7 +275,7 @@ version in the Hub itself.
 ```dockerfile
 FROM jupyter/base-notebook
 
-RUN pip install --no-cache-dir jupyterhub==1.4.1 && \
+RUN pip install --no-cache-dir 'jupyterhub==1.4.1' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```
@@ -429,9 +429,9 @@ USER ${NB_UID}
 # - Dashboards
 # - PyDoop
 # - PyHive
-RUN pip install --no-cache-dir jupyter_dashboards faker && \
+RUN pip install --no-cache-dir 'jupyter_dashboards' 'faker' && \
     jupyter dashboards quick-setup --sys-prefix && \
-    pip2 install --no-cache-dir pyhive pydoop thrift sasl thrift_sasl faker && \
+    pip2 install --no-cache-dir 'pyhive' 'pydoop' 'thrift' 'sasl' 'thrift_sasl' 'faker' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
@@ -487,7 +487,7 @@ FROM jupyter/minimal-notebook
 
 USER ${NB_UID}
 
-RUN pip install --no-cache-dir jupyter_contrib_nbextensions && \
+RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \
     # can modify or enable additional extensions here
     jupyter nbclassic-extension enable spellchecker/main --user && \
@@ -506,7 +506,7 @@ By adding the properties to `spark-defaults.conf`, the user no longer needs to e
 FROM jupyter/pyspark-notebook
 
 ARG DELTA_CORE_VERSION=""1.2.1""
-RUN pip install --no-cache-dir delta-spark==${DELTA_CORE_VERSION} && \
+RUN pip install --no-cache-dir 'delta-spark==${DELTA_CORE_VERSION}' && \
      fix-permissions ""${HOME}"" && \
      fix-permissions ""${CONDA_DIR}""","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index bf4ee113..e6abc1f3 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -167,12 +167,12 @@ You need to install conda-forge's gcc for Python xgboost to work correctly.
 Otherwise, you'll get an exception about libgomp.so.1 missing GOMP_4.0.
 
 ```bash
-mamba install --yes gcc && \
+mamba install --yes 'gcc' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-pip install --no-cache-dir xgboost && \
+pip install --no-cache-dir 'xgboost' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
@@ -275,7 +275,7 @@ version in the Hub itself.
 ```dockerfile
 FROM jupyter/base-notebook
 
-RUN pip install --no-cache-dir jupyterhub==1.4.1 && \
+RUN pip install --no-cache-dir 'jupyterhub==1.4.1' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```
@@ -429,9 +429,9 @@ USER ${NB_UID}
 # - Dashboards
 # - PyDoop
 # - PyHive
-RUN pip install --no-cache-dir jupyter_dashboards faker && \
+RUN pip install --no-cache-dir 'jupyter_dashboards' 'faker' && \
     jupyter dashboards quick-setup --sys-prefix && \
-    pip2 install --no-cache-dir pyhive pydoop thrift sasl thrift_sasl faker && \
+    pip2 install --no-cache-dir 'pyhive' 'pydoop' 'thrift' 'sasl' 'thrift_sasl' 'faker' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
@@ -487,7 +487,7 @@ FROM jupyter/minimal-notebook
 
 USER ${NB_UID}
 
-RUN pip install --no-cache-dir jupyter_contrib_nbextensions && \
+RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \
     # can modify or enable additional extensions here
     jupyter nbclassic-extension enable spellchecker/main --user && \
@@ -506,7 +506,7 @@ By adding the properties to `spark-defaults.conf`, the user no longer needs to e
 FROM jupyter/pyspark-notebook
 
 ARG DELTA_CORE_VERSION=""1.2.1""
-RUN pip install --no-cache-dir delta-spark==${DELTA_CORE_VERSION} && \
+RUN pip install --no-cache-dir 'delta-spark==${DELTA_CORE_VERSION}' && \
      fix-permissions ""${HOME}"" && \
      fix-permissions ""${CONDA_DIR}""",Yes
docs/using/recipes.md,docs/using/recipes.md,fc29c32237838d767e25c2147f0e0b5eb70b5a4e,57d6c600d1b633bda5763d05fba92f5af84b4b4c,Fix xgboost recipe,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index e6abc1f3..5851e786 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -163,19 +163,14 @@ RUN mamba install --yes 'jupyterlab_rise' && \
 
 ## xgboost
 
-You need to install conda-forge's gcc for Python xgboost to work correctly.
-Otherwise, you'll get an exception about libgomp.so.1 missing GOMP_4.0.
+```dockerfile
+FROM jupyter/base-notebook
 
-```bash
-mamba install --yes 'gcc' && \
+RUN mamba install --yes 'py-xgboost' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-pip install --no-cache-dir 'xgboost' && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
 # run ""import xgboost"" in python
 ```","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index e6abc1f3..5851e786 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -163,19 +163,14 @@ RUN mamba install --yes 'jupyterlab_rise' && \
 
 ## xgboost
 
-You need to install conda-forge's gcc for Python xgboost to work correctly.
-Otherwise, you'll get an exception about libgomp.so.1 missing GOMP_4.0.
+```dockerfile
+FROM jupyter/base-notebook
 
-```bash
-mamba install --yes 'gcc' && \
+RUN mamba install --yes 'py-xgboost' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-pip install --no-cache-dir 'xgboost' && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
 # run ""import xgboost"" in python
 ```",Yes
docs/using/recipes.md,docs/using/recipes.md,37afcd4c85890daf7f4efce9859cc179bba0bdad,fc29c32237838d767e25c2147f0e0b5eb70b5a4e,Update manpage enabling recipe,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 5851e786..c89838a7 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -204,7 +204,7 @@ Most containers, including our Ubuntu base image, ship without manpages installe
 You can use the following Dockerfile to inherit from one of our images to enable manpages:
 
 ```dockerfile
-FROM jupyter/datascience-notebookR
+FROM jupyter/base-notebook
 
 USER root
 
@@ -218,29 +218,17 @@ RUN rm /etc/dpkg/dpkg.cfg.d/excludes && \
 USER ${NB_UID}
 ```
 
-Adding the documentation on top of the existing single-user image wastes a lot of space
+Adding the documentation on top of the existing image wastes a lot of space
 and requires reinstalling every system package,
 which can take additional time and bandwidth.
-The `datascience-notebook` image has been shown to grow by almost 3GB when adding manpages in this way.
 Enabling manpages in the base Ubuntu layer prevents this container bloat.
 To achieve this, use the previous `Dockerfile`'s commands with the original `ubuntu` image as your base container:
 
 ```dockerfile
-ARG BASE_CONTAINER=ubuntu:22.04
-```
-
-For Ubuntu 18.04 (bionic) and earlier, you may also require to a workaround for a mandb bug, which was fixed in mandb >= 2.8.6.1:
-
-```dockerfile
-# https://git.savannah.gnu.org/cgit/man-db.git/commit/?id=8197d7824f814c5d4b992b4c8730b5b0f7ec589a
-# https://launchpadlibrarian.net/435841763/man-db_2.8.5-2_2.8.6-1.diff.gz
-
-RUN echo ""MANPATH_MAP ${CONDA_DIR}/bin ${CONDA_DIR}/man"" >> /etc/manpath.config && \
-    echo ""MANPATH_MAP ${CONDA_DIR}/bin ${CONDA_DIR}/share/man"" >> /etc/manpath.config && \
-    mandb
+FROM ubuntu:22.04
 ```
 
-Be sure to check the current base image in `base-notebook` before building.
+Be sure to check the current base image in `jupyter/docker-stacks-foundation` before building.
 
 ## JupyterHub","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 5851e786..c89838a7 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -204,7 +204,7 @@ Most containers, including our Ubuntu base image, ship without manpages installe
 You can use the following Dockerfile to inherit from one of our images to enable manpages:
 
 ```dockerfile
-FROM jupyter/datascience-notebookR
+FROM jupyter/base-notebook
 
 USER root
 
@@ -218,29 +218,17 @@ RUN rm /etc/dpkg/dpkg.cfg.d/excludes && \
 USER ${NB_UID}
 ```
 
-Adding the documentation on top of the existing single-user image wastes a lot of space
+Adding the documentation on top of the existing image wastes a lot of space
 and requires reinstalling every system package,
 which can take additional time and bandwidth.
-The `datascience-notebook` image has been shown to grow by almost 3GB when adding manpages in this way.
 Enabling manpages in the base Ubuntu layer prevents this container bloat.
 To achieve this, use the previous `Dockerfile`'s commands with the original `ubuntu` image as your base container:
 
 ```dockerfile
-ARG BASE_CONTAINER=ubuntu:22.04
+FROM ubuntu:22.04
 ```
 
-For Ubuntu 18.04 (bionic) and earlier, you may also require to a workaround for a mandb bug, which was fixed in mandb >= 2.8.6.1:
-
-```dockerfile
-# https://git.savannah.gnu.org/cgit/man-db.git/commit/?id=8197d7824f814c5d4b992b4c8730b5b0f7ec589a
-# https://launchpadlibrarian.net/435841763/man-db_2.8.5-2_2.8.6-1.diff.gz
-
-RUN echo ""MANPATH_MAP ${CONDA_DIR}/bin ${CONDA_DIR}/man"" >> /etc/manpath.config && \
-    echo ""MANPATH_MAP ${CONDA_DIR}/bin ${CONDA_DIR}/share/man"" >> /etc/manpath.config && \
-    mandb
-```
-
-Be sure to check the current base image in `base-notebook` before building.
+Be sure to check the current base image in `jupyter/docker-stacks-foundation` before building.
 
 ## JupyterHub",No
docs/using/recipes.md,docs/using/recipes.md,b6786dc79d8b0421aa09b6abe243fe619986ce0a,37afcd4c85890daf7f4efce9859cc179bba0bdad,Fix link,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index c89838a7..5eb5b572 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -149,7 +149,7 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/78>
 
 ```{note}
 We're providing the recipe to install JupyterLab extension.
-You can find the original Jupyter Notebook extenstion [here](http://github.com/damianavila/RISE)
+You can find the original Jupyter Notebook extenstion [here](https://github.com/damianavila/RISE)
 ```
 
 ```dockerfile","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index c89838a7..5eb5b572 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -149,7 +149,7 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/78>
 
 ```{note}
 We're providing the recipe to install JupyterLab extension.
-You can find the original Jupyter Notebook extenstion [here](http://github.com/damianavila/RISE)
+You can find the original Jupyter Notebook extenstion [here](https://github.com/damianavila/RISE)
 ```
 
 ```dockerfile",Yes
docs/using/recipes.md,docs/using/recipes.md,e8874a5fab5291e20bd1639b790180ef0b9f015f,b6786dc79d8b0421aa09b6abe243fe619986ce0a,Fix mamba install commands,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 5eb5b572..706d4a26 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -113,6 +113,7 @@ FROM jupyter/base-notebook
 
 # Install the Dask dashboard
 RUN mamba install --yes 'dask-labextension' && \
+    mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
@@ -582,8 +583,7 @@ RUN apt-get update --yes && \
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}
 
-RUN mamba install --yes \
-    'pyodbc' && \
+RUN mamba install --yes 'pyodbc' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 5eb5b572..706d4a26 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -113,6 +113,7 @@ FROM jupyter/base-notebook
 
 # Install the Dask dashboard
 RUN mamba install --yes 'dask-labextension' && \
+    mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
@@ -582,8 +583,7 @@ RUN apt-get update --yes && \
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}
 
-RUN mamba install --yes \
-    'pyodbc' && \
+RUN mamba install --yes 'pyodbc' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
docs/using/recipes.md,docs/using/recipes.md,4cc92ff41519edb30c47ea2e08a1f74a8ba55c74,e8874a5fab5291e20bd1639b790180ef0b9f015f,Fix jupyterhub installation example,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 706d4a26..48963f85 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -259,15 +259,12 @@ version in the Hub itself.
 ```dockerfile
 FROM jupyter/base-notebook
 
-RUN pip install --no-cache-dir 'jupyterhub==1.4.1' && \
+RUN mamba install --yes 'jupyterhub==4.0.1' && \
+    mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```
 
-Credit: [MinRK](https://github.com/jupyter/docker-stacks/issues/423#issuecomment-322767742)
-
-Ref: <https://github.com/jupyter/docker-stacks/issues/177>
-
 ## Spark
 
 A few suggestions have been made regarding using Docker Stacks with spark.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 706d4a26..48963f85 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -259,15 +259,12 @@ version in the Hub itself.
 ```dockerfile
 FROM jupyter/base-notebook
 
-RUN pip install --no-cache-dir 'jupyterhub==1.4.1' && \
+RUN mamba install --yes 'jupyterhub==4.0.1' && \
+    mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 ```
 
-Credit: [MinRK](https://github.com/jupyter/docker-stacks/issues/423#issuecomment-322767742)
-
-Ref: <https://github.com/jupyter/docker-stacks/issues/177>
-
 ## Spark
 
 A few suggestions have been made regarding using Docker Stacks with spark.",Yes
docs/using/recipes.md,docs/using/recipes.md,acad63dec190317eb4e212cb914a9c966fad516b,4cc92ff41519edb30c47ea2e08a1f74a8ba55c74,Delete redundant lines from xgboost recipe,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 48963f85..426198f6 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -171,8 +171,6 @@ RUN mamba install --yes 'py-xgboost' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
-
-# run ""import xgboost"" in python
 ```
 
 ## Running behind an nginx proxy","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 48963f85..426198f6 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -171,8 +171,6 @@ RUN mamba install --yes 'py-xgboost' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
-
-# run ""import xgboost"" in python
 ```
 
 ## Running behind an nginx proxy",Yes
tests/base-notebook/test_packages.py,tests/base-notebook/test_packages.py,4b2a473cbb94bb6499f8a6a24c0b37cab31e34f3,acad63dec190317eb4e212cb914a9c966fad516b,"Revert ""Temporarily disable tests using conda --json output""

This reverts commit 7c03161578d0d7f6c0bcc2a6c5305f5a93ac9fd9.","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index 9f6fef90..b56d6120 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -168,9 +168,6 @@ def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     )
 
 
-@pytest.mark.skip(
-    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
-)
 def test_r_packages(
     package_helper: CondaPackageHelper, r_packages: Iterable[str]
 ) -> None:
@@ -184,9 +181,6 @@ def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     return map(get_package_import_name, filter(python_package_predicate, packages))
 
 
-@pytest.mark.skip(
-    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
-)
 def test_python_packages(
     package_helper: CondaPackageHelper,
     python_packages: Iterable[str],","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index 9f6fef90..b56d6120 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -168,9 +168,6 @@ def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     )
 
 
-@pytest.mark.skip(
-    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
-)
 def test_r_packages(
     package_helper: CondaPackageHelper, r_packages: Iterable[str]
 ) -> None:
@@ -184,9 +181,6 @@ def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     return map(get_package_import_name, filter(python_package_predicate, packages))
 
 
-@pytest.mark.skip(
-    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
-)
 def test_python_packages(
     package_helper: CondaPackageHelper,
     python_packages: Iterable[str],",Yes
tests/base-notebook/test_packages.py,tests/base-notebook/test_packages.py,bc938c50dcad95002eeb5be6c8fd2cd111554ded,4b2a473cbb94bb6499f8a6a24c0b37cab31e34f3,Temporarily disable tests using conda --json output,"diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index b56d6120..9f6fef90 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -168,6 +168,9 @@ def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     )
 
 
+@pytest.mark.skip(
+    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
+)
 def test_r_packages(
     package_helper: CondaPackageHelper, r_packages: Iterable[str]
 ) -> None:
@@ -181,6 +184,9 @@ def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     return map(get_package_import_name, filter(python_package_predicate, packages))
 
 
+@pytest.mark.skip(
+    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
+)
 def test_python_packages(
     package_helper: CondaPackageHelper,
     python_packages: Iterable[str],","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index b56d6120..9f6fef90 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -168,6 +168,9 @@ def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     )
 
 
+@pytest.mark.skip(
+    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
+)
 def test_r_packages(
     package_helper: CondaPackageHelper, r_packages: Iterable[str]
 ) -> None:
@@ -181,6 +184,9 @@ def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     return map(get_package_import_name, filter(python_package_predicate, packages))
 
 
+@pytest.mark.skip(
+    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
+)
 def test_python_packages(
     package_helper: CondaPackageHelper,
     python_packages: Iterable[str],",Yes
.hadolint.yaml,.hadolint.yaml,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/.hadolint.yaml b/.hadolint.yaml
index 3d6d83e9..11ee2263 100644
--- a/.hadolint.yaml
+++ b/.hadolint.yaml
@@ -2,3 +2,4 @@
 ignored:
   - DL3006
   - DL3008
+  - DL3013","diff --git a/.hadolint.yaml b/.hadolint.yaml
index 3d6d83e9..11ee2263 100644
--- a/.hadolint.yaml
+++ b/.hadolint.yaml
@@ -2,3 +2,4 @@
 ignored:
   - DL3006
   - DL3008
+  - DL3013",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index aa5faab5..c3ca4a07 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -72,6 +72,16 @@ repos:
       - id: hadolint-docker
         entry: hadolint/hadolint:v2.12.1-beta hadolint
 
+  # Lint: Dockerfile
+  # We're linting .dockerfile files as well
+  - repo: https://github.com/hadolint/hadolint.git
+    rev: v2.12.1-beta
+    hooks:
+      - id: hadolint-docker
+        entry: hadolint/hadolint:v2.12.1-beta hadolint
+        types: [file]
+        files: \.dockerfile$
+
   # Lint: YAML
   - repo: https://github.com/adrienverge/yamllint.git
     rev: v1.32.0","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index aa5faab5..c3ca4a07 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -72,6 +72,16 @@ repos:
       - id: hadolint-docker
         entry: hadolint/hadolint:v2.12.1-beta hadolint
 
+  # Lint: Dockerfile
+  # We're linting .dockerfile files as well
+  - repo: https://github.com/hadolint/hadolint.git
+    rev: v2.12.1-beta
+    hooks:
+      - id: hadolint-docker
+        entry: hadolint/hadolint:v2.12.1-beta hadolint
+        types: [file]
+        files: \.dockerfile$
+
   # Lint: YAML
   - repo: https://github.com/adrienverge/yamllint.git
     rev: v1.32.0",Yes
docs/contributing/lint.md,docs/contributing/lint.md,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 4fb83bf7..1b213d05 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -50,6 +50,7 @@ The following rules are ignored by default for all images in the `.hadolint.yaml
   - `base-notebook` `FROM` clause is fixed but based on an argument (`ARG`).
   - Building downstream images from (`FROM`) the latest is done on purpose.
 - [`DL3008`][dl3008]: System packages are always updated (`apt-get`) to the latest version.
+- [`DL3013`][dl3013]: We always install latest packages using `pip`
 
 The preferred way to do it for other rules is to flag ignored ones in the `Dockerfile`.
 
@@ -69,4 +70,5 @@ RUN cd /tmp && echo ""hello!""
 [rules]: https://github.com/hadolint/hadolint#rules
 [dl3006]: https://github.com/hadolint/hadolint/wiki/DL3006
 [dl3008]: https://github.com/hadolint/hadolint/wiki/DL3008
+[dl3013]: https://github.com/hadolint/hadolint/wiki/DL3013
 [pre-commit]: https://pre-commit.com/","diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 4fb83bf7..1b213d05 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -50,6 +50,7 @@ The following rules are ignored by default for all images in the `.hadolint.yaml
   - `base-notebook` `FROM` clause is fixed but based on an argument (`ARG`).
   - Building downstream images from (`FROM`) the latest is done on purpose.
 - [`DL3008`][dl3008]: System packages are always updated (`apt-get`) to the latest version.
+- [`DL3013`][dl3013]: We always install latest packages using `pip`
 
 The preferred way to do it for other rules is to flag ignored ones in the `Dockerfile`.
 
@@ -69,4 +70,5 @@ RUN cd /tmp && echo ""hello!""
 [rules]: https://github.com/hadolint/hadolint#rules
 [dl3006]: https://github.com/hadolint/hadolint/wiki/DL3006
 [dl3008]: https://github.com/hadolint/hadolint/wiki/DL3008
+[dl3013]: https://github.com/hadolint/hadolint/wiki/DL3013
 [pre-commit]: https://pre-commit.com/",Yes
,docs/using/recipe_code/dask_jupyterlab.dockerfile,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/using/recipe_code/dask_jupyterlab.dockerfile b/docs/using/recipe_code/dask_jupyterlab.dockerfile
new file mode 100644
index 00000000..e9cb281e
--- /dev/null
+++ b/docs/using/recipe_code/dask_jupyterlab.dockerfile
@@ -0,0 +1,10 @@
+FROM jupyter/base-notebook
+
+# Install the Dask dashboard
+RUN mamba install --yes 'dask-labextension' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Dask Scheduler port
+EXPOSE 8787","diff --git a/docs/using/recipe_code/dask_jupyterlab.dockerfile b/docs/using/recipe_code/dask_jupyterlab.dockerfile
new file mode 100644
index 00000000..e9cb281e
--- /dev/null
+++ b/docs/using/recipe_code/dask_jupyterlab.dockerfile
@@ -0,0 +1,10 @@
+FROM jupyter/base-notebook
+
+# Install the Dask dashboard
+RUN mamba install --yes 'dask-labextension' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Dask Scheduler port
+EXPOSE 8787",Yes
,docs/using/recipe_code/jupyterhub_version.dockerfile,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
new file mode 100644
index 00000000..8704ded1
--- /dev/null
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -0,0 +1,6 @@
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'jupyterhub==4.0.1' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
new file mode 100644
index 00000000..8704ded1
--- /dev/null
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -0,0 +1,6 @@
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'jupyterhub==4.0.1' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
,docs/using/recipe_code/mamba_install.dockerfile,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/using/recipe_code/mamba_install.dockerfile b/docs/using/recipe_code/mamba_install.dockerfile
new file mode 100644
index 00000000..05e20bd9
--- /dev/null
+++ b/docs/using/recipe_code/mamba_install.dockerfile
@@ -0,0 +1,13 @@
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'flake8' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Install from the requirements.txt file
+COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
+RUN mamba install --yes --file /tmp/requirements.txt && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/mamba_install.dockerfile b/docs/using/recipe_code/mamba_install.dockerfile
new file mode 100644
index 00000000..05e20bd9
--- /dev/null
+++ b/docs/using/recipe_code/mamba_install.dockerfile
@@ -0,0 +1,13 @@
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'flake8' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Install from the requirements.txt file
+COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
+RUN mamba install --yes --file /tmp/requirements.txt && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
,docs/using/recipe_code/manpage_install.dockerfile,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/using/recipe_code/manpage_install.dockerfile b/docs/using/recipe_code/manpage_install.dockerfile
new file mode 100644
index 00000000..d3043258
--- /dev/null
+++ b/docs/using/recipe_code/manpage_install.dockerfile
@@ -0,0 +1,16 @@
+FROM jupyter/base-notebook
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# `/etc/dpkg/dpkg.cfg.d/excludes` contains several `path-exclude`s, including man pages
+# Remove it, then install man, install docs
+RUN rm /etc/dpkg/dpkg.cfg.d/excludes && \
+    apt-get update --yes && \
+    dpkg -l | grep ^ii | cut -d' ' -f3 | xargs apt-get install --yes --no-install-recommends --reinstall man && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}","diff --git a/docs/using/recipe_code/manpage_install.dockerfile b/docs/using/recipe_code/manpage_install.dockerfile
new file mode 100644
index 00000000..d3043258
--- /dev/null
+++ b/docs/using/recipe_code/manpage_install.dockerfile
@@ -0,0 +1,16 @@
+FROM jupyter/base-notebook
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# `/etc/dpkg/dpkg.cfg.d/excludes` contains several `path-exclude`s, including man pages
+# Remove it, then install man, install docs
+RUN rm /etc/dpkg/dpkg.cfg.d/excludes && \
+    apt-get update --yes && \
+    dpkg -l | grep ^ii | cut -d' ' -f3 | xargs apt-get install --yes --no-install-recommends --reinstall man && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}",Yes
,docs/using/recipe_code/microsoft_odbc.dockerfile,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
new file mode 100644
index 00000000..36cfc068
--- /dev/null
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -0,0 +1,30 @@
+FROM jupyter/base-notebook
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+ENV MSSQL_DRIVER ""ODBC Driver 18 for SQL Server""
+ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
+
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends curl gnupg2 lsb-release && \
+    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
+    curl ""https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list"" > /etc/apt/sources.list.d/mssql-release.list && \
+    apt-get update --yes && \
+    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends msodbcsql18 && \
+    # optional: for bcp and sqlcmd
+    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends mssql-tools18 && \
+    # optional: for unixODBC development headers
+    apt-get install --yes --no-install-recommends unixodbc-dev && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ${NB_UID}
+
+RUN mamba install --yes 'pyodbc' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
new file mode 100644
index 00000000..36cfc068
--- /dev/null
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -0,0 +1,30 @@
+FROM jupyter/base-notebook
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+ENV MSSQL_DRIVER ""ODBC Driver 18 for SQL Server""
+ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
+
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends curl gnupg2 lsb-release && \
+    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
+    curl ""https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list"" > /etc/apt/sources.list.d/mssql-release.list && \
+    apt-get update --yes && \
+    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends msodbcsql18 && \
+    # optional: for bcp and sqlcmd
+    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends mssql-tools18 && \
+    # optional: for unixODBC development headers
+    apt-get install --yes --no-install-recommends unixodbc-dev && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ${NB_UID}
+
+RUN mamba install --yes 'pyodbc' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
,docs/using/recipe_code/pip_install.dockerfile,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/using/recipe_code/pip_install.dockerfile b/docs/using/recipe_code/pip_install.dockerfile
new file mode 100644
index 00000000..60fbd46d
--- /dev/null
+++ b/docs/using/recipe_code/pip_install.dockerfile
@@ -0,0 +1,12 @@
+FROM jupyter/base-notebook
+
+# Install in the default python3 environment
+RUN pip install --no-cache-dir 'flake8' && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Install from the requirements.txt file
+COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
+RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/pip_install.dockerfile b/docs/using/recipe_code/pip_install.dockerfile
new file mode 100644
index 00000000..60fbd46d
--- /dev/null
+++ b/docs/using/recipe_code/pip_install.dockerfile
@@ -0,0 +1,12 @@
+FROM jupyter/base-notebook
+
+# Install in the default python3 environment
+RUN pip install --no-cache-dir 'flake8' && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Install from the requirements.txt file
+COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
+RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
,docs/using/recipe_code/rise_jupyterlab.dockerfile,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/using/recipe_code/rise_jupyterlab.dockerfile b/docs/using/recipe_code/rise_jupyterlab.dockerfile
new file mode 100644
index 00000000..e665b8e9
--- /dev/null
+++ b/docs/using/recipe_code/rise_jupyterlab.dockerfile
@@ -0,0 +1,6 @@
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'jupyterlab_rise' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/rise_jupyterlab.dockerfile b/docs/using/recipe_code/rise_jupyterlab.dockerfile
new file mode 100644
index 00000000..e665b8e9
--- /dev/null
+++ b/docs/using/recipe_code/rise_jupyterlab.dockerfile
@@ -0,0 +1,6 @@
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'jupyterlab_rise' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
,docs/using/recipe_code/xgboost.dockerfile,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/using/recipe_code/xgboost.dockerfile b/docs/using/recipe_code/xgboost.dockerfile
new file mode 100644
index 00000000..8b762ff6
--- /dev/null
+++ b/docs/using/recipe_code/xgboost.dockerfile
@@ -0,0 +1,6 @@
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'py-xgboost' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/xgboost.dockerfile b/docs/using/recipe_code/xgboost.dockerfile
new file mode 100644
index 00000000..8b762ff6
--- /dev/null
+++ b/docs/using/recipe_code/xgboost.dockerfile
@@ -0,0 +1,6 @@
+FROM jupyter/base-notebook
+
+RUN mamba install --yes 'py-xgboost' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
docs/using/recipes.md,docs/using/recipes.md,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 426198f6..f4477f12 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -28,37 +28,14 @@ See [Docker security documentation](https://docs.docker.com/engine/security/user
 Create a new Dockerfile like the one shown below.
 To use a requirements.txt file, first, create your `requirements.txt` file with the listing of packages desired.
 
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN mamba install --yes 'flake8' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
-# Install from the requirements.txt file
-COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
-RUN mamba install --yes --file /tmp/requirements.txt && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/mamba_install.dockerfile
+:language: docker
 ```
 
 `pip` usage is similar:
 
-```dockerfile
-FROM jupyter/base-notebook
-
-# Install in the default python3 environment
-RUN pip install --no-cache-dir 'flake8' && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
-# Install from the requirements.txt file
-COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
-RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/pip_install.dockerfile
+:language: docker
 ```
 
 Then build a new image.
@@ -108,17 +85,8 @@ RUN ""${CONDA_DIR}/envs/${conda_env}/bin/python"" -m ipykernel install --user --na
 [Dask JupyterLab Extension](https://github.com/dask/dask-labextension) provides a JupyterLab extension to manage Dask clusters, as well as embed Dask's dashboard plots directly into JupyterLab panes.
 Create the Dockerfile as:
 
-```dockerfile
-FROM jupyter/base-notebook
-
-# Install the Dask dashboard
-RUN mamba install --yes 'dask-labextension' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
-# Dask Scheduler port
-EXPOSE 8787
+```{literalinclude} recipe_code/dask_jupyterlab.dockerfile
+:language: docker
 ```
 
 And build the image as:
@@ -153,24 +121,14 @@ We're providing the recipe to install JupyterLab extension.
 You can find the original Jupyter Notebook extenstion [here](https://github.com/damianavila/RISE)
 ```
 
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN mamba install --yes 'jupyterlab_rise' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/rise_jupyterlab.dockerfile
+:language: docker
 ```
 
 ## xgboost
 
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN mamba install --yes 'py-xgboost' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/xgboost.dockerfile
+:language: docker
 ```
 
 ## Running behind an nginx proxy
@@ -202,19 +160,8 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/199>
 Most containers, including our Ubuntu base image, ship without manpages installed to save space.
 You can use the following Dockerfile to inherit from one of our images to enable manpages:
 
-```dockerfile
-FROM jupyter/base-notebook
-
-USER root
-
-# `/etc/dpkg/dpkg.cfg.d/excludes` contains several `path-exclude`s, including man pages
-# Remove it, then install man, install docs
-RUN rm /etc/dpkg/dpkg.cfg.d/excludes && \
-    apt-get update --yes && \
-    dpkg -l | grep ^ii | cut -d' ' -f3 | xargs apt-get install --yes --no-install-recommends --reinstall man && \
-    apt-get clean && rm -rf /var/lib/apt/lists/*
-
-USER ${NB_UID}
+```{literalinclude} recipe_code/manpage_install.dockerfile
+:language: docker
 ```
 
 Adding the documentation on top of the existing image wastes a lot of space
@@ -254,13 +201,8 @@ Credit: [Justin Tyberg](https://github.com/jtyberg), [quanghoc](https://github.c
 To use a specific version of JupyterHub, the version of `jupyterhub` in your image should match the
 version in the Hub itself.
 
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN mamba install --yes 'jupyterhub==4.0.1' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/jupyterhub_version.dockerfile
+:language: docker
 ```
 
 ## Spark
@@ -555,33 +497,8 @@ RUN ijsinstall
 
 The following recipe demonstrates how to add functionality to read from and write to an instance of Microsoft SQL server in your notebook.
 
-```dockerfile
-FROM jupyter/base-notebook
-
-USER root
-
-ENV MSSQL_DRIVER ""ODBC Driver 18 for SQL Server""
-ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
-
-RUN apt-get update --yes && \
-    apt-get install --yes --no-install-recommends curl gnupg2 lsb-release && \
-    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
-    curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list && \
-    apt-get update --yes && \
-    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends msodbcsql18 && \
-    # optional: for bcp and sqlcmd
-    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends mssql-tools18 && \
-    # optional: for unixODBC development headers
-    apt-get install -y unixodbc-dev && \
-    apt-get clean && rm -rf /var/lib/apt/lists/*
-
-# Switch back to jovyan to avoid accidental container runs as root
-USER ${NB_UID}
-
-RUN mamba install --yes 'pyodbc' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/microsoft_odbc.dockerfile
+:language: docker
 ```
 
 You can now use `pyodbc` and `sqlalchemy` to interact with the database.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 426198f6..f4477f12 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -28,37 +28,14 @@ See [Docker security documentation](https://docs.docker.com/engine/security/user
 Create a new Dockerfile like the one shown below.
 To use a requirements.txt file, first, create your `requirements.txt` file with the listing of packages desired.
 
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN mamba install --yes 'flake8' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
-# Install from the requirements.txt file
-COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
-RUN mamba install --yes --file /tmp/requirements.txt && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/mamba_install.dockerfile
+:language: docker
 ```
 
 `pip` usage is similar:
 
-```dockerfile
-FROM jupyter/base-notebook
-
-# Install in the default python3 environment
-RUN pip install --no-cache-dir 'flake8' && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
-# Install from the requirements.txt file
-COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/
-RUN pip install --no-cache-dir --requirement /tmp/requirements.txt && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/pip_install.dockerfile
+:language: docker
 ```
 
 Then build a new image.
@@ -108,17 +85,8 @@ RUN ""${CONDA_DIR}/envs/${conda_env}/bin/python"" -m ipykernel install --user --na
 [Dask JupyterLab Extension](https://github.com/dask/dask-labextension) provides a JupyterLab extension to manage Dask clusters, as well as embed Dask's dashboard plots directly into JupyterLab panes.
 Create the Dockerfile as:
 
-```dockerfile
-FROM jupyter/base-notebook
-
-# Install the Dask dashboard
-RUN mamba install --yes 'dask-labextension' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
-# Dask Scheduler port
-EXPOSE 8787
+```{literalinclude} recipe_code/dask_jupyterlab.dockerfile
+:language: docker
 ```
 
 And build the image as:
@@ -153,24 +121,14 @@ We're providing the recipe to install JupyterLab extension.
 You can find the original Jupyter Notebook extenstion [here](https://github.com/damianavila/RISE)
 ```
 
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN mamba install --yes 'jupyterlab_rise' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/rise_jupyterlab.dockerfile
+:language: docker
 ```
 
 ## xgboost
 
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN mamba install --yes 'py-xgboost' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/xgboost.dockerfile
+:language: docker
 ```
 
 ## Running behind an nginx proxy
@@ -202,19 +160,8 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/199>
 Most containers, including our Ubuntu base image, ship without manpages installed to save space.
 You can use the following Dockerfile to inherit from one of our images to enable manpages:
 
-```dockerfile
-FROM jupyter/base-notebook
-
-USER root
-
-# `/etc/dpkg/dpkg.cfg.d/excludes` contains several `path-exclude`s, including man pages
-# Remove it, then install man, install docs
-RUN rm /etc/dpkg/dpkg.cfg.d/excludes && \
-    apt-get update --yes && \
-    dpkg -l | grep ^ii | cut -d' ' -f3 | xargs apt-get install --yes --no-install-recommends --reinstall man && \
-    apt-get clean && rm -rf /var/lib/apt/lists/*
-
-USER ${NB_UID}
+```{literalinclude} recipe_code/manpage_install.dockerfile
+:language: docker
 ```
 
 Adding the documentation on top of the existing image wastes a lot of space
@@ -254,13 +201,8 @@ Credit: [Justin Tyberg](https://github.com/jtyberg), [quanghoc](https://github.c
 To use a specific version of JupyterHub, the version of `jupyterhub` in your image should match the
 version in the Hub itself.
 
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN mamba install --yes 'jupyterhub==4.0.1' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/jupyterhub_version.dockerfile
+:language: docker
 ```
 
 ## Spark
@@ -555,33 +497,8 @@ RUN ijsinstall
 
 The following recipe demonstrates how to add functionality to read from and write to an instance of Microsoft SQL server in your notebook.
 
-```dockerfile
-FROM jupyter/base-notebook
-
-USER root
-
-ENV MSSQL_DRIVER ""ODBC Driver 18 for SQL Server""
-ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
-
-RUN apt-get update --yes && \
-    apt-get install --yes --no-install-recommends curl gnupg2 lsb-release && \
-    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
-    curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list && \
-    apt-get update --yes && \
-    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends msodbcsql18 && \
-    # optional: for bcp and sqlcmd
-    ACCEPT_EULA=Y apt-get install --yes --no-install-recommends mssql-tools18 && \
-    # optional: for unixODBC development headers
-    apt-get install -y unixodbc-dev && \
-    apt-get clean && rm -rf /var/lib/apt/lists/*
-
-# Switch back to jovyan to avoid accidental container runs as root
-USER ${NB_UID}
-
-RUN mamba install --yes 'pyodbc' && \
-    mamba clean --all -f -y && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/microsoft_odbc.dockerfile
+:language: docker
 ```
 
 You can now use `pyodbc` and `sqlalchemy` to interact with the database.",Yes
tensorflow-notebook/Dockerfile,tensorflow-notebook/Dockerfile,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,bc938c50dcad95002eeb5be6c8fd2cd111554ded,Move recipe Dockerfiles to separate files (#1953),"diff --git a/tensorflow-notebook/Dockerfile b/tensorflow-notebook/Dockerfile
index 24a46d96..51070fdc 100644
--- a/tensorflow-notebook/Dockerfile
+++ b/tensorflow-notebook/Dockerfile
@@ -11,7 +11,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install Tensorflow with pip
-# hadolint ignore=DL3013
 RUN pip install --no-cache-dir tensorflow && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/tensorflow-notebook/Dockerfile b/tensorflow-notebook/Dockerfile
index 24a46d96..51070fdc 100644
--- a/tensorflow-notebook/Dockerfile
+++ b/tensorflow-notebook/Dockerfile
@@ -11,7 +11,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install Tensorflow with pip
-# hadolint ignore=DL3013
 RUN pip install --no-cache-dir tensorflow && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
docs/contributing/recipes.md,docs/contributing/recipes.md,3f257bdb4e78d1a84a7dc38b38cb70d783eae395,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,Warn outdated recipes might be broken (#1954),"diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index 313d755c..4af134b1 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -4,7 +4,8 @@ We welcome contributions of [recipes](../using/recipes.md), short examples of us
 Follow the process below to add a new recipe:
 
 1. Open the `docs/using/recipes.md` source file.
-2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Add the RISE extension`)
-3. Write the body of your recipe under the heading, including whatever command line, Dockerfile, links, etc. you need.
-4. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
+2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Slideshows with JupyterLab and RISE`)
+3. Write the body of your recipe under the heading, including whatever command line, links, etc. you need.
+4. Please, put your Dockerfile in a `recipe_code` subfolder.
+5. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.","diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index 313d755c..4af134b1 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -4,7 +4,8 @@ We welcome contributions of [recipes](../using/recipes.md), short examples of us
 Follow the process below to add a new recipe:
 
 1. Open the `docs/using/recipes.md` source file.
-2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Add the RISE extension`)
-3. Write the body of your recipe under the heading, including whatever command line, Dockerfile, links, etc. you need.
-4. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
+2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Slideshows with JupyterLab and RISE`)
+3. Write the body of your recipe under the heading, including whatever command line, links, etc. you need.
+4. Please, put your Dockerfile in a `recipe_code` subfolder.
+5. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.",Yes
docs/using/recipes.md,docs/using/recipes.md,3f257bdb4e78d1a84a7dc38b38cb70d783eae395,5e381019fdf981a9f3eb66b8eed8ed3358a8b2bd,Warn outdated recipes might be broken (#1954),"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index f4477f12..9be8582f 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -46,6 +46,10 @@ docker build --rm -t my-custom-image .
 
 ## Add a custom conda environment and Jupyter kernel
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 The default version of Python that ships with the image may not be the version you want.
 The instructions below permit adding a conda environment with a different Python version and making it accessible to Jupyter.
 
@@ -106,6 +110,10 @@ docker run -it --rm \
 
 ## Let's Encrypt a Server
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 See the README for a basic automation here
 <https://github.com/jupyter/docker-stacks/tree/main/examples/make-deploy>
 which includes steps for requesting and renewing a Let's Encrypt certificate.
@@ -133,6 +141,10 @@ You can find the original Jupyter Notebook extenstion [here](https://github.com/
 
 ## Running behind an nginx proxy
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 Sometimes it is helpful to run the Jupyter instance behind an nginx proxy, for example:
 
 - you would prefer to access the notebook at a server URL with a path
@@ -182,6 +194,10 @@ We also have contributed recipes for using JupyterHub.
 
 ### Use JupyterHub's dockerspawner
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 In most cases for use with DockerSpawner, given an image that already has a notebook stack set up,
 you would only need to add:
 
@@ -211,6 +227,10 @@ A few suggestions have been made regarding using Docker Stacks with spark.
 
 ### Using PySpark with AWS S3
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 Using Spark session for Hadoop 2.7.3
 
 ```python
@@ -267,6 +287,10 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/127>
 
 ### Using Local Spark JARs
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 ```python
 import os
 
@@ -291,6 +315,10 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/154>
 
 ### Using spark-packages.org
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 If you'd like to use packages from [spark-packages.org](https://spark-packages.org/), see
 [https://gist.github.com/parente/c95fdaba5a9a066efaab](https://gist.github.com/parente/c95fdaba5a9a066efaab)
 for an example of how to specify the package identifier in the environment before creating a
@@ -300,6 +328,10 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/43>
 
 ### Use jupyter/all-spark-notebooks with an existing Spark/YARN cluster
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 ```dockerfile
 FROM jupyter/all-spark-notebook
 
@@ -375,8 +407,6 @@ Credit: [britishbadger](https://github.com/britishbadger) from [docker-stacks/is
 
 ## Run Server inside an already secured environment (i.e., with no token)
 
-(Adapted from [issue 728](https://github.com/jupyter/docker-stacks/issues/728))
-
 The default security is very good.
 There are use cases, encouraged by containers, where the jupyter container and the system it runs within lie inside the security boundary.
 It is convenient to launch the server without a password or token in these use cases.
@@ -401,6 +431,10 @@ docker run -it --rm \
 
 ## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 NB: this works for classic notebooks only
 
 ```dockerfile
@@ -420,6 +454,10 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/675>
 
 ## Enable Delta Lake in Spark notebooks
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 Please note that the [Delta Lake](https://delta.io/) packages are only available for Spark version > `3.0`.
 By adding the properties to `spark-defaults.conf`, the user no longer needs to enable Delta support in each notebook.
 
@@ -448,6 +486,10 @@ RUN echo ""from pyspark.sql import SparkSession"" > /tmp/init-delta.py && \
 
 ## Add Custom Fonts in Scipy notebook
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 The example below is a Dockerfile to load Source Han Sans with normal weight, usually used for the web.
 
 ```dockerfile
@@ -465,6 +507,10 @@ RUN PYV=$(ls ""${CONDA_DIR}/lib"" | grep ^python) && \
 
 ## Enable clipboard in pandas on Linux systems
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 ```{admonition} Additional notes
     This solution works on Linux host systems.
     It is not required on Windows and won't work on macOS.
@@ -483,6 +529,10 @@ docker run -it --rm \
 
 ## Add ijavascript kernel to container
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
 
 ```dockerfile","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index f4477f12..9be8582f 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -46,6 +46,10 @@ docker build --rm -t my-custom-image .
 
 ## Add a custom conda environment and Jupyter kernel
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 The default version of Python that ships with the image may not be the version you want.
 The instructions below permit adding a conda environment with a different Python version and making it accessible to Jupyter.
 
@@ -106,6 +110,10 @@ docker run -it --rm \
 
 ## Let's Encrypt a Server
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 See the README for a basic automation here
 <https://github.com/jupyter/docker-stacks/tree/main/examples/make-deploy>
 which includes steps for requesting and renewing a Let's Encrypt certificate.
@@ -133,6 +141,10 @@ You can find the original Jupyter Notebook extenstion [here](https://github.com/
 
 ## Running behind an nginx proxy
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 Sometimes it is helpful to run the Jupyter instance behind an nginx proxy, for example:
 
 - you would prefer to access the notebook at a server URL with a path
@@ -182,6 +194,10 @@ We also have contributed recipes for using JupyterHub.
 
 ### Use JupyterHub's dockerspawner
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 In most cases for use with DockerSpawner, given an image that already has a notebook stack set up,
 you would only need to add:
 
@@ -211,6 +227,10 @@ A few suggestions have been made regarding using Docker Stacks with spark.
 
 ### Using PySpark with AWS S3
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 Using Spark session for Hadoop 2.7.3
 
 ```python
@@ -267,6 +287,10 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/127>
 
 ### Using Local Spark JARs
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 ```python
 import os
 
@@ -291,6 +315,10 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/154>
 
 ### Using spark-packages.org
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 If you'd like to use packages from [spark-packages.org](https://spark-packages.org/), see
 [https://gist.github.com/parente/c95fdaba5a9a066efaab](https://gist.github.com/parente/c95fdaba5a9a066efaab)
 for an example of how to specify the package identifier in the environment before creating a
@@ -300,6 +328,10 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/43>
 
 ### Use jupyter/all-spark-notebooks with an existing Spark/YARN cluster
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 ```dockerfile
 FROM jupyter/all-spark-notebook
 
@@ -375,8 +407,6 @@ Credit: [britishbadger](https://github.com/britishbadger) from [docker-stacks/is
 
 ## Run Server inside an already secured environment (i.e., with no token)
 
-(Adapted from [issue 728](https://github.com/jupyter/docker-stacks/issues/728))
-
 The default security is very good.
 There are use cases, encouraged by containers, where the jupyter container and the system it runs within lie inside the security boundary.
 It is convenient to launch the server without a password or token in these use cases.
@@ -401,6 +431,10 @@ docker run -it --rm \
 
 ## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 NB: this works for classic notebooks only
 
 ```dockerfile
@@ -420,6 +454,10 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/675>
 
 ## Enable Delta Lake in Spark notebooks
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 Please note that the [Delta Lake](https://delta.io/) packages are only available for Spark version > `3.0`.
 By adding the properties to `spark-defaults.conf`, the user no longer needs to enable Delta support in each notebook.
 
@@ -448,6 +486,10 @@ RUN echo ""from pyspark.sql import SparkSession"" > /tmp/init-delta.py && \
 
 ## Add Custom Fonts in Scipy notebook
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 The example below is a Dockerfile to load Source Han Sans with normal weight, usually used for the web.
 
 ```dockerfile
@@ -465,6 +507,10 @@ RUN PYV=$(ls ""${CONDA_DIR}/lib"" | grep ^python) && \
 
 ## Enable clipboard in pandas on Linux systems
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 ```{admonition} Additional notes
     This solution works on Linux host systems.
     It is not required on Windows and won't work on macOS.
@@ -483,6 +529,10 @@ docker run -it --rm \
 
 ## Add ijavascript kernel to container
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
 
 ```dockerfile",Yes
,.github/workflows/contributed-recipes.yml,7ebbe8614708e73122c2d730c93d5f1127b587ac,3f257bdb4e78d1a84a7dc38b38cb70d783eae395,"Build recipes in GitHub Actions (#1955)

* Build recipes in GitHub Actions

* Fix typo

* Fix matrix var name","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
new file mode 100644
index 00000000..61ddb6aa
--- /dev/null
+++ b/.github/workflows/contributed-recipes.yml
@@ -0,0 +1,47 @@
+name: Test contributed recipes
+
+on:
+  schedule:
+    # Images are rebuilt on Monday, so we're testing recipes each Tuesday
+    # Weekly, at 03:00 on Tuesday UTC time
+    - cron: ""0 3 * * 2""
+  pull_request:
+    paths:
+      - "".github/workflows/contributed-recipes.yml""
+      - ""docs/using/recipe_code/""
+  push:
+    branches:
+      - main
+    paths:
+      - "".github/workflows/contributed-recipes.yml""
+      - ""docs/using/recipe_code/""
+
+jobs:
+  test-recipes:
+    runs-on: ubuntu-latest
+    if: github.repository == 'jupyter/docker-stacks'
+
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v3
+
+      - name: Build recipe 🛠
+        run: docker build --rm --force-rm --tag my-custom-image -f ./${{ matrix.dockerfile }} ./
+        env:
+          DOCKER_BUILDKIT: 1
+          # Full logs for CI build
+          BUILDKIT_PROGRESS: plain
+        working-directory: docs/using/recipe_code
+        shell: bash
+
+    strategy:
+      matrix:
+        dockerfile:
+          [
+            dask_jupyterlab.dockerfile,
+            jupyterhub_version.dockerfile,
+            manpage_install.dockerfile,
+            microsoft_odbc.dockerfile,
+            rise_jupyterlab.dockerfile,
+            xgboost.dockerfile,
+          ]","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
new file mode 100644
index 00000000..61ddb6aa
--- /dev/null
+++ b/.github/workflows/contributed-recipes.yml
@@ -0,0 +1,47 @@
+name: Test contributed recipes
+
+on:
+  schedule:
+    # Images are rebuilt on Monday, so we're testing recipes each Tuesday
+    # Weekly, at 03:00 on Tuesday UTC time
+    - cron: ""0 3 * * 2""
+  pull_request:
+    paths:
+      - "".github/workflows/contributed-recipes.yml""
+      - ""docs/using/recipe_code/""
+  push:
+    branches:
+      - main
+    paths:
+      - "".github/workflows/contributed-recipes.yml""
+      - ""docs/using/recipe_code/""
+
+jobs:
+  test-recipes:
+    runs-on: ubuntu-latest
+    if: github.repository == 'jupyter/docker-stacks'
+
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v3
+
+      - name: Build recipe 🛠
+        run: docker build --rm --force-rm --tag my-custom-image -f ./${{ matrix.dockerfile }} ./
+        env:
+          DOCKER_BUILDKIT: 1
+          # Full logs for CI build
+          BUILDKIT_PROGRESS: plain
+        working-directory: docs/using/recipe_code
+        shell: bash
+
+    strategy:
+      matrix:
+        dockerfile:
+          [
+            dask_jupyterlab.dockerfile,
+            jupyterhub_version.dockerfile,
+            manpage_install.dockerfile,
+            microsoft_odbc.dockerfile,
+            rise_jupyterlab.dockerfile,
+            xgboost.dockerfile,
+          ]",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,900dfc9fc4f0036d25955c7cfec51ad840daf151,7ebbe8614708e73122c2d730c93d5f1127b587ac,Build pip and mamba recipes as well,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 61ddb6aa..9f88867d 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -40,8 +40,10 @@ jobs:
           [
             dask_jupyterlab.dockerfile,
             jupyterhub_version.dockerfile,
+            mamba_install.dockerfile,
             manpage_install.dockerfile,
             microsoft_odbc.dockerfile,
+            pip_install.dockerfile,
             rise_jupyterlab.dockerfile,
             xgboost.dockerfile,
           ]","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 61ddb6aa..9f88867d 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -40,8 +40,10 @@ jobs:
           [
             dask_jupyterlab.dockerfile,
             jupyterhub_version.dockerfile,
+            mamba_install.dockerfile,
             manpage_install.dockerfile,
             microsoft_odbc.dockerfile,
+            pip_install.dockerfile,
             rise_jupyterlab.dockerfile,
             xgboost.dockerfile,
           ]",Yes
,docs/using/recipe_code/requirements.txt,900dfc9fc4f0036d25955c7cfec51ad840daf151,7ebbe8614708e73122c2d730c93d5f1127b587ac,Build pip and mamba recipes as well,"diff --git a/docs/using/recipe_code/requirements.txt b/docs/using/recipe_code/requirements.txt
new file mode 100644
index 00000000..3379e2a5
--- /dev/null
+++ b/docs/using/recipe_code/requirements.txt
@@ -0,0 +1 @@
+autoflake","diff --git a/docs/using/recipe_code/requirements.txt b/docs/using/recipe_code/requirements.txt
new file mode 100644
index 00000000..3379e2a5
--- /dev/null
+++ b/docs/using/recipe_code/requirements.txt
@@ -0,0 +1 @@
+autoflake",Yes
docs/contributing/recipes.md,docs/contributing/recipes.md,4f2ac22a1b72e028202fc0607ee1509449f37af4,900dfc9fc4f0036d25955c7cfec51ad840daf151,Update contributing recipes makrdown,"diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index 4af134b1..48006744 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -6,6 +6,7 @@ Follow the process below to add a new recipe:
 1. Open the `docs/using/recipes.md` source file.
 2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Slideshows with JupyterLab and RISE`)
 3. Write the body of your recipe under the heading, including whatever command line, links, etc. you need.
-4. Please, put your Dockerfile in a `recipe_code` subfolder.
+4. If you have a Dockerfile, please put it in a `recipe_code` subfolder
+   and update [contributed-recipes workflow](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/contributed-recipes.yml) to include your file.
 5. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.","diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index 4af134b1..48006744 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -6,6 +6,7 @@ Follow the process below to add a new recipe:
 1. Open the `docs/using/recipes.md` source file.
 2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Slideshows with JupyterLab and RISE`)
 3. Write the body of your recipe under the heading, including whatever command line, links, etc. you need.
-4. Please, put your Dockerfile in a `recipe_code` subfolder.
+4. If you have a Dockerfile, please put it in a `recipe_code` subfolder
+   and update [contributed-recipes workflow](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/contributed-recipes.yml) to include your file.
 5. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.",Yes
docs/using/recipes.md,docs/using/recipes.md,46e92f69ac2bbb4f5f801e48d183519d27dc912f,4f2ac22a1b72e028202fc0607ee1509449f37af4,Unify docker build command,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 9be8582f..74952607 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -41,7 +41,7 @@ To use a requirements.txt file, first, create your `requirements.txt` file with
 Then build a new image.
 
 ```bash
-docker build --rm -t my-custom-image .
+docker build --rm --tag my-custom-image .
 ```
 
 ## Add a custom conda environment and Jupyter kernel
@@ -96,7 +96,7 @@ Create the Dockerfile as:
 And build the image as:
 
 ```bash
-docker build --tag my-custom-image .
+docker build --rm --tag my-custom-image .
 ```
 
 Once built, run using the command:","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 9be8582f..74952607 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -41,7 +41,7 @@ To use a requirements.txt file, first, create your `requirements.txt` file with
 Then build a new image.
 
 ```bash
-docker build --rm -t my-custom-image .
+docker build --rm --tag my-custom-image .
 ```
 
 ## Add a custom conda environment and Jupyter kernel
@@ -96,7 +96,7 @@ Create the Dockerfile as:
 And build the image as:
 
 ```bash
-docker build --tag my-custom-image .
+docker build --rm --tag my-custom-image .
 ```
 
 Once built, run using the command:",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,9dffd42758dcfd03c1848b710ceba19ee44971e7,46e92f69ac2bbb4f5f801e48d183519d27dc912f,Fix custom conda environment recipe,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 9f88867d..87f9d4e6 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -38,6 +38,7 @@ jobs:
       matrix:
         dockerfile:
           [
+            custom_environment.dockerfile,
             dask_jupyterlab.dockerfile,
             jupyterhub_version.dockerfile,
             mamba_install.dockerfile,","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 9f88867d..87f9d4e6 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -38,6 +38,7 @@ jobs:
       matrix:
         dockerfile:
           [
+            custom_environment.dockerfile,
             dask_jupyterlab.dockerfile,
             jupyterhub_version.dockerfile,
             mamba_install.dockerfile,",Yes
,docs/using/recipe_code/custom_environment.dockerfile,9dffd42758dcfd03c1848b710ceba19ee44971e7,46e92f69ac2bbb4f5f801e48d183519d27dc912f,Fix custom conda environment recipe,"diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
new file mode 100644
index 00000000..7b457ca8
--- /dev/null
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -0,0 +1,33 @@
+FROM jupyter/base-notebook
+
+# name your environment and choose the python version
+ARG env_name=python38
+ARG py_ver=3.8
+
+# you can add additional libraries here
+RUN mamba create --yes -p ""${CONDA_DIR}/envs/${env_name}"" \
+    python=${py_ver} \
+    'ipykernel' \
+    'jupyterlab' && \
+    mamba clean --all -f -y
+
+# alternatively, you can comment out the lines above and uncomment those below
+# if you'd prefer to use a YAML file present in the docker build context
+
+# COPY --chown=${NB_UID}:${NB_GID} environment.yml /tmp/
+# RUN mamba env create -p ""${CONDA_DIR}/envs/${env_name}"" -f /tmp/environment.yml && \
+#     mamba clean --all -f -y
+
+# create Python kernel and link it to jupyter
+RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --name=""${env_name}"" && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# any additional `pip` installs can be added by using the following line
+# using `mamba` is highly recommended
+RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
+    'flake8'
+
+# if you do not want this environment to be the default one, comment this line
+# hadolint ignore=DL3059
+RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
new file mode 100644
index 00000000..7b457ca8
--- /dev/null
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -0,0 +1,33 @@
+FROM jupyter/base-notebook
+
+# name your environment and choose the python version
+ARG env_name=python38
+ARG py_ver=3.8
+
+# you can add additional libraries here
+RUN mamba create --yes -p ""${CONDA_DIR}/envs/${env_name}"" \
+    python=${py_ver} \
+    'ipykernel' \
+    'jupyterlab' && \
+    mamba clean --all -f -y
+
+# alternatively, you can comment out the lines above and uncomment those below
+# if you'd prefer to use a YAML file present in the docker build context
+
+# COPY --chown=${NB_UID}:${NB_GID} environment.yml /tmp/
+# RUN mamba env create -p ""${CONDA_DIR}/envs/${env_name}"" -f /tmp/environment.yml && \
+#     mamba clean --all -f -y
+
+# create Python kernel and link it to jupyter
+RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --name=""${env_name}"" && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# any additional `pip` installs can be added by using the following line
+# using `mamba` is highly recommended
+RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
+    'flake8'
+
+# if you do not want this environment to be the default one, comment this line
+# hadolint ignore=DL3059
+RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""",Yes
docs/using/recipes.md,docs/using/recipes.md,9dffd42758dcfd03c1848b710ceba19ee44971e7,46e92f69ac2bbb4f5f801e48d183519d27dc912f,Fix custom conda environment recipe,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 74952607..282c6a0e 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -46,42 +46,13 @@ docker build --rm --tag my-custom-image .
 
 ## Add a custom conda environment and Jupyter kernel
 
-```{warning}
-This recipe is not tested and might be broken.
-```
-
 The default version of Python that ships with the image may not be the version you want.
 The instructions below permit adding a conda environment with a different Python version and making it accessible to Jupyter.
+You may also use older image like `jupyter/base-notebook:python-3.10`.
+List of all tags can be found [here](https://github.com/jupyter/docker-stacks/wiki)
 
-```dockerfile
-FROM jupyter/minimal-notebook
-
-# name your environment and choose the python version
-ARG conda_env=python37
-ARG py_ver=3.7
-
-# you can add additional libraries you want mamba to install by listing them below the first line and ending with ""&& \""
-RUN mamba create --yes -p ""${CONDA_DIR}/envs/${conda_env}"" python=${py_ver} ipython ipykernel && \
-    mamba clean --all -f -y
-
-# alternatively, you can comment out the lines above and uncomment those below
-# if you'd prefer to use a YAML file present in the docker build context
-
-# COPY --chown=${NB_UID}:${NB_GID} environment.yml ""/home/${NB_USER}/tmp/""
-# RUN cd ""/home/${NB_USER}/tmp/"" && \
-#     mamba env create -p ""${CONDA_DIR}/envs/${conda_env}"" -f environment.yml && \
-#     mamba clean --all -f -y
-
-# create Python kernel and link it to jupyter
-RUN ""${CONDA_DIR}/envs/${conda_env}/bin/python"" -m ipykernel install --user --name=""${conda_env}"" && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
-# any additional pip installs can be added by uncommenting the following line
-# RUN ""${CONDA_DIR}/envs/${conda_env}/bin/pip"" install --no-cache-dir
-
-# if you want this environment to be the default one, uncomment the following line:
-# RUN echo ""conda activate ${conda_env}"" >> ""${HOME}/.bashrc""
+```{literalinclude} recipe_code/custom_environment.dockerfile
+:language: docker
 ```
 
 ## Dask JupyterLab Extension","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 74952607..282c6a0e 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -46,42 +46,13 @@ docker build --rm --tag my-custom-image .
 
 ## Add a custom conda environment and Jupyter kernel
 
-```{warning}
-This recipe is not tested and might be broken.
-```
-
 The default version of Python that ships with the image may not be the version you want.
 The instructions below permit adding a conda environment with a different Python version and making it accessible to Jupyter.
+You may also use older image like `jupyter/base-notebook:python-3.10`.
+List of all tags can be found [here](https://github.com/jupyter/docker-stacks/wiki)
 
-```dockerfile
-FROM jupyter/minimal-notebook
-
-# name your environment and choose the python version
-ARG conda_env=python37
-ARG py_ver=3.7
-
-# you can add additional libraries you want mamba to install by listing them below the first line and ending with ""&& \""
-RUN mamba create --yes -p ""${CONDA_DIR}/envs/${conda_env}"" python=${py_ver} ipython ipykernel && \
-    mamba clean --all -f -y
-
-# alternatively, you can comment out the lines above and uncomment those below
-# if you'd prefer to use a YAML file present in the docker build context
-
-# COPY --chown=${NB_UID}:${NB_GID} environment.yml ""/home/${NB_USER}/tmp/""
-# RUN cd ""/home/${NB_USER}/tmp/"" && \
-#     mamba env create -p ""${CONDA_DIR}/envs/${conda_env}"" -f environment.yml && \
-#     mamba clean --all -f -y
-
-# create Python kernel and link it to jupyter
-RUN ""${CONDA_DIR}/envs/${conda_env}/bin/python"" -m ipykernel install --user --name=""${conda_env}"" && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
-
-# any additional pip installs can be added by uncommenting the following line
-# RUN ""${CONDA_DIR}/envs/${conda_env}/bin/pip"" install --no-cache-dir
-
-# if you want this environment to be the default one, uncomment the following line:
-# RUN echo ""conda activate ${conda_env}"" >> ""${HOME}/.bashrc""
+```{literalinclude} recipe_code/custom_environment.dockerfile
+:language: docker
 ```
 
 ## Dask JupyterLab Extension",Yes
docs/using/recipes.md,docs/using/recipes.md,32733a437d147d2a46d2e798093879a98d739444,9dffd42758dcfd03c1848b710ceba19ee44971e7,Improve style,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 282c6a0e..e3f6a078 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -46,8 +46,8 @@ docker build --rm --tag my-custom-image .
 
 ## Add a custom conda environment and Jupyter kernel
 
-The default version of Python that ships with the image may not be the version you want.
-The instructions below permit adding a conda environment with a different Python version and making it accessible to Jupyter.
+The default version of `Python` that ships with the image may not be the version you want.
+The instructions below permit adding a conda environment with a different `Python` version and making it accessible to Jupyter.
 You may also use older image like `jupyter/base-notebook:python-3.10`.
 List of all tags can be found [here](https://github.com/jupyter/docker-stacks/wiki)","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 282c6a0e..e3f6a078 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -46,8 +46,8 @@ docker build --rm --tag my-custom-image .
 
 ## Add a custom conda environment and Jupyter kernel
 
-The default version of Python that ships with the image may not be the version you want.
-The instructions below permit adding a conda environment with a different Python version and making it accessible to Jupyter.
+The default version of `Python` that ships with the image may not be the version you want.
+The instructions below permit adding a conda environment with a different `Python` version and making it accessible to Jupyter.
 You may also use older image like `jupyter/base-notebook:python-3.10`.
 List of all tags can be found [here](https://github.com/jupyter/docker-stacks/wiki)",Yes
examples/docker-compose/README.md,examples/docker-compose/README.md,ff657c7d51d67ab766e7bff6e453c808fb010cad,32733a437d147d2a46d2e798093879a98d739444,Remove tags from examples folder,"diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index 26a585f4..4d81cc1c 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -42,7 +42,7 @@ You can customize the docker-stack notebook image to deploy by modifying the `no
 For example, you can build and deploy a `jupyter/all-spark-notebook` by modifying the Dockerfile like so:
 
 ```dockerfile
-FROM jupyter/all-spark-notebook:2023-07-25
+FROM jupyter/all-spark-notebook
 # Your RUN commands and so on
 ```","diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index 26a585f4..4d81cc1c 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -42,7 +42,7 @@ You can customize the docker-stack notebook image to deploy by modifying the `no
 For example, you can build and deploy a `jupyter/all-spark-notebook` by modifying the Dockerfile like so:
 
 ```dockerfile
-FROM jupyter/all-spark-notebook:2023-07-25
+FROM jupyter/all-spark-notebook
 # Your RUN commands and so on
 ```",Yes
examples/docker-compose/notebook/Dockerfile,examples/docker-compose/notebook/Dockerfile,ff657c7d51d67ab766e7bff6e453c808fb010cad,32733a437d147d2a46d2e798093879a98d739444,Remove tags from examples folder,"diff --git a/examples/docker-compose/notebook/Dockerfile b/examples/docker-compose/notebook/Dockerfile
index 07846faa..13b758fd 100644
--- a/examples/docker-compose/notebook/Dockerfile
+++ b/examples/docker-compose/notebook/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook:2023-07-25
+FROM jupyter/minimal-notebook
 
 USER root","diff --git a/examples/docker-compose/notebook/Dockerfile b/examples/docker-compose/notebook/Dockerfile
index 07846faa..13b758fd 100644
--- a/examples/docker-compose/notebook/Dockerfile
+++ b/examples/docker-compose/notebook/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook:2023-07-25
+FROM jupyter/minimal-notebook
 
 USER root",Yes
examples/make-deploy/Dockerfile,examples/make-deploy/Dockerfile,ff657c7d51d67ab766e7bff6e453c808fb010cad,32733a437d147d2a46d2e798093879a98d739444,Remove tags from examples folder,"diff --git a/examples/make-deploy/Dockerfile b/examples/make-deploy/Dockerfile
index 07846faa..13b758fd 100644
--- a/examples/make-deploy/Dockerfile
+++ b/examples/make-deploy/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook:2023-07-25
+FROM jupyter/minimal-notebook
 
 USER root","diff --git a/examples/make-deploy/Dockerfile b/examples/make-deploy/Dockerfile
index 07846faa..13b758fd 100644
--- a/examples/make-deploy/Dockerfile
+++ b/examples/make-deploy/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook:2023-07-25
+FROM jupyter/minimal-notebook
 
 USER root",Yes
docs/using/recipes.md,docs/using/recipes.md,9590b0e13cec0862f1b304fb66cc5176daeef5f3,ff657c7d51d67ab766e7bff6e453c808fb010cad,Do not use --detach for docker-compose in recipe,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index e3f6a078..42b85cd9 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -125,7 +125,7 @@ Sometimes it is helpful to run the Jupyter instance behind an nginx proxy, for e
 
 Here is a [quick example of NGINX configuration](https://gist.github.com/cboettig/8643341bd3c93b62b5c2) to get started.
 You'll need a server, a `.crt` and `.key` file for your server, and `docker` & `docker-compose` installed.
-Then download the files at that gist and run `docker-compose up -d` to test it out.
+Then download the files at that gist and run `docker-compose up` to test it out.
 Customize the `nginx.conf` file to set the desired paths and add other services.
 
 ## Host volume mounts and notebook errors","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index e3f6a078..42b85cd9 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -125,7 +125,7 @@ Sometimes it is helpful to run the Jupyter instance behind an nginx proxy, for e
 
 Here is a [quick example of NGINX configuration](https://gist.github.com/cboettig/8643341bd3c93b62b5c2) to get started.
 You'll need a server, a `.crt` and `.key` file for your server, and `docker` & `docker-compose` installed.
-Then download the files at that gist and run `docker-compose up -d` to test it out.
+Then download the files at that gist and run `docker-compose up` to test it out.
 Customize the `nginx.conf` file to set the desired paths and add other services.
 
 ## Host volume mounts and notebook errors",Yes
docs/using/recipes.md,docs/using/recipes.md,35a8587e4a8eb07e00abe4f3c9fcf1a649f2f644,9590b0e13cec0862f1b304fb66cc5176daeef5f3,Update docs on using DockerSpawner,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 42b85cd9..f1efb5f2 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -163,25 +163,9 @@ Be sure to check the current base image in `jupyter/docker-stacks-foundation` be
 
 We also have contributed recipes for using JupyterHub.
 
-### Use JupyterHub's dockerspawner
+### Use JupyterHub's DockerSpawner
 
-```{warning}
-This recipe is not tested and might be broken.
-```
-
-In most cases for use with DockerSpawner, given an image that already has a notebook stack set up,
-you would only need to add:
-
-1. install the jupyterhub-singleuser script (for the correct Python version)
-2. change the command to launch the single-user server
-
-Swapping out the `FROM` line in the `jupyterhub/singleuser` Dockerfile should be enough for most
-cases.
-
-Credit: [Justin Tyberg](https://github.com/jtyberg), [quanghoc](https://github.com/quanghoc), and
-[Min RK](https://github.com/minrk) based on
-[docker-stacks/issues/124](https://github.com/jupyter/docker-stacks/issues/124) and
-[docker-stacks/pull/185](https://github.com/jupyter/docker-stacks/pull/185)
+You can find an example of using DockerSpawner [here](https://github.com/jupyterhub/jupyterhub-deploy-docker/tree/main/basic-example).
 
 ### Containers with a specific version of JupyterHub","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 42b85cd9..f1efb5f2 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -163,25 +163,9 @@ Be sure to check the current base image in `jupyter/docker-stacks-foundation` be
 
 We also have contributed recipes for using JupyterHub.
 
-### Use JupyterHub's dockerspawner
+### Use JupyterHub's DockerSpawner
 
-```{warning}
-This recipe is not tested and might be broken.
-```
-
-In most cases for use with DockerSpawner, given an image that already has a notebook stack set up,
-you would only need to add:
-
-1. install the jupyterhub-singleuser script (for the correct Python version)
-2. change the command to launch the single-user server
-
-Swapping out the `FROM` line in the `jupyterhub/singleuser` Dockerfile should be enough for most
-cases.
-
-Credit: [Justin Tyberg](https://github.com/jtyberg), [quanghoc](https://github.com/quanghoc), and
-[Min RK](https://github.com/minrk) based on
-[docker-stacks/issues/124](https://github.com/jupyter/docker-stacks/issues/124) and
-[docker-stacks/pull/185](https://github.com/jupyter/docker-stacks/pull/185)
+You can find an example of using DockerSpawner [here](https://github.com/jupyterhub/jupyterhub-deploy-docker/tree/main/basic-example).
 
 ### Containers with a specific version of JupyterHub",Yes
docs/using/recipes.md,docs/using/recipes.md,513218c44b0a3ba7538b2626a03e34623ee5d98f,35a8587e4a8eb07e00abe4f3c9fcf1a649f2f644,Update jupyterhub specific version choice docs,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index f1efb5f2..a57e37b6 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -169,8 +169,9 @@ You can find an example of using DockerSpawner [here](https://github.com/jupyter
 
 ### Containers with a specific version of JupyterHub
 
-To use a specific version of JupyterHub, the version of `jupyterhub` in your image should match the
-version in the Hub itself.
+The version of `jupyterhub` in your image should match the
+version in the JupyterHub itself.
+To use a specific version of JupyterHub, do the following:
 
 ```{literalinclude} recipe_code/jupyterhub_version.dockerfile
 :language: docker","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index f1efb5f2..a57e37b6 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -169,8 +169,9 @@ You can find an example of using DockerSpawner [here](https://github.com/jupyter
 
 ### Containers with a specific version of JupyterHub
 
-To use a specific version of JupyterHub, the version of `jupyterhub` in your image should match the
-version in the Hub itself.
+The version of `jupyterhub` in your image should match the
+version in the JupyterHub itself.
+To use a specific version of JupyterHub, do the following:
 
 ```{literalinclude} recipe_code/jupyterhub_version.dockerfile
 :language: docker",Yes
docs/using/recipes.md,docs/using/recipes.md,d169b6ad4543a2dccfbdbd1e93990c674078e60c,513218c44b0a3ba7538b2626a03e34623ee5d98f,Better wording,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index a57e37b6..08e76873 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -192,7 +192,8 @@ Using Spark session for Hadoop 2.7.3
 ```python
 import os
 
-# !ls /usr/local/spark/jars/hadoop* # to figure out what version of Hadoop
+# To figure out what version of Hadoop, run:
+# ls /usr/local/spark/jars/hadoop*
 os.environ[
     ""PYSPARK_SUBMIT_ARGS""
 ] = '--packages ""org.apache.hadoop:hadoop-aws:2.7.3"" pyspark-shell'","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index a57e37b6..08e76873 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -192,7 +192,8 @@ Using Spark session for Hadoop 2.7.3
 ```python
 import os
 
-# !ls /usr/local/spark/jars/hadoop* # to figure out what version of Hadoop
+# To figure out what version of Hadoop, run:
+# ls /usr/local/spark/jars/hadoop*
 os.environ[
     ""PYSPARK_SUBMIT_ARGS""
 ] = '--packages ""org.apache.hadoop:hadoop-aws:2.7.3"" pyspark-shell'",Yes
docs/using/recipes.md,docs/using/recipes.md,0291bd6fa1fe259fe80a285712441dd41e8f27f2,d169b6ad4543a2dccfbdbd1e93990c674078e60c,Use jupyter/base-notebook in an example,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 08e76873..09cbd9bd 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -395,7 +395,7 @@ This recipe is not tested and might be broken.
 NB: this works for classic notebooks only
 
 ```dockerfile
-FROM jupyter/minimal-notebook
+FROM jupyter/base-notebook
 
 USER ${NB_UID}","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 08e76873..09cbd9bd 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -395,7 +395,7 @@ This recipe is not tested and might be broken.
 NB: this works for classic notebooks only
 
 ```dockerfile
-FROM jupyter/minimal-notebook
+FROM jupyter/base-notebook
 
 USER ${NB_UID}",Yes
docs/using/recipes.md,docs/using/recipes.md,b323e5d850a00ee6fa496f45e636a56bcb1d93c9,0291bd6fa1fe259fe80a285712441dd41e8f27f2,Remove unused docker command,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 09cbd9bd..1e00a611 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -397,8 +397,6 @@ NB: this works for classic notebooks only
 ```dockerfile
 FROM jupyter/base-notebook
 
-USER ${NB_UID}
-
 RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \
     # can modify or enable additional extensions here","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 09cbd9bd..1e00a611 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -397,8 +397,6 @@ NB: this works for classic notebooks only
 ```dockerfile
 FROM jupyter/base-notebook
 
-USER ${NB_UID}
-
 RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \
     # can modify or enable additional extensions here",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,4a6057f58fb8c4210d4230d7eb952b936461b182,b323e5d850a00ee6fa496f45e636a56bcb1d93c9,Update spellcheck notebookv6 recipe,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 87f9d4e6..59f52979 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -45,6 +45,7 @@ jobs:
             manpage_install.dockerfile,
             microsoft_odbc.dockerfile,
             pip_install.dockerfile,
+            spellcheck_notebookv6.dockerfile,
             rise_jupyterlab.dockerfile,
             xgboost.dockerfile,
           ]","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 87f9d4e6..59f52979 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -45,6 +45,7 @@ jobs:
             manpage_install.dockerfile,
             microsoft_odbc.dockerfile,
             pip_install.dockerfile,
+            spellcheck_notebookv6.dockerfile,
             rise_jupyterlab.dockerfile,
             xgboost.dockerfile,
           ]",Yes
docs/using/recipes.md,docs/using/recipes.md,4a6057f58fb8c4210d4230d7eb952b936461b182,b323e5d850a00ee6fa496f45e636a56bcb1d93c9,Update spellcheck notebookv6 recipe,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 1e00a611..60f78d25 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -388,25 +388,15 @@ docker run -it --rm \
 
 ## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)
 
-```{warning}
-This recipe is not tested and might be broken.
+```{note}
+This recipe only works for NBCassic with Jupyter Notebook < 7.
+It is recommended to use [jupyterlab-spellchecker](https://github.com/jupyterlab-contrib/spellchecker) in modern environments.
 ```
 
-NB: this works for classic notebooks only
-
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
-    jupyter contrib nbextension install --user && \
-    # can modify or enable additional extensions here
-    jupyter nbclassic-extension enable spellchecker/main --user && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/spellcheck_notebookv6.dockerfile
+:language: docker
 ```
 
-Ref: <https://github.com/jupyter/docker-stacks/issues/675>
-
 ## Enable Delta Lake in Spark notebooks
 
 ```{warning}","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 1e00a611..60f78d25 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -388,25 +388,15 @@ docker run -it --rm \
 
 ## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)
 
-```{warning}
-This recipe is not tested and might be broken.
+```{note}
+This recipe only works for NBCassic with Jupyter Notebook < 7.
+It is recommended to use [jupyterlab-spellchecker](https://github.com/jupyterlab-contrib/spellchecker) in modern environments.
 ```
 
-NB: this works for classic notebooks only
-
-```dockerfile
-FROM jupyter/base-notebook
-
-RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
-    jupyter contrib nbextension install --user && \
-    # can modify or enable additional extensions here
-    jupyter nbclassic-extension enable spellchecker/main --user && \
-    fix-permissions ""${CONDA_DIR}"" && \
-    fix-permissions ""/home/${NB_USER}""
+```{literalinclude} recipe_code/spellcheck_notebookv6.dockerfile
+:language: docker
 ```
 
-Ref: <https://github.com/jupyter/docker-stacks/issues/675>
-
 ## Enable Delta Lake in Spark notebooks
 
 ```{warning}",Yes
,docs/using/recipe_code/spellcheck_notebookv6.dockerfile,f14658e28f20263c9c3250421941107b71a0031b,4a6057f58fb8c4210d4230d7eb952b936461b182,Add missing file,"diff --git a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
new file mode 100644
index 00000000..73418530
--- /dev/null
+++ b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
@@ -0,0 +1,8 @@
+FROM jupyter/base-notebook:notebook-6.5.4
+
+RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
+    jupyter contrib nbextension install --user && \
+    # can modify or enable additional extensions here
+    jupyter nbclassic-extension enable spellchecker/main --user && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
new file mode 100644
index 00000000..73418530
--- /dev/null
+++ b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
@@ -0,0 +1,8 @@
+FROM jupyter/base-notebook:notebook-6.5.4
+
+RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
+    jupyter contrib nbextension install --user && \
+    # can modify or enable additional extensions here
+    jupyter nbclassic-extension enable spellchecker/main --user && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
docs/using/recipes.md,docs/using/recipes.md,b4f1acc0d6ebaceee0dd6397252ecd80521b2ff0,f14658e28f20263c9c3250421941107b71a0031b,Use mamba instead of pin for delta-spark,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 60f78d25..92229345 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -409,10 +409,10 @@ By adding the properties to `spark-defaults.conf`, the user no longer needs to e
 ```dockerfile
 FROM jupyter/pyspark-notebook
 
-ARG DELTA_CORE_VERSION=""1.2.1""
-RUN pip install --no-cache-dir 'delta-spark==${DELTA_CORE_VERSION}' && \
-     fix-permissions ""${HOME}"" && \
-     fix-permissions ""${CONDA_DIR}""
+RUN mamba install --yes 'delta-spark' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${HOME}"" && \
+    fix-permissions ""${CONDA_DIR}""
 
 USER root","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 60f78d25..92229345 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -409,10 +409,10 @@ By adding the properties to `spark-defaults.conf`, the user no longer needs to e
 ```dockerfile
 FROM jupyter/pyspark-notebook
 
-ARG DELTA_CORE_VERSION=""1.2.1""
-RUN pip install --no-cache-dir 'delta-spark==${DELTA_CORE_VERSION}' && \
-     fix-permissions ""${HOME}"" && \
-     fix-permissions ""${CONDA_DIR}""
+RUN mamba install --yes 'delta-spark' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${HOME}"" && \
+    fix-permissions ""${CONDA_DIR}""
 
 USER root",Yes
docker-stacks-foundation/Dockerfile,docker-stacks-foundation/Dockerfile,3778ebff6e50fcdd5e90ab1396831b4637e18a5e,b4f1acc0d6ebaceee0dd6397252ecd80521b2ff0,Unify fix-permissions usage,"diff --git a/docker-stacks-foundation/Dockerfile b/docker-stacks-foundation/Dockerfile
index e6868736..7e62b64c 100644
--- a/docker-stacks-foundation/Dockerfile
+++ b/docker-stacks-foundation/Dockerfile
@@ -71,8 +71,8 @@ RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
     mkdir -p ""${CONDA_DIR}"" && \
     chown ""${NB_USER}:${NB_GID}"" ""${CONDA_DIR}"" && \
     chmod g+w /etc/passwd && \
-    fix-permissions ""${HOME}"" && \
-    fix-permissions ""${CONDA_DIR}""
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
 
 USER ${NB_UID}","diff --git a/docker-stacks-foundation/Dockerfile b/docker-stacks-foundation/Dockerfile
index e6868736..7e62b64c 100644
--- a/docker-stacks-foundation/Dockerfile
+++ b/docker-stacks-foundation/Dockerfile
@@ -71,8 +71,8 @@ RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
     mkdir -p ""${CONDA_DIR}"" && \
     chown ""${NB_USER}:${NB_GID}"" ""${CONDA_DIR}"" && \
     chmod g+w /etc/passwd && \
-    fix-permissions ""${HOME}"" && \
-    fix-permissions ""${CONDA_DIR}""
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
 
 USER ${NB_UID}",Yes
docs/using/recipes.md,docs/using/recipes.md,3778ebff6e50fcdd5e90ab1396831b4637e18a5e,b4f1acc0d6ebaceee0dd6397252ecd80521b2ff0,Unify fix-permissions usage,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 92229345..2da905b0 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -411,8 +411,8 @@ FROM jupyter/pyspark-notebook
 
 RUN mamba install --yes 'delta-spark' && \
     mamba clean --all -f -y && \
-    fix-permissions ""${HOME}"" && \
-    fix-permissions ""${CONDA_DIR}""
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
 
 USER root","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 92229345..2da905b0 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -411,8 +411,8 @@ FROM jupyter/pyspark-notebook
 
 RUN mamba install --yes 'delta-spark' && \
     mamba clean --all -f -y && \
-    fix-permissions ""${HOME}"" && \
-    fix-permissions ""${CONDA_DIR}""
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
 
 USER root",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,4387d1d12bbca121be6d8f97c9c5d39d6b0de779,3778ebff6e50fcdd5e90ab1396831b4637e18a5e,Add workflow_dispatch to contributed-recipes workflow,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 59f52979..804c9901 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -15,6 +15,7 @@ on:
     paths:
       - "".github/workflows/contributed-recipes.yml""
       - ""docs/using/recipe_code/""
+  workflow_dispatch:
 
 jobs:
   test-recipes:","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 59f52979..804c9901 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -15,6 +15,7 @@ on:
     paths:
       - "".github/workflows/contributed-recipes.yml""
       - ""docs/using/recipe_code/""
+  workflow_dispatch:
 
 jobs:
   test-recipes:",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,0b7d08cc5f8d9ac1aa9d8694f8d0f63e622e47fc,4387d1d12bbca121be6d8f97c9c5d39d6b0de779,Fix Docker Hub name,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 75e4a732..7f6bd2a7 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,4 +1,4 @@
-name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to DockerHub
+name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to Docker Hub
 
 env:
   OWNER: ${{ github.repository_owner }}","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 75e4a732..7f6bd2a7 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,4 +1,4 @@
-name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to DockerHub
+name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to Docker Hub
 
 env:
   OWNER: ${{ github.repository_owner }}",Yes
.github/workflows/hub-overview.yml,.github/workflows/hub-overview.yml,0b7d08cc5f8d9ac1aa9d8694f8d0f63e622e47fc,4387d1d12bbca121be6d8f97c9c5d39d6b0de779,Fix Docker Hub name,"diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index 2e5234e8..aef107f2 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -1,4 +1,4 @@
-name: Update dockerhub overviews
+name: Update Docker Hub overviews
 
 env:
   OWNER: ${{ github.repository_owner }}
@@ -23,7 +23,7 @@ on:
 
 jobs:
   update-dockerhub-overview:
-    name: Update dockerhub overviews
+    name: Update Docker Hub overviews
     runs-on: ubuntu-latest
     if: github.repository == 'jupyter/docker-stacks'
 
@@ -31,7 +31,7 @@ jobs:
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v3
 
-      - name: Push README to Dockerhub 🐳
+      - name: Push README to Docker Hub 🐳
         uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1
         env:
           DOCKER_USER: ${{ secrets.DOCKERHUB_USERNAME }}","diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index 2e5234e8..aef107f2 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -1,4 +1,4 @@
-name: Update dockerhub overviews
+name: Update Docker Hub overviews
 
 env:
   OWNER: ${{ github.repository_owner }}
@@ -23,7 +23,7 @@ on:
 
 jobs:
   update-dockerhub-overview:
-    name: Update dockerhub overviews
+    name: Update Docker Hub overviews
     runs-on: ubuntu-latest
     if: github.repository == 'jupyter/docker-stacks'
 
@@ -31,7 +31,7 @@ jobs:
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v3
 
-      - name: Push README to Dockerhub 🐳
+      - name: Push README to Docker Hub 🐳
         uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1
         env:
           DOCKER_USER: ${{ secrets.DOCKERHUB_USERNAME }}",Yes
README.md,README.md,0b7d08cc5f8d9ac1aa9d8694f8d0f63e622e47fc,4387d1d12bbca121be6d8f97c9c5d39d6b0de779,Fix Docker Hub name,"diff --git a/README.md b/README.md
index 714c2dad..94ee8e88 100644
--- a/README.md
+++ b/README.md
@@ -105,7 +105,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - [Issue Tracker on GitHub](https://github.com/jupyter/docker-stacks/issues)
 - [Jupyter Discourse Forum](https://discourse.jupyter.org/)
 - [Jupyter Website](https://jupyter.org)
-- [Images on DockerHub](https://hub.docker.com/u/jupyter)
+- [Images on Docker Hub](https://hub.docker.com/u/jupyter)
 
 ## CPU Architectures","diff --git a/README.md b/README.md
index 714c2dad..94ee8e88 100644
--- a/README.md
+++ b/README.md
@@ -105,7 +105,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - [Issue Tracker on GitHub](https://github.com/jupyter/docker-stacks/issues)
 - [Jupyter Discourse Forum](https://discourse.jupyter.org/)
 - [Jupyter Website](https://jupyter.org)
-- [Images on DockerHub](https://hub.docker.com/u/jupyter)
+- [Images on Docker Hub](https://hub.docker.com/u/jupyter)
 
 ## CPU Architectures",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,9cf9ff2b85abd64d5c9bb46deafd9ab6000ceb62,0b7d08cc5f8d9ac1aa9d8694f8d0f63e622e47fc,Call contributed-recipes check after docker build,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 804c9901..8210e25e 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -16,6 +16,7 @@ on:
       - "".github/workflows/contributed-recipes.yml""
       - ""docs/using/recipe_code/""
   workflow_dispatch:
+  workflow_call:
 
 jobs:
   test-recipes:","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 804c9901..8210e25e 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -16,6 +16,7 @@ on:
       - "".github/workflows/contributed-recipes.yml""
       - ""docs/using/recipe_code/""
   workflow_dispatch:
+  workflow_call:
 
 jobs:
   test-recipes:",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,9cf9ff2b85abd64d5c9bb46deafd9ab6000ceb62,0b7d08cc5f8d9ac1aa9d8694f8d0f63e622e47fc,Call contributed-recipes check after docker build,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index d6eec499..8d6a05f4 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -364,3 +364,8 @@ jobs:
     if: github.repository == 'jupyter/docker-stacks'
     permissions:
       contents: write
+
+  contributed-recipes:
+    uses: ./.github/workflows/contributed-recipes.yml
+    needs: [merge-tags]
+    if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index d6eec499..8d6a05f4 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -364,3 +364,8 @@ jobs:
     if: github.repository == 'jupyter/docker-stacks'
     permissions:
       contents: write
+
+  contributed-recipes:
+    uses: ./.github/workflows/contributed-recipes.yml
+    needs: [merge-tags]
+    if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,563601866815983a3289835dc404720afb990edb,9cf9ff2b85abd64d5c9bb46deafd9ab6000ceb62,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index c3ca4a07..8085b965 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -106,7 +106,7 @@ repos:
 
   # Lint: Python
   - repo: https://github.com/PyCQA/flake8
-    rev: 6.0.0
+    rev: 6.1.0
     hooks:
       - id: flake8","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index c3ca4a07..8085b965 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -106,7 +106,7 @@ repos:
 
   # Lint: Python
   - repo: https://github.com/PyCQA/flake8
-    rev: 6.0.0
+    rev: 6.1.0
     hooks:
       - id: flake8",Yes
docs/contributing/packages.md,docs/contributing/packages.md,d31f784b4305b2af02157f94fc1e9122f1f996cb,563601866815983a3289835dc404720afb990edb,Fix some typos,"diff --git a/docs/contributing/packages.md b/docs/contributing/packages.md
index 45537bd3..29f499d6 100644
--- a/docs/contributing/packages.md
+++ b/docs/contributing/packages.md
@@ -12,7 +12,7 @@ We pin major.minor version of python, so this will stay the same even after invo
 ## Outdated packages
 
 To help to identify packages that can be updated, you can use the following helper tool.
-It will list all the updateable packages installed in the `Dockerfile` --
+It will list all the outdated packages installed in the `Dockerfile` --
 dependencies are filtered to focus only on requested packages.
 
 ```bash","diff --git a/docs/contributing/packages.md b/docs/contributing/packages.md
index 45537bd3..29f499d6 100644
--- a/docs/contributing/packages.md
+++ b/docs/contributing/packages.md
@@ -12,7 +12,7 @@ We pin major.minor version of python, so this will stay the same even after invo
 ## Outdated packages
 
 To help to identify packages that can be updated, you can use the following helper tool.
-It will list all the updateable packages installed in the `Dockerfile` --
+It will list all the outdated packages installed in the `Dockerfile` --
 dependencies are filtered to focus only on requested packages.
 
 ```bash",Yes
docs/contributing/recipes.md,docs/contributing/recipes.md,d31f784b4305b2af02157f94fc1e9122f1f996cb,563601866815983a3289835dc404720afb990edb,Fix some typos,"diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index 48006744..98572c0f 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -6,7 +6,7 @@ Follow the process below to add a new recipe:
 1. Open the `docs/using/recipes.md` source file.
 2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Slideshows with JupyterLab and RISE`)
 3. Write the body of your recipe under the heading, including whatever command line, links, etc. you need.
-4. If you have a Dockerfile, please put it in a `recipe_code` subfolder
+4. If you have a Dockerfile, please put it in a `recipe_code` subdirectory
    and update [contributed-recipes workflow](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/contributed-recipes.yml) to include your file.
 5. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.","diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index 48006744..98572c0f 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -6,7 +6,7 @@ Follow the process below to add a new recipe:
 1. Open the `docs/using/recipes.md` source file.
 2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Slideshows with JupyterLab and RISE`)
 3. Write the body of your recipe under the heading, including whatever command line, links, etc. you need.
-4. If you have a Dockerfile, please put it in a `recipe_code` subfolder
+4. If you have a Dockerfile, please put it in a `recipe_code` subdirectory
    and update [contributed-recipes workflow](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/contributed-recipes.yml) to include your file.
 5. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,d31f784b4305b2af02157f94fc1e9122f1f996cb,563601866815983a3289835dc404720afb990edb,Fix some typos,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index b95dd513..35ebd6c6 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -50,7 +50,7 @@ When there's a new stack definition, check before merging the PR:
    The image links to the [blockdiag source](http://interactive.blockdiag.com/) used to create it.
 2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
 3. Necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
-4. A new repository is created in the `jupyter` org on Docker Hub
+4. A new repository is created in the `jupyter` org on Docker Hub,
    and it's named after the stack folder in the git repo.
 5. Grant the `stacks` team permission to write to this repo.","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index b95dd513..35ebd6c6 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -50,7 +50,7 @@ When there's a new stack definition, check before merging the PR:
    The image links to the [blockdiag source](http://interactive.blockdiag.com/) used to create it.
 2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
 3. Necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
-4. A new repository is created in the `jupyter` org on Docker Hub
+4. A new repository is created in the `jupyter` org on Docker Hub,
    and it's named after the stack folder in the git repo.
 5. Grant the `stacks` team permission to write to this repo.",Yes
README.md,README.md,8707b7a0b40e4afa5d2a6164890b4075555c2826,d31f784b4305b2af02157f94fc1e9122f1f996cb,Update tag example,"diff --git a/README.md b/README.md
index 94ee8e88..ed739a26 100644
--- a/README.md
+++ b/README.md
@@ -26,11 +26,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-25
+docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-31
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -45,11 +45,11 @@ The container remains intact for restart after the Server exits.
 
 **Example 2:**
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-31
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -112,7 +112,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-07-25`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-07-31`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images","diff --git a/README.md b/README.md
index 94ee8e88..ed739a26 100644
--- a/README.md
+++ b/README.md
@@ -26,11 +26,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-25
+docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-31
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -45,11 +45,11 @@ The container remains intact for restart after the Server exits.
 
 **Example 2:**
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-31
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -112,7 +112,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-07-25`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-07-31`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images",Yes
binder/Dockerfile,binder/Dockerfile,8707b7a0b40e4afa5d2a6164890b4075555c2826,d31f784b4305b2af02157f94fc1e9122f1f996cb,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 214a8008..dfe8ad8f 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -3,7 +3,7 @@
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-07-25
+ARG BASE_CONTAINER=$OWNER/base-notebook:2023-07-31
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -12,6 +12,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-07-25""
+ENV TAG=""2023-07-31""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 214a8008..dfe8ad8f 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -3,7 +3,7 @@
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-07-25
+ARG BASE_CONTAINER=$OWNER/base-notebook:2023-07-31
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -12,6 +12,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-07-25""
+ENV TAG=""2023-07-31""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,8707b7a0b40e4afa5d2a6164890b4075555c2826,d31f784b4305b2af02157f94fc1e9122f1f996cb,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index 923bbbd1..20600f84 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-25
+docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-31
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-07-25                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-07-31                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 **Example 2:**
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-31
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -130,7 +130,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -139,7 +139,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-07-25
+    docker.io/jupyter/r-notebook:2023-07-31
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 923bbbd1..20600f84 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-25
+docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-31
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-07-25                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-07-31                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 **Example 2:**
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-31
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -130,7 +130,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -139,7 +139,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-07-25
+    docker.io/jupyter/r-notebook:2023-07-31
 ```
 
 ```{warning}",Yes
docs/using/common.md,docs/using/common.md,e2a3c33d30aa195ff4aea43c938c0444c3b70f11,8707b7a0b40e4afa5d2a6164890b4075555c2826,Fix start.sh location in docs,"diff --git a/docs/using/common.md b/docs/using/common.md
index 6e04e5f8..71bb07eb 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -135,7 +135,7 @@ or executables (`chmod +x`) to be run to the paths below:
 - `/usr/local/bin/before-notebook.d/` - handled **after** all the standard options noted above are applied
   and ran right before the Server launches
 
-See the `run-hooks` function in the [`jupyter/base-notebook start.sh`](https://github.com/jupyter/docker-stacks/blob/main/docker-stacks-foundation/start.sh)
+See the `run-hooks` function in the [`jupyter/docker-stacks-foundation start.sh`](https://github.com/jupyter/docker-stacks/blob/main/docker-stacks-foundation/start.sh)
 script for execution details.
 
 ## SSL Certificates","diff --git a/docs/using/common.md b/docs/using/common.md
index 6e04e5f8..71bb07eb 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -135,7 +135,7 @@ or executables (`chmod +x`) to be run to the paths below:
 - `/usr/local/bin/before-notebook.d/` - handled **after** all the standard options noted above are applied
   and ran right before the Server launches
 
-See the `run-hooks` function in the [`jupyter/base-notebook start.sh`](https://github.com/jupyter/docker-stacks/blob/main/docker-stacks-foundation/start.sh)
+See the `run-hooks` function in the [`jupyter/docker-stacks-foundation start.sh`](https://github.com/jupyter/docker-stacks/blob/main/docker-stacks-foundation/start.sh)
 script for execution details.
 
 ## SSL Certificates",Yes
docs/contributing/lint.md,docs/contributing/lint.md,7057b1fc3c7375c52ca94b75222cf05348f7c23f,e2a3c33d30aa195ff4aea43c938c0444c3b70f11,Fix lint install command,"diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 1b213d05..92f22d19 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -13,7 +13,7 @@ To achieve this, use the generic task to install all Python development dependen
 
 ```sh
 # Install all development dependencies for the project
-pip install requirements-dev.txt
+pip install --upgrade -r requirements-dev.txt
 # It can also be installed directly
 pip install pre-commit
 ```","diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 1b213d05..92f22d19 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -13,7 +13,7 @@ To achieve this, use the generic task to install all Python development dependen
 
 ```sh
 # Install all development dependencies for the project
-pip install requirements-dev.txt
+pip install --upgrade -r requirements-dev.txt
 # It can also be installed directly
 pip install pre-commit
 ```",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,7202c631fdb512e0195ae8df6832ba5bcf1ba478,7057b1fc3c7375c52ca94b75222cf05348f7c23f,[pre-commit.ci] pre-commit autoupdate (#1956),"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 8085b965..9c438ea8 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.9.0
+    rev: v3.10.1
     hooks:
       - id: pyupgrade
         args: [--py39-plus]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 8085b965..9c438ea8 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.9.0
+    rev: v3.10.1
     hooks:
       - id: pyupgrade
         args: [--py39-plus]",Yes
docs/using/common.md,docs/using/common.md,b5003a0259dfc9b68836b6cf97348c4dff8322f9,7202c631fdb512e0195ae8df6832ba5bcf1ba478,"Add docs how to change frontend for JupyterHub singleuser image (#1957)

* Add docs how to change frontend for JupyterHub singleuser image

* Update common.md","diff --git a/docs/using/common.md b/docs/using/common.md
index 71bb07eb..68ec6146 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -194,10 +194,11 @@ Since `Jupyter Notebook v7` `jupyter-server` is used as a backend.
 | `server`                    | None             |
 | `retro`\*                   | RetroLab         |
 
-Notes:
-
-- \*Not installed at this time, but it could be the case in the future or in a community stack.
+```{note}
+- Changing frontend for **JupyterHub singleuser image** is described in [JupyterHub docs](https://jupyterhub.readthedocs.io/en/latest/howto/configuration/config-user-env.html#switching-back-to-the-classic-notebook).
+- \* `retro` is not installed at this time, but it could be the case in the future or in a community stack.
 - Any other valid `jupyter` subcommand that starts the Jupyter Application can be used.
+```
 
 Example:","diff --git a/docs/using/common.md b/docs/using/common.md
index 71bb07eb..68ec6146 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -194,10 +194,11 @@ Since `Jupyter Notebook v7` `jupyter-server` is used as a backend.
 | `server`                    | None             |
 | `retro`\*                   | RetroLab         |
 
-Notes:
-
-- \*Not installed at this time, but it could be the case in the future or in a community stack.
+```{note}
+- Changing frontend for **JupyterHub singleuser image** is described in [JupyterHub docs](https://jupyterhub.readthedocs.io/en/latest/howto/configuration/config-user-env.html#switching-back-to-the-classic-notebook).
+- \* `retro` is not installed at this time, but it could be the case in the future or in a community stack.
 - Any other valid `jupyter` subcommand that starts the Jupyter Application can be used.
+```
 
 Example:",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,83c70a7dbe2c07270c7d75d0f4238264277c5f95,b5003a0259dfc9b68836b6cf97348c4dff8322f9,Build contributed recipes one hour before building images,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 8210e25e..f91c09cd 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -2,9 +2,10 @@ name: Test contributed recipes
 
 on:
   schedule:
-    # Images are rebuilt on Monday, so we're testing recipes each Tuesday
-    # Weekly, at 03:00 on Tuesday UTC time
-    - cron: ""0 3 * * 2""
+    # Images are rebuilt at 03:00 on Monday UTC
+    # So we're testing recipes one hour in advance
+    # They will also be tested after building images
+    - cron: ""0 2 * * 1""
   pull_request:
     paths:
       - "".github/workflows/contributed-recipes.yml""","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 8210e25e..f91c09cd 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -2,9 +2,10 @@ name: Test contributed recipes
 
 on:
   schedule:
-    # Images are rebuilt on Monday, so we're testing recipes each Tuesday
-    # Weekly, at 03:00 on Tuesday UTC time
-    - cron: ""0 3 * * 2""
+    # Images are rebuilt at 03:00 on Monday UTC
+    # So we're testing recipes one hour in advance
+    # They will also be tested after building images
+    - cron: ""0 2 * * 1""
   pull_request:
     paths:
       - "".github/workflows/contributed-recipes.yml""",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,1d9e4f99a596bebc1ffa491a350315e715e74243,83c70a7dbe2c07270c7d75d0f4238264277c5f95,Improve pre-commit hadolint name,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 9c438ea8..6bb19b37 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -78,6 +78,7 @@ repos:
     rev: v2.12.1-beta
     hooks:
       - id: hadolint-docker
+        name: Lint *.dockerfile Dockerfiles
         entry: hadolint/hadolint:v2.12.1-beta hadolint
         types: [file]
         files: \.dockerfile$","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 9c438ea8..6bb19b37 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -78,6 +78,7 @@ repos:
     rev: v2.12.1-beta
     hooks:
       - id: hadolint-docker
+        name: Lint *.dockerfile Dockerfiles
         entry: hadolint/hadolint:v2.12.1-beta hadolint
         types: [file]
         files: \.dockerfile$",Yes
docs/using/selecting.md,docs/using/selecting.md,e1bd309263e542f68187a5d89c73c09fa599faa3,1d9e4f99a596bebc1ffa491a350315e715e74243,"Use curl instead of wget for Spark and Julia downloads (#1950)

Co-authored-by: Bjørn Jørgensen <bjornjorgensen@users.noreply.github.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 3723ba45..d823f020 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -71,6 +71,7 @@ It contains:
 
 - Everything in `jupyter/base-notebook`
 - Common useful utilities like
+  [curl](https://curl.se),
   [git](https://git-scm.com/),
   [nano](https://www.nano-editor.org/) (actually `nano-tiny`),
   [tzdata](https://www.iana.org/time-zones),","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 3723ba45..d823f020 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -71,6 +71,7 @@ It contains:
 
 - Everything in `jupyter/base-notebook`
 - Common useful utilities like
+  [curl](https://curl.se),
   [git](https://git-scm.com/),
   [nano](https://www.nano-editor.org/) (actually `nano-tiny`),
   [tzdata](https://www.iana.org/time-zones),",Yes
minimal-notebook/Dockerfile,minimal-notebook/Dockerfile,e1bd309263e542f68187a5d89c73c09fa599faa3,1d9e4f99a596bebc1ffa491a350315e715e74243,"Use curl instead of wget for Spark and Julia downloads (#1950)

Co-authored-by: Bjørn Jørgensen <bjornjorgensen@users.noreply.github.com>","diff --git a/minimal-notebook/Dockerfile b/minimal-notebook/Dockerfile
index 29f3bdda..6511304d 100644
--- a/minimal-notebook/Dockerfile
+++ b/minimal-notebook/Dockerfile
@@ -16,6 +16,7 @@ USER root
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     # Common useful utilities
+    curl \
     git \
     nano-tiny \
     tzdata \","diff --git a/minimal-notebook/Dockerfile b/minimal-notebook/Dockerfile
index 29f3bdda..6511304d 100644
--- a/minimal-notebook/Dockerfile
+++ b/minimal-notebook/Dockerfile
@@ -16,6 +16,7 @@ USER root
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     # Common useful utilities
+    curl \
     git \
     nano-tiny \
     tzdata \",Yes
minimal-notebook/setup-scripts/setup-julia.bash,minimal-notebook/setup-scripts/setup-julia.bash,e1bd309263e542f68187a5d89c73c09fa599faa3,1d9e4f99a596bebc1ffa491a350315e715e74243,"Use curl instead of wget for Spark and Julia downloads (#1950)

Co-authored-by: Bjørn Jørgensen <bjornjorgensen@users.noreply.github.com>","diff --git a/minimal-notebook/setup-scripts/setup-julia.bash b/minimal-notebook/setup-scripts/setup-julia.bash
index 29d2b172..d8782042 100755
--- a/minimal-notebook/setup-scripts/setup-julia.bash
+++ b/minimal-notebook/setup-scripts/setup-julia.bash
@@ -22,7 +22,8 @@ JULIA_MAJOR_MINOR=$(echo ""${JULIA_VERSION}"" | cut -d. -f 1,2)
 # Download and install Julia
 cd /tmp
 mkdir ""/opt/julia-${JULIA_VERSION}""
-wget --progress=dot:giga ""https://julialang-s3.julialang.org/bin/linux/${JULIA_SHORT_ARCH}/${JULIA_MAJOR_MINOR}/${JULIA_INSTALLER}""
+curl --progress-bar --location --output ""${JULIA_INSTALLER}"" \
+    ""https://julialang-s3.julialang.org/bin/linux/${JULIA_SHORT_ARCH}/${JULIA_MAJOR_MINOR}/${JULIA_INSTALLER}""
 tar xzf ""${JULIA_INSTALLER}"" -C ""/opt/julia-${JULIA_VERSION}"" --strip-components=1
 rm ""${JULIA_INSTALLER}""","diff --git a/minimal-notebook/setup-scripts/setup-julia.bash b/minimal-notebook/setup-scripts/setup-julia.bash
index 29d2b172..d8782042 100755
--- a/minimal-notebook/setup-scripts/setup-julia.bash
+++ b/minimal-notebook/setup-scripts/setup-julia.bash
@@ -22,7 +22,8 @@ JULIA_MAJOR_MINOR=$(echo ""${JULIA_VERSION}"" | cut -d. -f 1,2)
 # Download and install Julia
 cd /tmp
 mkdir ""/opt/julia-${JULIA_VERSION}""
-wget --progress=dot:giga ""https://julialang-s3.julialang.org/bin/linux/${JULIA_SHORT_ARCH}/${JULIA_MAJOR_MINOR}/${JULIA_INSTALLER}""
+curl --progress-bar --location --output ""${JULIA_INSTALLER}"" \
+    ""https://julialang-s3.julialang.org/bin/linux/${JULIA_SHORT_ARCH}/${JULIA_MAJOR_MINOR}/${JULIA_INSTALLER}""
 tar xzf ""${JULIA_INSTALLER}"" -C ""/opt/julia-${JULIA_VERSION}"" --strip-components=1
 rm ""${JULIA_INSTALLER}""",Yes
pyspark-notebook/Dockerfile,pyspark-notebook/Dockerfile,e1bd309263e542f68187a5d89c73c09fa599faa3,1d9e4f99a596bebc1ffa491a350315e715e74243,"Use curl instead of wget for Spark and Julia downloads (#1950)

Co-authored-by: Bjørn Jørgensen <bjornjorgensen@users.noreply.github.com>","diff --git a/pyspark-notebook/Dockerfile b/pyspark-notebook/Dockerfile
index ad981103..cff30a8e 100644
--- a/pyspark-notebook/Dockerfile
+++ b/pyspark-notebook/Dockerfile
@@ -36,9 +36,11 @@ WORKDIR /tmp
 # You need to use https://archive.apache.org/dist/ website if you want to download old Spark versions
 # But it seems to be slower, that's why we use recommended site for download
 RUN if [ -z ""${scala_version}"" ]; then \
-    wget --progress=dot:giga -O ""spark.tgz"" ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \
+    curl --progress-bar --location --output ""spark.tgz"" \
+        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \
   else \
-    wget --progress=dot:giga -O ""spark.tgz"" ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}.tgz""; \
+    curl --progress-bar --location --output ""spark.tgz"" \
+        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}.tgz""; \
   fi && \
   echo ""${spark_checksum} *spark.tgz"" | sha512sum -c - && \
   tar xzf ""spark.tgz"" -C /usr/local --owner root --group root --no-same-owner && \","diff --git a/pyspark-notebook/Dockerfile b/pyspark-notebook/Dockerfile
index ad981103..cff30a8e 100644
--- a/pyspark-notebook/Dockerfile
+++ b/pyspark-notebook/Dockerfile
@@ -36,9 +36,11 @@ WORKDIR /tmp
 # You need to use https://archive.apache.org/dist/ website if you want to download old Spark versions
 # But it seems to be slower, that's why we use recommended site for download
 RUN if [ -z ""${scala_version}"" ]; then \
-    wget --progress=dot:giga -O ""spark.tgz"" ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \
+    curl --progress-bar --location --output ""spark.tgz"" \
+        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \
   else \
-    wget --progress=dot:giga -O ""spark.tgz"" ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}.tgz""; \
+    curl --progress-bar --location --output ""spark.tgz"" \
+        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}.tgz""; \
   fi && \
   echo ""${spark_checksum} *spark.tgz"" | sha512sum -c - && \
   tar xzf ""spark.tgz"" -C /usr/local --owner root --group root --no-same-owner && \",Yes
aarch64-runner/setup.sh,aarch64-runner/setup.sh,c6ec6184ab96ddfe571b696dc2f4c0b2c011b02e,e1bd309263e542f68187a5d89c73c09fa599faa3,Fix chown for aarch64 runner,"diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index 96fb247a..751ab200 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -15,7 +15,7 @@ echo ""Setting up runner-user, who will run GitHub Actions runner""
 adduser --disabled-password --gecos """" ${GITHUB_RUNNER_USER}
 mkdir /home/${GITHUB_RUNNER_USER}/.ssh/
 cp ""/home/${SUDO_USER}/.ssh/authorized_keys"" ""/home/${GITHUB_RUNNER_USER}/.ssh/authorized_keys""
-chown ${GITHUB_RUNNER_USER}:${GITHUB_RUNNER_USER} /home/${GITHUB_RUNNER_USER}/.ssh/authorized_keys
+chown --recursive ${GITHUB_RUNNER_USER}:${GITHUB_RUNNER_USER} /home/${GITHUB_RUNNER_USER}/.ssh
 
 echo ""Setting up python3""
 apt-get install --yes --no-install-recommends python3","diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index 96fb247a..751ab200 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -15,7 +15,7 @@ echo ""Setting up runner-user, who will run GitHub Actions runner""
 adduser --disabled-password --gecos """" ${GITHUB_RUNNER_USER}
 mkdir /home/${GITHUB_RUNNER_USER}/.ssh/
 cp ""/home/${SUDO_USER}/.ssh/authorized_keys"" ""/home/${GITHUB_RUNNER_USER}/.ssh/authorized_keys""
-chown ${GITHUB_RUNNER_USER}:${GITHUB_RUNNER_USER} /home/${GITHUB_RUNNER_USER}/.ssh/authorized_keys
+chown --recursive ${GITHUB_RUNNER_USER}:${GITHUB_RUNNER_USER} /home/${GITHUB_RUNNER_USER}/.ssh
 
 echo ""Setting up python3""
 apt-get install --yes --no-install-recommends python3",Yes
aarch64-runner/setup.sh,aarch64-runner/setup.sh,0ba7a4c15aab9df6812a0de1139c4981a2a8b6c3,c6ec6184ab96ddfe571b696dc2f4c0b2c011b02e,Install latest docker version to aarch64 runners,"diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index 751ab200..dd8d40a0 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -22,6 +22,16 @@ apt-get install --yes --no-install-recommends python3
 curl -sS https://bootstrap.pypa.io/get-pip.py | python3
 
 echo ""Setting up docker""
-apt-get install --yes --no-install-recommends docker.io
+apt-get remove --yes docker.io docker-doc docker-compose podman-docker containerd runc
+apt-get update
+apt-get install --yes ca-certificates curl gnupg
+install -m 0755 -d /etc/apt/keyrings
+curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
+chmod a+r /etc/apt/keyrings/docker.gpg
+echo ""deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"" | \
+    tee /etc/apt/sources.list.d/docker.list > /dev/null
+apt-get update
+apt-get install --yes docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
+
 usermod -aG docker ${GITHUB_RUNNER_USER}
 chmod 666 /var/run/docker.sock","diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index 751ab200..dd8d40a0 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -22,6 +22,16 @@ apt-get install --yes --no-install-recommends python3
 curl -sS https://bootstrap.pypa.io/get-pip.py | python3
 
 echo ""Setting up docker""
-apt-get install --yes --no-install-recommends docker.io
+apt-get remove --yes docker.io docker-doc docker-compose podman-docker containerd runc
+apt-get update
+apt-get install --yes ca-certificates curl gnupg
+install -m 0755 -d /etc/apt/keyrings
+curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
+chmod a+r /etc/apt/keyrings/docker.gpg
+echo ""deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"" | \
+    tee /etc/apt/sources.list.d/docker.list > /dev/null
+apt-get update
+apt-get install --yes docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
+
 usermod -aG docker ${GITHUB_RUNNER_USER}
 chmod 666 /var/run/docker.sock",Yes
scipy-notebook/Dockerfile,scipy-notebook/Dockerfile,13c7da8fce95ac851e188860bb5edd7f7836d0cc,0ba7a4c15aab9df6812a0de1139c4981a2a8b6c3,Temporarily pin jupyterlab and notebook in scipy-notebook,"diff --git a/scipy-notebook/Dockerfile b/scipy-notebook/Dockerfile
index 6338f42e..714a7911 100644
--- a/scipy-notebook/Dockerfile
+++ b/scipy-notebook/Dockerfile
@@ -25,6 +25,10 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
+# mamba downgrades this packages to previous major version, which causes issues
+RUN echo 'jupyterlab >=4.0.4' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    echo 'notebook >=7.0.2' >> ""${CONDA_DIR}/conda-meta/pinned""
+
 # Install Python 3 packages
 RUN mamba install --yes \
     'altair' \","diff --git a/scipy-notebook/Dockerfile b/scipy-notebook/Dockerfile
index 6338f42e..714a7911 100644
--- a/scipy-notebook/Dockerfile
+++ b/scipy-notebook/Dockerfile
@@ -25,6 +25,10 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
+# mamba downgrades this packages to previous major version, which causes issues
+RUN echo 'jupyterlab >=4.0.4' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    echo 'notebook >=7.0.2' >> ""${CONDA_DIR}/conda-meta/pinned""
+
 # Install Python 3 packages
 RUN mamba install --yes \
     'altair' \",Yes
scipy-notebook/Dockerfile,scipy-notebook/Dockerfile,4f74f9a934b3fbaa17f99a49a3d67f1d5e3bedd0,13c7da8fce95ac851e188860bb5edd7f7836d0cc,Fix typo,"diff --git a/scipy-notebook/Dockerfile b/scipy-notebook/Dockerfile
index 714a7911..28382337 100644
--- a/scipy-notebook/Dockerfile
+++ b/scipy-notebook/Dockerfile
@@ -25,7 +25,7 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
-# mamba downgrades this packages to previous major version, which causes issues
+# mamba downgrades these packages to previous major versions, which causes issues
 RUN echo 'jupyterlab >=4.0.4' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     echo 'notebook >=7.0.2' >> ""${CONDA_DIR}/conda-meta/pinned""","diff --git a/scipy-notebook/Dockerfile b/scipy-notebook/Dockerfile
index 714a7911..28382337 100644
--- a/scipy-notebook/Dockerfile
+++ b/scipy-notebook/Dockerfile
@@ -25,7 +25,7 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
-# mamba downgrades this packages to previous major version, which causes issues
+# mamba downgrades these packages to previous major versions, which causes issues
 RUN echo 'jupyterlab >=4.0.4' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     echo 'notebook >=7.0.2' >> ""${CONDA_DIR}/conda-meta/pinned""",Yes
docs/using/common.md,docs/using/common.md,afe631199167f7674efae7db2fce5ffcacbc19b6,4f74f9a934b3fbaa17f99a49a3d67f1d5e3bedd0,Fix usage for -w in docs (#1967),"diff --git a/docs/using/common.md b/docs/using/common.md
index 68ec6146..806ce6c7 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -37,7 +37,7 @@ You do so by passing arguments to the `docker run` command.
   The default value is `jovyan`.
   Setting `NB_USER` refits the `jovyan` default user and ensures that the desired user has the correct file permissions
   for the new home directory created at `/home/<username>`.
-  For this option to take effect, you **must** run the container with `--user root`, set the working directory `-w ""/home/${NB_USER}""`
+  For this option to take effect, you **must** run the container with `--user root`, set the working directory `-w ""/home/<username>""`
   and set the environment variable `-e CHOWN_HOME=yes`.
 
   _Example usage:_
@@ -48,7 +48,7 @@ You do so by passing arguments to the `docker run` command.
       --user root \
       -e NB_USER=""my-username"" \
       -e CHOWN_HOME=yes \
-      -w ""/home/${NB_USER}"" \
+      -w ""/home/my-username"" \
       jupyter/base-notebook
   ```","diff --git a/docs/using/common.md b/docs/using/common.md
index 68ec6146..806ce6c7 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -37,7 +37,7 @@ You do so by passing arguments to the `docker run` command.
   The default value is `jovyan`.
   Setting `NB_USER` refits the `jovyan` default user and ensures that the desired user has the correct file permissions
   for the new home directory created at `/home/<username>`.
-  For this option to take effect, you **must** run the container with `--user root`, set the working directory `-w ""/home/${NB_USER}""`
+  For this option to take effect, you **must** run the container with `--user root`, set the working directory `-w ""/home/<username>""`
   and set the environment variable `-e CHOWN_HOME=yes`.
 
   _Example usage:_
@@ -48,7 +48,7 @@ You do so by passing arguments to the `docker run` command.
       --user root \
       -e NB_USER=""my-username"" \
       -e CHOWN_HOME=yes \
-      -w ""/home/${NB_USER}"" \
+      -w ""/home/my-username"" \
       jupyter/base-notebook
   ```",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,afe631199167f7674efae7db2fce5ffcacbc19b6,4f74f9a934b3fbaa17f99a49a3d67f1d5e3bedd0,Fix usage for -w in docs (#1967),"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 8abaebd6..b5d17b88 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -142,7 +142,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
         -e NB_GID=1234 \
         -e CHOWN_HOME=yes \
         -e CHOWN_HOME_OPTS=""-R"" \
-        -w ""/home/${NB_USER}"" \
+        -w ""/home/callisto"" \
         -v ""${PWD}""/test:/home/callisto/work \
         jupyter/minimal-notebook
 
@@ -162,7 +162,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
    - `-e NB_UID=1234` and `-e NB_GID=1234`: will set the `UID` and `GID` of the new user (`callisto`) to `1234`
    - `-e CHOWN_HOME_OPTS=""-R""` and `-e CHOWN_HOME=yes`: ensure that the new user is the owner of the `/home` directory and subdirectories
      (setting `CHOWN_HOME_OPTS=""-R` will ensure this change is applied recursively)
-   - `-w ""/home/${NB_USER}""` sets the working directory to be the new user's home
+   - `-w ""/home/callisto""` sets the working directory to be the new user's home
 
    ```{admonition} Additional notes
     In the example above, the `-v` flag is used to mount the local volume onto the new user's `/home` directory.
@@ -185,7 +185,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
        -e NB_GID=""$(id -g)""  \
        -e CHOWN_HOME=yes \
        -e CHOWN_HOME_OPTS=""-R"" \
-       -w ""/home/${NB_USER}"" \
+       -w ""/home/callisto"" \
        -v ""${PWD}""/test:/home/callisto/work \
        jupyter/minimal-notebook
    ```","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 8abaebd6..b5d17b88 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -142,7 +142,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
         -e NB_GID=1234 \
         -e CHOWN_HOME=yes \
         -e CHOWN_HOME_OPTS=""-R"" \
-        -w ""/home/${NB_USER}"" \
+        -w ""/home/callisto"" \
         -v ""${PWD}""/test:/home/callisto/work \
         jupyter/minimal-notebook
 
@@ -162,7 +162,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
    - `-e NB_UID=1234` and `-e NB_GID=1234`: will set the `UID` and `GID` of the new user (`callisto`) to `1234`
    - `-e CHOWN_HOME_OPTS=""-R""` and `-e CHOWN_HOME=yes`: ensure that the new user is the owner of the `/home` directory and subdirectories
      (setting `CHOWN_HOME_OPTS=""-R` will ensure this change is applied recursively)
-   - `-w ""/home/${NB_USER}""` sets the working directory to be the new user's home
+   - `-w ""/home/callisto""` sets the working directory to be the new user's home
 
    ```{admonition} Additional notes
     In the example above, the `-v` flag is used to mount the local volume onto the new user's `/home` directory.
@@ -185,7 +185,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
        -e NB_GID=""$(id -g)""  \
        -e CHOWN_HOME=yes \
        -e CHOWN_HOME_OPTS=""-R"" \
-       -w ""/home/${NB_USER}"" \
+       -w ""/home/callisto"" \
        -v ""${PWD}""/test:/home/callisto/work \
        jupyter/minimal-notebook
    ```",Yes
base-notebook/docker_healthcheck.py,base-notebook/docker_healthcheck.py,72ef9bc17da0617ae3b408983b8122a396bb87a6,afe631199167f7674efae7db2fce5ffcacbc19b6,"Healthcheck gives correct result even behind proxy (#1964)

* Fixed #1962

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update base-notebook/docker_healthcheck.py

Use empty string instead of None

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/base-notebook/docker_healthcheck.py b/base-notebook/docker_healthcheck.py
index 7c35a6b1..41bbc785 100755
--- a/base-notebook/docker_healthcheck.py
+++ b/base-notebook/docker_healthcheck.py
@@ -16,6 +16,11 @@ json_file = next(runtime_dir.glob(""*server-*.json""))
 url = json.loads(json_file.read_bytes())[""url""]
 url = url + ""api""
 
-r = requests.get(url, verify=False)  # request without SSL verification
+proxies = {
+    ""http"": """",
+    ""https"": """",
+}
+
+r = requests.get(url, proxies=proxies, verify=False)  # request without SSL verification
 r.raise_for_status()
 print(r.content)","diff --git a/base-notebook/docker_healthcheck.py b/base-notebook/docker_healthcheck.py
index 7c35a6b1..41bbc785 100755
--- a/base-notebook/docker_healthcheck.py
+++ b/base-notebook/docker_healthcheck.py
@@ -16,6 +16,11 @@ json_file = next(runtime_dir.glob(""*server-*.json""))
 url = json.loads(json_file.read_bytes())[""url""]
 url = url + ""api""
 
-r = requests.get(url, verify=False)  # request without SSL verification
+proxies = {
+    ""http"": """",
+    ""https"": """",
+}
+
+r = requests.get(url, proxies=proxies, verify=False)  # request without SSL verification
 r.raise_for_status()
 print(r.content)",Yes
tests/base-notebook/test_healthcheck.py,tests/base-notebook/test_healthcheck.py,72ef9bc17da0617ae3b408983b8122a396bb87a6,afe631199167f7674efae7db2fce5ffcacbc19b6,"Healthcheck gives correct result even behind proxy (#1964)

* Fixed #1962

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update base-notebook/docker_healthcheck.py

Use empty string instead of None

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 2b15faf6..73de1003 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -69,6 +69,53 @@ def test_health(
     assert get_health(running_container) == ""healthy""
 
 
+@pytest.mark.parametrize(
+    ""env,cmd,user"",
+    [
+        (
+            [""HTTPS_PROXY=host.docker.internal"", ""HTTP_PROXY=host.docker.internal""],
+            None,
+            None,
+        ),
+        (
+            [
+                ""NB_USER=testuser"",
+                ""CHOWN_HOME=1"",
+                ""JUPYTER_PORT=8123"",
+                ""HTTPS_PROXY=host.docker.internal"",
+                ""HTTP_PROXY=host.docker.internal"",
+            ],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            ""root"",
+        ),
+    ],
+)
+def test_health_proxy(
+    container: TrackedContainer,
+    env: Optional[list[str]],
+    cmd: Optional[list[str]],
+    user: Optional[str],
+) -> None:
+    running_container = container.run_detached(
+        tty=True,
+        environment=env,
+        command=cmd,
+        user=user,
+    )
+
+    # sleeping some time to let the server start
+    time_spent = 0.0
+    wait_time = 0.1
+    time_limit = 15
+    while time_spent < time_limit:
+        time.sleep(wait_time)
+        time_spent += wait_time
+        if get_health(running_container) == ""healthy"":
+            return
+
+    assert get_health(running_container) == ""healthy""
+
+
 @pytest.mark.parametrize(
     ""env,cmd,user"",
     [","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 2b15faf6..73de1003 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -69,6 +69,53 @@ def test_health(
     assert get_health(running_container) == ""healthy""
 
 
+@pytest.mark.parametrize(
+    ""env,cmd,user"",
+    [
+        (
+            [""HTTPS_PROXY=host.docker.internal"", ""HTTP_PROXY=host.docker.internal""],
+            None,
+            None,
+        ),
+        (
+            [
+                ""NB_USER=testuser"",
+                ""CHOWN_HOME=1"",
+                ""JUPYTER_PORT=8123"",
+                ""HTTPS_PROXY=host.docker.internal"",
+                ""HTTP_PROXY=host.docker.internal"",
+            ],
+            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            ""root"",
+        ),
+    ],
+)
+def test_health_proxy(
+    container: TrackedContainer,
+    env: Optional[list[str]],
+    cmd: Optional[list[str]],
+    user: Optional[str],
+) -> None:
+    running_container = container.run_detached(
+        tty=True,
+        environment=env,
+        command=cmd,
+        user=user,
+    )
+
+    # sleeping some time to let the server start
+    time_spent = 0.0
+    wait_time = 0.1
+    time_limit = 15
+    while time_spent < time_limit:
+        time.sleep(wait_time)
+        time_spent += wait_time
+        if get_health(running_container) == ""healthy"":
+            return
+
+    assert get_health(running_container) == ""healthy""
+
+
 @pytest.mark.parametrize(
     ""env,cmd,user"",
     [",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,284be27ee765d887694d023d0e10d51738766b4c,72ef9bc17da0617ae3b408983b8122a396bb87a6,Sort lines in contributed-recipes,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index f91c09cd..511b0b38 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -48,7 +48,7 @@ jobs:
             manpage_install.dockerfile,
             microsoft_odbc.dockerfile,
             pip_install.dockerfile,
-            spellcheck_notebookv6.dockerfile,
             rise_jupyterlab.dockerfile,
+            spellcheck_notebookv6.dockerfile,
             xgboost.dockerfile,
           ]","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index f91c09cd..511b0b38 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -48,7 +48,7 @@ jobs:
             manpage_install.dockerfile,
             microsoft_odbc.dockerfile,
             pip_install.dockerfile,
-            spellcheck_notebookv6.dockerfile,
             rise_jupyterlab.dockerfile,
+            spellcheck_notebookv6.dockerfile,
             xgboost.dockerfile,
           ]",Yes
README.md,README.md,cf2791494e81f6fcc457bb6aa3f3185c17a7dff8,284be27ee765d887694d023d0e10d51738766b4c,"Add info about root_dir in docs (#1971)

* Add info about root_dir in docs

* Add note to running.md as well

* Better wording","diff --git a/README.md b/README.md
index ed739a26..94c3db64 100644
--- a/README.md
+++ b/README.md
@@ -61,6 +61,13 @@ Due to the usage of [the flag `--rm`](https://docs.docker.com/engine/reference/r
 system when the container exits, but any changes made to the `~/work` directory and its files in the container will remain intact on the host.
 [The `-it` flag](https://docs.docker.com/engine/reference/commandline/run/#name) allocates pseudo-TTY.
 
+```{note}
+By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
+So, new notebooks will be saved there, unless you change the directory in the file browser.
+
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
+```
+
 ## Contributing
 
 Please see the [Contributor Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)","diff --git a/README.md b/README.md
index ed739a26..94c3db64 100644
--- a/README.md
+++ b/README.md
@@ -61,6 +61,13 @@ Due to the usage of [the flag `--rm`](https://docs.docker.com/engine/reference/r
 system when the container exits, but any changes made to the `~/work` directory and its files in the container will remain intact on the host.
 [The `-it` flag](https://docs.docker.com/engine/reference/commandline/run/#name) allocates pseudo-TTY.
 
+```{note}
+By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
+So, new notebooks will be saved there, unless you change the directory in the file browser.
+
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
+```
+
 ## Contributing
 
 Please see the [Contributor Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)",Yes
docs/using/running.md,docs/using/running.md,cf2791494e81f6fcc457bb6aa3f3185c17a7dff8,284be27ee765d887694d023d0e10d51738766b4c,"Add info about root_dir in docs (#1971)

* Add info about root_dir in docs

* Add note to running.md as well

* Better wording","diff --git a/docs/using/running.md b/docs/using/running.md
index 20600f84..4d492054 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -65,6 +65,13 @@ Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docke
 New files and changes in `~/work` in the container will be preserved.
 Any other changes made in the container will be lost.
 
+```{note}
+By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
+So, new notebooks will be saved there, unless you change the directory in the file browser.
+
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
+```
+
 **Example 3:**
 
 This command pulls the `jupyter/all-spark-notebook` image currently tagged `latest` from Docker Hub if an image tagged `latest` is not already present on the local host.","diff --git a/docs/using/running.md b/docs/using/running.md
index 20600f84..4d492054 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -65,6 +65,13 @@ Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docke
 New files and changes in `~/work` in the container will be preserved.
 Any other changes made in the container will be lost.
 
+```{note}
+By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
+So, new notebooks will be saved there, unless you change the directory in the file browser.
+
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
+```
+
 **Example 3:**
 
 This command pulls the `jupyter/all-spark-notebook` image currently tagged `latest` from Docker Hub if an image tagged `latest` is not already present on the local host.",Yes
examples/openshift/README.md,examples/openshift/README.md,66a93b228682522a706c33003107977bd0934342,cf2791494e81f6fcc457bb6aa3f3185c17a7dff8,Remove outdated list from examples,"diff --git a/examples/openshift/README.md b/examples/openshift/README.md
index 7895abbc..4f743f1d 100644
--- a/examples/openshift/README.md
+++ b/examples/openshift/README.md
@@ -108,15 +108,6 @@ oc new-app --template jupyter-notebook \
 
 You can deploy any of the Jupyter Project docker-stacks images.
 
-- jupyter/base-notebook
-- jupyter/r-notebook
-- jupyter/minimal-notebook
-- jupyter/scipy-notebook
-- jupyter/tensorflow-notebook
-- jupyter/datascience-notebook
-- jupyter/pyspark-notebook
-- jupyter/all-spark-notebook
-
 If you don't care what version of the image is used, add the `:latest` tag at the end of the image name, otherwise use the hash corresponding to the image version you want to use.
 
 ## Deleting the Notebook Instance","diff --git a/examples/openshift/README.md b/examples/openshift/README.md
index 7895abbc..4f743f1d 100644
--- a/examples/openshift/README.md
+++ b/examples/openshift/README.md
@@ -108,15 +108,6 @@ oc new-app --template jupyter-notebook \
 
 You can deploy any of the Jupyter Project docker-stacks images.
 
-- jupyter/base-notebook
-- jupyter/r-notebook
-- jupyter/minimal-notebook
-- jupyter/scipy-notebook
-- jupyter/tensorflow-notebook
-- jupyter/datascience-notebook
-- jupyter/pyspark-notebook
-- jupyter/all-spark-notebook
-
 If you don't care what version of the image is used, add the `:latest` tag at the end of the image name, otherwise use the hash corresponding to the image version you want to use.
 
 ## Deleting the Notebook Instance",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,affeb4ea00f64c6df1996a9d412146c7a148c43e,66a93b228682522a706c33003107977bd0934342,"Add a recipe to install OracleDB instant client (version 21.x) (#1970)

* Add a recipe to install OracleDB instant client

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Split java install command to avoid errors

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Split java install command to avoid errors

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: lint markdown to avoid max-lenght

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: add recipe to ci-cd and fixes from review

- Use ENV docker command to upload PATH variable for Jupyter notebook.
- Make installation faster by removing extra `apt-get` commands.
- Optimize credential files generation for the sake of legibility
- Change WORKDIR back at the end.
- Use mamba instead of pip to install the oracledb library.
- Keep conda instructions for the sake of consistency with the rest of
the recipes in the page.
  Like 'Add a custom conda environment and Jupyter kernel'.

* Update oracledb recipe using suggestion from PR

Optimize image of the docker image by chaining commands.

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix the chaining command to remove temp files

* Set the right value for WORKDIR

* chore: fix ci-cd and specify recipe scope

- Specify scope of the recipe to v.21. version of the plugin.
- Fix the ci-cd build.
- Avoid innecessary image optimisations

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: fix ci-cd and specify recipe scope

- Specify scope of the recipe to v.21. version of the plugin.
- Fix the ci-cd build.
- Avoid innecessary image optimisations

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: remove temporary file clean

* chore: fix typo

* Update oracledb.dockerfile

* Update recipes.md

* Use alien --install

* Fix typo

* Unify comments

* Update oracledb.dockerfile

* Update oracledb.dockerfile

* Add ARG to remove copy-paste

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 511b0b38..ce548c6a 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -47,6 +47,7 @@ jobs:
             mamba_install.dockerfile,
             manpage_install.dockerfile,
             microsoft_odbc.dockerfile,
+            oracledb.dockerfile,
             pip_install.dockerfile,
             rise_jupyterlab.dockerfile,
             spellcheck_notebookv6.dockerfile,","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 511b0b38..ce548c6a 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -47,6 +47,7 @@ jobs:
             mamba_install.dockerfile,
             manpage_install.dockerfile,
             microsoft_odbc.dockerfile,
+            oracledb.dockerfile,
             pip_install.dockerfile,
             rise_jupyterlab.dockerfile,
             spellcheck_notebookv6.dockerfile,",Yes
,docs/using/recipe_code/oracledb.dockerfile,affeb4ea00f64c6df1996a9d412146c7a148c43e,66a93b228682522a706c33003107977bd0934342,"Add a recipe to install OracleDB instant client (version 21.x) (#1970)

* Add a recipe to install OracleDB instant client

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Split java install command to avoid errors

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Split java install command to avoid errors

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: lint markdown to avoid max-lenght

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: add recipe to ci-cd and fixes from review

- Use ENV docker command to upload PATH variable for Jupyter notebook.
- Make installation faster by removing extra `apt-get` commands.
- Optimize credential files generation for the sake of legibility
- Change WORKDIR back at the end.
- Use mamba instead of pip to install the oracledb library.
- Keep conda instructions for the sake of consistency with the rest of
the recipes in the page.
  Like 'Add a custom conda environment and Jupyter kernel'.

* Update oracledb recipe using suggestion from PR

Optimize image of the docker image by chaining commands.

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix the chaining command to remove temp files

* Set the right value for WORKDIR

* chore: fix ci-cd and specify recipe scope

- Specify scope of the recipe to v.21. version of the plugin.
- Fix the ci-cd build.
- Avoid innecessary image optimisations

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: fix ci-cd and specify recipe scope

- Specify scope of the recipe to v.21. version of the plugin.
- Fix the ci-cd build.
- Avoid innecessary image optimisations

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: remove temporary file clean

* chore: fix typo

* Update oracledb.dockerfile

* Update recipes.md

* Use alien --install

* Fix typo

* Unify comments

* Update oracledb.dockerfile

* Update oracledb.dockerfile

* Add ARG to remove copy-paste

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
new file mode 100644
index 00000000..635880a7
--- /dev/null
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -0,0 +1,54 @@
+FROM jupyter/base-notebook
+
+USER root
+
+# Install java, javac and alien
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends software-properties-common && \
+    add-apt-repository universe && \
+    apt-get update --yes && \
+    apt-get install --yes --no-install-recommends alien default-jre default-jdk openjdk-11-jdk libaio1 && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+ARG instantclient_major_version=21
+ARG instantclient_version=${instantclient_major_version}.11.0.0.0-1
+ARG instantclient_url=https://download.oracle.com/otn_software/linux/instantclient/2111000
+
+# Then install Oracle SQL Instant client, SQL+Plus, tools and JDBC.
+# Note: You may need to change the URL to a newer version.
+# See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
+WORKDIR ""/tmp""
+RUN wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm && \
+    alien --install --scripts oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm && \
+    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm && \
+    alien --install --scripts oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm && \
+    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm && \
+    alien --install --scripts oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm && \
+    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm && \
+    alien --install --scripts oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm && \
+    chown -R ""${NB_UID}"":""${NB_GID}"" ""${HOME}/.rpmdb"" && \
+    rm -f ./*.rpm
+
+# Configure environment
+ENV ORACLE_HOME=/usr/lib/oracle/${instantclient_major_version}/client64
+ENV PATH=""${ORACLE_HOME}/bin:${PATH}""
+ENV LD_LIBRARY_PATH=""${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}""
+
+# (Optional) Add credentials for the Oracle Database server; files must be present on your `docker build PATH` folder.
+WORKDIR /usr/lib/oracle/${instantclient_major_version}/client64/lib/network/admin
+# Adding a wildcard `[]` on the last letter of the filename to avoid throwing an error if the file does not exist.
+# See: https://stackoverflow.com/questions/31528384/conditional-copy-add-in-dockerfile
+COPY cwallet.ss[o] ./
+COPY sqlnet.or[a] ./
+COPY tnsnames.or[a] ./
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ""${NB_UID}""
+
+WORKDIR ""${HOME}""
+
+# Install `oracledb` Python library to use Oracle SQL Instant Client
+RUN mamba install --yes 'oracledb' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
new file mode 100644
index 00000000..635880a7
--- /dev/null
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -0,0 +1,54 @@
+FROM jupyter/base-notebook
+
+USER root
+
+# Install java, javac and alien
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends software-properties-common && \
+    add-apt-repository universe && \
+    apt-get update --yes && \
+    apt-get install --yes --no-install-recommends alien default-jre default-jdk openjdk-11-jdk libaio1 && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+ARG instantclient_major_version=21
+ARG instantclient_version=${instantclient_major_version}.11.0.0.0-1
+ARG instantclient_url=https://download.oracle.com/otn_software/linux/instantclient/2111000
+
+# Then install Oracle SQL Instant client, SQL+Plus, tools and JDBC.
+# Note: You may need to change the URL to a newer version.
+# See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
+WORKDIR ""/tmp""
+RUN wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm && \
+    alien --install --scripts oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm && \
+    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm && \
+    alien --install --scripts oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm && \
+    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm && \
+    alien --install --scripts oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm && \
+    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm && \
+    alien --install --scripts oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm && \
+    chown -R ""${NB_UID}"":""${NB_GID}"" ""${HOME}/.rpmdb"" && \
+    rm -f ./*.rpm
+
+# Configure environment
+ENV ORACLE_HOME=/usr/lib/oracle/${instantclient_major_version}/client64
+ENV PATH=""${ORACLE_HOME}/bin:${PATH}""
+ENV LD_LIBRARY_PATH=""${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}""
+
+# (Optional) Add credentials for the Oracle Database server; files must be present on your `docker build PATH` folder.
+WORKDIR /usr/lib/oracle/${instantclient_major_version}/client64/lib/network/admin
+# Adding a wildcard `[]` on the last letter of the filename to avoid throwing an error if the file does not exist.
+# See: https://stackoverflow.com/questions/31528384/conditional-copy-add-in-dockerfile
+COPY cwallet.ss[o] ./
+COPY sqlnet.or[a] ./
+COPY tnsnames.or[a] ./
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ""${NB_UID}""
+
+WORKDIR ""${HOME}""
+
+# Install `oracledb` Python library to use Oracle SQL Instant Client
+RUN mamba install --yes 'oracledb' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
docs/using/recipes.md,docs/using/recipes.md,affeb4ea00f64c6df1996a9d412146c7a148c43e,66a93b228682522a706c33003107977bd0934342,"Add a recipe to install OracleDB instant client (version 21.x) (#1970)

* Add a recipe to install OracleDB instant client

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Split java install command to avoid errors

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Split java install command to avoid errors

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: lint markdown to avoid max-lenght

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: add recipe to ci-cd and fixes from review

- Use ENV docker command to upload PATH variable for Jupyter notebook.
- Make installation faster by removing extra `apt-get` commands.
- Optimize credential files generation for the sake of legibility
- Change WORKDIR back at the end.
- Use mamba instead of pip to install the oracledb library.
- Keep conda instructions for the sake of consistency with the rest of
the recipes in the page.
  Like 'Add a custom conda environment and Jupyter kernel'.

* Update oracledb recipe using suggestion from PR

Optimize image of the docker image by chaining commands.

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix the chaining command to remove temp files

* Set the right value for WORKDIR

* chore: fix ci-cd and specify recipe scope

- Specify scope of the recipe to v.21. version of the plugin.
- Fix the ci-cd build.
- Avoid innecessary image optimisations

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: fix ci-cd and specify recipe scope

- Specify scope of the recipe to v.21. version of the plugin.
- Fix the ci-cd build.
- Avoid innecessary image optimisations

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* chore: remove temporary file clean

* chore: fix typo

* Update oracledb.dockerfile

* Update recipes.md

* Use alien --install

* Fix typo

* Unify comments

* Update oracledb.dockerfile

* Update oracledb.dockerfile

* Add ARG to remove copy-paste

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 2da905b0..507e374e 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -499,3 +499,17 @@ The following recipe demonstrates how to add functionality to read from and writ
 You can now use `pyodbc` and `sqlalchemy` to interact with the database.
 
 Pre-built images are hosted in the [realiserad/jupyter-docker-mssql](https://github.com/Realiserad/jupyter-docker-mssql) repository.
+
+## Add Oracle SQL Instant client, SQL\*Plus and other tools (Version 21.x)
+
+The following recipe demonstrates how to add functionality to connect to a Oracle Database using [Oracle Instant Client](https://www.oracle.com/database/technologies/instant-client.html)
+in your notebook.
+This recipe installs version `21.11.0.0.0`.
+
+Nonetheless, go to the [Oracle Instant Client Download page](https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html) for the complete list of versions available.
+You may need to perform different steps for older versions;
+the may be explained on the ""Installation instructions"" section of the Downloads page.
+
+```{literalinclude} recipe_code/oracledb.dockerfile
+:language: docker
+```","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 2da905b0..507e374e 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -499,3 +499,17 @@ The following recipe demonstrates how to add functionality to read from and writ
 You can now use `pyodbc` and `sqlalchemy` to interact with the database.
 
 Pre-built images are hosted in the [realiserad/jupyter-docker-mssql](https://github.com/Realiserad/jupyter-docker-mssql) repository.
+
+## Add Oracle SQL Instant client, SQL\*Plus and other tools (Version 21.x)
+
+The following recipe demonstrates how to add functionality to connect to a Oracle Database using [Oracle Instant Client](https://www.oracle.com/database/technologies/instant-client.html)
+in your notebook.
+This recipe installs version `21.11.0.0.0`.
+
+Nonetheless, go to the [Oracle Instant Client Download page](https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html) for the complete list of versions available.
+You may need to perform different steps for older versions;
+the may be explained on the ""Installation instructions"" section of the Downloads page.
+
+```{literalinclude} recipe_code/oracledb.dockerfile
+:language: docker
+```",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,90cffa6c26f39cf62550fc5c0ec9da2185fdf67c,affeb4ea00f64c6df1996a9d412146c7a148c43e,"Build all contributed recipes automatically (#1973)

* Build all contributed recipes automatically

* Add missing file

* Add checkout repo

* Fix matrix

* Remove unused var

* Add typing","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index ce548c6a..d51bf3e4 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -20,8 +20,21 @@ on:
   workflow_call:
 
 jobs:
+  generate-matrix:
+    runs-on: ubuntu-latest
+    outputs:
+      matrix: ${{ steps.set-matrix.outputs.matrix }}
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v3
+
+      - name: Calculate recipes matrix 🛠
+        id: set-matrix
+        run: docs/using/recipe_code/generate_matrix.py >> $GITHUB_OUTPUT
+
   test-recipes:
     runs-on: ubuntu-latest
+    needs: generate-matrix
     if: github.repository == 'jupyter/docker-stacks'
 
     steps:
@@ -38,18 +51,4 @@ jobs:
         shell: bash
 
     strategy:
-      matrix:
-        dockerfile:
-          [
-            custom_environment.dockerfile,
-            dask_jupyterlab.dockerfile,
-            jupyterhub_version.dockerfile,
-            mamba_install.dockerfile,
-            manpage_install.dockerfile,
-            microsoft_odbc.dockerfile,
-            oracledb.dockerfile,
-            pip_install.dockerfile,
-            rise_jupyterlab.dockerfile,
-            spellcheck_notebookv6.dockerfile,
-            xgboost.dockerfile,
-          ]
+      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index ce548c6a..d51bf3e4 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -20,8 +20,21 @@ on:
   workflow_call:
 
 jobs:
+  generate-matrix:
+    runs-on: ubuntu-latest
+    outputs:
+      matrix: ${{ steps.set-matrix.outputs.matrix }}
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v3
+
+      - name: Calculate recipes matrix 🛠
+        id: set-matrix
+        run: docs/using/recipe_code/generate_matrix.py >> $GITHUB_OUTPUT
+
   test-recipes:
     runs-on: ubuntu-latest
+    needs: generate-matrix
     if: github.repository == 'jupyter/docker-stacks'
 
     steps:
@@ -38,18 +51,4 @@ jobs:
         shell: bash
 
     strategy:
-      matrix:
-        dockerfile:
-          [
-            custom_environment.dockerfile,
-            dask_jupyterlab.dockerfile,
-            jupyterhub_version.dockerfile,
-            mamba_install.dockerfile,
-            manpage_install.dockerfile,
-            microsoft_odbc.dockerfile,
-            oracledb.dockerfile,
-            pip_install.dockerfile,
-            rise_jupyterlab.dockerfile,
-            spellcheck_notebookv6.dockerfile,
-            xgboost.dockerfile,
-          ]
+      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}",Yes
docs/contributing/recipes.md,docs/contributing/recipes.md,90cffa6c26f39cf62550fc5c0ec9da2185fdf67c,affeb4ea00f64c6df1996a9d412146c7a148c43e,"Build all contributed recipes automatically (#1973)

* Build all contributed recipes automatically

* Add missing file

* Add checkout repo

* Fix matrix

* Remove unused var

* Add typing","diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index 98572c0f..d44ac242 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -6,7 +6,7 @@ Follow the process below to add a new recipe:
 1. Open the `docs/using/recipes.md` source file.
 2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Slideshows with JupyterLab and RISE`)
 3. Write the body of your recipe under the heading, including whatever command line, links, etc. you need.
-4. If you have a Dockerfile, please put it in a `recipe_code` subdirectory
-   and update [contributed-recipes workflow](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/contributed-recipes.yml) to include your file.
+4. If you have a Dockerfile, please put it in a `recipe_code` subdirectory.
+   This file will be built automatically by [contributed-recipes workflow](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/contributed-recipes.yml).
 5. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.","diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index 98572c0f..d44ac242 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -6,7 +6,7 @@ Follow the process below to add a new recipe:
 1. Open the `docs/using/recipes.md` source file.
 2. Add a second-level Markdown heading naming your recipe at the bottom of the file (e.g., `## Slideshows with JupyterLab and RISE`)
 3. Write the body of your recipe under the heading, including whatever command line, links, etc. you need.
-4. If you have a Dockerfile, please put it in a `recipe_code` subdirectory
-   and update [contributed-recipes workflow](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/contributed-recipes.yml) to include your file.
+4. If you have a Dockerfile, please put it in a `recipe_code` subdirectory.
+   This file will be built automatically by [contributed-recipes workflow](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/contributed-recipes.yml).
 5. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request) (PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.",Yes
,docs/using/recipe_code/generate_matrix.py,90cffa6c26f39cf62550fc5c0ec9da2185fdf67c,affeb4ea00f64c6df1996a9d412146c7a148c43e,"Build all contributed recipes automatically (#1973)

* Build all contributed recipes automatically

* Add missing file

* Add checkout repo

* Fix matrix

* Remove unused var

* Add typing","diff --git a/docs/using/recipe_code/generate_matrix.py b/docs/using/recipe_code/generate_matrix.py
new file mode 100755
index 00000000..ff588029
--- /dev/null
+++ b/docs/using/recipe_code/generate_matrix.py
@@ -0,0 +1,17 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import json
+from pathlib import Path
+from typing import Any
+
+THIS_DIR = Path(__file__).parent.resolve()
+
+
+def generate_matrix() -> dict[str, Any]:
+    dockerfiles = sorted(file.name for file in THIS_DIR.glob(""*.dockerfile""))
+    return {""dockerfile"": dockerfiles}
+
+
+if __name__ == ""__main__"":
+    print(""matrix="" + json.dumps(generate_matrix()))","diff --git a/docs/using/recipe_code/generate_matrix.py b/docs/using/recipe_code/generate_matrix.py
new file mode 100755
index 00000000..ff588029
--- /dev/null
+++ b/docs/using/recipe_code/generate_matrix.py
@@ -0,0 +1,17 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import json
+from pathlib import Path
+from typing import Any
+
+THIS_DIR = Path(__file__).parent.resolve()
+
+
+def generate_matrix() -> dict[str, Any]:
+    dockerfiles = sorted(file.name for file in THIS_DIR.glob(""*.dockerfile""))
+    return {""dockerfile"": dockerfiles}
+
+
+if __name__ == ""__main__"":
+    print(""matrix="" + json.dumps(generate_matrix()))",Yes
docs/conf.py,docs/conf.py,73d6fe4f556a85ce5edfefea9ca73fcc29b743bb,90cffa6c26f39cf62550fc5c0ec9da2185fdf67c,Replace rodbc link fow now,"diff --git a/docs/conf.py b/docs/conf.py
index dad3b3cb..7b828b1e 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -71,4 +71,5 @@ linkcheck_allowed_redirects = {
     r""https://results\.pre-commit\.ci/latest/github/jupyter/docker-stacks/main"": r""https://results\.pre-commit\.ci/run/github/.*"",  # Latest main CI build
     r""https://github\.com/jupyter/docker-stacks/issues/new.*"": r""https://github\.com/login.*"",  # GitHub wants user to be logon to use this features
     r""https://github\.com/orgs/jupyter/teams/docker-image-maintainers/members"": r""https://github\.com/login.*"",
+    r""https://www\.rdocumentation.org/packages/RODBC/"": r""https://www\.rdocumentation.org/packages/RODBC/*"",
 }","diff --git a/docs/conf.py b/docs/conf.py
index dad3b3cb..7b828b1e 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -71,4 +71,5 @@ linkcheck_allowed_redirects = {
     r""https://results\.pre-commit\.ci/latest/github/jupyter/docker-stacks/main"": r""https://results\.pre-commit\.ci/run/github/.*"",  # Latest main CI build
     r""https://github\.com/jupyter/docker-stacks/issues/new.*"": r""https://github\.com/login.*"",  # GitHub wants user to be logon to use this features
     r""https://github\.com/orgs/jupyter/teams/docker-image-maintainers/members"": r""https://github\.com/login.*"",
+    r""https://www\.rdocumentation.org/packages/RODBC/"": r""https://www\.rdocumentation.org/packages/RODBC/*"",
 }",Yes
docs/using/selecting.md,docs/using/selecting.md,73d6fe4f556a85ce5edfefea9ca73fcc29b743bb,90cffa6c26f39cf62550fc5c0ec9da2185fdf67c,Replace rodbc link fow now,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index d823f020..0b5003ab 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -103,7 +103,7 @@ It contains:
   [randomforest](https://cran.r-project.org/web/packages/randomForest/index.html),
   [rcurl](https://cran.r-project.org/web/packages/RCurl/index.html),
   [rmarkdown](https://rmarkdown.rstudio.com),
-  [rodbc](https://cran.r-project.org/web/packages/RODBC/index.html),
+  [rodbc](https://www.rdocumentation.org/packages/RODBC/),
   [rsqlite](https://cran.r-project.org/web/packages/RSQLite/index.html),
   [shiny](https://shiny.posit.co),
   [tidymodels](https://www.tidymodels.org/),","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index d823f020..0b5003ab 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -103,7 +103,7 @@ It contains:
   [randomforest](https://cran.r-project.org/web/packages/randomForest/index.html),
   [rcurl](https://cran.r-project.org/web/packages/RCurl/index.html),
   [rmarkdown](https://rmarkdown.rstudio.com),
-  [rodbc](https://cran.r-project.org/web/packages/RODBC/index.html),
+  [rodbc](https://www.rdocumentation.org/packages/RODBC/),
   [rsqlite](https://cran.r-project.org/web/packages/RSQLite/index.html),
   [shiny](https://shiny.posit.co),
   [tidymodels](https://www.tidymodels.org/),",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,aac56a610b3b112dfb0ad014b83265352381173e,73d6fe4f556a85ce5edfefea9ca73fcc29b743bb,"Build contributed recipes on aarch64 (#1974)

* Build contributed recipes on aarch64

* Add --pull to contributed recipes

* Exclude recipe not working on aarch64","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index d51bf3e4..5478efa8 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -33,7 +33,7 @@ jobs:
         run: docs/using/recipe_code/generate_matrix.py >> $GITHUB_OUTPUT
 
   test-recipes:
-    runs-on: ubuntu-latest
+    runs-on: ${{ matrix.runsOn }}
     needs: generate-matrix
     if: github.repository == 'jupyter/docker-stacks'
 
@@ -42,7 +42,8 @@ jobs:
         uses: actions/checkout@v3
 
       - name: Build recipe 🛠
-        run: docker build --rm --force-rm --tag my-custom-image -f ./${{ matrix.dockerfile }} ./
+        # We're pulling here to avoid accidentally using image which migt be present on aarch64 self-hosted runner
+        run: docker build --pull --rm --force-rm --tag my-custom-image -f ./${{ matrix.dockerfile }} ./
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index d51bf3e4..5478efa8 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -33,7 +33,7 @@ jobs:
         run: docs/using/recipe_code/generate_matrix.py >> $GITHUB_OUTPUT
 
   test-recipes:
-    runs-on: ubuntu-latest
+    runs-on: ${{ matrix.runsOn }}
     needs: generate-matrix
     if: github.repository == 'jupyter/docker-stacks'
 
@@ -42,7 +42,8 @@ jobs:
         uses: actions/checkout@v3
 
       - name: Build recipe 🛠
-        run: docker build --rm --force-rm --tag my-custom-image -f ./${{ matrix.dockerfile }} ./
+        # We're pulling here to avoid accidentally using image which migt be present on aarch64 self-hosted runner
+        run: docker build --pull --rm --force-rm --tag my-custom-image -f ./${{ matrix.dockerfile }} ./
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build",Yes
docs/using/recipe_code/generate_matrix.py,docs/using/recipe_code/generate_matrix.py,aac56a610b3b112dfb0ad014b83265352381173e,73d6fe4f556a85ce5edfefea9ca73fcc29b743bb,"Build contributed recipes on aarch64 (#1974)

* Build contributed recipes on aarch64

* Add --pull to contributed recipes

* Exclude recipe not working on aarch64","diff --git a/docs/using/recipe_code/generate_matrix.py b/docs/using/recipe_code/generate_matrix.py
index ff588029..417cdfb1 100755
--- a/docs/using/recipe_code/generate_matrix.py
+++ b/docs/using/recipe_code/generate_matrix.py
@@ -10,7 +10,11 @@ THIS_DIR = Path(__file__).parent.resolve()
 
 def generate_matrix() -> dict[str, Any]:
     dockerfiles = sorted(file.name for file in THIS_DIR.glob(""*.dockerfile""))
-    return {""dockerfile"": dockerfiles}
+    return {
+        ""dockerfile"": dockerfiles,
+        ""runsOn"": [""ubuntu-latest"", ""ARM64""],
+        ""exclude"": [{""dockerfile"": ""oracledb.dockerfile"", ""runsOn"": ""ARM64""}],
+    }
 
 
 if __name__ == ""__main__"":","diff --git a/docs/using/recipe_code/generate_matrix.py b/docs/using/recipe_code/generate_matrix.py
index ff588029..417cdfb1 100755
--- a/docs/using/recipe_code/generate_matrix.py
+++ b/docs/using/recipe_code/generate_matrix.py
@@ -10,7 +10,11 @@ THIS_DIR = Path(__file__).parent.resolve()
 
 def generate_matrix() -> dict[str, Any]:
     dockerfiles = sorted(file.name for file in THIS_DIR.glob(""*.dockerfile""))
-    return {""dockerfile"": dockerfiles}
+    return {
+        ""dockerfile"": dockerfiles,
+        ""runsOn"": [""ubuntu-latest"", ""ARM64""],
+        ""exclude"": [{""dockerfile"": ""oracledb.dockerfile"", ""runsOn"": ""ARM64""}],
+    }
 
 
 if __name__ == ""__main__"":",Yes
docs/using/recipes.md,docs/using/recipes.md,aac56a610b3b112dfb0ad014b83265352381173e,73d6fe4f556a85ce5edfefea9ca73fcc29b743bb,"Build contributed recipes on aarch64 (#1974)

* Build contributed recipes on aarch64

* Add --pull to contributed recipes

* Exclude recipe not working on aarch64","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 507e374e..8b958067 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -502,6 +502,10 @@ Pre-built images are hosted in the [realiserad/jupyter-docker-mssql](https://git
 
 ## Add Oracle SQL Instant client, SQL\*Plus and other tools (Version 21.x)
 
+```{note}
+This recipe only works for x86_64 architecture.
+```
+
 The following recipe demonstrates how to add functionality to connect to a Oracle Database using [Oracle Instant Client](https://www.oracle.com/database/technologies/instant-client.html)
 in your notebook.
 This recipe installs version `21.11.0.0.0`.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 507e374e..8b958067 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -502,6 +502,10 @@ Pre-built images are hosted in the [realiserad/jupyter-docker-mssql](https://git
 
 ## Add Oracle SQL Instant client, SQL\*Plus and other tools (Version 21.x)
 
+```{note}
+This recipe only works for x86_64 architecture.
+```
+
 The following recipe demonstrates how to add functionality to connect to a Oracle Database using [Oracle Instant Client](https://www.oracle.com/database/technologies/instant-client.html)
 in your notebook.
 This recipe installs version `21.11.0.0.0`.",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,a2da70c663a4ae24005ca67ac97f11e83919a85a,aac56a610b3b112dfb0ad014b83265352381173e,Remove unnecessary ARG variable in a recipe,"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 635880a7..5e8aa391 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,5 +1,9 @@
 FROM jupyter/base-notebook
 
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
 USER root
 
 # Install java, javac and alien
@@ -12,20 +16,21 @@ RUN apt-get update --yes && \
 
 ARG instantclient_major_version=21
 ARG instantclient_version=${instantclient_major_version}.11.0.0.0-1
-ARG instantclient_url=https://download.oracle.com/otn_software/linux/instantclient/2111000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools and JDBC.
 # Note: You may need to change the URL to a newer version.
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
 WORKDIR ""/tmp""
-RUN wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm && \
-    alien --install --scripts oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm && \
-    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm && \
-    alien --install --scripts oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm && \
-    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm && \
-    alien --install --scripts oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm && \
-    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm && \
-    alien --install --scripts oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm && \
+RUN short_version=""$(echo ""${instantclient_version}"" | tr -d '.' | cut -d ""-"" -f1)"" && \
+    instantclient_url=""https://download.oracle.com/otn_software/linux/instantclient/${short_version}"" && \
+    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm"" && \
     chown -R ""${NB_UID}"":""${NB_GID}"" ""${HOME}/.rpmdb"" && \
     rm -f ./*.rpm","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 635880a7..5e8aa391 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,5 +1,9 @@
 FROM jupyter/base-notebook
 
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
 USER root
 
 # Install java, javac and alien
@@ -12,20 +16,21 @@ RUN apt-get update --yes && \
 
 ARG instantclient_major_version=21
 ARG instantclient_version=${instantclient_major_version}.11.0.0.0-1
-ARG instantclient_url=https://download.oracle.com/otn_software/linux/instantclient/2111000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools and JDBC.
 # Note: You may need to change the URL to a newer version.
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
 WORKDIR ""/tmp""
-RUN wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm && \
-    alien --install --scripts oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm && \
-    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm && \
-    alien --install --scripts oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm && \
-    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm && \
-    alien --install --scripts oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm && \
-    wget --progress=dot:giga ${instantclient_url}/oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm && \
-    alien --install --scripts oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm && \
+RUN short_version=""$(echo ""${instantclient_version}"" | tr -d '.' | cut -d ""-"" -f1)"" && \
+    instantclient_url=""https://download.oracle.com/otn_software/linux/instantclient/${short_version}"" && \
+    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm"" && \
     chown -R ""${NB_UID}"":""${NB_GID}"" ""${HOME}/.rpmdb"" && \
     rm -f ./*.rpm",Yes
.readthedocs.yaml,.readthedocs.yaml,feb88727d1c865ca9977339ed8929d4416c4895d,a2da70c663a4ae24005ca67ac97f11e83919a85a,Update .readthedocs.yaml,"diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index 3a772387..f6a12ce2 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -10,13 +10,18 @@ build:
   tools:
     python: ""3.11""
     # You can also specify other tool versions:
-    # nodejs: ""19""
-    # rust: ""1.64""
-    # golang: ""1.19""
+    # nodejs: ""20""
+    # rust: ""1.70""
+    # golang: ""1.20""
 
 # Build documentation in the ""docs/"" directory with Sphinx
 sphinx:
   configuration: docs/conf.py
+  # You can configure Sphinx to use a different builder, for instance use the dirhtml builder for simpler URLs
+  # builder: ""dirhtml""
+  # Fail on all warnings to avoid broken references
+  # fail_on_warning: true
+
 # Optionally build your docs in additional formats such as PDF and ePub
 # formats:
 #    - pdf","diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index 3a772387..f6a12ce2 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -10,13 +10,18 @@ build:
   tools:
     python: ""3.11""
     # You can also specify other tool versions:
-    # nodejs: ""19""
-    # rust: ""1.64""
-    # golang: ""1.19""
+    # nodejs: ""20""
+    # rust: ""1.70""
+    # golang: ""1.20""
 
 # Build documentation in the ""docs/"" directory with Sphinx
 sphinx:
   configuration: docs/conf.py
+  # You can configure Sphinx to use a different builder, for instance use the dirhtml builder for simpler URLs
+  # builder: ""dirhtml""
+  # Fail on all warnings to avoid broken references
+  # fail_on_warning: true
+
 # Optionally build your docs in additional formats such as PDF and ePub
 # formats:
 #    - pdf",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index c72f2046..8afd780f 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -60,7 +60,7 @@ jobs:
         shell: bash
 
       - name: Build image 🛠
-        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} ${{ inputs.image }}/
+        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index c72f2046..8afd780f 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -60,7 +60,7 @@ jobs:
         shell: bash
 
       - name: Build image 🛠
-        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} ${{ inputs.image }}/
+        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 8d6a05f4..7b3f1638 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -20,17 +20,7 @@ on:
       - "".github/actions/download-manifests/action.yml""
       - "".github/actions/load-image/action.yml""
 
-      - ""all-spark-notebook/**""
-      - ""base-notebook/**""
-      - ""datascience-notebook/**""
-      - ""docker-stacks-foundation/**""
-      - ""julia-notebook/**""
-      - ""minimal-notebook/**""
-      - ""pyspark-notebook/**""
-      - ""r-notebook/**""
-      - ""scipy-notebook/**""
-      - ""tensorflow-notebook/**""
-
+      - ""images/**""
       - ""tagging/**""
       - ""tests/**""
       - ""requirements-dev.txt""
@@ -48,17 +38,7 @@ on:
       - "".github/actions/download-manifests/action.yml""
       - "".github/actions/load-image/action.yml""
 
-      - ""all-spark-notebook/**""
-      - ""base-notebook/**""
-      - ""datascience-notebook/**""
-      - ""docker-stacks-foundation/**""
-      - ""julia-notebook/**""
-      - ""minimal-notebook/**""
-      - ""pyspark-notebook/**""
-      - ""r-notebook/**""
-      - ""scipy-notebook/**""
-      - ""tensorflow-notebook/**""
-
+      - ""images/**""
       - ""tagging/**""
       - ""tests/**""
       - ""requirements-dev.txt""","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 8d6a05f4..7b3f1638 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -20,17 +20,7 @@ on:
       - "".github/actions/download-manifests/action.yml""
       - "".github/actions/load-image/action.yml""
 
-      - ""all-spark-notebook/**""
-      - ""base-notebook/**""
-      - ""datascience-notebook/**""
-      - ""docker-stacks-foundation/**""
-      - ""julia-notebook/**""
-      - ""minimal-notebook/**""
-      - ""pyspark-notebook/**""
-      - ""r-notebook/**""
-      - ""scipy-notebook/**""
-      - ""tensorflow-notebook/**""
-
+      - ""images/**""
       - ""tagging/**""
       - ""tests/**""
       - ""requirements-dev.txt""
@@ -48,17 +38,7 @@ on:
       - "".github/actions/download-manifests/action.yml""
       - "".github/actions/load-image/action.yml""
 
-      - ""all-spark-notebook/**""
-      - ""base-notebook/**""
-      - ""datascience-notebook/**""
-      - ""docker-stacks-foundation/**""
-      - ""julia-notebook/**""
-      - ""minimal-notebook/**""
-      - ""pyspark-notebook/**""
-      - ""r-notebook/**""
-      - ""scipy-notebook/**""
-      - ""tensorflow-notebook/**""
-
+      - ""images/**""
       - ""tagging/**""
       - ""tests/**""
       - ""requirements-dev.txt""",Yes
.github/workflows/hub-overview.yml,.github/workflows/hub-overview.yml,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index aef107f2..85bc7694 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -10,16 +10,7 @@ on:
     paths:
       - "".github/workflows/hub-overview.yml""
 
-      - ""all-spark-notebook/README.md""
-      - ""base-notebook/README.md""
-      - ""datascience-notebook/README.md""
-      - ""docker-stacks-foundation/README.md""
-      - ""julia-notebook/README.md""
-      - ""minimal-notebook/README.md""
-      - ""pyspark-notebook/README.md""
-      - ""r-notebook/README.md""
-      - ""scipy-notebook/README.md""
-      - ""tensorflow-notebook/README.md""
+      - ""images/*/README.md""
 
 jobs:
   update-dockerhub-overview:
@@ -40,7 +31,7 @@ jobs:
           destination_container_repo: ${{ env.OWNER }}/${{ matrix.image }}
           provider: dockerhub
           short_description: ${{ matrix.description }}
-          readme_file: ${{ matrix.image }}/README.md
+          readme_file: images/${{ matrix.image }}/README.md
 
     strategy:
       matrix:","diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index aef107f2..85bc7694 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -10,16 +10,7 @@ on:
     paths:
       - "".github/workflows/hub-overview.yml""
 
-      - ""all-spark-notebook/README.md""
-      - ""base-notebook/README.md""
-      - ""datascience-notebook/README.md""
-      - ""docker-stacks-foundation/README.md""
-      - ""julia-notebook/README.md""
-      - ""minimal-notebook/README.md""
-      - ""pyspark-notebook/README.md""
-      - ""r-notebook/README.md""
-      - ""scipy-notebook/README.md""
-      - ""tensorflow-notebook/README.md""
+      - ""images/*/README.md""
 
 jobs:
   update-dockerhub-overview:
@@ -40,7 +31,7 @@ jobs:
           destination_container_repo: ${{ env.OWNER }}/${{ matrix.image }}
           provider: dockerhub
           short_description: ${{ matrix.description }}
-          readme_file: ${{ matrix.image }}/README.md
+          readme_file: images/${{ matrix.image }}/README.md
 
     strategy:
       matrix:",Yes
Makefile,Makefile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/Makefile b/Makefile
index 483522a1..3af508cb 100644
--- a/Makefile
+++ b/Makefile
@@ -37,7 +37,7 @@ help:
 
 build/%: DOCKER_BUILD_ARGS?=
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(OWNER)/$(notdir $@):latest"" ""./$(notdir $@)"" --build-arg OWNER=""$(OWNER)""
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg OWNER=""$(OWNER)""
 	@echo -n ""Built image size: ""
 	@docker images ""$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks","diff --git a/Makefile b/Makefile
index 483522a1..3af508cb 100644
--- a/Makefile
+++ b/Makefile
@@ -37,7 +37,7 @@ help:
 
 build/%: DOCKER_BUILD_ARGS?=
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(OWNER)/$(notdir $@):latest"" ""./$(notdir $@)"" --build-arg OWNER=""$(OWNER)""
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg OWNER=""$(OWNER)""
 	@echo -n ""Built image size: ""
 	@docker images ""$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks",Yes
all-spark-notebook/.dockerignore,images/all-spark-notebook/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/all-spark-notebook/.dockerignore b/images/all-spark-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/all-spark-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/all-spark-notebook/.dockerignore b/images/all-spark-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/all-spark-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
all-spark-notebook/Dockerfile,images/all-spark-notebook/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
new file mode 100644
index 00000000..46509fac
--- /dev/null
+++ b/images/all-spark-notebook/Dockerfile
@@ -0,0 +1,38 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/pyspark-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# RSpark config
+ENV R_LIBS_USER ""${SPARK_HOME}/R/lib""
+RUN fix-permissions ""${R_LIBS_USER}""
+
+# R pre-requisites
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    fonts-dejavu \
+    gfortran \
+    gcc && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# R packages including IRKernel which gets installed globally.
+RUN mamba install --yes \
+    'r-base' \
+    'r-ggplot2' \
+    'r-irkernel' \
+    'r-rcurl' \
+    'r-sparklyr' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
new file mode 100644
index 00000000..46509fac
--- /dev/null
+++ b/images/all-spark-notebook/Dockerfile
@@ -0,0 +1,38 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/pyspark-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# RSpark config
+ENV R_LIBS_USER ""${SPARK_HOME}/R/lib""
+RUN fix-permissions ""${R_LIBS_USER}""
+
+# R pre-requisites
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    fonts-dejavu \
+    gfortran \
+    gcc && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# R packages including IRKernel which gets installed globally.
+RUN mamba install --yes \
+    'r-base' \
+    'r-ggplot2' \
+    'r-irkernel' \
+    'r-rcurl' \
+    'r-sparklyr' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
all-spark-notebook/README.md,images/all-spark-notebook/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/all-spark-notebook/README.md b/images/all-spark-notebook/README.md
new file mode 100644
index 00000000..898aca6a
--- /dev/null
+++ b/images/all-spark-notebook/README.md
@@ -0,0 +1,13 @@
+# Jupyter Notebook Python, R, Spark Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/all-spark-notebook/latest)](https://hub.docker.com/r/jupyter/all-spark-notebook/ ""jupyter/all-spark-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/all-spark-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-all-spark-notebook)
+- [Image Specifics :: Apache Spark](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#apache-spark)","diff --git a/images/all-spark-notebook/README.md b/images/all-spark-notebook/README.md
new file mode 100644
index 00000000..898aca6a
--- /dev/null
+++ b/images/all-spark-notebook/README.md
@@ -0,0 +1,13 @@
+# Jupyter Notebook Python, R, Spark Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/all-spark-notebook/latest)](https://hub.docker.com/r/jupyter/all-spark-notebook/ ""jupyter/all-spark-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/all-spark-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-all-spark-notebook)
+- [Image Specifics :: Apache Spark](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#apache-spark)",Yes
base-notebook/.dockerignore,images/base-notebook/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/base-notebook/.dockerignore b/images/base-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/base-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/base-notebook/.dockerignore b/images/base-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/base-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
base-notebook/Dockerfile,images/base-notebook/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
new file mode 100644
index 00000000..5f47a5d4
--- /dev/null
+++ b/images/base-notebook/Dockerfile
@@ -0,0 +1,74 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/docker-stacks-foundation
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Install all OS dependencies for Server that starts but lacks all
+# features (e.g., download as all possible file formats)
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    fonts-liberation \
+    # - pandoc is used to convert notebooks to html files
+    #   it's not present in aarch64 ubuntu image, so we install it here
+    pandoc \
+    # - run-one - a wrapper script that runs no more
+    #   than one unique  instance  of  some  command with a unique set of arguments,
+    #   we use `run-one-constantly` to support `RESTARTABLE` option
+    run-one && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# Install JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
+# Generate a Jupyter Server config
+# Cleanup temporary files
+# Correct permissions
+# Do all this in a single RUN command to avoid duplicating all of the
+# files across image layers when the permissions change
+WORKDIR /tmp
+RUN mamba install --yes \
+    'jupyterlab' \
+    'notebook' \
+    'jupyterhub' \
+    'nbclassic' && \
+    jupyter server --generate-config && \
+    mamba clean --all -f -y && \
+    npm cache clean --force && \
+    jupyter lab clean && \
+    rm -rf ""/home/${NB_USER}/.cache/yarn"" && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+ENV JUPYTER_PORT=8888
+EXPOSE $JUPYTER_PORT
+
+# Configure container startup
+CMD [""start-notebook.sh""]
+
+# Copy local files as late as possible to avoid cache busting
+COPY start-notebook.sh start-singleuser.sh /usr/local/bin/
+COPY jupyter_server_config.py docker_healthcheck.py /etc/jupyter/
+
+# Fix permissions on /etc/jupyter as root
+USER root
+RUN fix-permissions /etc/jupyter/
+
+# HEALTHCHECK documentation: https://docs.docker.com/engine/reference/builder/#healthcheck
+# This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server` and `retro` jupyter commands
+# https://github.com/jupyter/docker-stacks/issues/915#issuecomment-1068528799
+HEALTHCHECK --interval=5s --timeout=3s --start-period=5s --retries=3 \
+    CMD /etc/jupyter/docker_healthcheck.py || exit 1
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ${NB_UID}
+
+WORKDIR ""${HOME}""","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
new file mode 100644
index 00000000..5f47a5d4
--- /dev/null
+++ b/images/base-notebook/Dockerfile
@@ -0,0 +1,74 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/docker-stacks-foundation
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Install all OS dependencies for Server that starts but lacks all
+# features (e.g., download as all possible file formats)
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    fonts-liberation \
+    # - pandoc is used to convert notebooks to html files
+    #   it's not present in aarch64 ubuntu image, so we install it here
+    pandoc \
+    # - run-one - a wrapper script that runs no more
+    #   than one unique  instance  of  some  command with a unique set of arguments,
+    #   we use `run-one-constantly` to support `RESTARTABLE` option
+    run-one && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# Install JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
+# Generate a Jupyter Server config
+# Cleanup temporary files
+# Correct permissions
+# Do all this in a single RUN command to avoid duplicating all of the
+# files across image layers when the permissions change
+WORKDIR /tmp
+RUN mamba install --yes \
+    'jupyterlab' \
+    'notebook' \
+    'jupyterhub' \
+    'nbclassic' && \
+    jupyter server --generate-config && \
+    mamba clean --all -f -y && \
+    npm cache clean --force && \
+    jupyter lab clean && \
+    rm -rf ""/home/${NB_USER}/.cache/yarn"" && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+ENV JUPYTER_PORT=8888
+EXPOSE $JUPYTER_PORT
+
+# Configure container startup
+CMD [""start-notebook.sh""]
+
+# Copy local files as late as possible to avoid cache busting
+COPY start-notebook.sh start-singleuser.sh /usr/local/bin/
+COPY jupyter_server_config.py docker_healthcheck.py /etc/jupyter/
+
+# Fix permissions on /etc/jupyter as root
+USER root
+RUN fix-permissions /etc/jupyter/
+
+# HEALTHCHECK documentation: https://docs.docker.com/engine/reference/builder/#healthcheck
+# This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server` and `retro` jupyter commands
+# https://github.com/jupyter/docker-stacks/issues/915#issuecomment-1068528799
+HEALTHCHECK --interval=5s --timeout=3s --start-period=5s --retries=3 \
+    CMD /etc/jupyter/docker_healthcheck.py || exit 1
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ${NB_UID}
+
+WORKDIR ""${HOME}""",Yes
base-notebook/README.md,images/base-notebook/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/base-notebook/README.md b/images/base-notebook/README.md
new file mode 100644
index 00000000..618da14d
--- /dev/null
+++ b/images/base-notebook/README.md
@@ -0,0 +1,12 @@
+# Base Jupyter Notebook Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/base-notebook/latest)](https://hub.docker.com/r/jupyter/base-notebook/ ""jupyter/base-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/base-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-base-notebook)","diff --git a/images/base-notebook/README.md b/images/base-notebook/README.md
new file mode 100644
index 00000000..618da14d
--- /dev/null
+++ b/images/base-notebook/README.md
@@ -0,0 +1,12 @@
+# Base Jupyter Notebook Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/base-notebook/latest)](https://hub.docker.com/r/jupyter/base-notebook/ ""jupyter/base-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/base-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-base-notebook)",Yes
base-notebook/docker_healthcheck.py,images/base-notebook/docker_healthcheck.py,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/base-notebook/docker_healthcheck.py b/images/base-notebook/docker_healthcheck.py
new file mode 100755
index 00000000..41bbc785
--- /dev/null
+++ b/images/base-notebook/docker_healthcheck.py
@@ -0,0 +1,26 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import json
+import os
+from pathlib import Path
+
+import requests
+
+# A number of operations below deliberately don't check for possible errors
+# As this is a healthcheck, it should succeed or raise an exception on error
+
+runtime_dir = Path(""/home/"") / os.environ[""NB_USER""] / "".local/share/jupyter/runtime/""
+json_file = next(runtime_dir.glob(""*server-*.json""))
+
+url = json.loads(json_file.read_bytes())[""url""]
+url = url + ""api""
+
+proxies = {
+    ""http"": """",
+    ""https"": """",
+}
+
+r = requests.get(url, proxies=proxies, verify=False)  # request without SSL verification
+r.raise_for_status()
+print(r.content)","diff --git a/images/base-notebook/docker_healthcheck.py b/images/base-notebook/docker_healthcheck.py
new file mode 100755
index 00000000..41bbc785
--- /dev/null
+++ b/images/base-notebook/docker_healthcheck.py
@@ -0,0 +1,26 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import json
+import os
+from pathlib import Path
+
+import requests
+
+# A number of operations below deliberately don't check for possible errors
+# As this is a healthcheck, it should succeed or raise an exception on error
+
+runtime_dir = Path(""/home/"") / os.environ[""NB_USER""] / "".local/share/jupyter/runtime/""
+json_file = next(runtime_dir.glob(""*server-*.json""))
+
+url = json.loads(json_file.read_bytes())[""url""]
+url = url + ""api""
+
+proxies = {
+    ""http"": """",
+    ""https"": """",
+}
+
+r = requests.get(url, proxies=proxies, verify=False)  # request without SSL verification
+r.raise_for_status()
+print(r.content)",Yes
base-notebook/jupyter_server_config.py,images/base-notebook/jupyter_server_config.py,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/base-notebook/jupyter_server_config.py b/images/base-notebook/jupyter_server_config.py
new file mode 100644
index 00000000..c4c50147
--- /dev/null
+++ b/images/base-notebook/jupyter_server_config.py
@@ -0,0 +1,58 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+# mypy: ignore-errors
+import os
+import stat
+import subprocess
+
+from jupyter_core.paths import jupyter_data_dir
+
+c = get_config()  # noqa: F821
+c.ServerApp.ip = ""0.0.0.0""
+c.ServerApp.open_browser = False
+
+# to output both image/svg+xml and application/pdf plot formats in the notebook file
+c.InlineBackend.figure_formats = {""png"", ""jpeg"", ""svg"", ""pdf""}
+
+# https://github.com/jupyter/notebook/issues/3130
+c.FileContentsManager.delete_to_trash = False
+
+# Generate a self-signed certificate
+OPENSSL_CONFIG = """"""\
+[req]
+distinguished_name = req_distinguished_name
+[req_distinguished_name]
+""""""
+if ""GEN_CERT"" in os.environ:
+    dir_name = jupyter_data_dir()
+    pem_file = os.path.join(dir_name, ""notebook.pem"")
+    os.makedirs(dir_name, exist_ok=True)
+
+    # Generate an openssl.cnf file to set the distinguished name
+    cnf_file = os.path.join(os.getenv(""CONDA_DIR"", ""/usr/lib""), ""ssl"", ""openssl.cnf"")
+    if not os.path.isfile(cnf_file):
+        with open(cnf_file, ""w"") as fh:
+            fh.write(OPENSSL_CONFIG)
+
+    # Generate a certificate if one doesn't exist on disk
+    subprocess.check_call(
+        [
+            ""openssl"",
+            ""req"",
+            ""-new"",
+            ""-newkey=rsa:2048"",
+            ""-days=365"",
+            ""-nodes"",
+            ""-x509"",
+            ""-subj=/C=XX/ST=XX/L=XX/O=generated/CN=generated"",
+            f""-keyout={pem_file}"",
+            f""-out={pem_file}"",
+        ]
+    )
+    # Restrict access to the file
+    os.chmod(pem_file, stat.S_IRUSR | stat.S_IWUSR)
+    c.ServerApp.certfile = pem_file
+
+# Change default umask for all subprocesses of the Server if set in the environment
+if ""NB_UMASK"" in os.environ:
+    os.umask(int(os.environ[""NB_UMASK""], 8))","diff --git a/images/base-notebook/jupyter_server_config.py b/images/base-notebook/jupyter_server_config.py
new file mode 100644
index 00000000..c4c50147
--- /dev/null
+++ b/images/base-notebook/jupyter_server_config.py
@@ -0,0 +1,58 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+# mypy: ignore-errors
+import os
+import stat
+import subprocess
+
+from jupyter_core.paths import jupyter_data_dir
+
+c = get_config()  # noqa: F821
+c.ServerApp.ip = ""0.0.0.0""
+c.ServerApp.open_browser = False
+
+# to output both image/svg+xml and application/pdf plot formats in the notebook file
+c.InlineBackend.figure_formats = {""png"", ""jpeg"", ""svg"", ""pdf""}
+
+# https://github.com/jupyter/notebook/issues/3130
+c.FileContentsManager.delete_to_trash = False
+
+# Generate a self-signed certificate
+OPENSSL_CONFIG = """"""\
+[req]
+distinguished_name = req_distinguished_name
+[req_distinguished_name]
+""""""
+if ""GEN_CERT"" in os.environ:
+    dir_name = jupyter_data_dir()
+    pem_file = os.path.join(dir_name, ""notebook.pem"")
+    os.makedirs(dir_name, exist_ok=True)
+
+    # Generate an openssl.cnf file to set the distinguished name
+    cnf_file = os.path.join(os.getenv(""CONDA_DIR"", ""/usr/lib""), ""ssl"", ""openssl.cnf"")
+    if not os.path.isfile(cnf_file):
+        with open(cnf_file, ""w"") as fh:
+            fh.write(OPENSSL_CONFIG)
+
+    # Generate a certificate if one doesn't exist on disk
+    subprocess.check_call(
+        [
+            ""openssl"",
+            ""req"",
+            ""-new"",
+            ""-newkey=rsa:2048"",
+            ""-days=365"",
+            ""-nodes"",
+            ""-x509"",
+            ""-subj=/C=XX/ST=XX/L=XX/O=generated/CN=generated"",
+            f""-keyout={pem_file}"",
+            f""-out={pem_file}"",
+        ]
+    )
+    # Restrict access to the file
+    os.chmod(pem_file, stat.S_IRUSR | stat.S_IWUSR)
+    c.ServerApp.certfile = pem_file
+
+# Change default umask for all subprocesses of the Server if set in the environment
+if ""NB_UMASK"" in os.environ:
+    os.umask(int(os.environ[""NB_UMASK""], 8))",Yes
base-notebook/start-notebook.sh,images/base-notebook/start-notebook.sh,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/base-notebook/start-notebook.sh b/images/base-notebook/start-notebook.sh
new file mode 100755
index 00000000..4f673d22
--- /dev/null
+++ b/images/base-notebook/start-notebook.sh
@@ -0,0 +1,22 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+# The Jupyter command to launch
+# JupyterLab by default
+DOCKER_STACKS_JUPYTER_CMD=""${DOCKER_STACKS_JUPYTER_CMD:=lab}""
+
+if [[ -n ""${JUPYTERHUB_API_TOKEN}"" ]]; then
+    echo ""WARNING: using start-singleuser.sh instead of start-notebook.sh to start a server associated with JupyterHub.""
+    exec /usr/local/bin/start-singleuser.sh ""$@""
+fi
+
+wrapper=""""
+if [[ ""${RESTARTABLE}"" == ""yes"" ]]; then
+    wrapper=""run-one-constantly""
+fi
+
+# shellcheck disable=SC1091,SC2086
+exec /usr/local/bin/start.sh ${wrapper} jupyter ${DOCKER_STACKS_JUPYTER_CMD} ${NOTEBOOK_ARGS} ""$@""","diff --git a/images/base-notebook/start-notebook.sh b/images/base-notebook/start-notebook.sh
new file mode 100755
index 00000000..4f673d22
--- /dev/null
+++ b/images/base-notebook/start-notebook.sh
@@ -0,0 +1,22 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+# The Jupyter command to launch
+# JupyterLab by default
+DOCKER_STACKS_JUPYTER_CMD=""${DOCKER_STACKS_JUPYTER_CMD:=lab}""
+
+if [[ -n ""${JUPYTERHUB_API_TOKEN}"" ]]; then
+    echo ""WARNING: using start-singleuser.sh instead of start-notebook.sh to start a server associated with JupyterHub.""
+    exec /usr/local/bin/start-singleuser.sh ""$@""
+fi
+
+wrapper=""""
+if [[ ""${RESTARTABLE}"" == ""yes"" ]]; then
+    wrapper=""run-one-constantly""
+fi
+
+# shellcheck disable=SC1091,SC2086
+exec /usr/local/bin/start.sh ${wrapper} jupyter ${DOCKER_STACKS_JUPYTER_CMD} ${NOTEBOOK_ARGS} ""$@""",Yes
base-notebook/start-singleuser.sh,images/base-notebook/start-singleuser.sh,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/base-notebook/start-singleuser.sh b/images/base-notebook/start-singleuser.sh
new file mode 100755
index 00000000..a2166e2c
--- /dev/null
+++ b/images/base-notebook/start-singleuser.sh
@@ -0,0 +1,13 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+# set default ip to 0.0.0.0
+if [[ ""${NOTEBOOK_ARGS} $*"" != *""--ip=""* ]]; then
+    NOTEBOOK_ARGS=""--ip=0.0.0.0 ${NOTEBOOK_ARGS}""
+fi
+
+# shellcheck disable=SC1091,SC2086
+. /usr/local/bin/start.sh jupyterhub-singleuser ${NOTEBOOK_ARGS} ""$@""","diff --git a/images/base-notebook/start-singleuser.sh b/images/base-notebook/start-singleuser.sh
new file mode 100755
index 00000000..a2166e2c
--- /dev/null
+++ b/images/base-notebook/start-singleuser.sh
@@ -0,0 +1,13 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+# set default ip to 0.0.0.0
+if [[ ""${NOTEBOOK_ARGS} $*"" != *""--ip=""* ]]; then
+    NOTEBOOK_ARGS=""--ip=0.0.0.0 ${NOTEBOOK_ARGS}""
+fi
+
+# shellcheck disable=SC1091,SC2086
+. /usr/local/bin/start.sh jupyterhub-singleuser ${NOTEBOOK_ARGS} ""$@""",Yes
datascience-notebook/.dockerignore,images/datascience-notebook/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/datascience-notebook/.dockerignore b/images/datascience-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/datascience-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/datascience-notebook/.dockerignore b/images/datascience-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/datascience-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
datascience-notebook/Dockerfile,images/datascience-notebook/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
new file mode 100644
index 00000000..4833fef3
--- /dev/null
+++ b/images/datascience-notebook/Dockerfile
@@ -0,0 +1,62 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# R pre-requisites
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    fonts-dejavu \
+    gfortran \
+    gcc && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+# Julia dependencies
+# install Julia packages in /opt/julia instead of ${HOME}
+ENV JULIA_DEPOT_PATH=/opt/julia \
+    JULIA_PKGDIR=/opt/julia
+
+# Setup Julia
+RUN /opt/setup-scripts/setup-julia.bash
+
+USER ${NB_UID}
+
+# Setup IJulia kernel & other packages
+RUN /opt/setup-scripts/setup-julia-packages.bash
+
+# R packages including IRKernel which gets installed globally.
+# r-e1071: dependency of the caret R package
+RUN mamba install --yes \
+    'r-base' \
+    'r-caret' \
+    'r-crayon' \
+    'r-devtools' \
+    'r-e1071' \
+    'r-forecast' \
+    'r-hexbin' \
+    'r-htmltools' \
+    'r-htmlwidgets' \
+    'r-irkernel' \
+    'r-nycflights13' \
+    'r-randomforest' \
+    'r-rcurl' \
+    'r-rmarkdown' \
+    'r-rodbc' \
+    'r-rsqlite' \
+    'r-shiny' \
+    'r-tidymodels' \
+    'r-tidyverse' \
+    'rpy2' \
+    'unixodbc' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
new file mode 100644
index 00000000..4833fef3
--- /dev/null
+++ b/images/datascience-notebook/Dockerfile
@@ -0,0 +1,62 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# R pre-requisites
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    fonts-dejavu \
+    gfortran \
+    gcc && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+# Julia dependencies
+# install Julia packages in /opt/julia instead of ${HOME}
+ENV JULIA_DEPOT_PATH=/opt/julia \
+    JULIA_PKGDIR=/opt/julia
+
+# Setup Julia
+RUN /opt/setup-scripts/setup-julia.bash
+
+USER ${NB_UID}
+
+# Setup IJulia kernel & other packages
+RUN /opt/setup-scripts/setup-julia-packages.bash
+
+# R packages including IRKernel which gets installed globally.
+# r-e1071: dependency of the caret R package
+RUN mamba install --yes \
+    'r-base' \
+    'r-caret' \
+    'r-crayon' \
+    'r-devtools' \
+    'r-e1071' \
+    'r-forecast' \
+    'r-hexbin' \
+    'r-htmltools' \
+    'r-htmlwidgets' \
+    'r-irkernel' \
+    'r-nycflights13' \
+    'r-randomforest' \
+    'r-rcurl' \
+    'r-rmarkdown' \
+    'r-rodbc' \
+    'r-rsqlite' \
+    'r-shiny' \
+    'r-tidymodels' \
+    'r-tidyverse' \
+    'rpy2' \
+    'unixodbc' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
datascience-notebook/README.md,images/datascience-notebook/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/datascience-notebook/README.md b/images/datascience-notebook/README.md
new file mode 100644
index 00000000..64ef2007
--- /dev/null
+++ b/images/datascience-notebook/README.md
@@ -0,0 +1,12 @@
+# Jupyter Notebook Data Science Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/datascience-notebook/latest)](https://hub.docker.com/r/jupyter/datascience-notebook/ ""jupyter/datascience-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/datascience-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-datascience-notebook)","diff --git a/images/datascience-notebook/README.md b/images/datascience-notebook/README.md
new file mode 100644
index 00000000..64ef2007
--- /dev/null
+++ b/images/datascience-notebook/README.md
@@ -0,0 +1,12 @@
+# Jupyter Notebook Data Science Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/datascience-notebook/latest)](https://hub.docker.com/r/jupyter/datascience-notebook/ ""jupyter/datascience-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/datascience-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-datascience-notebook)",Yes
docker-stacks-foundation/.dockerignore,images/docker-stacks-foundation/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/docker-stacks-foundation/.dockerignore b/images/docker-stacks-foundation/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/docker-stacks-foundation/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/docker-stacks-foundation/.dockerignore b/images/docker-stacks-foundation/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/docker-stacks-foundation/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
new file mode 100644
index 00000000..7e62b64c
--- /dev/null
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -0,0 +1,135 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# Ubuntu 22.04 (jammy)
+# https://hub.docker.com/_/ubuntu/tags?page=1&name=jammy
+ARG ROOT_CONTAINER=ubuntu:22.04
+
+FROM $ROOT_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+ARG NB_USER=""jovyan""
+ARG NB_UID=""1000""
+ARG NB_GID=""100""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Install all OS dependencies for Server that starts
+# but lacks all features (e.g., download as all possible file formats)
+ENV DEBIAN_FRONTEND noninteractive
+RUN apt-get update --yes && \
+    # - apt-get upgrade is run to patch known vulnerabilities in apt-get packages as
+    #   the ubuntu base image is rebuilt too seldom sometimes (less than once a month)
+    apt-get upgrade --yes && \
+    apt-get install --yes --no-install-recommends \
+    # - bzip2 is necessary to extract the micromamba executable.
+    bzip2 \
+    ca-certificates \
+    locales \
+    sudo \
+    # - tini is installed as a helpful container entrypoint that reaps zombie
+    #   processes and such of the actual executable we want to start, see
+    #   https://github.com/krallin/tini#why-tini for details.
+    tini \
+    wget && \
+    apt-get clean && rm -rf /var/lib/apt/lists/* && \
+    echo ""en_US.UTF-8 UTF-8"" > /etc/locale.gen && \
+    locale-gen
+
+# Configure environment
+ENV CONDA_DIR=/opt/conda \
+    SHELL=/bin/bash \
+    NB_USER=""${NB_USER}"" \
+    NB_UID=${NB_UID} \
+    NB_GID=${NB_GID} \
+    LC_ALL=en_US.UTF-8 \
+    LANG=en_US.UTF-8 \
+    LANGUAGE=en_US.UTF-8
+ENV PATH=""${CONDA_DIR}/bin:${PATH}"" \
+    HOME=""/home/${NB_USER}""
+
+# Copy a script that we will use to correct permissions after running certain commands
+COPY fix-permissions /usr/local/bin/fix-permissions
+RUN chmod a+rx /usr/local/bin/fix-permissions
+
+# Enable prompt color in the skeleton .bashrc before creating the default NB_USER
+# hadolint ignore=SC2016
+RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashrc && \
+   # Add call to conda init script see https://stackoverflow.com/a/58081608/4413446
+   echo 'eval ""$(command conda shell.bash hook 2> /dev/null)""' >> /etc/skel/.bashrc
+
+# Create NB_USER with name jovyan user with UID=1000 and in the 'users' group
+# and make sure these dirs are writable by the `users` group.
+RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
+    sed -i.bak -e 's/^%admin/#%admin/' /etc/sudoers && \
+    sed -i.bak -e 's/^%sudo/#%sudo/' /etc/sudoers && \
+    useradd -l -m -s /bin/bash -N -u ""${NB_UID}"" ""${NB_USER}"" && \
+    mkdir -p ""${CONDA_DIR}"" && \
+    chown ""${NB_USER}:${NB_GID}"" ""${CONDA_DIR}"" && \
+    chmod g+w /etc/passwd && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+USER ${NB_UID}
+
+# Pin python version here, or set it to ""default""
+ARG PYTHON_VERSION=3.11
+
+# Setup work directory for backward-compatibility
+RUN mkdir ""/home/${NB_USER}/work"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Download and install Micromamba, and initialize Conda prefix.
+#   <https://github.com/mamba-org/mamba#micromamba>
+#   Similar projects using Micromamba:
+#     - Micromamba-Docker: <https://github.com/mamba-org/micromamba-docker>
+#     - repo2docker: <https://github.com/jupyterhub/repo2docker>
+# Install Python, Mamba and jupyter_core
+# Cleanup temporary files and remove Micromamba
+# Correct permissions
+# Do all this in a single RUN command to avoid duplicating all of the
+# files across image layers when the permissions change
+COPY --chown=""${NB_UID}:${NB_GID}"" initial-condarc ""${CONDA_DIR}/.condarc""
+WORKDIR /tmp
+RUN set -x && \
+    arch=$(uname -m) && \
+    if [ ""${arch}"" = ""x86_64"" ]; then \
+        # Should be simpler, see <https://github.com/mamba-org/mamba/issues/1437>
+        arch=""64""; \
+    fi && \
+    wget --progress=dot:giga -O /tmp/micromamba.tar.bz2 \
+        ""https://micromamba.snakepit.net/api/micromamba/linux-${arch}/latest"" && \
+    tar -xvjf /tmp/micromamba.tar.bz2 --strip-components=1 bin/micromamba && \
+    rm /tmp/micromamba.tar.bz2 && \
+    PYTHON_SPECIFIER=""python=${PYTHON_VERSION}"" && \
+    if [[ ""${PYTHON_VERSION}"" == ""default"" ]]; then PYTHON_SPECIFIER=""python""; fi && \
+    # Install the packages
+    ./micromamba install \
+        --root-prefix=""${CONDA_DIR}"" \
+        --prefix=""${CONDA_DIR}"" \
+        --yes \
+        ""${PYTHON_SPECIFIER}"" \
+        'mamba' \
+        'jupyter_core' && \
+    rm micromamba && \
+    # Pin major.minor version of python
+    mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Configure container startup
+ENTRYPOINT [""tini"", ""-g"", ""--""]
+CMD [""start.sh""]
+
+# Copy local files as late as possible to avoid cache busting
+COPY start.sh /usr/local/bin/
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ${NB_UID}
+
+WORKDIR ""${HOME}""","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
new file mode 100644
index 00000000..7e62b64c
--- /dev/null
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -0,0 +1,135 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# Ubuntu 22.04 (jammy)
+# https://hub.docker.com/_/ubuntu/tags?page=1&name=jammy
+ARG ROOT_CONTAINER=ubuntu:22.04
+
+FROM $ROOT_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+ARG NB_USER=""jovyan""
+ARG NB_UID=""1000""
+ARG NB_GID=""100""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Install all OS dependencies for Server that starts
+# but lacks all features (e.g., download as all possible file formats)
+ENV DEBIAN_FRONTEND noninteractive
+RUN apt-get update --yes && \
+    # - apt-get upgrade is run to patch known vulnerabilities in apt-get packages as
+    #   the ubuntu base image is rebuilt too seldom sometimes (less than once a month)
+    apt-get upgrade --yes && \
+    apt-get install --yes --no-install-recommends \
+    # - bzip2 is necessary to extract the micromamba executable.
+    bzip2 \
+    ca-certificates \
+    locales \
+    sudo \
+    # - tini is installed as a helpful container entrypoint that reaps zombie
+    #   processes and such of the actual executable we want to start, see
+    #   https://github.com/krallin/tini#why-tini for details.
+    tini \
+    wget && \
+    apt-get clean && rm -rf /var/lib/apt/lists/* && \
+    echo ""en_US.UTF-8 UTF-8"" > /etc/locale.gen && \
+    locale-gen
+
+# Configure environment
+ENV CONDA_DIR=/opt/conda \
+    SHELL=/bin/bash \
+    NB_USER=""${NB_USER}"" \
+    NB_UID=${NB_UID} \
+    NB_GID=${NB_GID} \
+    LC_ALL=en_US.UTF-8 \
+    LANG=en_US.UTF-8 \
+    LANGUAGE=en_US.UTF-8
+ENV PATH=""${CONDA_DIR}/bin:${PATH}"" \
+    HOME=""/home/${NB_USER}""
+
+# Copy a script that we will use to correct permissions after running certain commands
+COPY fix-permissions /usr/local/bin/fix-permissions
+RUN chmod a+rx /usr/local/bin/fix-permissions
+
+# Enable prompt color in the skeleton .bashrc before creating the default NB_USER
+# hadolint ignore=SC2016
+RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashrc && \
+   # Add call to conda init script see https://stackoverflow.com/a/58081608/4413446
+   echo 'eval ""$(command conda shell.bash hook 2> /dev/null)""' >> /etc/skel/.bashrc
+
+# Create NB_USER with name jovyan user with UID=1000 and in the 'users' group
+# and make sure these dirs are writable by the `users` group.
+RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
+    sed -i.bak -e 's/^%admin/#%admin/' /etc/sudoers && \
+    sed -i.bak -e 's/^%sudo/#%sudo/' /etc/sudoers && \
+    useradd -l -m -s /bin/bash -N -u ""${NB_UID}"" ""${NB_USER}"" && \
+    mkdir -p ""${CONDA_DIR}"" && \
+    chown ""${NB_USER}:${NB_GID}"" ""${CONDA_DIR}"" && \
+    chmod g+w /etc/passwd && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+USER ${NB_UID}
+
+# Pin python version here, or set it to ""default""
+ARG PYTHON_VERSION=3.11
+
+# Setup work directory for backward-compatibility
+RUN mkdir ""/home/${NB_USER}/work"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Download and install Micromamba, and initialize Conda prefix.
+#   <https://github.com/mamba-org/mamba#micromamba>
+#   Similar projects using Micromamba:
+#     - Micromamba-Docker: <https://github.com/mamba-org/micromamba-docker>
+#     - repo2docker: <https://github.com/jupyterhub/repo2docker>
+# Install Python, Mamba and jupyter_core
+# Cleanup temporary files and remove Micromamba
+# Correct permissions
+# Do all this in a single RUN command to avoid duplicating all of the
+# files across image layers when the permissions change
+COPY --chown=""${NB_UID}:${NB_GID}"" initial-condarc ""${CONDA_DIR}/.condarc""
+WORKDIR /tmp
+RUN set -x && \
+    arch=$(uname -m) && \
+    if [ ""${arch}"" = ""x86_64"" ]; then \
+        # Should be simpler, see <https://github.com/mamba-org/mamba/issues/1437>
+        arch=""64""; \
+    fi && \
+    wget --progress=dot:giga -O /tmp/micromamba.tar.bz2 \
+        ""https://micromamba.snakepit.net/api/micromamba/linux-${arch}/latest"" && \
+    tar -xvjf /tmp/micromamba.tar.bz2 --strip-components=1 bin/micromamba && \
+    rm /tmp/micromamba.tar.bz2 && \
+    PYTHON_SPECIFIER=""python=${PYTHON_VERSION}"" && \
+    if [[ ""${PYTHON_VERSION}"" == ""default"" ]]; then PYTHON_SPECIFIER=""python""; fi && \
+    # Install the packages
+    ./micromamba install \
+        --root-prefix=""${CONDA_DIR}"" \
+        --prefix=""${CONDA_DIR}"" \
+        --yes \
+        ""${PYTHON_SPECIFIER}"" \
+        'mamba' \
+        'jupyter_core' && \
+    rm micromamba && \
+    # Pin major.minor version of python
+    mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Configure container startup
+ENTRYPOINT [""tini"", ""-g"", ""--""]
+CMD [""start.sh""]
+
+# Copy local files as late as possible to avoid cache busting
+COPY start.sh /usr/local/bin/
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ${NB_UID}
+
+WORKDIR ""${HOME}""",Yes
docker-stacks-foundation/README.md,images/docker-stacks-foundation/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/docker-stacks-foundation/README.md b/images/docker-stacks-foundation/README.md
new file mode 100644
index 00000000..b4e4d2db
--- /dev/null
+++ b/images/docker-stacks-foundation/README.md
@@ -0,0 +1,12 @@
+# Foundation Jupyter Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/docker-stacks-foundation/latest)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/ ""jupyter/docker-stacks-foundation image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/docker-stacks-foundation](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-docker-stacks-foundation)","diff --git a/images/docker-stacks-foundation/README.md b/images/docker-stacks-foundation/README.md
new file mode 100644
index 00000000..b4e4d2db
--- /dev/null
+++ b/images/docker-stacks-foundation/README.md
@@ -0,0 +1,12 @@
+# Foundation Jupyter Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/docker-stacks-foundation/latest)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/ ""jupyter/docker-stacks-foundation image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/docker-stacks-foundation](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-docker-stacks-foundation)",Yes
docker-stacks-foundation/fix-permissions,images/docker-stacks-foundation/fix-permissions,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/docker-stacks-foundation/fix-permissions b/images/docker-stacks-foundation/fix-permissions
new file mode 100755
index 00000000..d167578b
--- /dev/null
+++ b/images/docker-stacks-foundation/fix-permissions
@@ -0,0 +1,35 @@
+#!/bin/bash
+# set permissions on a directory
+# after any installation, if a directory needs to be (human) user-writable,
+# run this script on it.
+# It will make everything in the directory owned by the group ${NB_GID}
+# and writable by that group.
+# Deployments that want to set a specific user id can preserve permissions
+# by adding the `--group-add users` line to `docker run`.
+
+# uses find to avoid touching files that already have the right permissions,
+# which would cause massive image explosion
+
+# right permissions are:
+# group=${NB_GID}
+# AND permissions include group rwX (directory-execute)
+# AND directories have setuid,setgid bits set
+
+set -e
+
+for d in ""$@""; do
+    find ""${d}"" \
+        ! \( \
+            -group ""${NB_GID}"" \
+            -a -perm -g+rwX \
+        \) \
+        -exec chgrp ""${NB_GID}"" -- {} \+ \
+        -exec chmod g+rwX -- {} \+
+    # setuid, setgid *on directories only*
+    find ""${d}"" \
+        \( \
+            -type d \
+            -a ! -perm -6000 \
+        \) \
+        -exec chmod +6000 -- {} \+
+done","diff --git a/images/docker-stacks-foundation/fix-permissions b/images/docker-stacks-foundation/fix-permissions
new file mode 100755
index 00000000..d167578b
--- /dev/null
+++ b/images/docker-stacks-foundation/fix-permissions
@@ -0,0 +1,35 @@
+#!/bin/bash
+# set permissions on a directory
+# after any installation, if a directory needs to be (human) user-writable,
+# run this script on it.
+# It will make everything in the directory owned by the group ${NB_GID}
+# and writable by that group.
+# Deployments that want to set a specific user id can preserve permissions
+# by adding the `--group-add users` line to `docker run`.
+
+# uses find to avoid touching files that already have the right permissions,
+# which would cause massive image explosion
+
+# right permissions are:
+# group=${NB_GID}
+# AND permissions include group rwX (directory-execute)
+# AND directories have setuid,setgid bits set
+
+set -e
+
+for d in ""$@""; do
+    find ""${d}"" \
+        ! \( \
+            -group ""${NB_GID}"" \
+            -a -perm -g+rwX \
+        \) \
+        -exec chgrp ""${NB_GID}"" -- {} \+ \
+        -exec chmod g+rwX -- {} \+
+    # setuid, setgid *on directories only*
+    find ""${d}"" \
+        \( \
+            -type d \
+            -a ! -perm -6000 \
+        \) \
+        -exec chmod +6000 -- {} \+
+done",Yes
docker-stacks-foundation/initial-condarc,images/docker-stacks-foundation/initial-condarc,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/docker-stacks-foundation/initial-condarc b/images/docker-stacks-foundation/initial-condarc
new file mode 100644
index 00000000..383aad3c
--- /dev/null
+++ b/images/docker-stacks-foundation/initial-condarc
@@ -0,0 +1,6 @@
+# Conda configuration see https://conda.io/projects/conda/en/latest/configuration.html
+
+auto_update_conda: false
+show_channel_urls: true
+channels:
+  - conda-forge","diff --git a/images/docker-stacks-foundation/initial-condarc b/images/docker-stacks-foundation/initial-condarc
new file mode 100644
index 00000000..383aad3c
--- /dev/null
+++ b/images/docker-stacks-foundation/initial-condarc
@@ -0,0 +1,6 @@
+# Conda configuration see https://conda.io/projects/conda/en/latest/configuration.html
+
+auto_update_conda: false
+show_channel_urls: true
+channels:
+  - conda-forge",Yes
docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
new file mode 100755
index 00000000..7c5859ee
--- /dev/null
+++ b/images/docker-stacks-foundation/start.sh
@@ -0,0 +1,262 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+# The _log function is used for everything this script wants to log. It will
+# always log errors and warnings, but can be silenced for other messages
+# by setting JUPYTER_DOCKER_STACKS_QUIET environment variable.
+_log () {
+    if [[ ""$*"" == ""ERROR:""* ]] || [[ ""$*"" == ""WARNING:""* ]] || [[ ""${JUPYTER_DOCKER_STACKS_QUIET}"" == """" ]]; then
+        echo ""$@""
+    fi
+}
+_log ""Entered start.sh with args:"" ""$@""
+
+# The run-hooks function looks for .sh scripts to source and executable files to
+# run within a passed directory.
+run-hooks () {
+    if [[ ! -d ""${1}"" ]] ; then
+        return
+    fi
+    _log ""${0}: running hooks in ${1} as uid / gid: $(id -u) / $(id -g)""
+    for f in ""${1}/""*; do
+        case ""${f}"" in
+            *.sh)
+                _log ""${0}: running script ${f}""
+                # shellcheck disable=SC1090
+                source ""${f}""
+                ;;
+            *)
+                if [[ -x ""${f}"" ]] ; then
+                    _log ""${0}: running executable ${f}""
+                    ""${f}""
+                else
+                    _log ""${0}: ignoring non-executable ${f}""
+                fi
+                ;;
+        esac
+    done
+    _log ""${0}: done running hooks in ${1}""
+}
+
+# A helper function to unset env vars listed in the value of the env var
+# JUPYTER_ENV_VARS_TO_UNSET.
+unset_explicit_env_vars () {
+    if [ -n ""${JUPYTER_ENV_VARS_TO_UNSET}"" ]; then
+        for env_var_to_unset in $(echo ""${JUPYTER_ENV_VARS_TO_UNSET}"" | tr ',' ' '); do
+            echo ""Unset ${env_var_to_unset} due to JUPYTER_ENV_VARS_TO_UNSET""
+            unset ""${env_var_to_unset}""
+        done
+        unset JUPYTER_ENV_VARS_TO_UNSET
+    fi
+}
+
+
+# Default to starting bash if no command was specified
+if [ $# -eq 0 ]; then
+    cmd=( ""bash"" )
+else
+    cmd=( ""$@"" )
+fi
+
+# NOTE: This hook will run as the user the container was started with!
+run-hooks /usr/local/bin/start-notebook.d
+
+# If the container started as the root user, then we have permission to refit
+# the jovyan user, and ensure file permissions, grant sudo rights, and such
+# things before we run the command passed to start.sh as the desired user
+# (NB_USER).
+#
+if [ ""$(id -u)"" == 0 ] ; then
+    # Environment variables:
+    # - NB_USER: the desired username and associated home folder
+    # - NB_UID: the desired user id
+    # - NB_GID: a group id we want our user to belong to
+    # - NB_GROUP: a group name we want for the group
+    # - GRANT_SUDO: a boolean (""1"" or ""yes"") to grant the user sudo rights
+    # - CHOWN_HOME: a boolean (""1"" or ""yes"") to chown the user's home folder
+    # - CHOWN_EXTRA: a comma separated list of paths to chown
+    # - CHOWN_HOME_OPTS / CHOWN_EXTRA_OPTS: arguments to the chown commands
+
+    # Refit the jovyan user to the desired the user (NB_USER)
+    if id jovyan &> /dev/null ; then
+        if ! usermod --home ""/home/${NB_USER}"" --login ""${NB_USER}"" jovyan 2>&1 | grep ""no changes"" > /dev/null; then
+            _log ""Updated the jovyan user:""
+            _log ""- username: jovyan       -> ${NB_USER}""
+            _log ""- home dir: /home/jovyan -> /home/${NB_USER}""
+        fi
+    elif ! id -u ""${NB_USER}"" &> /dev/null; then
+        _log ""ERROR: Neither the jovyan user or '${NB_USER}' exists. This could be the result of stopping and starting, the container with a different NB_USER environment variable.""
+        exit 1
+    fi
+    # Ensure the desired user (NB_USER) gets its desired user id (NB_UID) and is
+    # a member of the desired group (NB_GROUP, NB_GID)
+    if [ ""${NB_UID}"" != ""$(id -u ""${NB_USER}"")"" ] || [ ""${NB_GID}"" != ""$(id -g ""${NB_USER}"")"" ]; then
+        _log ""Update ${NB_USER}'s UID:GID to ${NB_UID}:${NB_GID}""
+        # Ensure the desired group's existence
+        if [ ""${NB_GID}"" != ""$(id -g ""${NB_USER}"")"" ]; then
+            groupadd --force --gid ""${NB_GID}"" --non-unique ""${NB_GROUP:-${NB_USER}}""
+        fi
+        # Recreate the desired user as we want it
+        userdel ""${NB_USER}""
+        useradd --home ""/home/${NB_USER}"" --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 --no-log-init ""${NB_USER}""
+    fi
+
+    # Move or symlink the jovyan home directory to the desired users home
+    # directory if it doesn't already exist, and update the current working
+    # directory to the new location if needed.
+    if [[ ""${NB_USER}"" != ""jovyan"" ]]; then
+        if [[ ! -e ""/home/${NB_USER}"" ]]; then
+            _log ""Attempting to copy /home/jovyan to /home/${NB_USER}...""
+            mkdir ""/home/${NB_USER}""
+            if cp -a /home/jovyan/. ""/home/${NB_USER}/""; then
+                _log ""Success!""
+            else
+                _log ""Failed to copy data from /home/jovyan to /home/${NB_USER}!""
+                _log ""Attempting to symlink /home/jovyan to /home/${NB_USER}...""
+                if ln -s /home/jovyan ""/home/${NB_USER}""; then
+                    _log ""Success creating symlink!""
+                else
+                    _log ""ERROR: Failed copy data from /home/jovyan to /home/${NB_USER} or to create symlink!""
+                    exit 1
+                fi
+            fi
+        fi
+        # Ensure the current working directory is updated to the new path
+        if [[ ""${PWD}/"" == ""/home/jovyan/""* ]]; then
+            new_wd=""/home/${NB_USER}/${PWD:13}""
+            _log ""Changing working directory to ${new_wd}""
+            cd ""${new_wd}""
+        fi
+    fi
+
+    # Optionally ensure the desired user get filesystem ownership of it's home
+    # folder and/or additional folders
+    if [[ ""${CHOWN_HOME}"" == ""1"" || ""${CHOWN_HOME}"" == ""yes"" ]]; then
+        _log ""Ensuring /home/${NB_USER} is owned by ${NB_UID}:${NB_GID} ${CHOWN_HOME_OPTS:+(chown options: ${CHOWN_HOME_OPTS})}""
+        # shellcheck disable=SC2086
+        chown ${CHOWN_HOME_OPTS} ""${NB_UID}:${NB_GID}"" ""/home/${NB_USER}""
+    fi
+    if [ -n ""${CHOWN_EXTRA}"" ]; then
+        for extra_dir in $(echo ""${CHOWN_EXTRA}"" | tr ',' ' '); do
+            _log ""Ensuring ${extra_dir} is owned by ${NB_UID}:${NB_GID} ${CHOWN_EXTRA_OPTS:+(chown options: ${CHOWN_EXTRA_OPTS})}""
+            # shellcheck disable=SC2086
+            chown ${CHOWN_EXTRA_OPTS} ""${NB_UID}:${NB_GID}"" ""${extra_dir}""
+        done
+    fi
+
+    # Update potentially outdated environment variables since image build
+    export XDG_CACHE_HOME=""/home/${NB_USER}/.cache""
+
+    # Prepend ${CONDA_DIR}/bin to sudo secure_path
+    sed -r ""s#Defaults\s+secure_path\s*=\s*\""?([^\""]+)\""?#Defaults secure_path=\""${CONDA_DIR}/bin:\1\""#"" /etc/sudoers | grep secure_path > /etc/sudoers.d/path
+
+    # Optionally grant passwordless sudo rights for the desired user
+    if [[ ""$GRANT_SUDO"" == ""1"" || ""$GRANT_SUDO"" == ""yes"" ]]; then
+        _log ""Granting ${NB_USER} passwordless sudo rights!""
+        echo ""${NB_USER} ALL=(ALL) NOPASSWD:ALL"" >> /etc/sudoers.d/added-by-start-script
+    fi
+
+    # NOTE: This hook is run as the root user!
+    run-hooks /usr/local/bin/before-notebook.d
+
+    unset_explicit_env_vars
+    _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
+    exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
+        PATH=""${PATH}"" \
+        PYTHONPATH=""${PYTHONPATH:-}"" \
+        ""${cmd[@]}""
+        # Notes on how we ensure that the environment that this container is started
+        # with is preserved (except vars listed in JUPYTER_ENV_VARS_TO_UNSET) when
+        # we transition from running as root to running as NB_USER.
+        #
+        # - We use `sudo` to execute the command as NB_USER. What then
+        #   happens to the environment will be determined by configuration in
+        #   /etc/sudoers and /etc/sudoers.d/* as well as flags we pass to the sudo
+        #   command. The behavior can be inspected with `sudo -V` run as root.
+        #
+        #   ref: `man sudo`    https://linux.die.net/man/8/sudo
+        #   ref: `man sudoers` https://www.sudo.ws/man/1.8.15/sudoers.man.html
+        #
+        # - We use the `--preserve-env` flag to pass through most environment
+        #   variables, but understand that exceptions are caused by the sudoers
+        #   configuration: `env_delete` and `env_check`.
+        #
+        # - We use the `--set-home` flag to set the HOME variable appropriately.
+        #
+        # - To reduce the default list of variables deleted by sudo, we could have
+        #   used `env_delete` from /etc/sudoers. It has higher priority than the
+        #   `--preserve-env` flag and the `env_keep` configuration.
+        #
+        # - We preserve PATH and PYTHONPATH explicitly. Note however that sudo
+        #   resolves `${cmd[@]}` using the ""secure_path"" variable we modified
+        #   above in /etc/sudoers.d/path. Thus PATH is irrelevant to how the above
+        #   sudo command resolves the path of `${cmd[@]}`. The PATH will be relevant
+        #   for resolving paths of any subprocesses spawned by `${cmd[@]}`.
+
+# The container didn't start as the root user, so we will have to act as the
+# user we started as.
+else
+    # Warn about misconfiguration of: granting sudo rights
+    if [[ ""${GRANT_SUDO}"" == ""1"" || ""${GRANT_SUDO}"" == ""yes"" ]]; then
+        _log ""WARNING: container must be started as root to grant sudo permissions!""
+    fi
+
+    JOVYAN_UID=""$(id -u jovyan 2>/dev/null)""  # The default UID for the jovyan user
+    JOVYAN_GID=""$(id -g jovyan 2>/dev/null)""  # The default GID for the jovyan user
+
+    # Attempt to ensure the user uid we currently run as has a named entry in
+    # the /etc/passwd file, as it avoids software crashing on hard assumptions
+    # on such entry. Writing to the /etc/passwd was allowed for the root group
+    # from the Dockerfile during build.
+    #
+    # ref: https://github.com/jupyter/docker-stacks/issues/552
+    if ! whoami &> /dev/null; then
+        _log ""There is no entry in /etc/passwd for our UID=$(id -u). Attempting to fix...""
+        if [[ -w /etc/passwd ]]; then
+            _log ""Renaming old jovyan user to nayvoj ($(id -u jovyan):$(id -g jovyan))""
+
+            # We cannot use ""sed --in-place"" since sed tries to create a temp file in
+            # /etc/ and we may not have write access. Apply sed on our own temp file:
+            sed --expression=""s/^jovyan:/nayvoj:/"" /etc/passwd > /tmp/passwd
+            echo ""${NB_USER}:x:$(id -u):$(id -g):,,,:/home/jovyan:/bin/bash"" >> /tmp/passwd
+            cat /tmp/passwd > /etc/passwd
+            rm /tmp/passwd
+
+            _log ""Added new ${NB_USER} user ($(id -u):$(id -g)). Fixed UID!""
+
+            if [[ ""${NB_USER}"" != ""jovyan"" ]]; then
+                _log ""WARNING: user is ${NB_USER} but home is /home/jovyan. You must run as root to rename the home directory!""
+            fi
+        else
+            _log ""WARNING: unable to fix missing /etc/passwd entry because we don't have write permission. Try setting gid=0 with \""--user=$(id -u):0\"".""
+        fi
+    fi
+
+    # Warn about misconfiguration of: desired username, user id, or group id.
+    # A misconfiguration occurs when the user modifies the default values of
+    # NB_USER, NB_UID, or NB_GID, but we cannot update those values because we
+    # are not root.
+    if [[ ""${NB_USER}"" != ""jovyan"" && ""${NB_USER}"" != ""$(id -un)"" ]]; then
+        _log ""WARNING: container must be started as root to change the desired user's name with NB_USER=\""${NB_USER}\""!""
+    fi
+    if [[ ""${NB_UID}"" != ""${JOVYAN_UID}"" && ""${NB_UID}"" != ""$(id -u)"" ]]; then
+        _log ""WARNING: container must be started as root to change the desired user's id with NB_UID=\""${NB_UID}\""!""
+    fi
+    if [[ ""${NB_GID}"" != ""${JOVYAN_GID}"" && ""${NB_GID}"" != ""$(id -g)"" ]]; then
+        _log ""WARNING: container must be started as root to change the desired user's group id with NB_GID=\""${NB_GID}\""!""
+    fi
+
+    # Warn if the user isn't able to write files to ${HOME}
+    if [[ ! -w /home/jovyan ]]; then
+        _log ""WARNING: no write access to /home/jovyan. Try starting the container with group 'users' (100), e.g. using \""--group-add=users\"".""
+    fi
+
+    # NOTE: This hook is run as the user we started the container as!
+    run-hooks /usr/local/bin/before-notebook.d
+    unset_explicit_env_vars
+    _log ""Executing the command:"" ""${cmd[@]}""
+    exec ""${cmd[@]}""
+fi","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
new file mode 100755
index 00000000..7c5859ee
--- /dev/null
+++ b/images/docker-stacks-foundation/start.sh
@@ -0,0 +1,262 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+# The _log function is used for everything this script wants to log. It will
+# always log errors and warnings, but can be silenced for other messages
+# by setting JUPYTER_DOCKER_STACKS_QUIET environment variable.
+_log () {
+    if [[ ""$*"" == ""ERROR:""* ]] || [[ ""$*"" == ""WARNING:""* ]] || [[ ""${JUPYTER_DOCKER_STACKS_QUIET}"" == """" ]]; then
+        echo ""$@""
+    fi
+}
+_log ""Entered start.sh with args:"" ""$@""
+
+# The run-hooks function looks for .sh scripts to source and executable files to
+# run within a passed directory.
+run-hooks () {
+    if [[ ! -d ""${1}"" ]] ; then
+        return
+    fi
+    _log ""${0}: running hooks in ${1} as uid / gid: $(id -u) / $(id -g)""
+    for f in ""${1}/""*; do
+        case ""${f}"" in
+            *.sh)
+                _log ""${0}: running script ${f}""
+                # shellcheck disable=SC1090
+                source ""${f}""
+                ;;
+            *)
+                if [[ -x ""${f}"" ]] ; then
+                    _log ""${0}: running executable ${f}""
+                    ""${f}""
+                else
+                    _log ""${0}: ignoring non-executable ${f}""
+                fi
+                ;;
+        esac
+    done
+    _log ""${0}: done running hooks in ${1}""
+}
+
+# A helper function to unset env vars listed in the value of the env var
+# JUPYTER_ENV_VARS_TO_UNSET.
+unset_explicit_env_vars () {
+    if [ -n ""${JUPYTER_ENV_VARS_TO_UNSET}"" ]; then
+        for env_var_to_unset in $(echo ""${JUPYTER_ENV_VARS_TO_UNSET}"" | tr ',' ' '); do
+            echo ""Unset ${env_var_to_unset} due to JUPYTER_ENV_VARS_TO_UNSET""
+            unset ""${env_var_to_unset}""
+        done
+        unset JUPYTER_ENV_VARS_TO_UNSET
+    fi
+}
+
+
+# Default to starting bash if no command was specified
+if [ $# -eq 0 ]; then
+    cmd=( ""bash"" )
+else
+    cmd=( ""$@"" )
+fi
+
+# NOTE: This hook will run as the user the container was started with!
+run-hooks /usr/local/bin/start-notebook.d
+
+# If the container started as the root user, then we have permission to refit
+# the jovyan user, and ensure file permissions, grant sudo rights, and such
+# things before we run the command passed to start.sh as the desired user
+# (NB_USER).
+#
+if [ ""$(id -u)"" == 0 ] ; then
+    # Environment variables:
+    # - NB_USER: the desired username and associated home folder
+    # - NB_UID: the desired user id
+    # - NB_GID: a group id we want our user to belong to
+    # - NB_GROUP: a group name we want for the group
+    # - GRANT_SUDO: a boolean (""1"" or ""yes"") to grant the user sudo rights
+    # - CHOWN_HOME: a boolean (""1"" or ""yes"") to chown the user's home folder
+    # - CHOWN_EXTRA: a comma separated list of paths to chown
+    # - CHOWN_HOME_OPTS / CHOWN_EXTRA_OPTS: arguments to the chown commands
+
+    # Refit the jovyan user to the desired the user (NB_USER)
+    if id jovyan &> /dev/null ; then
+        if ! usermod --home ""/home/${NB_USER}"" --login ""${NB_USER}"" jovyan 2>&1 | grep ""no changes"" > /dev/null; then
+            _log ""Updated the jovyan user:""
+            _log ""- username: jovyan       -> ${NB_USER}""
+            _log ""- home dir: /home/jovyan -> /home/${NB_USER}""
+        fi
+    elif ! id -u ""${NB_USER}"" &> /dev/null; then
+        _log ""ERROR: Neither the jovyan user or '${NB_USER}' exists. This could be the result of stopping and starting, the container with a different NB_USER environment variable.""
+        exit 1
+    fi
+    # Ensure the desired user (NB_USER) gets its desired user id (NB_UID) and is
+    # a member of the desired group (NB_GROUP, NB_GID)
+    if [ ""${NB_UID}"" != ""$(id -u ""${NB_USER}"")"" ] || [ ""${NB_GID}"" != ""$(id -g ""${NB_USER}"")"" ]; then
+        _log ""Update ${NB_USER}'s UID:GID to ${NB_UID}:${NB_GID}""
+        # Ensure the desired group's existence
+        if [ ""${NB_GID}"" != ""$(id -g ""${NB_USER}"")"" ]; then
+            groupadd --force --gid ""${NB_GID}"" --non-unique ""${NB_GROUP:-${NB_USER}}""
+        fi
+        # Recreate the desired user as we want it
+        userdel ""${NB_USER}""
+        useradd --home ""/home/${NB_USER}"" --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 --no-log-init ""${NB_USER}""
+    fi
+
+    # Move or symlink the jovyan home directory to the desired users home
+    # directory if it doesn't already exist, and update the current working
+    # directory to the new location if needed.
+    if [[ ""${NB_USER}"" != ""jovyan"" ]]; then
+        if [[ ! -e ""/home/${NB_USER}"" ]]; then
+            _log ""Attempting to copy /home/jovyan to /home/${NB_USER}...""
+            mkdir ""/home/${NB_USER}""
+            if cp -a /home/jovyan/. ""/home/${NB_USER}/""; then
+                _log ""Success!""
+            else
+                _log ""Failed to copy data from /home/jovyan to /home/${NB_USER}!""
+                _log ""Attempting to symlink /home/jovyan to /home/${NB_USER}...""
+                if ln -s /home/jovyan ""/home/${NB_USER}""; then
+                    _log ""Success creating symlink!""
+                else
+                    _log ""ERROR: Failed copy data from /home/jovyan to /home/${NB_USER} or to create symlink!""
+                    exit 1
+                fi
+            fi
+        fi
+        # Ensure the current working directory is updated to the new path
+        if [[ ""${PWD}/"" == ""/home/jovyan/""* ]]; then
+            new_wd=""/home/${NB_USER}/${PWD:13}""
+            _log ""Changing working directory to ${new_wd}""
+            cd ""${new_wd}""
+        fi
+    fi
+
+    # Optionally ensure the desired user get filesystem ownership of it's home
+    # folder and/or additional folders
+    if [[ ""${CHOWN_HOME}"" == ""1"" || ""${CHOWN_HOME}"" == ""yes"" ]]; then
+        _log ""Ensuring /home/${NB_USER} is owned by ${NB_UID}:${NB_GID} ${CHOWN_HOME_OPTS:+(chown options: ${CHOWN_HOME_OPTS})}""
+        # shellcheck disable=SC2086
+        chown ${CHOWN_HOME_OPTS} ""${NB_UID}:${NB_GID}"" ""/home/${NB_USER}""
+    fi
+    if [ -n ""${CHOWN_EXTRA}"" ]; then
+        for extra_dir in $(echo ""${CHOWN_EXTRA}"" | tr ',' ' '); do
+            _log ""Ensuring ${extra_dir} is owned by ${NB_UID}:${NB_GID} ${CHOWN_EXTRA_OPTS:+(chown options: ${CHOWN_EXTRA_OPTS})}""
+            # shellcheck disable=SC2086
+            chown ${CHOWN_EXTRA_OPTS} ""${NB_UID}:${NB_GID}"" ""${extra_dir}""
+        done
+    fi
+
+    # Update potentially outdated environment variables since image build
+    export XDG_CACHE_HOME=""/home/${NB_USER}/.cache""
+
+    # Prepend ${CONDA_DIR}/bin to sudo secure_path
+    sed -r ""s#Defaults\s+secure_path\s*=\s*\""?([^\""]+)\""?#Defaults secure_path=\""${CONDA_DIR}/bin:\1\""#"" /etc/sudoers | grep secure_path > /etc/sudoers.d/path
+
+    # Optionally grant passwordless sudo rights for the desired user
+    if [[ ""$GRANT_SUDO"" == ""1"" || ""$GRANT_SUDO"" == ""yes"" ]]; then
+        _log ""Granting ${NB_USER} passwordless sudo rights!""
+        echo ""${NB_USER} ALL=(ALL) NOPASSWD:ALL"" >> /etc/sudoers.d/added-by-start-script
+    fi
+
+    # NOTE: This hook is run as the root user!
+    run-hooks /usr/local/bin/before-notebook.d
+
+    unset_explicit_env_vars
+    _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
+    exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
+        PATH=""${PATH}"" \
+        PYTHONPATH=""${PYTHONPATH:-}"" \
+        ""${cmd[@]}""
+        # Notes on how we ensure that the environment that this container is started
+        # with is preserved (except vars listed in JUPYTER_ENV_VARS_TO_UNSET) when
+        # we transition from running as root to running as NB_USER.
+        #
+        # - We use `sudo` to execute the command as NB_USER. What then
+        #   happens to the environment will be determined by configuration in
+        #   /etc/sudoers and /etc/sudoers.d/* as well as flags we pass to the sudo
+        #   command. The behavior can be inspected with `sudo -V` run as root.
+        #
+        #   ref: `man sudo`    https://linux.die.net/man/8/sudo
+        #   ref: `man sudoers` https://www.sudo.ws/man/1.8.15/sudoers.man.html
+        #
+        # - We use the `--preserve-env` flag to pass through most environment
+        #   variables, but understand that exceptions are caused by the sudoers
+        #   configuration: `env_delete` and `env_check`.
+        #
+        # - We use the `--set-home` flag to set the HOME variable appropriately.
+        #
+        # - To reduce the default list of variables deleted by sudo, we could have
+        #   used `env_delete` from /etc/sudoers. It has higher priority than the
+        #   `--preserve-env` flag and the `env_keep` configuration.
+        #
+        # - We preserve PATH and PYTHONPATH explicitly. Note however that sudo
+        #   resolves `${cmd[@]}` using the ""secure_path"" variable we modified
+        #   above in /etc/sudoers.d/path. Thus PATH is irrelevant to how the above
+        #   sudo command resolves the path of `${cmd[@]}`. The PATH will be relevant
+        #   for resolving paths of any subprocesses spawned by `${cmd[@]}`.
+
+# The container didn't start as the root user, so we will have to act as the
+# user we started as.
+else
+    # Warn about misconfiguration of: granting sudo rights
+    if [[ ""${GRANT_SUDO}"" == ""1"" || ""${GRANT_SUDO}"" == ""yes"" ]]; then
+        _log ""WARNING: container must be started as root to grant sudo permissions!""
+    fi
+
+    JOVYAN_UID=""$(id -u jovyan 2>/dev/null)""  # The default UID for the jovyan user
+    JOVYAN_GID=""$(id -g jovyan 2>/dev/null)""  # The default GID for the jovyan user
+
+    # Attempt to ensure the user uid we currently run as has a named entry in
+    # the /etc/passwd file, as it avoids software crashing on hard assumptions
+    # on such entry. Writing to the /etc/passwd was allowed for the root group
+    # from the Dockerfile during build.
+    #
+    # ref: https://github.com/jupyter/docker-stacks/issues/552
+    if ! whoami &> /dev/null; then
+        _log ""There is no entry in /etc/passwd for our UID=$(id -u). Attempting to fix...""
+        if [[ -w /etc/passwd ]]; then
+            _log ""Renaming old jovyan user to nayvoj ($(id -u jovyan):$(id -g jovyan))""
+
+            # We cannot use ""sed --in-place"" since sed tries to create a temp file in
+            # /etc/ and we may not have write access. Apply sed on our own temp file:
+            sed --expression=""s/^jovyan:/nayvoj:/"" /etc/passwd > /tmp/passwd
+            echo ""${NB_USER}:x:$(id -u):$(id -g):,,,:/home/jovyan:/bin/bash"" >> /tmp/passwd
+            cat /tmp/passwd > /etc/passwd
+            rm /tmp/passwd
+
+            _log ""Added new ${NB_USER} user ($(id -u):$(id -g)). Fixed UID!""
+
+            if [[ ""${NB_USER}"" != ""jovyan"" ]]; then
+                _log ""WARNING: user is ${NB_USER} but home is /home/jovyan. You must run as root to rename the home directory!""
+            fi
+        else
+            _log ""WARNING: unable to fix missing /etc/passwd entry because we don't have write permission. Try setting gid=0 with \""--user=$(id -u):0\"".""
+        fi
+    fi
+
+    # Warn about misconfiguration of: desired username, user id, or group id.
+    # A misconfiguration occurs when the user modifies the default values of
+    # NB_USER, NB_UID, or NB_GID, but we cannot update those values because we
+    # are not root.
+    if [[ ""${NB_USER}"" != ""jovyan"" && ""${NB_USER}"" != ""$(id -un)"" ]]; then
+        _log ""WARNING: container must be started as root to change the desired user's name with NB_USER=\""${NB_USER}\""!""
+    fi
+    if [[ ""${NB_UID}"" != ""${JOVYAN_UID}"" && ""${NB_UID}"" != ""$(id -u)"" ]]; then
+        _log ""WARNING: container must be started as root to change the desired user's id with NB_UID=\""${NB_UID}\""!""
+    fi
+    if [[ ""${NB_GID}"" != ""${JOVYAN_GID}"" && ""${NB_GID}"" != ""$(id -g)"" ]]; then
+        _log ""WARNING: container must be started as root to change the desired user's group id with NB_GID=\""${NB_GID}\""!""
+    fi
+
+    # Warn if the user isn't able to write files to ${HOME}
+    if [[ ! -w /home/jovyan ]]; then
+        _log ""WARNING: no write access to /home/jovyan. Try starting the container with group 'users' (100), e.g. using \""--group-add=users\"".""
+    fi
+
+    # NOTE: This hook is run as the user we started the container as!
+    run-hooks /usr/local/bin/before-notebook.d
+    unset_explicit_env_vars
+    _log ""Executing the command:"" ""${cmd[@]}""
+    exec ""${cmd[@]}""
+fi",Yes
julia-notebook/.dockerignore,images/julia-notebook/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/julia-notebook/.dockerignore b/images/julia-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/julia-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/julia-notebook/.dockerignore b/images/julia-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/julia-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
julia-notebook/Dockerfile,images/julia-notebook/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
new file mode 100644
index 00000000..cee9aa99
--- /dev/null
+++ b/images/julia-notebook/Dockerfile
@@ -0,0 +1,26 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/minimal-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Julia dependencies
+# install Julia packages in /opt/julia instead of ${HOME}
+ENV JULIA_DEPOT_PATH=/opt/julia \
+    JULIA_PKGDIR=/opt/julia
+
+# Setup Julia
+RUN /opt/setup-scripts/setup-julia.bash
+
+USER ${NB_UID}
+
+# Setup IJulia kernel & other packages
+RUN /opt/setup-scripts/setup-julia-packages.bash","diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
new file mode 100644
index 00000000..cee9aa99
--- /dev/null
+++ b/images/julia-notebook/Dockerfile
@@ -0,0 +1,26 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/minimal-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Julia dependencies
+# install Julia packages in /opt/julia instead of ${HOME}
+ENV JULIA_DEPOT_PATH=/opt/julia \
+    JULIA_PKGDIR=/opt/julia
+
+# Setup Julia
+RUN /opt/setup-scripts/setup-julia.bash
+
+USER ${NB_UID}
+
+# Setup IJulia kernel & other packages
+RUN /opt/setup-scripts/setup-julia-packages.bash",Yes
julia-notebook/README.md,images/julia-notebook/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/julia-notebook/README.md b/images/julia-notebook/README.md
new file mode 100644
index 00000000..dfca913b
--- /dev/null
+++ b/images/julia-notebook/README.md
@@ -0,0 +1,12 @@
+# Jupyter Notebook Julia Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/julia-notebook/latest)](https://hub.docker.com/r/jupyter/julia-notebook/ ""jupyter/julia-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/julia-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-julia-notebook)","diff --git a/images/julia-notebook/README.md b/images/julia-notebook/README.md
new file mode 100644
index 00000000..dfca913b
--- /dev/null
+++ b/images/julia-notebook/README.md
@@ -0,0 +1,12 @@
+# Jupyter Notebook Julia Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/julia-notebook/latest)](https://hub.docker.com/r/jupyter/julia-notebook/ ""jupyter/julia-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/julia-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-julia-notebook)",Yes
minimal-notebook/.dockerignore,images/minimal-notebook/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/minimal-notebook/.dockerignore b/images/minimal-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/minimal-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/minimal-notebook/.dockerignore b/images/minimal-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/minimal-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
minimal-notebook/Dockerfile,images/minimal-notebook/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
new file mode 100644
index 00000000..6511304d
--- /dev/null
+++ b/images/minimal-notebook/Dockerfile
@@ -0,0 +1,49 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/base-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Install all OS dependencies for fully functional Server
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    # Common useful utilities
+    curl \
+    git \
+    nano-tiny \
+    tzdata \
+    unzip \
+    vim-tiny \
+    # git-over-ssh
+    openssh-client \
+    # less is needed to run help in R
+    # see: https://github.com/jupyter/docker-stacks/issues/1588
+    less \
+    # nbconvert dependencies
+    # https://nbconvert.readthedocs.io/en/latest/install.html#installing-tex
+    texlive-xetex \
+    texlive-fonts-recommended \
+    texlive-plain-generic \
+    # Enable clipboard on Linux host systems
+    xclip && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+# Create alternative for nano -> nano-tiny
+RUN update-alternatives --install /usr/bin/nano nano /bin/nano-tiny 10
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ${NB_UID}
+
+# Add R mimetype option to specify how the plot returns from R to the browser
+COPY --chown=${NB_UID}:${NB_GID} Rprofile.site /opt/conda/lib/R/etc/
+
+# Add setup scripts that may be used by downstream images or inherited images
+COPY setup-scripts/ /opt/setup-scripts/","diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
new file mode 100644
index 00000000..6511304d
--- /dev/null
+++ b/images/minimal-notebook/Dockerfile
@@ -0,0 +1,49 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/base-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Install all OS dependencies for fully functional Server
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    # Common useful utilities
+    curl \
+    git \
+    nano-tiny \
+    tzdata \
+    unzip \
+    vim-tiny \
+    # git-over-ssh
+    openssh-client \
+    # less is needed to run help in R
+    # see: https://github.com/jupyter/docker-stacks/issues/1588
+    less \
+    # nbconvert dependencies
+    # https://nbconvert.readthedocs.io/en/latest/install.html#installing-tex
+    texlive-xetex \
+    texlive-fonts-recommended \
+    texlive-plain-generic \
+    # Enable clipboard on Linux host systems
+    xclip && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+# Create alternative for nano -> nano-tiny
+RUN update-alternatives --install /usr/bin/nano nano /bin/nano-tiny 10
+
+# Switch back to jovyan to avoid accidental container runs as root
+USER ${NB_UID}
+
+# Add R mimetype option to specify how the plot returns from R to the browser
+COPY --chown=${NB_UID}:${NB_GID} Rprofile.site /opt/conda/lib/R/etc/
+
+# Add setup scripts that may be used by downstream images or inherited images
+COPY setup-scripts/ /opt/setup-scripts/",Yes
minimal-notebook/README.md,images/minimal-notebook/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/minimal-notebook/README.md b/images/minimal-notebook/README.md
new file mode 100644
index 00000000..40697fa1
--- /dev/null
+++ b/images/minimal-notebook/README.md
@@ -0,0 +1,12 @@
+# Minimal Jupyter Notebook Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/minimal-notebook/latest)](https://hub.docker.com/r/jupyter/minimal-notebook/ ""jupyter/minimal-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/minimal-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-minimal-notebook)","diff --git a/images/minimal-notebook/README.md b/images/minimal-notebook/README.md
new file mode 100644
index 00000000..40697fa1
--- /dev/null
+++ b/images/minimal-notebook/README.md
@@ -0,0 +1,12 @@
+# Minimal Jupyter Notebook Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/minimal-notebook/latest)](https://hub.docker.com/r/jupyter/minimal-notebook/ ""jupyter/minimal-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/minimal-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-minimal-notebook)",Yes
minimal-notebook/Rprofile.site,images/minimal-notebook/Rprofile.site,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/minimal-notebook/Rprofile.site b/images/minimal-notebook/Rprofile.site
new file mode 100644
index 00000000..3d6a93cc
--- /dev/null
+++ b/images/minimal-notebook/Rprofile.site
@@ -0,0 +1,4 @@
+# Add R mimetype to specify how the plot returns from R to the browser.
+# https://notebook.community/andrie/jupyter-notebook-samples/Changing%20R%20plot%20options%20in%20Jupyter
+
+options(jupyter.plot_mimetypes = c('text/plain', 'image/png', 'image/jpeg', 'image/svg+xml', 'application/pdf'))","diff --git a/images/minimal-notebook/Rprofile.site b/images/minimal-notebook/Rprofile.site
new file mode 100644
index 00000000..3d6a93cc
--- /dev/null
+++ b/images/minimal-notebook/Rprofile.site
@@ -0,0 +1,4 @@
+# Add R mimetype to specify how the plot returns from R to the browser.
+# https://notebook.community/andrie/jupyter-notebook-samples/Changing%20R%20plot%20options%20in%20Jupyter
+
+options(jupyter.plot_mimetypes = c('text/plain', 'image/png', 'image/jpeg', 'image/svg+xml', 'application/pdf'))",Yes
minimal-notebook/setup-scripts/setup-julia-packages.bash,images/minimal-notebook/setup-scripts/setup-julia-packages.bash,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
new file mode 100755
index 00000000..7cc0a45f
--- /dev/null
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -0,0 +1,33 @@
+#!/bin/bash
+set -exuo pipefail
+# Requirements:
+# - Run as non-root user
+# - The JULIA_PKGDIR environment variable is set
+# - Julia is already set up, with the setup-julia.bash command
+
+# Install base Julia packages
+julia -e '
+import Pkg;
+Pkg.update();
+Pkg.add([
+    ""HDF5"",
+    ""IJulia"",
+    ""Pluto""
+]);
+Pkg.precompile();
+'
+
+# Move the kernelspec out of ${HOME} to the system share location.
+# Avoids problems with runtime UID change not taking effect properly
+# on the .local folder in the jovyan home dir.
+mv ""${HOME}/.local/share/jupyter/kernels/julia""* ""${CONDA_DIR}/share/jupyter/kernels/""
+chmod -R go+rx ""${CONDA_DIR}/share/jupyter""
+rm -rf ""${HOME}/.local""
+fix-permissions ""${JULIA_PKGDIR}"" ""${CONDA_DIR}/share/jupyter""
+
+# Install jupyter-pluto-proxy to get Pluto to work on JupyterHub
+mamba install --yes \
+    'jupyter-pluto-proxy' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
new file mode 100755
index 00000000..7cc0a45f
--- /dev/null
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -0,0 +1,33 @@
+#!/bin/bash
+set -exuo pipefail
+# Requirements:
+# - Run as non-root user
+# - The JULIA_PKGDIR environment variable is set
+# - Julia is already set up, with the setup-julia.bash command
+
+# Install base Julia packages
+julia -e '
+import Pkg;
+Pkg.update();
+Pkg.add([
+    ""HDF5"",
+    ""IJulia"",
+    ""Pluto""
+]);
+Pkg.precompile();
+'
+
+# Move the kernelspec out of ${HOME} to the system share location.
+# Avoids problems with runtime UID change not taking effect properly
+# on the .local folder in the jovyan home dir.
+mv ""${HOME}/.local/share/jupyter/kernels/julia""* ""${CONDA_DIR}/share/jupyter/kernels/""
+chmod -R go+rx ""${CONDA_DIR}/share/jupyter""
+rm -rf ""${HOME}/.local""
+fix-permissions ""${JULIA_PKGDIR}"" ""${CONDA_DIR}/share/jupyter""
+
+# Install jupyter-pluto-proxy to get Pluto to work on JupyterHub
+mamba install --yes \
+    'jupyter-pluto-proxy' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
minimal-notebook/setup-scripts/setup-julia.bash,images/minimal-notebook/setup-scripts/setup-julia.bash,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/minimal-notebook/setup-scripts/setup-julia.bash b/images/minimal-notebook/setup-scripts/setup-julia.bash
new file mode 100755
index 00000000..d8782042
--- /dev/null
+++ b/images/minimal-notebook/setup-scripts/setup-julia.bash
@@ -0,0 +1,40 @@
+#!/bin/bash
+set -exuo pipefail
+# Requirements:
+# - Run as the root user
+# - The JULIA_PKGDIR environment variable is set
+
+# Default julia version to install if env var is not set
+# Check https://julialang.org/downloads/
+JULIA_VERSION=""${JULIA_VERSION:-1.9.2}""
+
+# Figure out what architecture we are installing in
+JULIA_ARCH=$(uname -m)
+JULIA_SHORT_ARCH=""${JULIA_ARCH}""
+if [ ""${JULIA_SHORT_ARCH}"" == ""x86_64"" ]; then
+    JULIA_SHORT_ARCH=""x64""
+fi
+
+# Figure out Julia Installer URL
+JULIA_INSTALLER=""julia-${JULIA_VERSION}-linux-${JULIA_ARCH}.tar.gz""
+JULIA_MAJOR_MINOR=$(echo ""${JULIA_VERSION}"" | cut -d. -f 1,2)
+
+# Download and install Julia
+cd /tmp
+mkdir ""/opt/julia-${JULIA_VERSION}""
+curl --progress-bar --location --output ""${JULIA_INSTALLER}"" \
+    ""https://julialang-s3.julialang.org/bin/linux/${JULIA_SHORT_ARCH}/${JULIA_MAJOR_MINOR}/${JULIA_INSTALLER}""
+tar xzf ""${JULIA_INSTALLER}"" -C ""/opt/julia-${JULIA_VERSION}"" --strip-components=1
+rm ""${JULIA_INSTALLER}""
+
+# Link Julia installed version to /usr/local/bin, so julia launches it
+ln -fs /opt/julia-*/bin/julia /usr/local/bin/julia
+
+# Tell Julia where conda libraries are
+mkdir -p /etc/julia
+echo ""push!(Libdl.DL_LOAD_PATH, \""${CONDA_DIR}/lib\"")"" >> /etc/julia/juliarc.jl
+
+# Create JULIA_PKGDIR, where user libraries are installed
+mkdir ""${JULIA_PKGDIR}""
+chown ""${NB_USER}"" ""${JULIA_PKGDIR}""
+fix-permissions ""${JULIA_PKGDIR}""","diff --git a/images/minimal-notebook/setup-scripts/setup-julia.bash b/images/minimal-notebook/setup-scripts/setup-julia.bash
new file mode 100755
index 00000000..d8782042
--- /dev/null
+++ b/images/minimal-notebook/setup-scripts/setup-julia.bash
@@ -0,0 +1,40 @@
+#!/bin/bash
+set -exuo pipefail
+# Requirements:
+# - Run as the root user
+# - The JULIA_PKGDIR environment variable is set
+
+# Default julia version to install if env var is not set
+# Check https://julialang.org/downloads/
+JULIA_VERSION=""${JULIA_VERSION:-1.9.2}""
+
+# Figure out what architecture we are installing in
+JULIA_ARCH=$(uname -m)
+JULIA_SHORT_ARCH=""${JULIA_ARCH}""
+if [ ""${JULIA_SHORT_ARCH}"" == ""x86_64"" ]; then
+    JULIA_SHORT_ARCH=""x64""
+fi
+
+# Figure out Julia Installer URL
+JULIA_INSTALLER=""julia-${JULIA_VERSION}-linux-${JULIA_ARCH}.tar.gz""
+JULIA_MAJOR_MINOR=$(echo ""${JULIA_VERSION}"" | cut -d. -f 1,2)
+
+# Download and install Julia
+cd /tmp
+mkdir ""/opt/julia-${JULIA_VERSION}""
+curl --progress-bar --location --output ""${JULIA_INSTALLER}"" \
+    ""https://julialang-s3.julialang.org/bin/linux/${JULIA_SHORT_ARCH}/${JULIA_MAJOR_MINOR}/${JULIA_INSTALLER}""
+tar xzf ""${JULIA_INSTALLER}"" -C ""/opt/julia-${JULIA_VERSION}"" --strip-components=1
+rm ""${JULIA_INSTALLER}""
+
+# Link Julia installed version to /usr/local/bin, so julia launches it
+ln -fs /opt/julia-*/bin/julia /usr/local/bin/julia
+
+# Tell Julia where conda libraries are
+mkdir -p /etc/julia
+echo ""push!(Libdl.DL_LOAD_PATH, \""${CONDA_DIR}/lib\"")"" >> /etc/julia/juliarc.jl
+
+# Create JULIA_PKGDIR, where user libraries are installed
+mkdir ""${JULIA_PKGDIR}""
+chown ""${NB_USER}"" ""${JULIA_PKGDIR}""
+fix-permissions ""${JULIA_PKGDIR}""",Yes
pyspark-notebook/.dockerignore,images/pyspark-notebook/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/pyspark-notebook/.dockerignore b/images/pyspark-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/pyspark-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/pyspark-notebook/.dockerignore b/images/pyspark-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/pyspark-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
new file mode 100644
index 00000000..cff30a8e
--- /dev/null
+++ b/images/pyspark-notebook/Dockerfile
@@ -0,0 +1,79 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Spark dependencies
+# Default values can be overridden at build time
+# (ARGS are in lower case to distinguish them from ENV)
+ARG spark_version=""3.4.1""
+ARG hadoop_version=""3""
+ARG scala_version
+ARG spark_checksum=""5a21295b4c3d1d3f8fc85375c711c7c23e3eeb3ec9ea91778f149d8d321e3905e2f44cf19c69a28df693cffd536f7316706c78932e7e148d224424150f18b2c5""
+ARG openjdk_version=""17""
+
+ENV APACHE_SPARK_VERSION=""${spark_version}"" \
+    HADOOP_VERSION=""${hadoop_version}""
+
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    ""openjdk-${openjdk_version}-jre-headless"" \
+    ca-certificates-java && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+# Spark installation
+WORKDIR /tmp
+
+# You need to use https://archive.apache.org/dist/ website if you want to download old Spark versions
+# But it seems to be slower, that's why we use recommended site for download
+RUN if [ -z ""${scala_version}"" ]; then \
+    curl --progress-bar --location --output ""spark.tgz"" \
+        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \
+  else \
+    curl --progress-bar --location --output ""spark.tgz"" \
+        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}.tgz""; \
+  fi && \
+  echo ""${spark_checksum} *spark.tgz"" | sha512sum -c - && \
+  tar xzf ""spark.tgz"" -C /usr/local --owner root --group root --no-same-owner && \
+  rm ""spark.tgz""
+
+# Configure Spark
+ENV SPARK_HOME=/usr/local/spark
+ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info"" \
+    PATH=""${PATH}:${SPARK_HOME}/bin""
+
+RUN if [ -z ""${scala_version}"" ]; then \
+    ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}"" ""${SPARK_HOME}""; \
+  else \
+    ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}"" ""${SPARK_HOME}""; \
+  fi && \
+  # Add a link in the before_notebook hook in order to source automatically PYTHONPATH && \
+  mkdir -p /usr/local/bin/before-notebook.d && \
+  ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/spark-config.sh
+
+# Configure IPython system-wide
+COPY ipython_kernel_config.py ""/etc/ipython/""
+RUN fix-permissions ""/etc/ipython/""
+
+USER ${NB_UID}
+
+# Install pyarrow
+# Temporarily pin pandas to version 1.5.3, see: https://github.com/jupyter/docker-stacks/issues/1924
+RUN mamba install --yes \
+    'pandas>=1.5.3,<2.0.0' \
+    'pyarrow' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+WORKDIR ""${HOME}""
+EXPOSE 4040","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
new file mode 100644
index 00000000..cff30a8e
--- /dev/null
+++ b/images/pyspark-notebook/Dockerfile
@@ -0,0 +1,79 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# Spark dependencies
+# Default values can be overridden at build time
+# (ARGS are in lower case to distinguish them from ENV)
+ARG spark_version=""3.4.1""
+ARG hadoop_version=""3""
+ARG scala_version
+ARG spark_checksum=""5a21295b4c3d1d3f8fc85375c711c7c23e3eeb3ec9ea91778f149d8d321e3905e2f44cf19c69a28df693cffd536f7316706c78932e7e148d224424150f18b2c5""
+ARG openjdk_version=""17""
+
+ENV APACHE_SPARK_VERSION=""${spark_version}"" \
+    HADOOP_VERSION=""${hadoop_version}""
+
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    ""openjdk-${openjdk_version}-jre-headless"" \
+    ca-certificates-java && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+# Spark installation
+WORKDIR /tmp
+
+# You need to use https://archive.apache.org/dist/ website if you want to download old Spark versions
+# But it seems to be slower, that's why we use recommended site for download
+RUN if [ -z ""${scala_version}"" ]; then \
+    curl --progress-bar --location --output ""spark.tgz"" \
+        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \
+  else \
+    curl --progress-bar --location --output ""spark.tgz"" \
+        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}.tgz""; \
+  fi && \
+  echo ""${spark_checksum} *spark.tgz"" | sha512sum -c - && \
+  tar xzf ""spark.tgz"" -C /usr/local --owner root --group root --no-same-owner && \
+  rm ""spark.tgz""
+
+# Configure Spark
+ENV SPARK_HOME=/usr/local/spark
+ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info"" \
+    PATH=""${PATH}:${SPARK_HOME}/bin""
+
+RUN if [ -z ""${scala_version}"" ]; then \
+    ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}"" ""${SPARK_HOME}""; \
+  else \
+    ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}"" ""${SPARK_HOME}""; \
+  fi && \
+  # Add a link in the before_notebook hook in order to source automatically PYTHONPATH && \
+  mkdir -p /usr/local/bin/before-notebook.d && \
+  ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/spark-config.sh
+
+# Configure IPython system-wide
+COPY ipython_kernel_config.py ""/etc/ipython/""
+RUN fix-permissions ""/etc/ipython/""
+
+USER ${NB_UID}
+
+# Install pyarrow
+# Temporarily pin pandas to version 1.5.3, see: https://github.com/jupyter/docker-stacks/issues/1924
+RUN mamba install --yes \
+    'pandas>=1.5.3,<2.0.0' \
+    'pyarrow' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+WORKDIR ""${HOME}""
+EXPOSE 4040",Yes
pyspark-notebook/README.md,images/pyspark-notebook/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/pyspark-notebook/README.md b/images/pyspark-notebook/README.md
new file mode 100644
index 00000000..1be04343
--- /dev/null
+++ b/images/pyspark-notebook/README.md
@@ -0,0 +1,13 @@
+# Jupyter Notebook Python, Spark Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/pyspark-notebook/latest)](https://hub.docker.com/r/jupyter/pyspark-notebook/ ""jupyter/pyspark-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/pyspark-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-pyspark-notebook)
+- [Image Specifics :: Apache Spark](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#apache-spark)","diff --git a/images/pyspark-notebook/README.md b/images/pyspark-notebook/README.md
new file mode 100644
index 00000000..1be04343
--- /dev/null
+++ b/images/pyspark-notebook/README.md
@@ -0,0 +1,13 @@
+# Jupyter Notebook Python, Spark Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/pyspark-notebook/latest)](https://hub.docker.com/r/jupyter/pyspark-notebook/ ""jupyter/pyspark-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/pyspark-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-pyspark-notebook)
+- [Image Specifics :: Apache Spark](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#apache-spark)",Yes
pyspark-notebook/ipython_kernel_config.py,images/pyspark-notebook/ipython_kernel_config.py,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/pyspark-notebook/ipython_kernel_config.py b/images/pyspark-notebook/ipython_kernel_config.py
new file mode 100644
index 00000000..f3efbe19
--- /dev/null
+++ b/images/pyspark-notebook/ipython_kernel_config.py
@@ -0,0 +1,14 @@
+# Configuration file for ipython-kernel.
+# See <https://ipython.readthedocs.io/en/stable/config/options/kernel.html>
+
+# With IPython >= 6.0.0, all outputs to stdout/stderr are captured.
+# It is the case for subprocesses and output of compiled libraries like Spark.
+# Those logs now both head to notebook logs and in notebooks outputs.
+# Logs are particularly verbose with Spark, that is why we turn them off through this flag.
+# <https://github.com/jupyter/docker-stacks/issues/1423>
+
+# Attempt to capture and forward low-level output, e.g. produced by Extension
+#  libraries.
+#  Default: True
+# type:ignore
+c.IPKernelApp.capture_fd_output = False  # noqa: F821","diff --git a/images/pyspark-notebook/ipython_kernel_config.py b/images/pyspark-notebook/ipython_kernel_config.py
new file mode 100644
index 00000000..f3efbe19
--- /dev/null
+++ b/images/pyspark-notebook/ipython_kernel_config.py
@@ -0,0 +1,14 @@
+# Configuration file for ipython-kernel.
+# See <https://ipython.readthedocs.io/en/stable/config/options/kernel.html>
+
+# With IPython >= 6.0.0, all outputs to stdout/stderr are captured.
+# It is the case for subprocesses and output of compiled libraries like Spark.
+# Those logs now both head to notebook logs and in notebooks outputs.
+# Logs are particularly verbose with Spark, that is why we turn them off through this flag.
+# <https://github.com/jupyter/docker-stacks/issues/1423>
+
+# Attempt to capture and forward low-level output, e.g. produced by Extension
+#  libraries.
+#  Default: True
+# type:ignore
+c.IPKernelApp.capture_fd_output = False  # noqa: F821",Yes
r-notebook/.dockerignore,images/r-notebook/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/r-notebook/.dockerignore b/images/r-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/r-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/r-notebook/.dockerignore b/images/r-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/r-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
r-notebook/Dockerfile,images/r-notebook/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/r-notebook/Dockerfile b/images/r-notebook/Dockerfile
new file mode 100644
index 00000000..579aa8f7
--- /dev/null
+++ b/images/r-notebook/Dockerfile
@@ -0,0 +1,53 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/minimal-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# R pre-requisites
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    fonts-dejavu \
+    unixodbc \
+    unixodbc-dev \
+    r-cran-rodbc \
+    gfortran \
+    gcc && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# R packages including IRKernel which gets installed globally.
+# r-e1071: dependency of the caret R package
+RUN mamba install --yes \
+    'r-base' \
+    'r-caret' \
+    'r-crayon' \
+    'r-devtools' \
+    'r-e1071' \
+    'r-forecast' \
+    'r-hexbin' \
+    'r-htmltools' \
+    'r-htmlwidgets' \
+    'r-irkernel' \
+    'r-nycflights13' \
+    'r-randomforest' \
+    'r-rcurl' \
+    'r-rmarkdown' \
+    'r-rodbc' \
+    'r-rsqlite' \
+    'r-shiny' \
+    'r-tidymodels' \
+    'r-tidyverse' \
+    'unixodbc' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/images/r-notebook/Dockerfile b/images/r-notebook/Dockerfile
new file mode 100644
index 00000000..579aa8f7
--- /dev/null
+++ b/images/r-notebook/Dockerfile
@@ -0,0 +1,53 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/minimal-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+# R pre-requisites
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    fonts-dejavu \
+    unixodbc \
+    unixodbc-dev \
+    r-cran-rodbc \
+    gfortran \
+    gcc && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# R packages including IRKernel which gets installed globally.
+# r-e1071: dependency of the caret R package
+RUN mamba install --yes \
+    'r-base' \
+    'r-caret' \
+    'r-crayon' \
+    'r-devtools' \
+    'r-e1071' \
+    'r-forecast' \
+    'r-hexbin' \
+    'r-htmltools' \
+    'r-htmlwidgets' \
+    'r-irkernel' \
+    'r-nycflights13' \
+    'r-randomforest' \
+    'r-rcurl' \
+    'r-rmarkdown' \
+    'r-rodbc' \
+    'r-rsqlite' \
+    'r-shiny' \
+    'r-tidymodels' \
+    'r-tidyverse' \
+    'unixodbc' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
r-notebook/README.md,images/r-notebook/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
new file mode 100644
index 00000000..045ed123
--- /dev/null
+++ b/images/r-notebook/README.md
@@ -0,0 +1,12 @@
+# Jupyter Notebook R Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/r-notebook/latest)](https://hub.docker.com/r/jupyter/r-notebook/ ""jupyter/r-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/r-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-r-notebook)","diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
new file mode 100644
index 00000000..045ed123
--- /dev/null
+++ b/images/r-notebook/README.md
@@ -0,0 +1,12 @@
+# Jupyter Notebook R Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/r-notebook/latest)](https://hub.docker.com/r/jupyter/r-notebook/ ""jupyter/r-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/r-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-r-notebook)",Yes
scipy-notebook/.dockerignore,images/scipy-notebook/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/scipy-notebook/.dockerignore b/images/scipy-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/scipy-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/scipy-notebook/.dockerignore b/images/scipy-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/scipy-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
new file mode 100644
index 00000000..28382337
--- /dev/null
+++ b/images/scipy-notebook/Dockerfile
@@ -0,0 +1,84 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/minimal-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    # for cython: https://cython.readthedocs.io/en/latest/src/quickstart/install.html
+    build-essential \
+    # for latex labels
+    cm-super \
+    dvipng \
+    # for matplotlib anim
+    ffmpeg && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# mamba downgrades these packages to previous major versions, which causes issues
+RUN echo 'jupyterlab >=4.0.4' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    echo 'notebook >=7.0.2' >> ""${CONDA_DIR}/conda-meta/pinned""
+
+# Install Python 3 packages
+RUN mamba install --yes \
+    'altair' \
+    'beautifulsoup4' \
+    'bokeh' \
+    'bottleneck' \
+    'cloudpickle' \
+    'conda-forge::blas=*=openblas' \
+    'cython' \
+    'dask' \
+    'dill' \
+    'h5py' \
+    'ipympl'\
+    'ipywidgets' \
+    'jupyterlab-git' \
+    'matplotlib-base' \
+    'numba' \
+    'numexpr' \
+    'openpyxl' \
+    'pandas' \
+    'patsy' \
+    'protobuf' \
+    'pytables' \
+    'scikit-image' \
+    'scikit-learn' \
+    'scipy' \
+    'seaborn' \
+    'sqlalchemy' \
+    'statsmodels' \
+    'sympy' \
+    'widgetsnbextension'\
+    'xlrd' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Install facets which does not have a pip or conda package at the moment
+WORKDIR /tmp
+RUN git clone https://github.com/PAIR-code/facets.git && \
+    jupyter nbclassic-extension install facets/facets-dist/ --sys-prefix && \
+    rm -rf /tmp/facets && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Import matplotlib the first time to build the font cache.
+ENV XDG_CACHE_HOME=""/home/${NB_USER}/.cache/""
+
+RUN MPLBACKEND=Agg python -c ""import matplotlib.pyplot"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+USER ${NB_UID}
+
+WORKDIR ""${HOME}""","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
new file mode 100644
index 00000000..28382337
--- /dev/null
+++ b/images/scipy-notebook/Dockerfile
@@ -0,0 +1,84 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/minimal-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+USER root
+
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    # for cython: https://cython.readthedocs.io/en/latest/src/quickstart/install.html
+    build-essential \
+    # for latex labels
+    cm-super \
+    dvipng \
+    # for matplotlib anim
+    ffmpeg && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# mamba downgrades these packages to previous major versions, which causes issues
+RUN echo 'jupyterlab >=4.0.4' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    echo 'notebook >=7.0.2' >> ""${CONDA_DIR}/conda-meta/pinned""
+
+# Install Python 3 packages
+RUN mamba install --yes \
+    'altair' \
+    'beautifulsoup4' \
+    'bokeh' \
+    'bottleneck' \
+    'cloudpickle' \
+    'conda-forge::blas=*=openblas' \
+    'cython' \
+    'dask' \
+    'dill' \
+    'h5py' \
+    'ipympl'\
+    'ipywidgets' \
+    'jupyterlab-git' \
+    'matplotlib-base' \
+    'numba' \
+    'numexpr' \
+    'openpyxl' \
+    'pandas' \
+    'patsy' \
+    'protobuf' \
+    'pytables' \
+    'scikit-image' \
+    'scikit-learn' \
+    'scipy' \
+    'seaborn' \
+    'sqlalchemy' \
+    'statsmodels' \
+    'sympy' \
+    'widgetsnbextension'\
+    'xlrd' && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Install facets which does not have a pip or conda package at the moment
+WORKDIR /tmp
+RUN git clone https://github.com/PAIR-code/facets.git && \
+    jupyter nbclassic-extension install facets/facets-dist/ --sys-prefix && \
+    rm -rf /tmp/facets && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# Import matplotlib the first time to build the font cache.
+ENV XDG_CACHE_HOME=""/home/${NB_USER}/.cache/""
+
+RUN MPLBACKEND=Agg python -c ""import matplotlib.pyplot"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+USER ${NB_UID}
+
+WORKDIR ""${HOME}""",Yes
scipy-notebook/README.md,images/scipy-notebook/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/scipy-notebook/README.md b/images/scipy-notebook/README.md
new file mode 100644
index 00000000..e34693d1
--- /dev/null
+++ b/images/scipy-notebook/README.md
@@ -0,0 +1,12 @@
+# Jupyter Notebook Scientific Python Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/scipy-notebook/latest)](https://hub.docker.com/r/jupyter/scipy-notebook/ ""jupyter/scipy-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/scipy-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-scipy-notebook)","diff --git a/images/scipy-notebook/README.md b/images/scipy-notebook/README.md
new file mode 100644
index 00000000..e34693d1
--- /dev/null
+++ b/images/scipy-notebook/README.md
@@ -0,0 +1,12 @@
+# Jupyter Notebook Scientific Python Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/scipy-notebook/latest)](https://hub.docker.com/r/jupyter/scipy-notebook/ ""jupyter/scipy-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/scipy-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-scipy-notebook)",Yes
tensorflow-notebook/.dockerignore,images/tensorflow-notebook/.dockerignore,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/tensorflow-notebook/.dockerignore b/images/tensorflow-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/tensorflow-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/tensorflow-notebook/.dockerignore b/images/tensorflow-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/tensorflow-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
tensorflow-notebook/Dockerfile,images/tensorflow-notebook/Dockerfile,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
new file mode 100644
index 00000000..51070fdc
--- /dev/null
+++ b/images/tensorflow-notebook/Dockerfile
@@ -0,0 +1,16 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install Tensorflow with pip
+RUN pip install --no-cache-dir tensorflow && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
new file mode 100644
index 00000000..51070fdc
--- /dev/null
+++ b/images/tensorflow-notebook/Dockerfile
@@ -0,0 +1,16 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install Tensorflow with pip
+RUN pip install --no-cache-dir tensorflow && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
tensorflow-notebook/README.md,images/tensorflow-notebook/README.md,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/images/tensorflow-notebook/README.md b/images/tensorflow-notebook/README.md
new file mode 100644
index 00000000..5f896fd6
--- /dev/null
+++ b/images/tensorflow-notebook/README.md
@@ -0,0 +1,13 @@
+# Jupyter Notebook Deep Learning Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/tensorflow-notebook/latest)](https://hub.docker.com/r/jupyter/tensorflow-notebook/ ""jupyter/tensorflow-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/tensorflow-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-tensorflow-notebook)
+- [Image Specifics :: Tensorflow](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#tensorflow)","diff --git a/images/tensorflow-notebook/README.md b/images/tensorflow-notebook/README.md
new file mode 100644
index 00000000..5f896fd6
--- /dev/null
+++ b/images/tensorflow-notebook/README.md
@@ -0,0 +1,13 @@
+# Jupyter Notebook Deep Learning Stack
+
+[![docker pulls](https://img.shields.io/docker/pulls/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
+[![docker stars](https://img.shields.io/docker/stars/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
+[![image size](https://img.shields.io/docker/image-size/jupyter/tensorflow-notebook/latest)](https://hub.docker.com/r/jupyter/tensorflow-notebook/ ""jupyter/tensorflow-notebook image size"")
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/tensorflow-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-tensorflow-notebook)
+- [Image Specifics :: Tensorflow](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/specifics.html#tensorflow)",Yes
tagging/write_manifest.py,tagging/write_manifest.py,a5b40a6f1117bd675565b3673e063125dd74eac3,feb88727d1c865ca9977339ed8929d4416c4895d,Move all images to images dir (#1972),"diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index f81e0213..14a01a15 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -38,7 +38,7 @@ def write_build_history_line(
     links_column = MARKDOWN_LINE_BREAK.join(
         [
             f""[Git diff](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
-            f""[Dockerfile](https://github.com/jupyter/docker-stacks/blob/{commit_hash}/{short_image_name}/Dockerfile)"",
+            f""[Dockerfile](https://github.com/jupyter/docker-stacks/blob/{commit_hash}/images/{short_image_name}/Dockerfile)"",
             f""[Build manifest](./{filename})"",
         ]
     )","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index f81e0213..14a01a15 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -38,7 +38,7 @@ def write_build_history_line(
     links_column = MARKDOWN_LINE_BREAK.join(
         [
             f""[Git diff](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
-            f""[Dockerfile](https://github.com/jupyter/docker-stacks/blob/{commit_hash}/{short_image_name}/Dockerfile)"",
+            f""[Dockerfile](https://github.com/jupyter/docker-stacks/blob/{commit_hash}/images/{short_image_name}/Dockerfile)"",
             f""[Build manifest](./{filename})"",
         ]
     )",Yes
docs/using/selecting.md,docs/using/selecting.md,2ecdaec83269a10c28e5c62d5bd5f8fd91db59d6,a5b40a6f1117bd675565b3673e063125dd74eac3,Fix images links,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 0b5003ab..77837733 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -18,8 +18,8 @@ The following sections describe these images, including their contents, relation
 
 ### jupyter/docker-stacks-foundation
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/docker-stacks-foundation) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/docker-stacks-foundation/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/docker-stacks-foundation) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/docker-stacks-foundation/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/docker-stacks-foundation/tags/)
 
 `jupyter/docker-stacks-foundation` is a small image supporting a majority of [options common across all core stacks](common.md).
@@ -43,8 +43,8 @@ It contains:
 
 ### jupyter/base-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/base-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/base-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/base-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/base-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/base-notebook/tags/)
 
 `jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
@@ -61,8 +61,8 @@ It contains:
 
 ### jupyter/minimal-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/minimal-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/minimal-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/minimal-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/minimal-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/minimal-notebook/tags/)
 
 `jupyter/minimal-notebook` adds command-line tools useful when working in Jupyter applications.
@@ -81,8 +81,8 @@ It contains:
 
 ### jupyter/r-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/r-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/r-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/r-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/r-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/r-notebook/tags/)
 
 `jupyter/r-notebook` includes popular packages from the R ecosystem listed below:
@@ -112,8 +112,8 @@ It contains:
 
 ### jupyter/julia-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/julia-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/julia-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/julia-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/julia-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/julia-notebook/tags/)
 
 `jupyter/julia-notebook` includes popular packages from the Julia ecosystem listed below:
@@ -126,8 +126,8 @@ It contains:
 
 ### jupyter/scipy-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/scipy-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/scipy-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/scipy-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/scipy-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/scipy-notebook/tags/)
 
 `jupyter/scipy-notebook` includes popular packages from the scientific Python ecosystem.
@@ -170,8 +170,8 @@ It contains:
 
 ### jupyter/tensorflow-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/tensorflow-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/tensorflow-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/tensorflow-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/tensorflow-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/tensorflow-notebook/tags/)
 
 `jupyter/tensorflow-notebook` includes popular Python deep learning libraries.
@@ -181,8 +181,8 @@ It contains:
 
 ### jupyter/datascience-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/datascience-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/datascience-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/datascience-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/datascience-notebook/tags/)
 
 `jupyter/datascience-notebook` includes libraries for data analysis from the Julia, Python, and R
@@ -198,8 +198,8 @@ communities.
 
 ### jupyter/pyspark-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/pyspark-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/pyspark-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/pyspark-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/pyspark-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/pyspark-notebook/tags/)
 
 `jupyter/pyspark-notebook` includes Python support for Apache Spark.
@@ -210,8 +210,8 @@ communities.
 
 ### jupyter/all-spark-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/all-spark-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/all-spark-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/all-spark-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/all-spark-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/all-spark-notebook/tags/)
 
 `jupyter/all-spark-notebook` includes Python and R support for Apache Spark.","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 0b5003ab..77837733 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -18,8 +18,8 @@ The following sections describe these images, including their contents, relation
 
 ### jupyter/docker-stacks-foundation
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/docker-stacks-foundation) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/docker-stacks-foundation/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/docker-stacks-foundation) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/docker-stacks-foundation/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/docker-stacks-foundation/tags/)
 
 `jupyter/docker-stacks-foundation` is a small image supporting a majority of [options common across all core stacks](common.md).
@@ -43,8 +43,8 @@ It contains:
 
 ### jupyter/base-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/base-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/base-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/base-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/base-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/base-notebook/tags/)
 
 `jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
@@ -61,8 +61,8 @@ It contains:
 
 ### jupyter/minimal-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/minimal-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/minimal-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/minimal-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/minimal-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/minimal-notebook/tags/)
 
 `jupyter/minimal-notebook` adds command-line tools useful when working in Jupyter applications.
@@ -81,8 +81,8 @@ It contains:
 
 ### jupyter/r-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/r-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/r-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/r-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/r-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/r-notebook/tags/)
 
 `jupyter/r-notebook` includes popular packages from the R ecosystem listed below:
@@ -112,8 +112,8 @@ It contains:
 
 ### jupyter/julia-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/julia-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/julia-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/julia-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/julia-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/julia-notebook/tags/)
 
 `jupyter/julia-notebook` includes popular packages from the Julia ecosystem listed below:
@@ -126,8 +126,8 @@ It contains:
 
 ### jupyter/scipy-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/scipy-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/scipy-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/scipy-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/scipy-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/scipy-notebook/tags/)
 
 `jupyter/scipy-notebook` includes popular packages from the scientific Python ecosystem.
@@ -170,8 +170,8 @@ It contains:
 
 ### jupyter/tensorflow-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/tensorflow-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/tensorflow-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/tensorflow-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/tensorflow-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/tensorflow-notebook/tags/)
 
 `jupyter/tensorflow-notebook` includes popular Python deep learning libraries.
@@ -181,8 +181,8 @@ It contains:
 
 ### jupyter/datascience-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/datascience-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/datascience-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/datascience-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/datascience-notebook/tags/)
 
 `jupyter/datascience-notebook` includes libraries for data analysis from the Julia, Python, and R
@@ -198,8 +198,8 @@ communities.
 
 ### jupyter/pyspark-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/pyspark-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/pyspark-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/pyspark-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/pyspark-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/pyspark-notebook/tags/)
 
 `jupyter/pyspark-notebook` includes Python support for Apache Spark.
@@ -210,8 +210,8 @@ communities.
 
 ### jupyter/all-spark-notebook
 
-[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/all-spark-notebook) |
-[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/all-spark-notebook/Dockerfile) |
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/all-spark-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/all-spark-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/all-spark-notebook/tags/)
 
 `jupyter/all-spark-notebook` includes Python and R support for Apache Spark.",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,a7a4be9e394841ecddbaeca48a2b5c1e1dd6001c,2ecdaec83269a10c28e5c62d5bd5f8fd91db59d6,Fix more broken links,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 72085d85..9da623d8 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -131,7 +131,7 @@ you merge a GitHub pull request to the main branch of your project.
 ## Defining Your Image
 
 Make edits to the Dockerfile in your project to add third-party libraries and configure Jupyter applications.
-Refer to the Dockerfiles for the core stacks (e.g., [jupyter/datascience-notebook](https://github.com/jupyter/docker-stacks/blob/main/datascience-notebook/Dockerfile))
+Refer to the Dockerfiles for the core stacks (e.g., [jupyter/datascience-notebook](https://github.com/jupyter/docker-stacks/blob/main/images/datascience-notebook/Dockerfile))
 to get a feel for what's possible and the best practices.
 
 [Submit pull requests](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 72085d85..9da623d8 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -131,7 +131,7 @@ you merge a GitHub pull request to the main branch of your project.
 ## Defining Your Image
 
 Make edits to the Dockerfile in your project to add third-party libraries and configure Jupyter applications.
-Refer to the Dockerfiles for the core stacks (e.g., [jupyter/datascience-notebook](https://github.com/jupyter/docker-stacks/blob/main/datascience-notebook/Dockerfile))
+Refer to the Dockerfiles for the core stacks (e.g., [jupyter/datascience-notebook](https://github.com/jupyter/docker-stacks/blob/main/images/datascience-notebook/Dockerfile))
 to get a feel for what's possible and the best practices.
 
 [Submit pull requests](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)",Yes
docs/using/common.md,docs/using/common.md,a7a4be9e394841ecddbaeca48a2b5c1e1dd6001c,2ecdaec83269a10c28e5c62d5bd5f8fd91db59d6,Fix more broken links,"diff --git a/docs/using/common.md b/docs/using/common.md
index 806ce6c7..986ad735 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -135,7 +135,7 @@ or executables (`chmod +x`) to be run to the paths below:
 - `/usr/local/bin/before-notebook.d/` - handled **after** all the standard options noted above are applied
   and ran right before the Server launches
 
-See the `run-hooks` function in the [`jupyter/docker-stacks-foundation start.sh`](https://github.com/jupyter/docker-stacks/blob/main/docker-stacks-foundation/start.sh)
+See the `run-hooks` function in the [`jupyter/docker-stacks-foundation start.sh`](https://github.com/jupyter/docker-stacks/blob/main/images/docker-stacks-foundation/start.sh)
 script for execution details.
 
 ## SSL Certificates
@@ -171,7 +171,7 @@ For additional information about using SSL, see the following:
 - The [docker-stacks/examples](https://github.com/jupyter/docker-stacks/tree/main/examples)
   for information about how to use
   [Let's Encrypt](https://letsencrypt.org/) certificates when you run these stacks on a publicly visible domain.
-- The [`jupyter_server_config.py`](https://github.com/jupyter/docker-stacks/blob/main/base-notebook/jupyter_server_config.py)
+- The [`jupyter_server_config.py`](https://github.com/jupyter/docker-stacks/blob/main/images/base-notebook/jupyter_server_config.py)
   file for how this Docker image generates a self-signed certificate.
 - The [Jupyter Server documentation](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#securing-a-jupyter-server)
   for best practices about securing a public Server in general.","diff --git a/docs/using/common.md b/docs/using/common.md
index 806ce6c7..986ad735 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -135,7 +135,7 @@ or executables (`chmod +x`) to be run to the paths below:
 - `/usr/local/bin/before-notebook.d/` - handled **after** all the standard options noted above are applied
   and ran right before the Server launches
 
-See the `run-hooks` function in the [`jupyter/docker-stacks-foundation start.sh`](https://github.com/jupyter/docker-stacks/blob/main/docker-stacks-foundation/start.sh)
+See the `run-hooks` function in the [`jupyter/docker-stacks-foundation start.sh`](https://github.com/jupyter/docker-stacks/blob/main/images/docker-stacks-foundation/start.sh)
 script for execution details.
 
 ## SSL Certificates
@@ -171,7 +171,7 @@ For additional information about using SSL, see the following:
 - The [docker-stacks/examples](https://github.com/jupyter/docker-stacks/tree/main/examples)
   for information about how to use
   [Let's Encrypt](https://letsencrypt.org/) certificates when you run these stacks on a publicly visible domain.
-- The [`jupyter_server_config.py`](https://github.com/jupyter/docker-stacks/blob/main/base-notebook/jupyter_server_config.py)
+- The [`jupyter_server_config.py`](https://github.com/jupyter/docker-stacks/blob/main/images/base-notebook/jupyter_server_config.py)
   file for how this Docker image generates a self-signed certificate.
 - The [Jupyter Server documentation](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#securing-a-jupyter-server)
   for best practices about securing a public Server in general.",Yes
README.md,README.md,5e65115ea43d2ac9f2f5d8a4833f7660c41decea,a7a4be9e394841ecddbaeca48a2b5c1e1dd6001c,Update example date,"diff --git a/README.md b/README.md
index 94c3db64..ad9429d8 100644
--- a/README.md
+++ b/README.md
@@ -26,11 +26,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-31
+docker run -p 10000:8888 jupyter/scipy-notebook:2023-08-19
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -45,11 +45,11 @@ The container remains intact for restart after the Server exits.
 
 **Example 2:**
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-31
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-08-19
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -119,7 +119,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-07-31`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-08-19`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images","diff --git a/README.md b/README.md
index 94c3db64..ad9429d8 100644
--- a/README.md
+++ b/README.md
@@ -26,11 +26,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-07-31
+docker run -p 10000:8888 jupyter/scipy-notebook:2023-08-19
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -45,11 +45,11 @@ The container remains intact for restart after the Server exits.
 
 **Example 2:**
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-07-31
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-08-19
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -119,7 +119,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-07-31`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-08-19`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images",Yes
binder/Dockerfile,binder/Dockerfile,5e65115ea43d2ac9f2f5d8a4833f7660c41decea,a7a4be9e394841ecddbaeca48a2b5c1e1dd6001c,Update example date,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index dfe8ad8f..be4c4033 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -3,7 +3,7 @@
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-07-31
+ARG BASE_CONTAINER=$OWNER/base-notebook:2023-08-19
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -12,6 +12,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-07-31""
+ENV TAG=""2023-08-19""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index dfe8ad8f..be4c4033 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -3,7 +3,7 @@
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-07-31
+ARG BASE_CONTAINER=$OWNER/base-notebook:2023-08-19
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -12,6 +12,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-07-31""
+ENV TAG=""2023-08-19""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,5e65115ea43d2ac9f2f5d8a4833f7660c41decea,a7a4be9e394841ecddbaeca48a2b5c1e1dd6001c,Update example date,"diff --git a/docs/using/running.md b/docs/using/running.md
index 4d492054..822a2efc 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-31
+docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-08-19
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-07-31                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-08-19                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 **Example 2:**
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-31
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-08-19
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -137,7 +137,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -146,7 +146,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-07-31
+    docker.io/jupyter/r-notebook:2023-08-19
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 4d492054..822a2efc 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 **Example 1:**
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-07-31
+docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-08-19
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-07-31                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-08-19                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 **Example 2:**
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-07-31
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-08-19
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -137,7 +137,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-07-31` from Docker Hub if it is not already present on the local host.
+This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -146,7 +146,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-07-31
+    docker.io/jupyter/r-notebook:2023-08-19
 ```
 
 ```{warning}",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,f801c382792af7b178d5e06564bca0d147b9ccfb,5e65115ea43d2ac9f2f5d8a4833f7660c41decea,Give a better example of adding new image,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 35ebd6c6..d420df43 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -41,7 +41,7 @@ Pushing the `Run Workflow` button will trigger this process.
 In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
 ```
 
-You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1926/files).
+You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1936/files).
 
 When there's a new stack definition, check before merging the PR:","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 35ebd6c6..d420df43 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -41,7 +41,7 @@ Pushing the `Run Workflow` button will trigger this process.
 In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
 ```
 
-You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1926/files).
+You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1936/files).
 
 When there's a new stack definition, check before merging the PR:",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,d154bdd800fa12f8ba310405b7a1f9944aed5784,f801c382792af7b178d5e06564bca0d147b9ccfb,Fix oracledb recipe,"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 5e8aa391..4614ec4e 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,12 +1,8 @@
 FROM jupyter/base-notebook
 
-# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
-# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
-SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
-
 USER root
 
-# Install java, javac and alien
+# Install Java & Oracle SQL Instant Client
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends software-properties-common && \
     add-apt-repository universe && \
@@ -14,34 +10,38 @@ RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends alien default-jre default-jdk openjdk-11-jdk libaio1 && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
-ARG instantclient_major_version=21
-ARG instantclient_version=${instantclient_major_version}.11.0.0.0-1
+# Oracle
+ARG INSTANTCLIENT_MAJOR_VERSION=21
+ARG INSTANTCLIENT_VERSION=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1
+ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2111000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools and JDBC.
 # Note: You may need to change the URL to a newer version.
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
-WORKDIR ""/tmp""
-RUN short_version=""$(echo ""${instantclient_version}"" | tr -d '.' | cut -d ""-"" -f1)"" && \
-    instantclient_url=""https://download.oracle.com/otn_software/linux/instantclient/${short_version}"" && \
-    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm"" && \
+RUN mkdir ""/opt/oracle""
+WORKDIR ""/opt/oracle""
+RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclite-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-basiclite-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-sqlplus-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-tools-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-tools-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-jdbc-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-jdbc-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
     chown -R ""${NB_UID}"":""${NB_GID}"" ""${HOME}/.rpmdb"" && \
     rm -f ./*.rpm
 
-# Configure environment
-ENV ORACLE_HOME=/usr/lib/oracle/${instantclient_major_version}/client64
-ENV PATH=""${ORACLE_HOME}/bin:${PATH}""
-ENV LD_LIBRARY_PATH=""${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}""
-
-# (Optional) Add credentials for the Oracle Database server; files must be present on your `docker build PATH` folder.
-WORKDIR /usr/lib/oracle/${instantclient_major_version}/client64/lib/network/admin
-# Adding a wildcard `[]` on the last letter of the filename to avoid throwing an error if the file does not exist.
+# And configure variables
+RUN echo ""ORACLE_HOME=/usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64"" >> ""${HOME}/.bashrc"" && \
+    echo ""PATH=${ORACLE_HOME}/bin:$PATH"" >> ""${HOME}/.bashrc"" && \
+    echo ""LD_LIBRARY_PATH=${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}"" >> ""${HOME}/.bashrc"" && \
+    echo ""export ORACLE_HOME"" >> ""${HOME}/.bashrc"" && \
+    echo ""export PATH"" >> ""${HOME}/.bashrc"" && \
+    echo ""export LD_LIBRARY_PATH"" >> ""${HOME}/.bashrc""
+
+# Add credentials for /redacted/ using Oracle Db.
+WORKDIR /usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64/lib/network/admin/
+# Add a wildcard `[]` on the last letter of the filename to avoid throwing an error if the file does not exist.
 # See: https://stackoverflow.com/questions/31528384/conditional-copy-add-in-dockerfile
 COPY cwallet.ss[o] ./
 COPY sqlnet.or[a] ./","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 5e8aa391..4614ec4e 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,12 +1,8 @@
 FROM jupyter/base-notebook
 
-# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
-# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
-SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
-
 USER root
 
-# Install java, javac and alien
+# Install Java & Oracle SQL Instant Client
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends software-properties-common && \
     add-apt-repository universe && \
@@ -14,34 +10,38 @@ RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends alien default-jre default-jdk openjdk-11-jdk libaio1 && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
-ARG instantclient_major_version=21
-ARG instantclient_version=${instantclient_major_version}.11.0.0.0-1
+# Oracle
+ARG INSTANTCLIENT_MAJOR_VERSION=21
+ARG INSTANTCLIENT_VERSION=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1
+ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2111000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools and JDBC.
 # Note: You may need to change the URL to a newer version.
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
-WORKDIR ""/tmp""
-RUN short_version=""$(echo ""${instantclient_version}"" | tr -d '.' | cut -d ""-"" -f1)"" && \
-    instantclient_url=""https://download.oracle.com/otn_software/linux/instantclient/${short_version}"" && \
-    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-basiclite-${instantclient_version}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-sqlplus-${instantclient_version}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-tools-${instantclient_version}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${instantclient_url}/oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-jdbc-${instantclient_version}.el8.x86_64.rpm"" && \
+RUN mkdir ""/opt/oracle""
+WORKDIR ""/opt/oracle""
+RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclite-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-basiclite-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-sqlplus-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-tools-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-tools-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-jdbc-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+    alien --install --scripts ""oracle-instantclient-jdbc-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
     chown -R ""${NB_UID}"":""${NB_GID}"" ""${HOME}/.rpmdb"" && \
     rm -f ./*.rpm
 
-# Configure environment
-ENV ORACLE_HOME=/usr/lib/oracle/${instantclient_major_version}/client64
-ENV PATH=""${ORACLE_HOME}/bin:${PATH}""
-ENV LD_LIBRARY_PATH=""${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}""
+# And configure variables
+RUN echo ""ORACLE_HOME=/usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64"" >> ""${HOME}/.bashrc"" && \
+    echo ""PATH=${ORACLE_HOME}/bin:$PATH"" >> ""${HOME}/.bashrc"" && \
+    echo ""LD_LIBRARY_PATH=${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}"" >> ""${HOME}/.bashrc"" && \
+    echo ""export ORACLE_HOME"" >> ""${HOME}/.bashrc"" && \
+    echo ""export PATH"" >> ""${HOME}/.bashrc"" && \
+    echo ""export LD_LIBRARY_PATH"" >> ""${HOME}/.bashrc""
 
-# (Optional) Add credentials for the Oracle Database server; files must be present on your `docker build PATH` folder.
-WORKDIR /usr/lib/oracle/${instantclient_major_version}/client64/lib/network/admin
-# Adding a wildcard `[]` on the last letter of the filename to avoid throwing an error if the file does not exist.
+# Add credentials for /redacted/ using Oracle Db.
+WORKDIR /usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64/lib/network/admin/
+# Add a wildcard `[]` on the last letter of the filename to avoid throwing an error if the file does not exist.
 # See: https://stackoverflow.com/questions/31528384/conditional-copy-add-in-dockerfile
 COPY cwallet.ss[o] ./
 COPY sqlnet.or[a] ./",No
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,803652a6c108d91b32badef934a13a5ab879f7f1,d154bdd800fa12f8ba310405b7a1f9944aed5784,Fix contributed-recipes trigger,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 5478efa8..bdf53fdc 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -9,13 +9,13 @@ on:
   pull_request:
     paths:
       - "".github/workflows/contributed-recipes.yml""
-      - ""docs/using/recipe_code/""
+      - ""docs/using/recipe_code/**""
   push:
     branches:
       - main
     paths:
       - "".github/workflows/contributed-recipes.yml""
-      - ""docs/using/recipe_code/""
+      - ""docs/using/recipe_code/**""
   workflow_dispatch:
   workflow_call:","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 5478efa8..bdf53fdc 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -9,13 +9,13 @@ on:
   pull_request:
     paths:
       - "".github/workflows/contributed-recipes.yml""
-      - ""docs/using/recipe_code/""
+      - ""docs/using/recipe_code/**""
   push:
     branches:
       - main
     paths:
       - "".github/workflows/contributed-recipes.yml""
-      - ""docs/using/recipe_code/""
+      - ""docs/using/recipe_code/**""
   workflow_dispatch:
   workflow_call:",Yes
docs/using/recipe_code/custom_environment.dockerfile,docs/using/recipe_code/custom_environment.dockerfile,49a3caa5fba3a1604165076efb3190cc579006b2,803652a6c108d91b32badef934a13a5ab879f7f1,Trigger CI,"diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 7b457ca8..5cbe5e5d 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,33 +1,33 @@
 FROM jupyter/base-notebook
 
-# name your environment and choose the python version
+# Name your environment and choose the python version
 ARG env_name=python38
 ARG py_ver=3.8
 
-# you can add additional libraries here
+# You can add additional libraries here
 RUN mamba create --yes -p ""${CONDA_DIR}/envs/${env_name}"" \
     python=${py_ver} \
     'ipykernel' \
     'jupyterlab' && \
     mamba clean --all -f -y
 
-# alternatively, you can comment out the lines above and uncomment those below
+# Alternatively, you can comment out the lines above and uncomment those below
 # if you'd prefer to use a YAML file present in the docker build context
 
 # COPY --chown=${NB_UID}:${NB_GID} environment.yml /tmp/
 # RUN mamba env create -p ""${CONDA_DIR}/envs/${env_name}"" -f /tmp/environment.yml && \
 #     mamba clean --all -f -y
 
-# create Python kernel and link it to jupyter
+# Create Python kernel and link it to jupyter
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --name=""${env_name}"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# any additional `pip` installs can be added by using the following line
-# using `mamba` is highly recommended
+# Any additional `pip` installs can be added by using the following line
+# Using `mamba` is highly recommended though
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
     'flake8'
 
-# if you do not want this environment to be the default one, comment this line
+# If you do not want this environment to be the default one, comment this line
 # hadolint ignore=DL3059
 RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 7b457ca8..5cbe5e5d 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,33 +1,33 @@
 FROM jupyter/base-notebook
 
-# name your environment and choose the python version
+# Name your environment and choose the python version
 ARG env_name=python38
 ARG py_ver=3.8
 
-# you can add additional libraries here
+# You can add additional libraries here
 RUN mamba create --yes -p ""${CONDA_DIR}/envs/${env_name}"" \
     python=${py_ver} \
     'ipykernel' \
     'jupyterlab' && \
     mamba clean --all -f -y
 
-# alternatively, you can comment out the lines above and uncomment those below
+# Alternatively, you can comment out the lines above and uncomment those below
 # if you'd prefer to use a YAML file present in the docker build context
 
 # COPY --chown=${NB_UID}:${NB_GID} environment.yml /tmp/
 # RUN mamba env create -p ""${CONDA_DIR}/envs/${env_name}"" -f /tmp/environment.yml && \
 #     mamba clean --all -f -y
 
-# create Python kernel and link it to jupyter
+# Create Python kernel and link it to jupyter
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --name=""${env_name}"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# any additional `pip` installs can be added by using the following line
-# using `mamba` is highly recommended
+# Any additional `pip` installs can be added by using the following line
+# Using `mamba` is highly recommended though
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
     'flake8'
 
-# if you do not want this environment to be the default one, comment this line
+# If you do not want this environment to be the default one, comment this line
 # hadolint ignore=DL3059
 RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""",Yes
images/r-notebook/README.md,images/r-notebook/README.md,99daf2041dcb780aabb6488dada5279ff1268923,49a3caa5fba3a1604165076efb3190cc579006b2,Trigger CI,"diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
index 045ed123..155865d9 100644
--- a/images/r-notebook/README.md
+++ b/images/r-notebook/README.md
@@ -6,7 +6,7 @@
 
 GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
 
-Please visit the project documentation site for help to use and contribute to this image and others.
+Please visit the project documentation website for help to use and contribute to this image and others.
 
 - [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
 - [Selecting an Image :: Core Stacks :: jupyter/r-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-r-notebook)","diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
index 045ed123..155865d9 100644
--- a/images/r-notebook/README.md
+++ b/images/r-notebook/README.md
@@ -6,7 +6,7 @@
 
 GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
 
-Please visit the project documentation site for help to use and contribute to this image and others.
+Please visit the project documentation website for help to use and contribute to this image and others.
 
 - [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
 - [Selecting an Image :: Core Stacks :: jupyter/r-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-r-notebook)",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,22196fecfa6c326af773f4453ceacc2182cf02b3,99daf2041dcb780aabb6488dada5279ff1268923,Do not run docker workflow when only README.md changes,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 7b3f1638..55fb9e20 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -21,6 +21,7 @@ on:
       - "".github/actions/load-image/action.yml""
 
       - ""images/**""
+      - ""!images/*/README.md""
       - ""tagging/**""
       - ""tests/**""
       - ""requirements-dev.txt""
@@ -39,6 +40,7 @@ on:
       - "".github/actions/load-image/action.yml""
 
       - ""images/**""
+      - ""!images/*/README.md""
       - ""tagging/**""
       - ""tests/**""
       - ""requirements-dev.txt""","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 7b3f1638..55fb9e20 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -21,6 +21,7 @@ on:
       - "".github/actions/load-image/action.yml""
 
       - ""images/**""
+      - ""!images/*/README.md""
       - ""tagging/**""
       - ""tests/**""
       - ""requirements-dev.txt""
@@ -39,6 +40,7 @@ on:
       - "".github/actions/load-image/action.yml""
 
       - ""images/**""
+      - ""!images/*/README.md""
       - ""tagging/**""
       - ""tests/**""
       - ""requirements-dev.txt""",Yes
images/r-notebook/README.md,images/r-notebook/README.md,e6f209e372522775c43b04376a48ce3ca5f8e4c4,22196fecfa6c326af773f4453ceacc2182cf02b3,Revert images/r-notebook/README.md,"diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
index 155865d9..045ed123 100644
--- a/images/r-notebook/README.md
+++ b/images/r-notebook/README.md
@@ -6,7 +6,7 @@
 
 GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
 
-Please visit the project documentation website for help to use and contribute to this image and others.
+Please visit the project documentation site for help to use and contribute to this image and others.
 
 - [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
 - [Selecting an Image :: Core Stacks :: jupyter/r-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-r-notebook)","diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
index 155865d9..045ed123 100644
--- a/images/r-notebook/README.md
+++ b/images/r-notebook/README.md
@@ -6,7 +6,7 @@
 
 GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
 
-Please visit the project documentation website for help to use and contribute to this image and others.
+Please visit the project documentation site for help to use and contribute to this image and others.
 
 - [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
 - [Selecting an Image :: Core Stacks :: jupyter/r-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-r-notebook)",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,cf9a8b6624588b5e1f5955aacaecabf61be061c7,e6f209e372522775c43b04376a48ce3ca5f8e4c4,"Small improvements to startup hooks (#1976)

* Small improvements to startup hooks

* Fix","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 7e62b64c..b9663dea 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -129,6 +129,12 @@ CMD [""start.sh""]
 # Copy local files as late as possible to avoid cache busting
 COPY start.sh /usr/local/bin/
 
+USER root
+
+# Create dirs for startup hooks
+RUN mkdir /usr/local/bin/start-notebook.d && \
+    mkdir /usr/local/bin/before-notebook.d
+
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 7e62b64c..b9663dea 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -129,6 +129,12 @@ CMD [""start.sh""]
 # Copy local files as late as possible to avoid cache busting
 COPY start.sh /usr/local/bin/
 
+USER root
+
+# Create dirs for startup hooks
+RUN mkdir /usr/local/bin/start-notebook.d && \
+    mkdir /usr/local/bin/before-notebook.d
+
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,cf9a8b6624588b5e1f5955aacaecabf61be061c7,e6f209e372522775c43b04376a48ce3ca5f8e4c4,"Small improvements to startup hooks (#1976)

* Small improvements to startup hooks

* Fix","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 7c5859ee..d1a0a3ea 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -20,25 +20,25 @@ run-hooks () {
     if [[ ! -d ""${1}"" ]] ; then
         return
     fi
-    _log ""${0}: running hooks in ${1} as uid / gid: $(id -u) / $(id -g)""
+    _log ""${0}: running hooks in: ${1} as uid: $(id -u) gid: $(id -g)""
     for f in ""${1}/""*; do
         case ""${f}"" in
             *.sh)
-                _log ""${0}: running script ${f}""
+                _log ""${0}: sourcing shell script: ${f}""
                 # shellcheck disable=SC1090
                 source ""${f}""
                 ;;
             *)
                 if [[ -x ""${f}"" ]] ; then
-                    _log ""${0}: running executable ${f}""
+                    _log ""${0}: running executable: ${f}""
                     ""${f}""
                 else
-                    _log ""${0}: ignoring non-executable ${f}""
+                    _log ""${0}: ignoring non-executable: ${f}""
                 fi
                 ;;
         esac
     done
-    _log ""${0}: done running hooks in ${1}""
+    _log ""${0}: done running hooks in: ${1}""
 }
 
 # A helper function to unset env vars listed in the value of the env var","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 7c5859ee..d1a0a3ea 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -20,25 +20,25 @@ run-hooks () {
     if [[ ! -d ""${1}"" ]] ; then
         return
     fi
-    _log ""${0}: running hooks in ${1} as uid / gid: $(id -u) / $(id -g)""
+    _log ""${0}: running hooks in: ${1} as uid: $(id -u) gid: $(id -g)""
     for f in ""${1}/""*; do
         case ""${f}"" in
             *.sh)
-                _log ""${0}: running script ${f}""
+                _log ""${0}: sourcing shell script: ${f}""
                 # shellcheck disable=SC1090
                 source ""${f}""
                 ;;
             *)
                 if [[ -x ""${f}"" ]] ; then
-                    _log ""${0}: running executable ${f}""
+                    _log ""${0}: running executable: ${f}""
                     ""${f}""
                 else
-                    _log ""${0}: ignoring non-executable ${f}""
+                    _log ""${0}: ignoring non-executable: ${f}""
                 fi
                 ;;
         esac
     done
-    _log ""${0}: done running hooks in ${1}""
+    _log ""${0}: done running hooks in: ${1}""
 }
 
 # A helper function to unset env vars listed in the value of the env var",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,cf9a8b6624588b5e1f5955aacaecabf61be061c7,e6f209e372522775c43b04376a48ce3ca5f8e4c4,"Small improvements to startup hooks (#1976)

* Small improvements to startup hooks

* Fix","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index cff30a8e..ee7a780a 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -57,7 +57,6 @@ RUN if [ -z ""${scala_version}"" ]; then \
     ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}"" ""${SPARK_HOME}""; \
   fi && \
   # Add a link in the before_notebook hook in order to source automatically PYTHONPATH && \
-  mkdir -p /usr/local/bin/before-notebook.d && \
   ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/spark-config.sh
 
 # Configure IPython system-wide","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index cff30a8e..ee7a780a 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -57,7 +57,6 @@ RUN if [ -z ""${scala_version}"" ]; then \
     ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}"" ""${SPARK_HOME}""; \
   fi && \
   # Add a link in the before_notebook hook in order to source automatically PYTHONPATH && \
-  mkdir -p /usr/local/bin/before-notebook.d && \
   ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/spark-config.sh
 
 # Configure IPython system-wide",Yes
README.md,README.md,948f0bb3365f9b2a35a6ed01c313eb39b11dbc3a,cf9a8b6624588b5e1f5955aacaecabf61be061c7,"Add info how to persist user data (#1977)

* Add info how to persist user data

* Improve wording

* Add note

* Better wording","diff --git a/README.md b/README.md
index ad9429d8..b9eb6097 100644
--- a/README.md
+++ b/README.md
@@ -24,7 +24,7 @@ and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.
 
-**Example 1:**
+### Example 1
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
@@ -43,7 +43,7 @@ where:
 
 The container remains intact for restart after the Server exits.
 
-**Example 2:**
+### Example 2
 
 This command pulls the `jupyter/datascience-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.","diff --git a/README.md b/README.md
index ad9429d8..b9eb6097 100644
--- a/README.md
+++ b/README.md
@@ -24,7 +24,7 @@ and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.
 
-**Example 1:**
+### Example 1
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
@@ -43,7 +43,7 @@ where:
 
 The container remains intact for restart after the Server exits.
 
-**Example 2:**
+### Example 2
 
 This command pulls the `jupyter/datascience-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.",Yes
docs/using/faq.md,docs/using/faq.md,948f0bb3365f9b2a35a6ed01c313eb39b11dbc3a,cf9a8b6624588b5e1f5955aacaecabf61be061c7,"Add info how to persist user data (#1977)

* Add info how to persist user data

* Improve wording

* Add note

* Better wording","diff --git a/docs/using/faq.md b/docs/using/faq.md
index 1d417190..a072d58f 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -1,5 +1,27 @@
 # Frequently Asked Questions (FAQ)
 
+## How to persist user data
+
+There are 2 types of data, which you might want to persist.
+
+1. If you want to persist your environment (i.e. packages installed by `mamba`, `conda`, `pip`, `apt-get` and so on),
+   then you should create an inherited image and install them only once while building your Dockerfile.
+   An example for using `mamba` and `pip` in a child image is available
+   [here](./recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
+
+   ```{note}
+   If you install a package inside a running container (for example you run `pip install <package>` in a terminal),
+   it won't be preserved when you next run your image.
+   To make it work, install this package in your inherited image and rerun `docker build` command.
+   ```
+
+2. If you want to persist user-data (files created by you, like `python` scripts, notebooks, text files and so on),
+   then you should use a
+   [Docker bind mount](https://docs.docker.com/storage/bind-mounts/) or
+   [Docker Volume](https://docs.docker.com/storage/volumes/).
+   You can find [an example of using bind mount here](./running.md#example-2).
+   There is also [a mount troubleshooting section](./troubleshooting.md#permission-denied-when-mounting-volumes) if you experience any issues.
+
 ## Why we do not add your favorite package
 
 We have lots of users with different packages they want to use.","diff --git a/docs/using/faq.md b/docs/using/faq.md
index 1d417190..a072d58f 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -1,5 +1,27 @@
 # Frequently Asked Questions (FAQ)
 
+## How to persist user data
+
+There are 2 types of data, which you might want to persist.
+
+1. If you want to persist your environment (i.e. packages installed by `mamba`, `conda`, `pip`, `apt-get` and so on),
+   then you should create an inherited image and install them only once while building your Dockerfile.
+   An example for using `mamba` and `pip` in a child image is available
+   [here](./recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
+
+   ```{note}
+   If you install a package inside a running container (for example you run `pip install <package>` in a terminal),
+   it won't be preserved when you next run your image.
+   To make it work, install this package in your inherited image and rerun `docker build` command.
+   ```
+
+2. If you want to persist user-data (files created by you, like `python` scripts, notebooks, text files and so on),
+   then you should use a
+   [Docker bind mount](https://docs.docker.com/storage/bind-mounts/) or
+   [Docker Volume](https://docs.docker.com/storage/volumes/).
+   You can find [an example of using bind mount here](./running.md#example-2).
+   There is also [a mount troubleshooting section](./troubleshooting.md#permission-denied-when-mounting-volumes) if you experience any issues.
+
 ## Why we do not add your favorite package
 
 We have lots of users with different packages they want to use.",Yes
docs/using/recipes.md,docs/using/recipes.md,948f0bb3365f9b2a35a6ed01c313eb39b11dbc3a,cf9a8b6624588b5e1f5955aacaecabf61be061c7,"Add info how to persist user data (#1977)

* Add info how to persist user data

* Improve wording

* Add note

* Better wording","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 8b958067..cfeb4ced 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -44,6 +44,14 @@ Then build a new image.
 docker build --rm --tag my-custom-image .
 ```
 
+You can then run the image as follows:
+
+```bash
+docker run -it --rm \
+    -p 8888:8888 \
+    my-custom-image
+```
+
 ## Add a custom conda environment and Jupyter kernel
 
 The default version of `Python` that ships with the image may not be the version you want.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 8b958067..cfeb4ced 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -44,6 +44,14 @@ Then build a new image.
 docker build --rm --tag my-custom-image .
 ```
 
+You can then run the image as follows:
+
+```bash
+docker run -it --rm \
+    -p 8888:8888 \
+    my-custom-image
+```
+
 ## Add a custom conda environment and Jupyter kernel
 
 The default version of `Python` that ships with the image may not be the version you want.",Yes
docs/using/running.md,docs/using/running.md,948f0bb3365f9b2a35a6ed01c313eb39b11dbc3a,cf9a8b6624588b5e1f5955aacaecabf61be061c7,"Add info how to persist user data (#1977)

* Add info how to persist user data

* Improve wording

* Add note

* Better wording","diff --git a/docs/using/running.md b/docs/using/running.md
index 822a2efc..d8761fbf 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -13,7 +13,7 @@ You can launch a local Docker container from the Jupyter Docker Stacks using the
 There are numerous ways to configure containers using the CLI.
 The following are some common patterns.
 
-**Example 1:**
+### Example 1
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
@@ -51,7 +51,7 @@ docker rm 221331c047c4
 # 221331c047c4
 ```
 
-**Example 2:**
+### Example 2
 
 This command pulls the `jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
@@ -72,7 +72,7 @@ So, new notebooks will be saved there, unless you change the directory in the fi
 To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
-**Example 3:**
+### Example 3
 
 This command pulls the `jupyter/all-spark-notebook` image currently tagged `latest` from Docker Hub if an image tagged `latest` is not already present on the local host.
 It then starts a container named `notebook` running a JupyterLab server and exposes the server on a randomly selected port.
@@ -118,7 +118,7 @@ docker rm notebook
 
 An alternative to using the Docker CLI is to use the Podman CLI. Podman is mostly compatible with Docker.
 
-**Example 4:**
+### Podman example
 
 If we use Podman instead of Docker in the situation given in _Example 2_, it will look like this:","diff --git a/docs/using/running.md b/docs/using/running.md
index 822a2efc..d8761fbf 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -13,7 +13,7 @@ You can launch a local Docker container from the Jupyter Docker Stacks using the
 There are numerous ways to configure containers using the CLI.
 The following are some common patterns.
 
-**Example 1:**
+### Example 1
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
@@ -51,7 +51,7 @@ docker rm 221331c047c4
 # 221331c047c4
 ```
 
-**Example 2:**
+### Example 2
 
 This command pulls the `jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
@@ -72,7 +72,7 @@ So, new notebooks will be saved there, unless you change the directory in the fi
 To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
-**Example 3:**
+### Example 3
 
 This command pulls the `jupyter/all-spark-notebook` image currently tagged `latest` from Docker Hub if an image tagged `latest` is not already present on the local host.
 It then starts a container named `notebook` running a JupyterLab server and exposes the server on a randomly selected port.
@@ -118,7 +118,7 @@ docker rm notebook
 
 An alternative to using the Docker CLI is to use the Podman CLI. Podman is mostly compatible with Docker.
 
-**Example 4:**
+### Podman example
 
 If we use Podman instead of Docker in the situation given in _Example 2_, it will look like this:",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,9b9cccc821b3addef80954061719ceaac76e68ec,948f0bb3365f9b2a35a6ed01c313eb39b11dbc3a,Move host arch to a separate field of bug report,"diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index a76cbf52..e520d5e1 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -35,10 +35,19 @@ body:
 
   - type: input
     attributes:
-      label: Host OS system and architecture running docker image
+      label: Host OS system
       placeholder: |
         Example:
-        Ubuntu 22.04 / aarch64
+        Ubuntu 22.04
+    validations:
+      required: true
+
+  - type: dropdown
+    attributes:
+      label: Host architecture
+      options:
+        - x86_64
+        - aarch64
     validations:
       required: true","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index a76cbf52..e520d5e1 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -35,10 +35,19 @@ body:
 
   - type: input
     attributes:
-      label: Host OS system and architecture running docker image
+      label: Host OS system
       placeholder: |
         Example:
-        Ubuntu 22.04 / aarch64
+        Ubuntu 22.04
+    validations:
+      required: true
+
+  - type: dropdown
+    attributes:
+      label: Host architecture
+      options:
+        - x86_64
+        - aarch64
     validations:
       required: true",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,2c2bdae247000d4b2ac3cee864ada3f2496113ee,9b9cccc821b3addef80954061719ceaac76e68ec,Use base-notebook in issue template,"diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index e520d5e1..2ccb3bb9 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -58,7 +58,7 @@ body:
         What complete docker command do you run to launch the container (omitting sensitive values)?
       placeholder: |
         Example:
-        `docker run -it --rm -p 8888:8888 jupyter/all-spark-notebook`
+        `docker run -it --rm -p 8888:8888 jupyter/base-notebook`
     validations:
       required: true","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index e520d5e1..2ccb3bb9 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -58,7 +58,7 @@ body:
         What complete docker command do you run to launch the container (omitting sensitive values)?
       placeholder: |
         Example:
-        `docker run -it --rm -p 8888:8888 jupyter/all-spark-notebook`
+        `docker run -it --rm -p 8888:8888 jupyter/base-notebook`
     validations:
       required: true",Yes
docs/using/recipe_code/custom_environment.dockerfile,docs/using/recipe_code/custom_environment.dockerfile,b88eba3e59612d80fc333086d01db7a366c6e082,2c2bdae247000d4b2ac3cee864ada3f2496113ee,"Update the custom env recipe to correctly activate it by default (#1975)

* Update the custom env recipe to correctly activate it by default

* Remove obsolete line

* Better wording","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 5cbe5e5d..11bca849 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,8 +1,8 @@
 FROM jupyter/base-notebook
 
 # Name your environment and choose the python version
-ARG env_name=python38
-ARG py_ver=3.8
+ARG env_name=python310
+ARG py_ver=3.10
 
 # You can add additional libraries here
 RUN mamba create --yes -p ""${CONDA_DIR}/envs/${env_name}"" \
@@ -28,6 +28,17 @@ RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --nam
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
     'flake8'
 
-# If you do not want this environment to be the default one, comment this line
-# hadolint ignore=DL3059
+# Creating a startup hook, which will activate our custom environment by default in Jupyter Notebook
+# More info about startup hooks: https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#startup-hooks
+# You can comment this section to keep the default environment in Jupyter Notebook
+USER root
+RUN activate_custom_env_script=/usr/local/bin/before-notebook.d/activate_custom_env.sh && \
+    echo ""#!/bin/bash"" > ${activate_custom_env_script} && \
+    echo ""eval \""$(conda shell.bash activate ""${env_name}"")\"""" >> ${activate_custom_env_script} && \
+    chmod +x ${activate_custom_env_script}
+
+USER ${NB_UID}
+
+# Making this environment default in Terminal
+# You can comment this line to keep the default environment in Terminal
 RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 5cbe5e5d..11bca849 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,8 +1,8 @@
 FROM jupyter/base-notebook
 
 # Name your environment and choose the python version
-ARG env_name=python38
-ARG py_ver=3.8
+ARG env_name=python310
+ARG py_ver=3.10
 
 # You can add additional libraries here
 RUN mamba create --yes -p ""${CONDA_DIR}/envs/${env_name}"" \
@@ -28,6 +28,17 @@ RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --nam
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
     'flake8'
 
-# If you do not want this environment to be the default one, comment this line
-# hadolint ignore=DL3059
+# Creating a startup hook, which will activate our custom environment by default in Jupyter Notebook
+# More info about startup hooks: https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#startup-hooks
+# You can comment this section to keep the default environment in Jupyter Notebook
+USER root
+RUN activate_custom_env_script=/usr/local/bin/before-notebook.d/activate_custom_env.sh && \
+    echo ""#!/bin/bash"" > ${activate_custom_env_script} && \
+    echo ""eval \""$(conda shell.bash activate ""${env_name}"")\"""" >> ${activate_custom_env_script} && \
+    chmod +x ${activate_custom_env_script}
+
+USER ${NB_UID}
+
+# Making this environment default in Terminal
+# You can comment this line to keep the default environment in Terminal
 RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,5f8524df5b20ce8d0e9daefb48eaa45a85382d5d,b88eba3e59612d80fc333086d01db7a366c6e082,Use long options in useradd (#1978),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index b9663dea..d3504eb1 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -67,7 +67,7 @@ RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashr
 RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
     sed -i.bak -e 's/^%admin/#%admin/' /etc/sudoers && \
     sed -i.bak -e 's/^%sudo/#%sudo/' /etc/sudoers && \
-    useradd -l -m -s /bin/bash -N -u ""${NB_UID}"" ""${NB_USER}"" && \
+    useradd --no-log-init --create-home --shell /bin/bash --uid ""${NB_UID}"" --no-user-group ""${NB_USER}"" && \
     mkdir -p ""${CONDA_DIR}"" && \
     chown ""${NB_USER}:${NB_GID}"" ""${CONDA_DIR}"" && \
     chmod g+w /etc/passwd && \","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index b9663dea..d3504eb1 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -67,7 +67,7 @@ RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashr
 RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
     sed -i.bak -e 's/^%admin/#%admin/' /etc/sudoers && \
     sed -i.bak -e 's/^%sudo/#%sudo/' /etc/sudoers && \
-    useradd -l -m -s /bin/bash -N -u ""${NB_UID}"" ""${NB_USER}"" && \
+    useradd --no-log-init --create-home --shell /bin/bash --uid ""${NB_UID}"" --no-user-group ""${NB_USER}"" && \
     mkdir -p ""${CONDA_DIR}"" && \
     chown ""${NB_USER}:${NB_GID}"" ""${CONDA_DIR}"" && \
     chmod g+w /etc/passwd && \",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,5f8524df5b20ce8d0e9daefb48eaa45a85382d5d,b88eba3e59612d80fc333086d01db7a366c6e082,Use long options in useradd (#1978),"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index d1a0a3ea..4ccd3792 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -101,7 +101,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         fi
         # Recreate the desired user as we want it
         userdel ""${NB_USER}""
-        useradd --home ""/home/${NB_USER}"" --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 --no-log-init ""${NB_USER}""
+        useradd --no-log-init --home ""/home/${NB_USER}"" --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
     fi
 
     # Move or symlink the jovyan home directory to the desired users home","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index d1a0a3ea..4ccd3792 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -101,7 +101,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         fi
         # Recreate the desired user as we want it
         userdel ""${NB_USER}""
-        useradd --home ""/home/${NB_USER}"" --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 --no-log-init ""${NB_USER}""
+        useradd --no-log-init --home ""/home/${NB_USER}"" --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
     fi
 
     # Move or symlink the jovyan home directory to the desired users home",Yes
docs/conf.py,docs/conf.py,ecf4ea5f86910faf86c101159cc671010989046e,5f8524df5b20ce8d0e9daefb48eaa45a85382d5d,"Revert ""Replace rodbc link fow now""

This reverts commit 73d6fe4f556a85ce5edfefea9ca73fcc29b743bb.","diff --git a/docs/conf.py b/docs/conf.py
index 7b828b1e..dad3b3cb 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -71,5 +71,4 @@ linkcheck_allowed_redirects = {
     r""https://results\.pre-commit\.ci/latest/github/jupyter/docker-stacks/main"": r""https://results\.pre-commit\.ci/run/github/.*"",  # Latest main CI build
     r""https://github\.com/jupyter/docker-stacks/issues/new.*"": r""https://github\.com/login.*"",  # GitHub wants user to be logon to use this features
     r""https://github\.com/orgs/jupyter/teams/docker-image-maintainers/members"": r""https://github\.com/login.*"",
-    r""https://www\.rdocumentation.org/packages/RODBC/"": r""https://www\.rdocumentation.org/packages/RODBC/*"",
 }","diff --git a/docs/conf.py b/docs/conf.py
index 7b828b1e..dad3b3cb 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -71,5 +71,4 @@ linkcheck_allowed_redirects = {
     r""https://results\.pre-commit\.ci/latest/github/jupyter/docker-stacks/main"": r""https://results\.pre-commit\.ci/run/github/.*"",  # Latest main CI build
     r""https://github\.com/jupyter/docker-stacks/issues/new.*"": r""https://github\.com/login.*"",  # GitHub wants user to be logon to use this features
     r""https://github\.com/orgs/jupyter/teams/docker-image-maintainers/members"": r""https://github\.com/login.*"",
-    r""https://www\.rdocumentation.org/packages/RODBC/"": r""https://www\.rdocumentation.org/packages/RODBC/*"",
 }",Yes
docs/using/selecting.md,docs/using/selecting.md,ecf4ea5f86910faf86c101159cc671010989046e,5f8524df5b20ce8d0e9daefb48eaa45a85382d5d,"Revert ""Replace rodbc link fow now""

This reverts commit 73d6fe4f556a85ce5edfefea9ca73fcc29b743bb.","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 77837733..dd5cd0f4 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -103,7 +103,7 @@ It contains:
   [randomforest](https://cran.r-project.org/web/packages/randomForest/index.html),
   [rcurl](https://cran.r-project.org/web/packages/RCurl/index.html),
   [rmarkdown](https://rmarkdown.rstudio.com),
-  [rodbc](https://www.rdocumentation.org/packages/RODBC/),
+  [rodbc](https://cran.r-project.org/web/packages/RODBC/index.html),
   [rsqlite](https://cran.r-project.org/web/packages/RSQLite/index.html),
   [shiny](https://shiny.posit.co),
   [tidymodels](https://www.tidymodels.org/),","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 77837733..dd5cd0f4 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -103,7 +103,7 @@ It contains:
   [randomforest](https://cran.r-project.org/web/packages/randomForest/index.html),
   [rcurl](https://cran.r-project.org/web/packages/RCurl/index.html),
   [rmarkdown](https://rmarkdown.rstudio.com),
-  [rodbc](https://www.rdocumentation.org/packages/RODBC/),
+  [rodbc](https://cran.r-project.org/web/packages/RODBC/index.html),
   [rsqlite](https://cran.r-project.org/web/packages/RSQLite/index.html),
   [shiny](https://shiny.posit.co),
   [tidymodels](https://www.tidymodels.org/),",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,d400e383cc1df74dde5bea5468f8bb812546d62d,ecf4ea5f86910faf86c101159cc671010989046e,Update some links,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 6bb19b37..ee6132ec 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.4.1
+    rev: v1.5.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -52,7 +52,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.0.0
+    rev: v3.0.2
     hooks:
       - id: prettier
 
@@ -66,7 +66,7 @@ repos:
       - id: trailing-whitespace
 
   # Lint: Dockerfile
-  - repo: https://github.com/hadolint/hadolint.git
+  - repo: https://github.com/hadolint/hadolint
     rev: v2.12.1-beta
     hooks:
       - id: hadolint-docker
@@ -74,7 +74,7 @@ repos:
 
   # Lint: Dockerfile
   # We're linting .dockerfile files as well
-  - repo: https://github.com/hadolint/hadolint.git
+  - repo: https://github.com/hadolint/hadolint
     rev: v2.12.1-beta
     hooks:
       - id: hadolint-docker
@@ -84,7 +84,7 @@ repos:
         files: \.dockerfile$
 
   # Lint: YAML
-  - repo: https://github.com/adrienverge/yamllint.git
+  - repo: https://github.com/adrienverge/yamllint
     rev: v1.32.0
     hooks:
       - id: yamllint
@@ -92,7 +92,7 @@ repos:
         files: \.(yaml|yml)$
 
   # Lint: Bash scripts
-  - repo: https://github.com/openstack-dev/bashate.git
+  - repo: https://github.com/openstack/bashate
     rev: 2.1.1
     hooks:
       - id: bashate
@@ -137,13 +137,13 @@ repos:
       - id: nbqa-flake8
 
   # Run black on python code blocks in documentation files.
-  - repo: https://github.com/asottile/blacken-docs
-    rev: 1.15.0
+  - repo: https://github.com/adamchainz/blacken-docs
+    rev: 1.16.0
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if
         # the python code blocks includes jupyter specific additions such as % or !
-        # See https://github.com/asottile/blacken-docs/issues/127 for an upstream
+        # See https://github.com/adamchainz/blacken-docs/issues/127 for an upstream
         # feature request about this.
         args: [--target-version=py39, --skip-errors]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 6bb19b37..ee6132ec 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.4.1
+    rev: v1.5.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -52,7 +52,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.0.0
+    rev: v3.0.2
     hooks:
       - id: prettier
 
@@ -66,7 +66,7 @@ repos:
       - id: trailing-whitespace
 
   # Lint: Dockerfile
-  - repo: https://github.com/hadolint/hadolint.git
+  - repo: https://github.com/hadolint/hadolint
     rev: v2.12.1-beta
     hooks:
       - id: hadolint-docker
@@ -74,7 +74,7 @@ repos:
 
   # Lint: Dockerfile
   # We're linting .dockerfile files as well
-  - repo: https://github.com/hadolint/hadolint.git
+  - repo: https://github.com/hadolint/hadolint
     rev: v2.12.1-beta
     hooks:
       - id: hadolint-docker
@@ -84,7 +84,7 @@ repos:
         files: \.dockerfile$
 
   # Lint: YAML
-  - repo: https://github.com/adrienverge/yamllint.git
+  - repo: https://github.com/adrienverge/yamllint
     rev: v1.32.0
     hooks:
       - id: yamllint
@@ -92,7 +92,7 @@ repos:
         files: \.(yaml|yml)$
 
   # Lint: Bash scripts
-  - repo: https://github.com/openstack-dev/bashate.git
+  - repo: https://github.com/openstack/bashate
     rev: 2.1.1
     hooks:
       - id: bashate
@@ -137,13 +137,13 @@ repos:
       - id: nbqa-flake8
 
   # Run black on python code blocks in documentation files.
-  - repo: https://github.com/asottile/blacken-docs
-    rev: 1.15.0
+  - repo: https://github.com/adamchainz/blacken-docs
+    rev: 1.16.0
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if
         # the python code blocks includes jupyter specific additions such as % or !
-        # See https://github.com/asottile/blacken-docs/issues/127 for an upstream
+        # See https://github.com/adamchainz/blacken-docs/issues/127 for an upstream
         # feature request about this.
         args: [--target-version=py39, --skip-errors]",Yes
docs/conf.py,docs/conf.py,d400e383cc1df74dde5bea5468f8bb812546d62d,ecf4ea5f86910faf86c101159cc671010989046e,Update some links,"diff --git a/docs/conf.py b/docs/conf.py
index dad3b3cb..7ef2b342 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -57,7 +57,7 @@ source_suffix = {
 }
 pygments_style = ""sphinx""
 
-# MyST configuration reference: https://myst-parser.readthedocs.io/en/latest/sphinx/reference.html
+# MyST configuration reference: https://myst-parser.readthedocs.io/en/latest/configuration.html
 myst_heading_anchors = 3
 
 linkcheck_ignore = [","diff --git a/docs/conf.py b/docs/conf.py
index dad3b3cb..7ef2b342 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -57,7 +57,7 @@ source_suffix = {
 }
 pygments_style = ""sphinx""
 
-# MyST configuration reference: https://myst-parser.readthedocs.io/en/latest/sphinx/reference.html
+# MyST configuration reference: https://myst-parser.readthedocs.io/en/latest/configuration.html
 myst_heading_anchors = 3
 
 linkcheck_ignore = [",Yes
examples/make-deploy/letsencrypt.makefile,examples/make-deploy/letsencrypt.makefile,d400e383cc1df74dde5bea5468f8bb812546d62d,ecf4ea5f86910faf86c101159cc671010989046e,Update some links,"diff --git a/examples/make-deploy/letsencrypt.makefile b/examples/make-deploy/letsencrypt.makefile
index 3ef9b092..19549657 100644
--- a/examples/make-deploy/letsencrypt.makefile
+++ b/examples/make-deploy/letsencrypt.makefile
@@ -3,7 +3,7 @@
 
 # BE CAREFUL when using Docker engine <1.10 because running a container with
 # `--rm` option while mounting a docker volume may wipe out the volume.
-# See issue: https://github.com/docker/docker/issues/17907
+# See issue: https://github.com/moby/moby/issues/17907
 
 # Use letsencrypt production server by default to get a real cert.
 # Use CERT_SERVER=--staging to hit the staging server (not a real cert).","diff --git a/examples/make-deploy/letsencrypt.makefile b/examples/make-deploy/letsencrypt.makefile
index 3ef9b092..19549657 100644
--- a/examples/make-deploy/letsencrypt.makefile
+++ b/examples/make-deploy/letsencrypt.makefile
@@ -3,7 +3,7 @@
 
 # BE CAREFUL when using Docker engine <1.10 because running a container with
 # `--rm` option while mounting a docker volume may wipe out the volume.
-# See issue: https://github.com/docker/docker/issues/17907
+# See issue: https://github.com/moby/moby/issues/17907
 
 # Use letsencrypt production server by default to get a real cert.
 # Use CERT_SERVER=--staging to hit the staging server (not a real cert).",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,d400e383cc1df74dde5bea5468f8bb812546d62d,ecf4ea5f86910faf86c101159cc671010989046e,Update some links,"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 4ccd3792..b770efcd 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -178,7 +178,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         #   command. The behavior can be inspected with `sudo -V` run as root.
         #
         #   ref: `man sudo`    https://linux.die.net/man/8/sudo
-        #   ref: `man sudoers` https://www.sudo.ws/man/1.8.15/sudoers.man.html
+        #   ref: `man sudoers` https://www.sudo.ws/docs/man/sudoers.man/
         #
         # - We use the `--preserve-env` flag to pass through most environment
         #   variables, but understand that exceptions are caused by the sudoers","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 4ccd3792..b770efcd 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -178,7 +178,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         #   command. The behavior can be inspected with `sudo -V` run as root.
         #
         #   ref: `man sudo`    https://linux.die.net/man/8/sudo
-        #   ref: `man sudoers` https://www.sudo.ws/man/1.8.15/sudoers.man.html
+        #   ref: `man sudoers` https://www.sudo.ws/docs/man/sudoers.man/
         #
         # - We use the `--preserve-env` flag to pass through most environment
         #   variables, but understand that exceptions are caused by the sudoers",Yes
images/scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,d400e383cc1df74dde5bea5468f8bb812546d62d,ecf4ea5f86910faf86c101159cc671010989046e,Update some links,"diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 28382337..82708471 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -67,7 +67,7 @@ RUN mamba install --yes \
 
 # Install facets which does not have a pip or conda package at the moment
 WORKDIR /tmp
-RUN git clone https://github.com/PAIR-code/facets.git && \
+RUN git clone https://github.com/PAIR-code/facets && \
     jupyter nbclassic-extension install facets/facets-dist/ --sys-prefix && \
     rm -rf /tmp/facets && \
     fix-permissions ""${CONDA_DIR}"" && \","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 28382337..82708471 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -67,7 +67,7 @@ RUN mamba install --yes \
 
 # Install facets which does not have a pip or conda package at the moment
 WORKDIR /tmp
-RUN git clone https://github.com/PAIR-code/facets.git && \
+RUN git clone https://github.com/PAIR-code/facets && \
     jupyter nbclassic-extension install facets/facets-dist/ --sys-prefix && \
     rm -rf /tmp/facets && \
     fix-permissions ""${CONDA_DIR}"" && \",Yes
tests/base-notebook/test_packages.py,tests/base-notebook/test_packages.py,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,d400e383cc1df74dde5bea5468f8bb812546d62d,"Revert ""Temporarily disable tests using conda --json output""

This reverts commit bc938c50dcad95002eeb5be6c8fd2cd111554ded.","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index 9f6fef90..b56d6120 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -168,9 +168,6 @@ def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     )
 
 
-@pytest.mark.skip(
-    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
-)
 def test_r_packages(
     package_helper: CondaPackageHelper, r_packages: Iterable[str]
 ) -> None:
@@ -184,9 +181,6 @@ def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     return map(get_package_import_name, filter(python_package_predicate, packages))
 
 
-@pytest.mark.skip(
-    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
-)
 def test_python_packages(
     package_helper: CondaPackageHelper,
     python_packages: Iterable[str],","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index 9f6fef90..b56d6120 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -168,9 +168,6 @@ def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     )
 
 
-@pytest.mark.skip(
-    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
-)
 def test_r_packages(
     package_helper: CondaPackageHelper, r_packages: Iterable[str]
 ) -> None:
@@ -184,9 +181,6 @@ def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
     return map(get_package_import_name, filter(python_package_predicate, packages))
 
 
-@pytest.mark.skip(
-    reason=""conda 23.7.2 contains regression fix for --json and --debug flags, but it's not yet released on conda-forge""
-)
 def test_python_packages(
     package_helper: CondaPackageHelper,
     python_packages: Iterable[str],",Yes
docs/using/common.md,docs/using/common.md,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/docs/using/common.md b/docs/using/common.md
index 986ad735..dab66fed 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -86,7 +86,7 @@ You do so by passing arguments to the `docker run` command.
 
   ```{note}
   `NB_UMASK` when set only applies to the Jupyter process itself -
-  you cannot use it to set a `umask` for additional files created during run-hooks.
+  you cannot use it to set a `umask` for additional files created during `run-hooks.sh`.
   For example, via `pip` or `conda`.
   If you need to set a `umask` for these, you **must** set the `umask` value for each command.
   ```
@@ -135,7 +135,7 @@ or executables (`chmod +x`) to be run to the paths below:
 - `/usr/local/bin/before-notebook.d/` - handled **after** all the standard options noted above are applied
   and ran right before the Server launches
 
-See the `run-hooks` function in the [`jupyter/docker-stacks-foundation start.sh`](https://github.com/jupyter/docker-stacks/blob/main/images/docker-stacks-foundation/start.sh)
+See the `run-hooks.sh` script [here](https://github.com/jupyter/docker-stacks/blob/main/images/docker-stacks-foundation/run-hooks.sh) and how it's used in the [`start.sh`](https://github.com/jupyter/docker-stacks/blob/main/images/docker-stacks-foundation/start.sh)
 script for execution details.
 
 ## SSL Certificates","diff --git a/docs/using/common.md b/docs/using/common.md
index 986ad735..dab66fed 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -86,7 +86,7 @@ You do so by passing arguments to the `docker run` command.
 
   ```{note}
   `NB_UMASK` when set only applies to the Jupyter process itself -
-  you cannot use it to set a `umask` for additional files created during run-hooks.
+  you cannot use it to set a `umask` for additional files created during `run-hooks.sh`.
   For example, via `pip` or `conda`.
   If you need to set a `umask` for these, you **must** set the `umask` value for each command.
   ```
@@ -135,7 +135,7 @@ or executables (`chmod +x`) to be run to the paths below:
 - `/usr/local/bin/before-notebook.d/` - handled **after** all the standard options noted above are applied
   and ran right before the Server launches
 
-See the `run-hooks` function in the [`jupyter/docker-stacks-foundation start.sh`](https://github.com/jupyter/docker-stacks/blob/main/images/docker-stacks-foundation/start.sh)
+See the `run-hooks.sh` script [here](https://github.com/jupyter/docker-stacks/blob/main/images/docker-stacks-foundation/run-hooks.sh) and how it's used in the [`start.sh`](https://github.com/jupyter/docker-stacks/blob/main/images/docker-stacks-foundation/start.sh)
 script for execution details.
 
 ## SSL Certificates",Yes
docs/using/selecting.md,docs/using/selecting.md,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index dd5cd0f4..69e70553 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -36,6 +36,7 @@ It contains:
   with ownership over the `/home/jovyan` and `/opt/conda` paths
 - `tini` as the container entry point
 - A `start.sh` script as the default command - useful for running alternative commands in the container as applications are added (e.g. `ipython`, `jupyter kernelgateway`, `jupyter lab`)
+- A `run-hooks.sh` script, which can source/run files in a given directory
 - Options for a passwordless sudo
 - Common system libraries like `bzip2`, `ca-certificates`, `locales`
 - `wget` to download external files","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index dd5cd0f4..69e70553 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -36,6 +36,7 @@ It contains:
   with ownership over the `/home/jovyan` and `/opt/conda` paths
 - `tini` as the container entry point
 - A `start.sh` script as the default command - useful for running alternative commands in the container as applications are added (e.g. `ipython`, `jupyter kernelgateway`, `jupyter lab`)
+- A `run-hooks.sh` script, which can source/run files in a given directory
 - Options for a passwordless sudo
 - Common system libraries like `bzip2`, `ca-certificates`, `locales`
 - `wget` to download external files",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index d3504eb1..5fbcd86c 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -127,7 +127,7 @@ ENTRYPOINT [""tini"", ""-g"", ""--""]
 CMD [""start.sh""]
 
 # Copy local files as late as possible to avoid cache busting
-COPY start.sh /usr/local/bin/
+COPY run-hooks.sh start.sh /usr/local/bin/
 
 USER root","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index d3504eb1..5fbcd86c 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -127,7 +127,7 @@ ENTRYPOINT [""tini"", ""-g"", ""--""]
 CMD [""start.sh""]
 
 # Copy local files as late as possible to avoid cache busting
-COPY start.sh /usr/local/bin/
+COPY run-hooks.sh start.sh /usr/local/bin/
 
 USER root",Yes
,images/docker-stacks-foundation/run-hooks.sh,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/images/docker-stacks-foundation/run-hooks.sh b/images/docker-stacks-foundation/run-hooks.sh
new file mode 100755
index 00000000..146b1e14
--- /dev/null
+++ b/images/docker-stacks-foundation/run-hooks.sh
@@ -0,0 +1,38 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# The run-hooks.sh script looks for *.sh scripts to source
+# and executable files to run within a passed directory
+
+if [ ""$#"" -ne 1 ]; then
+    echo ""Should pass exactly one directory""
+    return 1
+fi
+
+if [[ ! -d ""${1}"" ]] ; then
+    echo ""Directory ${1} doesn't exist or is not a directory""
+    return 1
+fi
+
+echo ""Running hooks in: ${1} as uid: $(id -u) gid: $(id -g)""
+for f in ""${1}/""*; do
+    # Hadling a case when the directory is empty
+    [ -e ""${f}"" ] || continue
+    case ""${f}"" in
+        *.sh)
+            echo ""Sourcing shell script: ${f}""
+            # shellcheck disable=SC1090
+            source ""${f}""
+            ;;
+        *)
+            if [ -x ""${f}"" ] ; then
+                echo ""Running executable: ${f}""
+                ""${f}""
+            else
+                echo ""Ignoring non-executable: ${f}""
+            fi
+            ;;
+    esac
+done
+echo ""Done running hooks in: ${1}""","diff --git a/images/docker-stacks-foundation/run-hooks.sh b/images/docker-stacks-foundation/run-hooks.sh
new file mode 100755
index 00000000..146b1e14
--- /dev/null
+++ b/images/docker-stacks-foundation/run-hooks.sh
@@ -0,0 +1,38 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# The run-hooks.sh script looks for *.sh scripts to source
+# and executable files to run within a passed directory
+
+if [ ""$#"" -ne 1 ]; then
+    echo ""Should pass exactly one directory""
+    return 1
+fi
+
+if [[ ! -d ""${1}"" ]] ; then
+    echo ""Directory ${1} doesn't exist or is not a directory""
+    return 1
+fi
+
+echo ""Running hooks in: ${1} as uid: $(id -u) gid: $(id -g)""
+for f in ""${1}/""*; do
+    # Hadling a case when the directory is empty
+    [ -e ""${f}"" ] || continue
+    case ""${f}"" in
+        *.sh)
+            echo ""Sourcing shell script: ${f}""
+            # shellcheck disable=SC1090
+            source ""${f}""
+            ;;
+        *)
+            if [ -x ""${f}"" ] ; then
+                echo ""Running executable: ${f}""
+                ""${f}""
+            else
+                echo ""Ignoring non-executable: ${f}""
+            fi
+            ;;
+    esac
+done
+echo ""Done running hooks in: ${1}""",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index b770efcd..d8b97bdb 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -14,33 +14,6 @@ _log () {
 }
 _log ""Entered start.sh with args:"" ""$@""
 
-# The run-hooks function looks for .sh scripts to source and executable files to
-# run within a passed directory.
-run-hooks () {
-    if [[ ! -d ""${1}"" ]] ; then
-        return
-    fi
-    _log ""${0}: running hooks in: ${1} as uid: $(id -u) gid: $(id -g)""
-    for f in ""${1}/""*; do
-        case ""${f}"" in
-            *.sh)
-                _log ""${0}: sourcing shell script: ${f}""
-                # shellcheck disable=SC1090
-                source ""${f}""
-                ;;
-            *)
-                if [[ -x ""${f}"" ]] ; then
-                    _log ""${0}: running executable: ${f}""
-                    ""${f}""
-                else
-                    _log ""${0}: ignoring non-executable: ${f}""
-                fi
-                ;;
-        esac
-    done
-    _log ""${0}: done running hooks in: ${1}""
-}
-
 # A helper function to unset env vars listed in the value of the env var
 # JUPYTER_ENV_VARS_TO_UNSET.
 unset_explicit_env_vars () {
@@ -62,7 +35,8 @@ else
 fi
 
 # NOTE: This hook will run as the user the container was started with!
-run-hooks /usr/local/bin/start-notebook.d
+# shellcheck disable=SC1091
+source /usr/local/bin/run-hooks.sh /usr/local/bin/start-notebook.d
 
 # If the container started as the root user, then we have permission to refit
 # the jovyan user, and ensure file permissions, grant sudo rights, and such
@@ -160,7 +134,8 @@ if [ ""$(id -u)"" == 0 ] ; then
     fi
 
     # NOTE: This hook is run as the root user!
-    run-hooks /usr/local/bin/before-notebook.d
+    # shellcheck disable=SC1091
+    source /usr/local/bin/run-hooks.sh /usr/local/bin/before-notebook.d
 
     unset_explicit_env_vars
     _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
@@ -255,7 +230,8 @@ else
     fi
 
     # NOTE: This hook is run as the user we started the container as!
-    run-hooks /usr/local/bin/before-notebook.d
+    # shellcheck disable=SC1091
+    source /usr/local/bin/run-hooks.sh /usr/local/bin/before-notebook.d
     unset_explicit_env_vars
     _log ""Executing the command:"" ""${cmd[@]}""
     exec ""${cmd[@]}""","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index b770efcd..d8b97bdb 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -14,33 +14,6 @@ _log () {
 }
 _log ""Entered start.sh with args:"" ""$@""
 
-# The run-hooks function looks for .sh scripts to source and executable files to
-# run within a passed directory.
-run-hooks () {
-    if [[ ! -d ""${1}"" ]] ; then
-        return
-    fi
-    _log ""${0}: running hooks in: ${1} as uid: $(id -u) gid: $(id -g)""
-    for f in ""${1}/""*; do
-        case ""${f}"" in
-            *.sh)
-                _log ""${0}: sourcing shell script: ${f}""
-                # shellcheck disable=SC1090
-                source ""${f}""
-                ;;
-            *)
-                if [[ -x ""${f}"" ]] ; then
-                    _log ""${0}: running executable: ${f}""
-                    ""${f}""
-                else
-                    _log ""${0}: ignoring non-executable: ${f}""
-                fi
-                ;;
-        esac
-    done
-    _log ""${0}: done running hooks in: ${1}""
-}
-
 # A helper function to unset env vars listed in the value of the env var
 # JUPYTER_ENV_VARS_TO_UNSET.
 unset_explicit_env_vars () {
@@ -62,7 +35,8 @@ else
 fi
 
 # NOTE: This hook will run as the user the container was started with!
-run-hooks /usr/local/bin/start-notebook.d
+# shellcheck disable=SC1091
+source /usr/local/bin/run-hooks.sh /usr/local/bin/start-notebook.d
 
 # If the container started as the root user, then we have permission to refit
 # the jovyan user, and ensure file permissions, grant sudo rights, and such
@@ -160,7 +134,8 @@ if [ ""$(id -u)"" == 0 ] ; then
     fi
 
     # NOTE: This hook is run as the root user!
-    run-hooks /usr/local/bin/before-notebook.d
+    # shellcheck disable=SC1091
+    source /usr/local/bin/run-hooks.sh /usr/local/bin/before-notebook.d
 
     unset_explicit_env_vars
     _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
@@ -255,7 +230,8 @@ else
     fi
 
     # NOTE: This hook is run as the user we started the container as!
-    run-hooks /usr/local/bin/before-notebook.d
+    # shellcheck disable=SC1091
+    source /usr/local/bin/run-hooks.sh /usr/local/bin/before-notebook.d
     unset_explicit_env_vars
     _log ""Executing the command:"" ""${cmd[@]}""
     exec ""${cmd[@]}""",Yes
tests/conftest.py,tests/conftest.py,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/tests/conftest.py b/tests/conftest.py
index f7a538a8..8f633d47 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -108,6 +108,7 @@ class TrackedContainer:
         timeout: int,
         no_warnings: bool = True,
         no_errors: bool = True,
+        no_failure: bool = True,
         **kwargs: Any,
     ) -> str:
         running_container = self.run_detached(**kwargs)
@@ -119,7 +120,10 @@ class TrackedContainer:
             assert not self.get_warnings(logs)
         if no_errors:
             assert not self.get_errors(logs)
-        assert rv == 0 or rv[""StatusCode""] == 0
+        if no_failure:
+            assert rv == 0 or rv[""StatusCode""] == 0
+        else:
+            assert rv != 0 and rv[""StatusCode""] != 0
         return logs
 
     @staticmethod","diff --git a/tests/conftest.py b/tests/conftest.py
index f7a538a8..8f633d47 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -108,6 +108,7 @@ class TrackedContainer:
         timeout: int,
         no_warnings: bool = True,
         no_errors: bool = True,
+        no_failure: bool = True,
         **kwargs: Any,
     ) -> str:
         running_container = self.run_detached(**kwargs)
@@ -119,7 +120,10 @@ class TrackedContainer:
             assert not self.get_warnings(logs)
         if no_errors:
             assert not self.get_errors(logs)
-        assert rv == 0 or rv[""StatusCode""] == 0
+        if no_failure:
+            assert rv == 0 or rv[""StatusCode""] == 0
+        else:
+            assert rv != 0 and rv[""StatusCode""] != 0
         return logs
 
     @staticmethod",Yes
,tests/docker-stacks-foundation/run-hooks-data/executable.py,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/tests/docker-stacks-foundation/run-hooks-data/executable.py b/tests/docker-stacks-foundation/run-hooks-data/executable.py
new file mode 100755
index 00000000..5fb2b9a3
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-data/executable.py
@@ -0,0 +1,5 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+print(""Executable python file was successfully run"")","diff --git a/tests/docker-stacks-foundation/run-hooks-data/executable.py b/tests/docker-stacks-foundation/run-hooks-data/executable.py
new file mode 100755
index 00000000..5fb2b9a3
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-data/executable.py
@@ -0,0 +1,5 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+print(""Executable python file was successfully run"")",Yes
,tests/docker-stacks-foundation/run-hooks-data/non_executable.py,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/tests/docker-stacks-foundation/run-hooks-data/non_executable.py b/tests/docker-stacks-foundation/run-hooks-data/non_executable.py
new file mode 100644
index 00000000..19c8d0b7
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-data/non_executable.py
@@ -0,0 +1,5 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+assert False","diff --git a/tests/docker-stacks-foundation/run-hooks-data/non_executable.py b/tests/docker-stacks-foundation/run-hooks-data/non_executable.py
new file mode 100644
index 00000000..19c8d0b7
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-data/non_executable.py
@@ -0,0 +1,5 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+assert False",Yes
,tests/docker-stacks-foundation/run-hooks-data/run-me.sh,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/tests/docker-stacks-foundation/run-hooks-data/run-me.sh b/tests/docker-stacks-foundation/run-hooks-data/run-me.sh
new file mode 100644
index 00000000..f4dc08aa
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-data/run-me.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+export SOME_VAR=123","diff --git a/tests/docker-stacks-foundation/run-hooks-data/run-me.sh b/tests/docker-stacks-foundation/run-hooks-data/run-me.sh
new file mode 100644
index 00000000..f4dc08aa
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-data/run-me.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+export SOME_VAR=123",Yes
,tests/docker-stacks-foundation/test_run_hooks.py,74bbd0bffc3b444e2d65279739bc2d681b6199e2,c2bf3c6bfd5ca26b1ef069d7d8d8722101cb1006,"Implement run-hooks as a separate script (#1979)

* Implement run-hooks as a separate script

* Add more tests

* Add more docs","diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
new file mode 100644
index 00000000..c97d4ec7
--- /dev/null
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -0,0 +1,95 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import logging
+from pathlib import Path
+
+from tests.conftest import TrackedContainer
+
+LOGGER = logging.getLogger(__name__)
+THIS_DIR = Path(__file__).parent.resolve()
+
+
+def test_run_hooks_zero_args(container: TrackedContainer) -> None:
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        no_failure=False,
+        command=[""bash"", ""-c"", ""source /usr/local/bin/run-hooks.sh""],
+    )
+    assert ""Should pass exactly one directory"" in logs
+
+
+def test_run_hooks_two_args(container: TrackedContainer) -> None:
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        no_failure=False,
+        command=[
+            ""bash"",
+            ""-c"",
+            ""source /usr/local/bin/run-hooks.sh first-arg second-arg"",
+        ],
+    )
+    assert ""Should pass exactly one directory"" in logs
+
+
+def test_run_hooks_missing_dir(container: TrackedContainer) -> None:
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        no_failure=False,
+        command=[
+            ""bash"",
+            ""-c"",
+            ""source /usr/local/bin/run-hooks.sh /tmp/missing-dir/"",
+        ],
+    )
+    assert ""Directory /tmp/missing-dir/ doesn't exist or is not a directory"" in logs
+
+
+def test_run_hooks_dir_is_file(container: TrackedContainer) -> None:
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        no_failure=False,
+        command=[
+            ""bash"",
+            ""-c"",
+            ""touch /tmp/some-file && source /usr/local/bin/run-hooks.sh /tmp/some-file"",
+        ],
+    )
+    assert ""Directory /tmp/some-file doesn't exist or is not a directory"" in logs
+
+
+def test_run_hooks_empty_dir(container: TrackedContainer) -> None:
+    container.run_and_wait(
+        timeout=5,
+        tty=True,
+        command=[
+            ""bash"",
+            ""-c"",
+            ""mkdir /tmp/empty-dir && source /usr/local/bin/run-hooks.sh /tmp/empty-dir/"",
+        ],
+    )
+
+
+def test_run_hooks_with_files(container: TrackedContainer) -> None:
+    host_data_dir = THIS_DIR / ""run-hooks-data""
+    cont_data_dir = ""/home/jovyan/data""
+    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
+    # Unfortunately, Docker treats all files in mounter dir as executable files
+    # So we make a copy of mounted dir inside a container
+    command = (
+        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
+        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/ &&""
+        ""echo SOME_VAR is ${SOME_VAR}""
+    )
+    logs = container.run_and_wait(
+        timeout=5,
+        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
+        tty=True,
+        command=[""bash"", ""-c"", command],
+    )
+    assert ""Executable python file was successfully"" in logs
+    assert ""Ignoring non-executable: /home/jovyan/data-copy//non_executable.py"" in logs
+    assert ""SOME_VAR is 123"" in logs","diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
new file mode 100644
index 00000000..c97d4ec7
--- /dev/null
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -0,0 +1,95 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import logging
+from pathlib import Path
+
+from tests.conftest import TrackedContainer
+
+LOGGER = logging.getLogger(__name__)
+THIS_DIR = Path(__file__).parent.resolve()
+
+
+def test_run_hooks_zero_args(container: TrackedContainer) -> None:
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        no_failure=False,
+        command=[""bash"", ""-c"", ""source /usr/local/bin/run-hooks.sh""],
+    )
+    assert ""Should pass exactly one directory"" in logs
+
+
+def test_run_hooks_two_args(container: TrackedContainer) -> None:
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        no_failure=False,
+        command=[
+            ""bash"",
+            ""-c"",
+            ""source /usr/local/bin/run-hooks.sh first-arg second-arg"",
+        ],
+    )
+    assert ""Should pass exactly one directory"" in logs
+
+
+def test_run_hooks_missing_dir(container: TrackedContainer) -> None:
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        no_failure=False,
+        command=[
+            ""bash"",
+            ""-c"",
+            ""source /usr/local/bin/run-hooks.sh /tmp/missing-dir/"",
+        ],
+    )
+    assert ""Directory /tmp/missing-dir/ doesn't exist or is not a directory"" in logs
+
+
+def test_run_hooks_dir_is_file(container: TrackedContainer) -> None:
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        no_failure=False,
+        command=[
+            ""bash"",
+            ""-c"",
+            ""touch /tmp/some-file && source /usr/local/bin/run-hooks.sh /tmp/some-file"",
+        ],
+    )
+    assert ""Directory /tmp/some-file doesn't exist or is not a directory"" in logs
+
+
+def test_run_hooks_empty_dir(container: TrackedContainer) -> None:
+    container.run_and_wait(
+        timeout=5,
+        tty=True,
+        command=[
+            ""bash"",
+            ""-c"",
+            ""mkdir /tmp/empty-dir && source /usr/local/bin/run-hooks.sh /tmp/empty-dir/"",
+        ],
+    )
+
+
+def test_run_hooks_with_files(container: TrackedContainer) -> None:
+    host_data_dir = THIS_DIR / ""run-hooks-data""
+    cont_data_dir = ""/home/jovyan/data""
+    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
+    # Unfortunately, Docker treats all files in mounter dir as executable files
+    # So we make a copy of mounted dir inside a container
+    command = (
+        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
+        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/ &&""
+        ""echo SOME_VAR is ${SOME_VAR}""
+    )
+    logs = container.run_and_wait(
+        timeout=5,
+        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
+        tty=True,
+        command=[""bash"", ""-c"", command],
+    )
+    assert ""Executable python file was successfully"" in logs
+    assert ""Ignoring non-executable: /home/jovyan/data-copy//non_executable.py"" in logs
+    assert ""SOME_VAR is 123"" in logs",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,2aa9e0fe363ed6a9b6f4a4777558862e77c63362,74bbd0bffc3b444e2d65279739bc2d681b6199e2,"Add --build-arg OWNER to build process, so forks use correct images","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 8afd780f..7453f681 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -60,7 +60,7 @@ jobs:
         shell: bash
 
       - name: Build image 🛠
-        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/
+        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/ --build-arg OWNER=${{ env.OWNER }}
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 8afd780f..7453f681 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -60,7 +60,7 @@ jobs:
         shell: bash
 
       - name: Build image 🛠
-        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/
+        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/ --build-arg OWNER=${{ env.OWNER }}
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,44f9962dcb12025cf08a02d88afe645b7e03d460,2aa9e0fe363ed6a9b6f4a4777558862e77c63362,Specify /bin/bash shell in useradd (#1980),"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index d8b97bdb..1a559dbc 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -75,7 +75,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         fi
         # Recreate the desired user as we want it
         userdel ""${NB_USER}""
-        useradd --no-log-init --home ""/home/${NB_USER}"" --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
+        useradd --no-log-init --home ""/home/${NB_USER}"" --shell /bin/bash --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
     fi
 
     # Move or symlink the jovyan home directory to the desired users home","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index d8b97bdb..1a559dbc 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -75,7 +75,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         fi
         # Recreate the desired user as we want it
         userdel ""${NB_USER}""
-        useradd --no-log-init --home ""/home/${NB_USER}"" --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
+        useradd --no-log-init --home ""/home/${NB_USER}"" --shell /bin/bash --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
     fi
 
     # Move or symlink the jovyan home directory to the desired users home",Yes
tests/conftest.py,tests/conftest.py,7a4381ff2fd1c30f62c0f57ea13b7c08087c6077,44f9962dcb12025cf08a02d88afe645b7e03d460,Use only rv['StatusCode'] to simplify code (#1982),"diff --git a/tests/conftest.py b/tests/conftest.py
index 8f633d47..0e592543 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -120,10 +120,7 @@ class TrackedContainer:
             assert not self.get_warnings(logs)
         if no_errors:
             assert not self.get_errors(logs)
-        if no_failure:
-            assert rv == 0 or rv[""StatusCode""] == 0
-        else:
-            assert rv != 0 and rv[""StatusCode""] != 0
+        assert no_failure == (rv[""StatusCode""] == 0)
         return logs
 
     @staticmethod","diff --git a/tests/conftest.py b/tests/conftest.py
index 8f633d47..0e592543 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -120,10 +120,7 @@ class TrackedContainer:
             assert not self.get_warnings(logs)
         if no_errors:
             assert not self.get_errors(logs)
-        if no_failure:
-            assert rv == 0 or rv[""StatusCode""] == 0
-        else:
-            assert rv != 0 and rv[""StatusCode""] != 0
+        assert no_failure == (rv[""StatusCode""] == 0)
         return logs
 
     @staticmethod",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,cc47dbd7d84a86ebfad3bd4cd8d73047d60e2f71,7a4381ff2fd1c30f62c0f57ea13b7c08087c6077,Preserve LD_LIBRARY_PATH in start.sh (#1981),"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 1a559dbc..7c5eb939 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -140,6 +140,7 @@ if [ ""$(id -u)"" == 0 ] ; then
     unset_explicit_env_vars
     _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
     exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
+        LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}"" \
         PATH=""${PATH}"" \
         PYTHONPATH=""${PYTHONPATH:-}"" \
         ""${cmd[@]}""
@@ -165,7 +166,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         #   used `env_delete` from /etc/sudoers. It has higher priority than the
         #   `--preserve-env` flag and the `env_keep` configuration.
         #
-        # - We preserve PATH and PYTHONPATH explicitly. Note however that sudo
+        # - We preserve LD_LIBRARY_PATH, PATH and PYTHONPATH explicitly. Note however that sudo
         #   resolves `${cmd[@]}` using the ""secure_path"" variable we modified
         #   above in /etc/sudoers.d/path. Thus PATH is irrelevant to how the above
         #   sudo command resolves the path of `${cmd[@]}`. The PATH will be relevant","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 1a559dbc..7c5eb939 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -140,6 +140,7 @@ if [ ""$(id -u)"" == 0 ] ; then
     unset_explicit_env_vars
     _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
     exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
+        LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}"" \
         PATH=""${PATH}"" \
         PYTHONPATH=""${PYTHONPATH:-}"" \
         ""${cmd[@]}""
@@ -165,7 +166,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         #   used `env_delete` from /etc/sudoers. It has higher priority than the
         #   `--preserve-env` flag and the `env_keep` configuration.
         #
-        # - We preserve PATH and PYTHONPATH explicitly. Note however that sudo
+        # - We preserve LD_LIBRARY_PATH, PATH and PYTHONPATH explicitly. Note however that sudo
         #   resolves `${cmd[@]}` using the ""secure_path"" variable we modified
         #   above in /etc/sudoers.d/path. Thus PATH is irrelevant to how the above
         #   sudo command resolves the path of `${cmd[@]}`. The PATH will be relevant",Yes
examples/README.md,examples/README.md,17fdc2d2a5e92c4f73d796374af05f85fd1888b7,cc47dbd7d84a86ebfad3bd4cd8d73047d60e2f71,Fix examples README.md,"diff --git a/examples/README.md b/examples/README.md
index e7daff64..7bb53eb7 100644
--- a/examples/README.md
+++ b/examples/README.md
@@ -1,4 +1,4 @@
 # Examples
 
-These examples and not tested and might not work.
+These examples are not tested and might not work.
 Please, send PRs if you start using these examples and see some issues.","diff --git a/examples/README.md b/examples/README.md
index e7daff64..7bb53eb7 100644
--- a/examples/README.md
+++ b/examples/README.md
@@ -1,4 +1,4 @@
 # Examples
 
-These examples and not tested and might not work.
+These examples are not tested and might not work.
 Please, send PRs if you start using these examples and see some issues.",Yes
Makefile,Makefile,1167e9b5e04df3d7456ddbc579bf434cf5c219b5,17fdc2d2a5e92c4f73d796374af05f85fd1888b7,Remove pre-commit from Makefile as it doesn't make anything easier,"diff --git a/Makefile b/Makefile
index 3af508cb..b6613794 100644
--- a/Makefile
+++ b/Makefile
@@ -88,14 +88,6 @@ img-rm-dang: ## remove dangling images (tagged None)
 
 
 
-pre-commit-all: ## run pre-commit hook on all files
-	@pre-commit run --all-files --hook-stage manual
-pre-commit-install: ## set up the git hook scripts
-	@pre-commit --version
-	@pre-commit install
-
-
-
 pull/%: ## pull a jupyter image
 	docker pull ""$(OWNER)/$(notdir $@)""
 pull-all: $(foreach I, $(ALL_IMAGES), pull/$(I)) ## pull all images","diff --git a/Makefile b/Makefile
index 3af508cb..b6613794 100644
--- a/Makefile
+++ b/Makefile
@@ -88,14 +88,6 @@ img-rm-dang: ## remove dangling images (tagged None)
 
 
 
-pre-commit-all: ## run pre-commit hook on all files
-	@pre-commit run --all-files --hook-stage manual
-pre-commit-install: ## set up the git hook scripts
-	@pre-commit --version
-	@pre-commit install
-
-
-
 pull/%: ## pull a jupyter image
 	docker pull ""$(OWNER)/$(notdir $@)""
 pull-all: $(foreach I, $(ALL_IMAGES), pull/$(I)) ## pull all images",Yes
docs/contributing/lint.md,docs/contributing/lint.md,1167e9b5e04df3d7456ddbc579bf434cf5c219b5,17fdc2d2a5e92c4f73d796374af05f85fd1888b7,Remove pre-commit from Makefile as it doesn't make anything easier,"diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 92f22d19..ae9d91aa 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -21,7 +21,7 @@ pip install pre-commit
 Then the git hooks scripts configured for the project in `.pre-commit-config.yaml` need to be installed in the local git repository.
 
 ```sh
-make pre-commit-install
+pre-commit install
 ```
 
 ### Run
@@ -34,7 +34,12 @@ Hadolint pre-commit uses Docker to run, so `docker` should be running while runn
 ```
 
 ```sh
-make pre-commit-all
+pre-commit run --all-files --hook-stage manual
+```
+
+```{note}
+We're running `pre-commit` with `--hook-stage manual`, because works with changed files, which doesn't work well for mypy.
+More information can be found in [`.pre-commit-config.yaml` file](https://github.com/jupyter/docker-stacks/blob/main/.pre-commit-config.yaml)
 ```
 
 ## Image Lint","diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 92f22d19..ae9d91aa 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -21,7 +21,7 @@ pip install pre-commit
 Then the git hooks scripts configured for the project in `.pre-commit-config.yaml` need to be installed in the local git repository.
 
 ```sh
-make pre-commit-install
+pre-commit install
 ```
 
 ### Run
@@ -34,7 +34,12 @@ Hadolint pre-commit uses Docker to run, so `docker` should be running while runn
 ```
 
 ```sh
-make pre-commit-all
+pre-commit run --all-files --hook-stage manual
+```
+
+```{note}
+We're running `pre-commit` with `--hook-stage manual`, because works with changed files, which doesn't work well for mypy.
+More information can be found in [`.pre-commit-config.yaml` file](https://github.com/jupyter/docker-stacks/blob/main/.pre-commit-config.yaml)
 ```
 
 ## Image Lint",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,04b3d0c8dffef72e43c5653a7f963c0136c701a4,1167e9b5e04df3d7456ddbc579bf434cf5c219b5,Use _log functions in start.sh,"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 7c5eb939..b7f61ce5 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -19,7 +19,7 @@ _log ""Entered start.sh with args:"" ""$@""
 unset_explicit_env_vars () {
     if [ -n ""${JUPYTER_ENV_VARS_TO_UNSET}"" ]; then
         for env_var_to_unset in $(echo ""${JUPYTER_ENV_VARS_TO_UNSET}"" | tr ',' ' '); do
-            echo ""Unset ${env_var_to_unset} due to JUPYTER_ENV_VARS_TO_UNSET""
+            _log ""Unset ${env_var_to_unset} due to JUPYTER_ENV_VARS_TO_UNSET""
             unset ""${env_var_to_unset}""
         done
         unset JUPYTER_ENV_VARS_TO_UNSET","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 7c5eb939..b7f61ce5 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -19,7 +19,7 @@ _log ""Entered start.sh with args:"" ""$@""
 unset_explicit_env_vars () {
     if [ -n ""${JUPYTER_ENV_VARS_TO_UNSET}"" ]; then
         for env_var_to_unset in $(echo ""${JUPYTER_ENV_VARS_TO_UNSET}"" | tr ',' ' '); do
-            echo ""Unset ${env_var_to_unset} due to JUPYTER_ENV_VARS_TO_UNSET""
+            _log ""Unset ${env_var_to_unset} due to JUPYTER_ENV_VARS_TO_UNSET""
             unset ""${env_var_to_unset}""
         done
         unset JUPYTER_ENV_VARS_TO_UNSET",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,6aded4bc1d846a8029284a0d18ced06cbae118fd,04b3d0c8dffef72e43c5653a7f963c0136c701a4,Fix style,"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index b7f61ce5..ac4f02da 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -136,8 +136,8 @@ if [ ""$(id -u)"" == 0 ] ; then
     # NOTE: This hook is run as the root user!
     # shellcheck disable=SC1091
     source /usr/local/bin/run-hooks.sh /usr/local/bin/before-notebook.d
-
     unset_explicit_env_vars
+
     _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
     exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
         LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}"" \
@@ -234,6 +234,7 @@ else
     # shellcheck disable=SC1091
     source /usr/local/bin/run-hooks.sh /usr/local/bin/before-notebook.d
     unset_explicit_env_vars
+
     _log ""Executing the command:"" ""${cmd[@]}""
     exec ""${cmd[@]}""
 fi","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index b7f61ce5..ac4f02da 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -136,8 +136,8 @@ if [ ""$(id -u)"" == 0 ] ; then
     # NOTE: This hook is run as the root user!
     # shellcheck disable=SC1091
     source /usr/local/bin/run-hooks.sh /usr/local/bin/before-notebook.d
-
     unset_explicit_env_vars
+
     _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
     exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
         LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}"" \
@@ -234,6 +234,7 @@ else
     # shellcheck disable=SC1091
     source /usr/local/bin/run-hooks.sh /usr/local/bin/before-notebook.d
     unset_explicit_env_vars
+
     _log ""Executing the command:"" ""${cmd[@]}""
     exec ""${cmd[@]}""
 fi",Yes
tests/docker-stacks-foundation/test_user_options.py,tests/docker-stacks-foundation/test_user_options.py,6aded4bc1d846a8029284a0d18ced06cbae118fd,04b3d0c8dffef72e43c5653a7f963c0136c701a4,Fix style,"diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index cfb344cf..8702af50 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -243,7 +243,7 @@ def test_container_not_delete_bind_mount(
 
 
 @pytest.mark.parametrize(""enable_root"", [False, True])
-def test_jupyter_env_vars_to_unset_as_root(
+def test_jupyter_env_vars_to_unset(
     container: TrackedContainer, enable_root: bool
 ) -> None:
     """"""Environment variables names listed in JUPYTER_ENV_VARS_TO_UNSET","diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index cfb344cf..8702af50 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -243,7 +243,7 @@ def test_container_not_delete_bind_mount(
 
 
 @pytest.mark.parametrize(""enable_root"", [False, True])
-def test_jupyter_env_vars_to_unset_as_root(
+def test_jupyter_env_vars_to_unset(
     container: TrackedContainer, enable_root: bool
 ) -> None:
     """"""Environment variables names listed in JUPYTER_ENV_VARS_TO_UNSET",Yes
images/base-notebook/jupyter_server_config.py,images/base-notebook/jupyter_server_config.py,0d8b4e498766fb451e3ba08f9ade9da344db5d83,6aded4bc1d846a8029284a0d18ced06cbae118fd,Replace os with pathlib where paths are used (#1984),"diff --git a/images/base-notebook/jupyter_server_config.py b/images/base-notebook/jupyter_server_config.py
index c4c50147..5c13308a 100644
--- a/images/base-notebook/jupyter_server_config.py
+++ b/images/base-notebook/jupyter_server_config.py
@@ -4,6 +4,7 @@
 import os
 import stat
 import subprocess
+from pathlib import Path
 
 from jupyter_core.paths import jupyter_data_dir
 
@@ -24,15 +25,14 @@ distinguished_name = req_distinguished_name
 [req_distinguished_name]
 """"""
 if ""GEN_CERT"" in os.environ:
-    dir_name = jupyter_data_dir()
-    pem_file = os.path.join(dir_name, ""notebook.pem"")
-    os.makedirs(dir_name, exist_ok=True)
+    dir_name = Path(jupyter_data_dir())
+    dir_name.mkdir(parents=True, exist_ok=True)
+    pem_file = dir_name / ""notebook.pem""
 
     # Generate an openssl.cnf file to set the distinguished name
-    cnf_file = os.path.join(os.getenv(""CONDA_DIR"", ""/usr/lib""), ""ssl"", ""openssl.cnf"")
-    if not os.path.isfile(cnf_file):
-        with open(cnf_file, ""w"") as fh:
-            fh.write(OPENSSL_CONFIG)
+    cnf_file = Path(os.getenv(""CONDA_DIR"", ""/usr/lib"")) / ""ssl/openssl.cnf""
+    if not cnf_file.exists():
+        cnf_file.write_text(OPENSSL_CONFIG)
 
     # Generate a certificate if one doesn't exist on disk
     subprocess.check_call(
@@ -50,8 +50,8 @@ if ""GEN_CERT"" in os.environ:
         ]
     )
     # Restrict access to the file
-    os.chmod(pem_file, stat.S_IRUSR | stat.S_IWUSR)
-    c.ServerApp.certfile = pem_file
+    pem_file.chmod(stat.S_IRUSR | stat.S_IWUSR)
+    c.ServerApp.certfile = str(pem_file)
 
 # Change default umask for all subprocesses of the Server if set in the environment
 if ""NB_UMASK"" in os.environ:","diff --git a/images/base-notebook/jupyter_server_config.py b/images/base-notebook/jupyter_server_config.py
index c4c50147..5c13308a 100644
--- a/images/base-notebook/jupyter_server_config.py
+++ b/images/base-notebook/jupyter_server_config.py
@@ -4,6 +4,7 @@
 import os
 import stat
 import subprocess
+from pathlib import Path
 
 from jupyter_core.paths import jupyter_data_dir
 
@@ -24,15 +25,14 @@ distinguished_name = req_distinguished_name
 [req_distinguished_name]
 """"""
 if ""GEN_CERT"" in os.environ:
-    dir_name = jupyter_data_dir()
-    pem_file = os.path.join(dir_name, ""notebook.pem"")
-    os.makedirs(dir_name, exist_ok=True)
+    dir_name = Path(jupyter_data_dir())
+    dir_name.mkdir(parents=True, exist_ok=True)
+    pem_file = dir_name / ""notebook.pem""
 
     # Generate an openssl.cnf file to set the distinguished name
-    cnf_file = os.path.join(os.getenv(""CONDA_DIR"", ""/usr/lib""), ""ssl"", ""openssl.cnf"")
-    if not os.path.isfile(cnf_file):
-        with open(cnf_file, ""w"") as fh:
-            fh.write(OPENSSL_CONFIG)
+    cnf_file = Path(os.getenv(""CONDA_DIR"", ""/usr/lib"")) / ""ssl/openssl.cnf""
+    if not cnf_file.exists():
+        cnf_file.write_text(OPENSSL_CONFIG)
 
     # Generate a certificate if one doesn't exist on disk
     subprocess.check_call(
@@ -50,8 +50,8 @@ if ""GEN_CERT"" in os.environ:
         ]
     )
     # Restrict access to the file
-    os.chmod(pem_file, stat.S_IRUSR | stat.S_IWUSR)
-    c.ServerApp.certfile = pem_file
+    pem_file.chmod(stat.S_IRUSR | stat.S_IWUSR)
+    c.ServerApp.certfile = str(pem_file)
 
 # Change default umask for all subprocesses of the Server if set in the environment
 if ""NB_UMASK"" in os.environ:",Yes
tests/scipy-notebook/data/matplotlib/matplotlib_1.py,tests/scipy-notebook/data/matplotlib/matplotlib_1.py,0d8b4e498766fb451e3ba08f9ade9da344db5d83,6aded4bc1d846a8029284a0d18ced06cbae118fd,Replace os with pathlib where paths are used (#1984),"diff --git a/tests/scipy-notebook/data/matplotlib/matplotlib_1.py b/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
index e1a0add6..8ccf369e 100644
--- a/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
+++ b/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
@@ -1,8 +1,6 @@
 # Matplotlib: Create a simple plot example.
 # Refs: https://matplotlib.org/stable/gallery/lines_bars_and_markers/simple_plot.html
 
-import os
-
 # Optional test with [Matplotlib Jupyter Integration](https://github.com/matplotlib/ipympl)
 # %matplotlib widget
 import matplotlib.pyplot as plt
@@ -21,7 +19,8 @@ ax.set(
     title=""About as simple as it gets, folks"",
 )
 ax.grid()
+
 # Note that the test can be run headless by checking if an image is produced
-file_path = os.path.join(""/tmp"", ""test.png"")
+file_path = ""/tmp/test.png""
 fig.savefig(file_path)
 print(f""File {file_path} saved"")","diff --git a/tests/scipy-notebook/data/matplotlib/matplotlib_1.py b/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
index e1a0add6..8ccf369e 100644
--- a/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
+++ b/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
@@ -1,8 +1,6 @@
 # Matplotlib: Create a simple plot example.
 # Refs: https://matplotlib.org/stable/gallery/lines_bars_and_markers/simple_plot.html
 
-import os
-
 # Optional test with [Matplotlib Jupyter Integration](https://github.com/matplotlib/ipympl)
 # %matplotlib widget
 import matplotlib.pyplot as plt
@@ -21,7 +19,8 @@ ax.set(
     title=""About as simple as it gets, folks"",
 )
 ax.grid()
+
 # Note that the test can be run headless by checking if an image is produced
-file_path = os.path.join(""/tmp"", ""test.png"")
+file_path = ""/tmp/test.png""
 fig.savefig(file_path)
 print(f""File {file_path} saved"")",Yes
tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py,tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py,0d8b4e498766fb451e3ba08f9ade9da344db5d83,6aded4bc1d846a8029284a0d18ced06cbae118fd,Replace os with pathlib where paths are used (#1984),"diff --git a/tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py b/tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py
index 951a3d87..8944f2b8 100644
--- a/tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py
+++ b/tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py
@@ -1,6 +1,4 @@
 # Matplotlib: Test tex fonts
-import os
-
 import matplotlib
 import matplotlib.pyplot as plt
 
@@ -22,6 +20,6 @@ y = [1, 2]
 ax.plot(x, y, label=""a label"")
 ax.legend(fontsize=15)
 
-file_path = os.path.join(""/tmp"", ""test_fonts.png"")
+file_path = ""/tmp/test_fonts.png""
 fig.savefig(file_path)
 print(f""File {file_path} saved"")","diff --git a/tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py b/tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py
index 951a3d87..8944f2b8 100644
--- a/tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py
+++ b/tests/scipy-notebook/data/matplotlib/matplotlib_fonts_1.py
@@ -1,6 +1,4 @@
 # Matplotlib: Test tex fonts
-import os
-
 import matplotlib
 import matplotlib.pyplot as plt
 
@@ -22,6 +20,6 @@ y = [1, 2]
 ax.plot(x, y, label=""a label"")
 ax.legend(fontsize=15)
 
-file_path = os.path.join(""/tmp"", ""test_fonts.png"")
+file_path = ""/tmp/test_fonts.png""
 fig.savefig(file_path)
 print(f""File {file_path} saved"")",Yes
docs/using/specifics.md,docs/using/specifics.md,c7ce00b9fda91915468dc3ed668f6247ea7ab8a4,0d8b4e498766fb451e3ba08f9ade9da344db5d83,Add info about pyspark recipe,"diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 53dc0e40..3ad16a54 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -57,11 +57,15 @@ You can build a `pyspark-notebook` image with a different `Spark` version by ove
 
 For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2` and OpenJDK `11`.
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 ```bash
 # From the root of the project
 # Build the image with different arguments
 docker build --rm --force-rm \
-    -t jupyter/pyspark-notebook:spark-3.2.0 ./pyspark-notebook \
+    -t jupyter/pyspark-notebook:spark-3.2.0 ./images/pyspark-notebook \
     --build-arg spark_version=3.2.0 \
     --build-arg hadoop_version=3.2 \
     --build-arg spark_checksum=707DDE035926A50B75E53FCA72CADA519F3239B14A96546911CB4916A58DCF69A1D2BFDD2C7DD5899324DBD82B6EEAB9797A7B4ABF86736FFCA4C26D0E0BF0EE \","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 53dc0e40..3ad16a54 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -57,11 +57,15 @@ You can build a `pyspark-notebook` image with a different `Spark` version by ove
 
 For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2` and OpenJDK `11`.
 
+```{warning}
+This recipe is not tested and might be broken.
+```
+
 ```bash
 # From the root of the project
 # Build the image with different arguments
 docker build --rm --force-rm \
-    -t jupyter/pyspark-notebook:spark-3.2.0 ./pyspark-notebook \
+    -t jupyter/pyspark-notebook:spark-3.2.0 ./images/pyspark-notebook \
     --build-arg spark_version=3.2.0 \
     --build-arg hadoop_version=3.2 \
     --build-arg spark_checksum=707DDE035926A50B75E53FCA72CADA519F3239B14A96546911CB4916A58DCF69A1D2BFDD2C7DD5899324DBD82B6EEAB9797A7B4ABF86736FFCA4C26D0E0BF0EE \",Yes
images/minimal-notebook/setup-scripts/setup-julia.bash,images/minimal-notebook/setup-scripts/setup-julia.bash,3d3aa48b22d90bc3ef6130131a3298882e693b25,c7ce00b9fda91915468dc3ed668f6247ea7ab8a4,Update setup-julia.bash with Julia v1.9.3 (#1985),"diff --git a/images/minimal-notebook/setup-scripts/setup-julia.bash b/images/minimal-notebook/setup-scripts/setup-julia.bash
index d8782042..137b225f 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia.bash
@@ -6,7 +6,7 @@ set -exuo pipefail
 
 # Default julia version to install if env var is not set
 # Check https://julialang.org/downloads/
-JULIA_VERSION=""${JULIA_VERSION:-1.9.2}""
+JULIA_VERSION=""${JULIA_VERSION:-1.9.3}""
 
 # Figure out what architecture we are installing in
 JULIA_ARCH=$(uname -m)","diff --git a/images/minimal-notebook/setup-scripts/setup-julia.bash b/images/minimal-notebook/setup-scripts/setup-julia.bash
index d8782042..137b225f 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia.bash
@@ -6,7 +6,7 @@ set -exuo pipefail
 
 # Default julia version to install if env var is not set
 # Check https://julialang.org/downloads/
-JULIA_VERSION=""${JULIA_VERSION:-1.9.2}""
+JULIA_VERSION=""${JULIA_VERSION:-1.9.3}""
 
 # Figure out what architecture we are installing in
 JULIA_ARCH=$(uname -m)",Yes
docs/using/selecting.md,docs/using/selecting.md,02870bd138b549ffd00390e3388a026b9abbeed3,3d3aa48b22d90bc3ef6130131a3298882e693b25,"Update selecting.md without duplicated julia-notebook info (#1986)

- datascience-notebook now references julia-notebook
- also modified a line under julia-notebook for consistency with r-notebook","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 69e70553..450e463a 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -120,7 +120,7 @@ It contains:
 `jupyter/julia-notebook` includes popular packages from the Julia ecosystem listed below:
 
 - Everything in `jupyter/minimal-notebook` and its ancestor images
-- The [Julia Programming Language](https://julialang.org/)
+- The [Julia](https://julialang.org/) compiler and base environment
 - [IJulia](https://github.com/JuliaLang/IJulia.jl) to support Julia code in Jupyter notebook
 - [Pluto.jl](https://plutojl.org/) reactive Julia notebook interface, made accessible with [jupyter-pluto-proxy](https://github.com/yuvipanda/jupyter-pluto-proxy)
 - [HDF5](https://github.com/JuliaIO/HDF5.jl) package
@@ -186,16 +186,11 @@ It contains:
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/datascience-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/datascience-notebook/tags/)
 
-`jupyter/datascience-notebook` includes libraries for data analysis from the Julia, Python, and R
-communities.
+`jupyter/datascience-notebook` includes libraries for data analysis from the Python, and R, and Julia communities.
 
-- Everything in the `jupyter/scipy-notebook` and `jupyter/r-notebook` images and their ancestor
+- Everything in the `jupyter/scipy-notebook`, `jupyter/r-notebook`, and `jupyter/julia-notebook` images and their ancestor
   images
 - [rpy2](https://rpy2.github.io/doc/latest/html/index.html) package
-- The [Julia](https://julialang.org/) compiler and base environment
-- [IJulia](https://github.com/JuliaLang/IJulia.jl) to support Julia code in Jupyter notebooks
-- [Pluto.jl](https://plutojl.org/) reactive Julia notebook interface, made accessible with [jupyter-pluto-proxy](https://github.com/yuvipanda/jupyter-pluto-proxy)
-- [HDF5](https://github.com/JuliaIO/HDF5.jl) package
 
 ### jupyter/pyspark-notebook","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 69e70553..450e463a 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -120,7 +120,7 @@ It contains:
 `jupyter/julia-notebook` includes popular packages from the Julia ecosystem listed below:
 
 - Everything in `jupyter/minimal-notebook` and its ancestor images
-- The [Julia Programming Language](https://julialang.org/)
+- The [Julia](https://julialang.org/) compiler and base environment
 - [IJulia](https://github.com/JuliaLang/IJulia.jl) to support Julia code in Jupyter notebook
 - [Pluto.jl](https://plutojl.org/) reactive Julia notebook interface, made accessible with [jupyter-pluto-proxy](https://github.com/yuvipanda/jupyter-pluto-proxy)
 - [HDF5](https://github.com/JuliaIO/HDF5.jl) package
@@ -186,16 +186,11 @@ It contains:
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/datascience-notebook/Dockerfile) |
 [Docker Hub image tags](https://hub.docker.com/r/jupyter/datascience-notebook/tags/)
 
-`jupyter/datascience-notebook` includes libraries for data analysis from the Julia, Python, and R
-communities.
+`jupyter/datascience-notebook` includes libraries for data analysis from the Python, and R, and Julia communities.
 
-- Everything in the `jupyter/scipy-notebook` and `jupyter/r-notebook` images and their ancestor
+- Everything in the `jupyter/scipy-notebook`, `jupyter/r-notebook`, and `jupyter/julia-notebook` images and their ancestor
   images
 - [rpy2](https://rpy2.github.io/doc/latest/html/index.html) package
-- The [Julia](https://julialang.org/) compiler and base environment
-- [IJulia](https://github.com/JuliaLang/IJulia.jl) to support Julia code in Jupyter notebooks
-- [Pluto.jl](https://plutojl.org/) reactive Julia notebook interface, made accessible with [jupyter-pluto-proxy](https://github.com/yuvipanda/jupyter-pluto-proxy)
-- [HDF5](https://github.com/JuliaIO/HDF5.jl) package
 
 ### jupyter/pyspark-notebook",Yes
images/docker-stacks-foundation/run-hooks.sh,images/docker-stacks-foundation/run-hooks.sh,3675f63d085bbf9535c012d1f44ed5e808381788,02870bd138b549ffd00390e3388a026b9abbeed3,Test run_hooks when executables fail (#1987),"diff --git a/images/docker-stacks-foundation/run-hooks.sh b/images/docker-stacks-foundation/run-hooks.sh
index 146b1e14..d5dc28ea 100755
--- a/images/docker-stacks-foundation/run-hooks.sh
+++ b/images/docker-stacks-foundation/run-hooks.sh
@@ -24,11 +24,19 @@ for f in ""${1}/""*; do
             echo ""Sourcing shell script: ${f}""
             # shellcheck disable=SC1090
             source ""${f}""
+            # shellcheck disable=SC2181
+            if [ $? -ne 0 ] ; then
+                echo ""${f} has failed, continuing execution""
+            fi
             ;;
         *)
             if [ -x ""${f}"" ] ; then
                 echo ""Running executable: ${f}""
                 ""${f}""
+                # shellcheck disable=SC2181
+                if [ $? -ne 0 ] ; then
+                    echo ""${f} has failed, continuing execution""
+                fi
             else
                 echo ""Ignoring non-executable: ${f}""
             fi","diff --git a/images/docker-stacks-foundation/run-hooks.sh b/images/docker-stacks-foundation/run-hooks.sh
index 146b1e14..d5dc28ea 100755
--- a/images/docker-stacks-foundation/run-hooks.sh
+++ b/images/docker-stacks-foundation/run-hooks.sh
@@ -24,11 +24,19 @@ for f in ""${1}/""*; do
             echo ""Sourcing shell script: ${f}""
             # shellcheck disable=SC1090
             source ""${f}""
+            # shellcheck disable=SC2181
+            if [ $? -ne 0 ] ; then
+                echo ""${f} has failed, continuing execution""
+            fi
             ;;
         *)
             if [ -x ""${f}"" ] ; then
                 echo ""Running executable: ${f}""
                 ""${f}""
+                # shellcheck disable=SC2181
+                if [ $? -ne 0 ] ; then
+                    echo ""${f} has failed, continuing execution""
+                fi
             else
                 echo ""Ignoring non-executable: ${f}""
             fi",Yes
,tests/docker-stacks-foundation/run-hooks-failures/a.sh,3675f63d085bbf9535c012d1f44ed5e808381788,02870bd138b549ffd00390e3388a026b9abbeed3,Test run_hooks when executables fail (#1987),"diff --git a/tests/docker-stacks-foundation/run-hooks-failures/a.sh b/tests/docker-stacks-foundation/run-hooks-failures/a.sh
new file mode 100644
index 00000000..7dabeeb8
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-failures/a.sh
@@ -0,0 +1,11 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Started: a.sh""
+
+export OTHER_VAR=456
+
+run-unknown-command
+
+echo ""Finished: a.sh""","diff --git a/tests/docker-stacks-foundation/run-hooks-failures/a.sh b/tests/docker-stacks-foundation/run-hooks-failures/a.sh
new file mode 100644
index 00000000..7dabeeb8
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-failures/a.sh
@@ -0,0 +1,11 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Started: a.sh""
+
+export OTHER_VAR=456
+
+run-unknown-command
+
+echo ""Finished: a.sh""",Yes
,tests/docker-stacks-foundation/run-hooks-failures/b.py,3675f63d085bbf9535c012d1f44ed5e808381788,02870bd138b549ffd00390e3388a026b9abbeed3,Test run_hooks when executables fail (#1987),"diff --git a/tests/docker-stacks-foundation/run-hooks-failures/b.py b/tests/docker-stacks-foundation/run-hooks-failures/b.py
new file mode 100755
index 00000000..cc5b0a71
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-failures/b.py
@@ -0,0 +1,12 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import os
+import sys
+
+print(""Started: b.py"")
+print(f""OTHER_VAR={os.environ['OTHER_VAR']}"")
+
+sys.exit(1)
+
+print(""Finished: b.py"")","diff --git a/tests/docker-stacks-foundation/run-hooks-failures/b.py b/tests/docker-stacks-foundation/run-hooks-failures/b.py
new file mode 100755
index 00000000..cc5b0a71
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-failures/b.py
@@ -0,0 +1,12 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import os
+import sys
+
+print(""Started: b.py"")
+print(f""OTHER_VAR={os.environ['OTHER_VAR']}"")
+
+sys.exit(1)
+
+print(""Finished: b.py"")",Yes
,tests/docker-stacks-foundation/run-hooks-failures/c.sh,3675f63d085bbf9535c012d1f44ed5e808381788,02870bd138b549ffd00390e3388a026b9abbeed3,Test run_hooks when executables fail (#1987),"diff --git a/tests/docker-stacks-foundation/run-hooks-failures/c.sh b/tests/docker-stacks-foundation/run-hooks-failures/c.sh
new file mode 100644
index 00000000..a71e69fc
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-failures/c.sh
@@ -0,0 +1,7 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Started: c.sh""
+
+run-unknown-command","diff --git a/tests/docker-stacks-foundation/run-hooks-failures/c.sh b/tests/docker-stacks-foundation/run-hooks-failures/c.sh
new file mode 100644
index 00000000..a71e69fc
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-failures/c.sh
@@ -0,0 +1,7 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Started: c.sh""
+
+run-unknown-command",Yes
,tests/docker-stacks-foundation/run-hooks-failures/d.sh,3675f63d085bbf9535c012d1f44ed5e808381788,02870bd138b549ffd00390e3388a026b9abbeed3,Test run_hooks when executables fail (#1987),"diff --git a/tests/docker-stacks-foundation/run-hooks-failures/d.sh b/tests/docker-stacks-foundation/run-hooks-failures/d.sh
new file mode 100644
index 00000000..abc646a7
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-failures/d.sh
@@ -0,0 +1,11 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+echo ""Started: d.sh""
+
+run-unknown-command
+
+echo ""Finished: d.sh""","diff --git a/tests/docker-stacks-foundation/run-hooks-failures/d.sh b/tests/docker-stacks-foundation/run-hooks-failures/d.sh
new file mode 100644
index 00000000..abc646a7
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-failures/d.sh
@@ -0,0 +1,11 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+echo ""Started: d.sh""
+
+run-unknown-command
+
+echo ""Finished: d.sh""",Yes
tests/docker-stacks-foundation/test_run_hooks.py,tests/docker-stacks-foundation/test_run_hooks.py,3675f63d085bbf9535c012d1f44ed5e808381788,02870bd138b549ffd00390e3388a026b9abbeed3,Test run_hooks when executables fail (#1987),"diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index c97d4ec7..0774f5f5 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -93,3 +93,37 @@ def test_run_hooks_with_files(container: TrackedContainer) -> None:
     assert ""Executable python file was successfully"" in logs
     assert ""Ignoring non-executable: /home/jovyan/data-copy//non_executable.py"" in logs
     assert ""SOME_VAR is 123"" in logs
+
+
+def test_run_hooks_with_failures(container: TrackedContainer) -> None:
+    host_data_dir = THIS_DIR / ""run-hooks-failures""
+    cont_data_dir = ""/home/jovyan/data""
+    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
+    # Unfortunately, Docker treats all files in mounter dir as executable files
+    # So we make a copy of mounted dir inside a container
+    command = (
+        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
+        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/""
+    )
+    logs = container.run_and_wait(
+        timeout=5,
+        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
+        tty=True,
+        no_failure=False,
+        command=[""bash"", ""-c"", command],
+    )
+
+    for file in [""a.sh"", ""b.py"", ""c.sh"", ""d.sh""]:
+        assert f""Started: {file}"" in logs
+
+    for file in [""a.sh""]:
+        assert f""Finished: {file}"" in logs
+    for file in [""b.py"", ""c.sh"", ""d.sh""]:
+        assert f""Finished: {file}"" not in logs
+
+    for file in [""b.py"", ""c.sh""]:
+        assert (
+            f""/home/jovyan/data-copy//{file} has failed, continuing execution"" in logs
+        )
+
+    assert ""OTHER_VAR=456"" in logs","diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index c97d4ec7..0774f5f5 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -93,3 +93,37 @@ def test_run_hooks_with_files(container: TrackedContainer) -> None:
     assert ""Executable python file was successfully"" in logs
     assert ""Ignoring non-executable: /home/jovyan/data-copy//non_executable.py"" in logs
     assert ""SOME_VAR is 123"" in logs
+
+
+def test_run_hooks_with_failures(container: TrackedContainer) -> None:
+    host_data_dir = THIS_DIR / ""run-hooks-failures""
+    cont_data_dir = ""/home/jovyan/data""
+    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
+    # Unfortunately, Docker treats all files in mounter dir as executable files
+    # So we make a copy of mounted dir inside a container
+    command = (
+        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
+        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/""
+    )
+    logs = container.run_and_wait(
+        timeout=5,
+        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
+        tty=True,
+        no_failure=False,
+        command=[""bash"", ""-c"", command],
+    )
+
+    for file in [""a.sh"", ""b.py"", ""c.sh"", ""d.sh""]:
+        assert f""Started: {file}"" in logs
+
+    for file in [""a.sh""]:
+        assert f""Finished: {file}"" in logs
+    for file in [""b.py"", ""c.sh"", ""d.sh""]:
+        assert f""Finished: {file}"" not in logs
+
+    for file in [""b.py"", ""c.sh""]:
+        assert (
+            f""/home/jovyan/data-copy//{file} has failed, continuing execution"" in logs
+        )
+
+    assert ""OTHER_VAR=456"" in logs",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,ab90b125ba892e0a87d3d280bcc9e39de2261768,3675f63d085bbf9535c012d1f44ed5e808381788,"Bump actions/checkout from 3 to 4 (#1988)

Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.
- [Release notes](https://github.com/actions/checkout/releases)
- [Changelog](https://github.com/actions/checkout/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/checkout/compare/v3...v4)

---
updated-dependencies:
- dependency-name: actions/checkout
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index bdf53fdc..59938180 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -26,7 +26,7 @@ jobs:
       matrix: ${{ steps.set-matrix.outputs.matrix }}
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
 
       - name: Calculate recipes matrix 🛠
         id: set-matrix
@@ -39,7 +39,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
 
       - name: Build recipe 🛠
         # We're pulling here to avoid accidentally using image which migt be present on aarch64 self-hosted runner","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index bdf53fdc..59938180 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -26,7 +26,7 @@ jobs:
       matrix: ${{ steps.set-matrix.outputs.matrix }}
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
 
       - name: Calculate recipes matrix 🛠
         id: set-matrix
@@ -39,7 +39,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
 
       - name: Build recipe 🛠
         # We're pulling here to avoid accidentally using image which migt be present on aarch64 self-hosted runner",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,ab90b125ba892e0a87d3d280bcc9e39de2261768,3675f63d085bbf9535c012d1f44ed5e808381788,"Bump actions/checkout from 3 to 4 (#1988)

Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.
- [Release notes](https://github.com/actions/checkout/releases)
- [Changelog](https://github.com/actions/checkout/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/checkout/compare/v3...v4)

---
updated-dependencies:
- dependency-name: actions/checkout
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 7453f681..a15e8eb1 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -29,7 +29,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
         with:","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 7453f681..a15e8eb1 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -29,7 +29,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
         with:",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,ab90b125ba892e0a87d3d280bcc9e39de2261768,3675f63d085bbf9535c012d1f44ed5e808381788,"Bump actions/checkout from 3 to 4 (#1988)

Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.
- [Release notes](https://github.com/actions/checkout/releases)
- [Changelog](https://github.com/actions/checkout/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/checkout/compare/v3...v4)

---
updated-dependencies:
- dependency-name: actions/checkout
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 7287b0cf..d11d6afc 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -22,7 +22,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
         with:","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 7287b0cf..d11d6afc 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -22,7 +22,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
         with:",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,ab90b125ba892e0a87d3d280bcc9e39de2261768,3675f63d085bbf9535c012d1f44ed5e808381788,"Bump actions/checkout from 3 to 4 (#1988)

Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.
- [Release notes](https://github.com/actions/checkout/releases)
- [Changelog](https://github.com/actions/checkout/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/checkout/compare/v3...v4)

---
updated-dependencies:
- dependency-name: actions/checkout
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 7f6bd2a7..c9629e1e 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -26,7 +26,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
         with:","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 7f6bd2a7..c9629e1e 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -26,7 +26,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
         with:",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,ab90b125ba892e0a87d3d280bcc9e39de2261768,3675f63d085bbf9535c012d1f44ed5e808381788,"Bump actions/checkout from 3 to 4 (#1988)

Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.
- [Release notes](https://github.com/actions/checkout/releases)
- [Changelog](https://github.com/actions/checkout/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/checkout/compare/v3...v4)

---
updated-dependencies:
- dependency-name: actions/checkout
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index d5747c64..a0403e12 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -11,7 +11,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
         with:
@@ -29,7 +29,7 @@ jobs:
         shell: bash
 
       - name: Checkout Wiki Repo 📃
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
         with:
           repository: ${{ github.repository }}.wiki
           path: wiki/","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index d5747c64..a0403e12 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -11,7 +11,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
         with:
@@ -29,7 +29,7 @@ jobs:
         shell: bash
 
       - name: Checkout Wiki Repo 📃
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
         with:
           repository: ${{ github.repository }}.wiki
           path: wiki/",Yes
.github/workflows/hub-overview.yml,.github/workflows/hub-overview.yml,ab90b125ba892e0a87d3d280bcc9e39de2261768,3675f63d085bbf9535c012d1f44ed5e808381788,"Bump actions/checkout from 3 to 4 (#1988)

Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.
- [Release notes](https://github.com/actions/checkout/releases)
- [Changelog](https://github.com/actions/checkout/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/checkout/compare/v3...v4)

---
updated-dependencies:
- dependency-name: actions/checkout
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index 85bc7694..1c144845 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -20,7 +20,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
 
       - name: Push README to Docker Hub 🐳
         uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1","diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index 85bc7694..1c144845 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -20,7 +20,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
 
       - name: Push README to Docker Hub 🐳
         uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1",Yes
.github/workflows/pre-commit.yml,.github/workflows/pre-commit.yml,ab90b125ba892e0a87d3d280bcc9e39de2261768,3675f63d085bbf9535c012d1f44ed5e808381788,"Bump actions/checkout from 3 to 4 (#1988)

Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.
- [Release notes](https://github.com/actions/checkout/releases)
- [Changelog](https://github.com/actions/checkout/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/checkout/compare/v3...v4)

---
updated-dependencies:
- dependency-name: actions/checkout
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/pre-commit.yml b/.github/workflows/pre-commit.yml
index 20bcf94f..18413db2 100644
--- a/.github/workflows/pre-commit.yml
+++ b/.github/workflows/pre-commit.yml
@@ -17,7 +17,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
 
       - name: Set Up Python 🐍
         uses: actions/setup-python@v4","diff --git a/.github/workflows/pre-commit.yml b/.github/workflows/pre-commit.yml
index 20bcf94f..18413db2 100644
--- a/.github/workflows/pre-commit.yml
+++ b/.github/workflows/pre-commit.yml
@@ -17,7 +17,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
 
       - name: Set Up Python 🐍
         uses: actions/setup-python@v4",Yes
.github/workflows/sphinx.yml,.github/workflows/sphinx.yml,ab90b125ba892e0a87d3d280bcc9e39de2261768,3675f63d085bbf9535c012d1f44ed5e808381788,"Bump actions/checkout from 3 to 4 (#1988)

Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.
- [Release notes](https://github.com/actions/checkout/releases)
- [Changelog](https://github.com/actions/checkout/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/checkout/compare/v3...v4)

---
updated-dependencies:
- dependency-name: actions/checkout
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index ffc0259f..fcdf03b7 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -32,7 +32,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
         with:
           fetch-depth: 0","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index ffc0259f..fcdf03b7 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -32,7 +32,7 @@ jobs:
 
     steps:
       - name: Checkout Repo ⚡️
-        uses: actions/checkout@v3
+        uses: actions/checkout@v4
         with:
           fetch-depth: 0",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,0a122d53a01b22fb64d8b776a8d55e143efc06c1,ab90b125ba892e0a87d3d280bcc9e39de2261768,"[pre-commit.ci] pre-commit autoupdate (#1989)

updates:
- [github.com/pre-commit/mirrors-prettier: v3.0.2 → v3.0.3](https://github.com/pre-commit/mirrors-prettier/compare/v3.0.2...v3.0.3)
- [github.com/igorshubovych/markdownlint-cli: v0.35.0 → v0.36.0](https://github.com/igorshubovych/markdownlint-cli/compare/v0.35.0...v0.36.0)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index ee6132ec..9b2467e4 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -52,7 +52,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.0.2
+    rev: v3.0.3
     hooks:
       - id: prettier
 
@@ -113,7 +113,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.35.0
+    rev: v0.36.0
     hooks:
       - id: markdownlint
         args: [""--fix""]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index ee6132ec..9b2467e4 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -52,7 +52,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.0.2
+    rev: v3.0.3
     hooks:
       - id: prettier
 
@@ -113,7 +113,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.35.0
+    rev: v0.36.0
     hooks:
       - id: markdownlint
         args: [""--fix""]",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,b72e40b2e3b1a5cd46b972dd576ff89be1d8b440,0a122d53a01b22fb64d8b776a8d55e143efc06c1,Do not set default name for the issues,"diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 2ccb3bb9..aeedcf94 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -1,6 +1,5 @@
 name: Bug report
 description: Create a report to help us improve
-title: ""[BUG] - <title>""
 labels: [""type:Bug""]
 
 body:","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 2ccb3bb9..aeedcf94 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -1,6 +1,5 @@
 name: Bug report
 description: Create a report to help us improve
-title: ""[BUG] - <title>""
 labels: [""type:Bug""]
 
 body:",Yes
.github/ISSUE_TEMPLATE/feature_request.yml,.github/ISSUE_TEMPLATE/feature_request.yml,b72e40b2e3b1a5cd46b972dd576ff89be1d8b440,0a122d53a01b22fb64d8b776a8d55e143efc06c1,Do not set default name for the issues,"diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index 2dc1d106..d0aff55d 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -1,6 +1,5 @@
 name: Feature request
 description: Suggest a new feature for this project
-title: ""[ENH] - <title>""
 labels: [""type:Enhancement""]
 
 body:","diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index 2dc1d106..d0aff55d 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -1,6 +1,5 @@
 name: Feature request
 description: Suggest a new feature for this project
-title: ""[ENH] - <title>""
 labels: [""type:Enhancement""]
 
 body:",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,52a999a554fe42951e017f7be132d808695a1261,b72e40b2e3b1a5cd46b972dd576ff89be1d8b440,"Upgrade `Apache Spark` to 3.5.0 (#1995)

* 1.

* add note for pandas version

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update images/pyspark-notebook/Dockerfile

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index ee7a780a..37cceb0c 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -15,10 +15,10 @@ USER root
 # Spark dependencies
 # Default values can be overridden at build time
 # (ARGS are in lower case to distinguish them from ENV)
-ARG spark_version=""3.4.1""
+ARG spark_version=""3.5.0""
 ARG hadoop_version=""3""
 ARG scala_version
-ARG spark_checksum=""5a21295b4c3d1d3f8fc85375c711c7c23e3eeb3ec9ea91778f149d8d321e3905e2f44cf19c69a28df693cffd536f7316706c78932e7e148d224424150f18b2c5""
+ARG spark_checksum=""8883c67e0a138069e597f3e7d4edbbd5c3a565d50b28644aad02856a1ec1da7cb92b8f80454ca427118f69459ea326eaa073cf7b1a860c3b796f4b07c2101319""
 ARG openjdk_version=""17""
 
 ENV APACHE_SPARK_VERSION=""${spark_version}"" \
@@ -66,9 +66,14 @@ RUN fix-permissions ""/etc/ipython/""
 USER ${NB_UID}
 
 # Install pyarrow
-# Temporarily pin pandas to version 1.5.3, see: https://github.com/jupyter/docker-stacks/issues/1924
+# NOTE: It's important to ensure compatibility between Pandas versions.
+# The pandas version in this Dockerfile should match the version
+# on which the Pandas API for Spark is built.
+# To find the right version:
+# 1. Check out the Spark branch you are on.
+# 2. Find the pandas version in the file spark/dev/infra/Dockerfile.
 RUN mamba install --yes \
-    'pandas>=1.5.3,<2.0.0' \
+    'pandas=2.0.3' \
     'pyarrow' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index ee7a780a..37cceb0c 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -15,10 +15,10 @@ USER root
 # Spark dependencies
 # Default values can be overridden at build time
 # (ARGS are in lower case to distinguish them from ENV)
-ARG spark_version=""3.4.1""
+ARG spark_version=""3.5.0""
 ARG hadoop_version=""3""
 ARG scala_version
-ARG spark_checksum=""5a21295b4c3d1d3f8fc85375c711c7c23e3eeb3ec9ea91778f149d8d321e3905e2f44cf19c69a28df693cffd536f7316706c78932e7e148d224424150f18b2c5""
+ARG spark_checksum=""8883c67e0a138069e597f3e7d4edbbd5c3a565d50b28644aad02856a1ec1da7cb92b8f80454ca427118f69459ea326eaa073cf7b1a860c3b796f4b07c2101319""
 ARG openjdk_version=""17""
 
 ENV APACHE_SPARK_VERSION=""${spark_version}"" \
@@ -66,9 +66,14 @@ RUN fix-permissions ""/etc/ipython/""
 USER ${NB_UID}
 
 # Install pyarrow
-# Temporarily pin pandas to version 1.5.3, see: https://github.com/jupyter/docker-stacks/issues/1924
+# NOTE: It's important to ensure compatibility between Pandas versions.
+# The pandas version in this Dockerfile should match the version
+# on which the Pandas API for Spark is built.
+# To find the right version:
+# 1. Check out the Spark branch you are on.
+# 2. Find the pandas version in the file spark/dev/infra/Dockerfile.
 RUN mamba install --yes \
-    'pandas>=1.5.3,<2.0.0' \
+    'pandas=2.0.3' \
     'pyarrow' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \",Yes
tests/pyspark-notebook/units/unit_pandas_version.py,tests/pyspark-notebook/units/unit_pandas_version.py,52a999a554fe42951e017f7be132d808695a1261,b72e40b2e3b1a5cd46b972dd576ff89be1d8b440,"Upgrade `Apache Spark` to 3.5.0 (#1995)

* 1.

* add note for pandas version

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update images/pyspark-notebook/Dockerfile

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/pyspark-notebook/units/unit_pandas_version.py b/tests/pyspark-notebook/units/unit_pandas_version.py
index 1728effa..03920db4 100644
--- a/tests/pyspark-notebook/units/unit_pandas_version.py
+++ b/tests/pyspark-notebook/units/unit_pandas_version.py
@@ -2,4 +2,4 @@
 # Distributed under the terms of the Modified BSD License.
 import pandas
 
-assert pandas.__version__ == ""1.5.3""
+assert pandas.__version__ == ""2.0.3""","diff --git a/tests/pyspark-notebook/units/unit_pandas_version.py b/tests/pyspark-notebook/units/unit_pandas_version.py
index 1728effa..03920db4 100644
--- a/tests/pyspark-notebook/units/unit_pandas_version.py
+++ b/tests/pyspark-notebook/units/unit_pandas_version.py
@@ -2,4 +2,4 @@
 # Distributed under the terms of the Modified BSD License.
 import pandas
 
-assert pandas.__version__ == ""1.5.3""
+assert pandas.__version__ == ""2.0.3""",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,aa2403a808d31222769511bbd9248a32cb230073,52a999a554fe42951e017f7be132d808695a1261,"Bump docker/login-action from 2.2.0 to 3.0.0 (#1998)

Bumps [docker/login-action](https://github.com/docker/login-action) from 2.2.0 to 3.0.0.
- [Release notes](https://github.com/docker/login-action/releases)
- [Commits](https://github.com/docker/login-action/compare/465a07811f14bebb1938fbed4728c6a1ff8901fc...343f7c4344506bcbf9b4de18042ae17996df046d)

---
updated-dependencies:
- dependency-name: docker/login-action
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index d11d6afc..3e4142d4 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -50,7 +50,7 @@ jobs:
 
       - name: Login to Docker Hub 🔐
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
-        uses: docker/login-action@465a07811f14bebb1938fbed4728c6a1ff8901fc # v2.2.0
+        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           username: ${{ secrets.DOCKERHUB_USERNAME }}
           password: ${{ secrets.DOCKERHUB_TOKEN }}","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index d11d6afc..3e4142d4 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -50,7 +50,7 @@ jobs:
 
       - name: Login to Docker Hub 🔐
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
-        uses: docker/login-action@465a07811f14bebb1938fbed4728c6a1ff8901fc # v2.2.0
+        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           username: ${{ secrets.DOCKERHUB_USERNAME }}
           password: ${{ secrets.DOCKERHUB_TOKEN }}",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,aa2403a808d31222769511bbd9248a32cb230073,52a999a554fe42951e017f7be132d808695a1261,"Bump docker/login-action from 2.2.0 to 3.0.0 (#1998)

Bumps [docker/login-action](https://github.com/docker/login-action) from 2.2.0 to 3.0.0.
- [Release notes](https://github.com/docker/login-action/releases)
- [Commits](https://github.com/docker/login-action/compare/465a07811f14bebb1938fbed4728c6a1ff8901fc...343f7c4344506bcbf9b4de18042ae17996df046d)

---
updated-dependencies:
- dependency-name: docker/login-action
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index c9629e1e..adb7f1bb 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -39,7 +39,7 @@ jobs:
 
       - name: Login to Docker Hub 🔐
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
-        uses: docker/login-action@465a07811f14bebb1938fbed4728c6a1ff8901fc # v2.2.0
+        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           username: ${{ secrets.DOCKERHUB_USERNAME }}
           password: ${{ secrets.DOCKERHUB_TOKEN }}","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index c9629e1e..adb7f1bb 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -39,7 +39,7 @@ jobs:
 
       - name: Login to Docker Hub 🔐
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
-        uses: docker/login-action@465a07811f14bebb1938fbed4728c6a1ff8901fc # v2.2.0
+        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           username: ${{ secrets.DOCKERHUB_USERNAME }}
           password: ${{ secrets.DOCKERHUB_TOKEN }}",Yes
.github/workflows/hub-overview.yml,.github/workflows/hub-overview.yml,11709140d025a036dacd4ff75b3456618df5da7e,aa2403a808d31222769511bbd9248a32cb230073,Add workflow_dispatch to hub-overview,"diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index 1c144845..fa27d555 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -11,6 +11,7 @@ on:
       - "".github/workflows/hub-overview.yml""
 
       - ""images/*/README.md""
+  workflow_dispatch:
 
 jobs:
   update-dockerhub-overview:","diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index 1c144845..fa27d555 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -11,6 +11,7 @@ on:
       - "".github/workflows/hub-overview.yml""
 
       - ""images/*/README.md""
+  workflow_dispatch:
 
 jobs:
   update-dockerhub-overview:",Yes
.github/workflows/hub-overview.yml,.github/workflows/hub-overview.yml,d9712f033b45b58066ce965655b7667189845796,11709140d025a036dacd4ff75b3456618df5da7e,Remove names from jobs,"diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index fa27d555..162f08a6 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -15,7 +15,6 @@ on:
 
 jobs:
   update-dockerhub-overview:
-    name: Update Docker Hub overviews
     runs-on: ubuntu-latest
     if: github.repository == 'jupyter/docker-stacks'","diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index fa27d555..162f08a6 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -15,7 +15,6 @@ on:
 
 jobs:
   update-dockerhub-overview:
-    name: Update Docker Hub overviews
     runs-on: ubuntu-latest
     if: github.repository == 'jupyter/docker-stacks'",Yes
.github/workflows/pre-commit.yml,.github/workflows/pre-commit.yml,d9712f033b45b58066ce965655b7667189845796,11709140d025a036dacd4ff75b3456618df5da7e,Remove names from jobs,"diff --git a/.github/workflows/pre-commit.yml b/.github/workflows/pre-commit.yml
index 18413db2..e0ed9f54 100644
--- a/.github/workflows/pre-commit.yml
+++ b/.github/workflows/pre-commit.yml
@@ -12,7 +12,6 @@ permissions:
 
 jobs:
   run-hooks:
-    name: Run pre-commit hooks
     runs-on: ubuntu-latest
 
     steps:","diff --git a/.github/workflows/pre-commit.yml b/.github/workflows/pre-commit.yml
index 18413db2..e0ed9f54 100644
--- a/.github/workflows/pre-commit.yml
+++ b/.github/workflows/pre-commit.yml
@@ -12,7 +12,6 @@ permissions:
 
 jobs:
   run-hooks:
-    name: Run pre-commit hooks
     runs-on: ubuntu-latest
 
     steps:",Yes
.github/workflows/sphinx.yml,.github/workflows/sphinx.yml,d9712f033b45b58066ce965655b7667189845796,11709140d025a036dacd4ff75b3456618df5da7e,Remove names from jobs,"diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index fcdf03b7..78f1b950 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -24,7 +24,6 @@ on:
 
 jobs:
   build-docs:
-    name: Build Sphinx Documentation
     permissions:
       contents: write
     if: github.repository == 'jupyter/docker-stacks' || github.event_name != 'schedule'","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index fcdf03b7..78f1b950 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -24,7 +24,6 @@ on:
 
 jobs:
   build-docs:
-    name: Build Sphinx Documentation
     permissions:
       contents: write
     if: github.repository == 'jupyter/docker-stacks' || github.event_name != 'schedule'",Yes
.github/workflows/hub-overview.yml,.github/workflows/hub-overview.yml,23c758cde3ff7f60241ab4a2dc2a21034a6228b0,d9712f033b45b58066ce965655b7667189845796,Better name for update-overview job,"diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index 162f08a6..9f37eae5 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -14,8 +14,9 @@ on:
   workflow_dispatch:
 
 jobs:
-  update-dockerhub-overview:
+  update-overview:
     runs-on: ubuntu-latest
+    name: update-overview (${{matrix.image}})
     if: github.repository == 'jupyter/docker-stacks'
 
     steps:","diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
index 162f08a6..9f37eae5 100644
--- a/.github/workflows/hub-overview.yml
+++ b/.github/workflows/hub-overview.yml
@@ -14,8 +14,9 @@ on:
   workflow_dispatch:
 
 jobs:
-  update-dockerhub-overview:
+  update-overview:
     runs-on: ubuntu-latest
+    name: update-overview (${{matrix.image}})
     if: github.repository == 'jupyter/docker-stacks'
 
     steps:",Yes
README.md,README.md,94b57514f9ed0256f314a54750fb29083066ad18,23c758cde3ff7f60241ab4a2dc2a21034a6228b0,Update example date,"diff --git a/README.md b/README.md
index b9eb6097..ada720e2 100644
--- a/README.md
+++ b/README.md
@@ -26,11 +26,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-08-19
+docker run -p 10000:8888 jupyter/scipy-notebook:2023-09-25
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -45,11 +45,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-08-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-09-25
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -119,7 +119,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-08-19`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-09-25`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images","diff --git a/README.md b/README.md
index b9eb6097..ada720e2 100644
--- a/README.md
+++ b/README.md
@@ -26,11 +26,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-08-19
+docker run -p 10000:8888 jupyter/scipy-notebook:2023-09-25
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -45,11 +45,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-08-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-09-25
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -119,7 +119,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-08-19`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-09-25`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images",Yes
binder/Dockerfile,binder/Dockerfile,94b57514f9ed0256f314a54750fb29083066ad18,23c758cde3ff7f60241ab4a2dc2a21034a6228b0,Update example date,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index be4c4033..2cc9a346 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -3,7 +3,7 @@
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-08-19
+ARG BASE_CONTAINER=$OWNER/base-notebook:2023-09-25
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -12,6 +12,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-08-19""
+ENV TAG=""2023-09-25""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index be4c4033..2cc9a346 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -3,7 +3,7 @@
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-08-19
+ARG BASE_CONTAINER=$OWNER/base-notebook:2023-09-25
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -12,6 +12,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-08-19""
+ENV TAG=""2023-09-25""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,94b57514f9ed0256f314a54750fb29083066ad18,23c758cde3ff7f60241ab4a2dc2a21034a6228b0,Update example date,"diff --git a/docs/using/running.md b/docs/using/running.md
index d8761fbf..4e764184 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-08-19
+docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-09-25
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-08-19                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-09-25                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-08-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-09-25
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -137,7 +137,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -146,7 +146,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-08-19
+    docker.io/jupyter/r-notebook:2023-09-25
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index d8761fbf..4e764184 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-08-19
+docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-09-25
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-08-19                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-09-25                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-08-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-09-25
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -137,7 +137,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-08-19` from Docker Hub if it is not already present on the local host.
+This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -146,7 +146,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-08-19
+    docker.io/jupyter/r-notebook:2023-09-25
 ```
 
 ```{warning}",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,7e1a19a8427f99652c75d1d4fda3df780721b574,94b57514f9ed0256f314a54750fb29083066ad18,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 9b2467e4..524e28ed 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.10.1
+    rev: v3.13.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.7.0
+    rev: 23.9.1
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -113,7 +113,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.36.0
+    rev: v0.37.0
     hooks:
       - id: markdownlint
         args: [""--fix""]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 9b2467e4..524e28ed 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.10.1
+    rev: v3.13.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.7.0
+    rev: 23.9.1
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -113,7 +113,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.36.0
+    rev: v0.37.0
     hooks:
       - id: markdownlint
         args: [""--fix""]",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,58a8a965c81db91b4c4fe089964b981429584926,7e1a19a8427f99652c75d1d4fda3df780721b574,"[pre-commit.ci] pre-commit autoupdate (#2003)

updates:
- [github.com/asottile/pyupgrade: v3.13.0 → v3.14.0](https://github.com/asottile/pyupgrade/compare/v3.13.0...v3.14.0)
- [github.com/shellcheck-py/shellcheck-py: v0.9.0.5 → v0.9.0.6](https://github.com/shellcheck-py/shellcheck-py/compare/v0.9.0.5...v0.9.0.6)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 524e28ed..79eaf045 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.13.0
+    rev: v3.14.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -100,7 +100,7 @@ repos:
 
   # Lint: Shell scripts
   - repo: https://github.com/shellcheck-py/shellcheck-py
-    rev: v0.9.0.5
+    rev: v0.9.0.6
     hooks:
       - id: shellcheck
         args: [""-x""]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 524e28ed..79eaf045 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.13.0
+    rev: v3.14.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -100,7 +100,7 @@ repos:
 
   # Lint: Shell scripts
   - repo: https://github.com/shellcheck-py/shellcheck-py
-    rev: v0.9.0.5
+    rev: v0.9.0.6
     hooks:
       - id: shellcheck
         args: [""-x""]",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,2ed00102380c2f689b516c55089164379609d8fc,58a8a965c81db91b4c4fe089964b981429584926,Add urllib3 to mypy check,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 79eaf045..bc9f1fa9 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -40,7 +40,15 @@ repos:
       - id: mypy
         args: [--config, ./mypy.ini]
         additional_dependencies:
-          [""numpy"", ""pytest"", ""requests"", ""types-requests"", ""types-tabulate""]
+          [
+            ""numpy"",
+            ""pytest"",
+            ""requests"",
+            ""urllib3"",
+            ""types-requests"",
+            ""types-tabulate"",
+            ""types-urllib3"",
+          ]
         # Unfortunately, `pre-commit` only runs on changed files
         # This doesn't work well with `mypy --follow-imports error`
         # See: https://github.com/pre-commit/mirrors-mypy/issues/34#issuecomment-1062160321","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 79eaf045..bc9f1fa9 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -40,7 +40,15 @@ repos:
       - id: mypy
         args: [--config, ./mypy.ini]
         additional_dependencies:
-          [""numpy"", ""pytest"", ""requests"", ""types-requests"", ""types-tabulate""]
+          [
+            ""numpy"",
+            ""pytest"",
+            ""requests"",
+            ""urllib3"",
+            ""types-requests"",
+            ""types-tabulate"",
+            ""types-urllib3"",
+          ]
         # Unfortunately, `pre-commit` only runs on changed files
         # This doesn't work well with `mypy --follow-imports error`
         # See: https://github.com/pre-commit/mirrors-mypy/issues/34#issuecomment-1062160321",Yes
mypy.ini,mypy.ini,2ed00102380c2f689b516c55089164379609d8fc,58a8a965c81db91b4c4fe089964b981429584926,Add urllib3 to mypy check,"diff --git a/mypy.ini b/mypy.ini
index f35b2e18..decc686c 100644
--- a/mypy.ini
+++ b/mypy.ini
@@ -41,6 +41,3 @@ ignore_missing_imports = True
 
 [mypy-tensorflow.*]
 ignore_missing_imports = True
-
-[mypy-urllib3.*]
-ignore_missing_imports = True","diff --git a/mypy.ini b/mypy.ini
index f35b2e18..decc686c 100644
--- a/mypy.ini
+++ b/mypy.ini
@@ -41,6 +41,3 @@ ignore_missing_imports = True
 
 [mypy-tensorflow.*]
 ignore_missing_imports = True
-
-[mypy-urllib3.*]
-ignore_missing_imports = True",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,fbbf24585dd63f0d6a6709aed1640f03782bf21f,2ed00102380c2f689b516c55089164379609d8fc,Fix PyCQA repo,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index bc9f1fa9..b0023a0d 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -20,7 +20,7 @@ repos:
         args: [--py39-plus]
 
   # Automatically sort python imports
-  - repo: https://github.com/pycqa/isort
+  - repo: https://github.com/PyCQA/isort
     rev: 5.12.0
     hooks:
       - id: isort","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index bc9f1fa9..b0023a0d 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -20,7 +20,7 @@ repos:
         args: [--py39-plus]
 
   # Automatically sort python imports
-  - repo: https://github.com/pycqa/isort
+  - repo: https://github.com/PyCQA/isort
     rev: 5.12.0
     hooks:
       - id: isort",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,4c0c0aa1715f8f5f964192462228a84bb540ed69,fbbf24585dd63f0d6a6709aed1640f03782bf21f,"Bump stefanzweifel/git-auto-commit-action from 4.16.0 to 5.0.0 (#2005)

Bumps [stefanzweifel/git-auto-commit-action](https://github.com/stefanzweifel/git-auto-commit-action) from 4.16.0 to 5.0.0.
- [Release notes](https://github.com/stefanzweifel/git-auto-commit-action/releases)
- [Changelog](https://github.com/stefanzweifel/git-auto-commit-action/blob/master/CHANGELOG.md)
- [Commits](https://github.com/stefanzweifel/git-auto-commit-action/compare/3ea6ae190baf489ba007f7c92608f33ce20ef04a...8756aa072ef5b4a080af5dc8fef36c5d586e521d)

---
updated-dependencies:
- dependency-name: stefanzweifel/git-auto-commit-action
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index a0403e12..24d931ae 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -40,7 +40,7 @@ jobs:
 
       - name: Push Wiki to GitHub 📤
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
-        uses: stefanzweifel/git-auto-commit-action@3ea6ae190baf489ba007f7c92608f33ce20ef04a # v4.16.0
+        uses: stefanzweifel/git-auto-commit-action@8756aa072ef5b4a080af5dc8fef36c5d586e521d # v5.0.0
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""
           repository: wiki/","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index a0403e12..24d931ae 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -40,7 +40,7 @@ jobs:
 
       - name: Push Wiki to GitHub 📤
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
-        uses: stefanzweifel/git-auto-commit-action@3ea6ae190baf489ba007f7c92608f33ce20ef04a # v4.16.0
+        uses: stefanzweifel/git-auto-commit-action@8756aa072ef5b4a080af5dc8fef36c5d586e521d # v5.0.0
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""
           repository: wiki/",Yes
README.md,README.md,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/README.md b/README.md
index ada720e2..49934d91 100644
--- a/README.md
+++ b/README.md
@@ -65,7 +65,7 @@ system when the container exits, but any changes made to the `~/work` directory
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
 So, new notebooks will be saved there, unless you change the directory in the file browser.
 
-To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
 ## Contributing","diff --git a/README.md b/README.md
index ada720e2..49934d91 100644
--- a/README.md
+++ b/README.md
@@ -65,7 +65,7 @@ system when the container exits, but any changes made to the `~/work` directory
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
 So, new notebooks will be saved there, unless you change the directory in the file browser.
 
-To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
 ## Contributing",Yes
docs/using/common.md,docs/using/common.md,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/common.md b/docs/using/common.md
index dab66fed..e2fee1f5 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -1,14 +1,14 @@
 # Common Features
 
 Except for `jupyter/docker-stacks-foundation`, a container launched from any Jupyter Docker Stacks image runs a Jupyter Server with the JupyterLab frontend.
-The container does so by executing a `start-notebook.sh` script.
+The container does so by executing a `start-notebook.py` script.
 This script configures the internal container environment and then runs `jupyter lab`, passing any command-line arguments received.
 
 This page describes the options supported by the startup script and how to bypass it to run alternative commands.
 
 ## Jupyter Server Options
 
-You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.sh` script when launching the container.
+You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.py` script when launching the container.
 
 1. For example, to secure the Jupyter Server with a [custom password](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#preparing-a-hashed-password)
    hashed using `jupyter_server.auth.passwd()` instead of the default token,
@@ -16,19 +16,19 @@ You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/l
 
    ```bash
    docker run -it --rm -p 8888:8888 jupyter/base-notebook \
-       start-notebook.sh --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
+       start-notebook.py --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
    docker run  -it --rm -p 8888:8888 jupyter/base-notebook \
-       start-notebook.sh --ServerApp.base_url=/customized/url/prefix/
+       start-notebook.py --ServerApp.base_url=/customized/url/prefix/
    ```
 
 ## Docker Options
 
-You may instruct the `start-notebook.sh` script to customize the container environment before launching the Server.
+You may instruct the `start-notebook.py` script to customize the container environment before launching the Server.
 You do so by passing arguments to the `docker run` command.
 
 ### User-related configurations
@@ -104,7 +104,7 @@ You do so by passing arguments to the `docker run` command.
   You do **not** need this option to allow the user to `conda` or `pip` install additional packages.
   This option is helpful for cases when you wish to give `${NB_USER}` the ability to install OS packages with `apt` or modify other root-owned files in the container.
   You **must** run the container with `--user root` for this option to take effect.
-  (The `start-notebook.sh` script will `su ${NB_USER}` after adding `${NB_USER}` to sudoers.)
+  (The `start-notebook.py` script will `su ${NB_USER}` after adding `${NB_USER}` to sudoers.)
   **You should only enable `sudo` if you trust the user or if the container runs on an isolated host.**
 
 ### Additional runtime configurations
@@ -147,7 +147,7 @@ For example, to mount a host folder containing a `notebook.key` and `notebook.cr
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder:/etc/ssl/notebook \
     jupyter/base-notebook \
-    start-notebook.sh \
+    start-notebook.py \
     --ServerApp.keyfile=/etc/ssl/notebook/notebook.key \
     --ServerApp.certfile=/etc/ssl/notebook/notebook.crt
 ```
@@ -159,7 +159,7 @@ For example:
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder/notebook.pem:/etc/ssl/notebook.pem \
     jupyter/base-notebook \
-    start-notebook.sh \
+    start-notebook.py \
     --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
 
@@ -220,7 +220,7 @@ docker run -it --rm \
 
 ### `start.sh`
 
-The `start-notebook.sh` script inherits most of its option handling capability from a more generic `start.sh` script.
+The `start-notebook.py` script inherits most of its option handling capability from a more generic `start.sh` script.
 The `start.sh` script supports all the features described above but allows you to specify an arbitrary command to execute.
 For example, to run the text-based `ipython` console in a container, do the following:","diff --git a/docs/using/common.md b/docs/using/common.md
index dab66fed..e2fee1f5 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -1,14 +1,14 @@
 # Common Features
 
 Except for `jupyter/docker-stacks-foundation`, a container launched from any Jupyter Docker Stacks image runs a Jupyter Server with the JupyterLab frontend.
-The container does so by executing a `start-notebook.sh` script.
+The container does so by executing a `start-notebook.py` script.
 This script configures the internal container environment and then runs `jupyter lab`, passing any command-line arguments received.
 
 This page describes the options supported by the startup script and how to bypass it to run alternative commands.
 
 ## Jupyter Server Options
 
-You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.sh` script when launching the container.
+You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html) to the `start-notebook.py` script when launching the container.
 
 1. For example, to secure the Jupyter Server with a [custom password](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#preparing-a-hashed-password)
    hashed using `jupyter_server.auth.passwd()` instead of the default token,
@@ -16,19 +16,19 @@ You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/l
 
    ```bash
    docker run -it --rm -p 8888:8888 jupyter/base-notebook \
-       start-notebook.sh --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
+       start-notebook.py --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
    docker run  -it --rm -p 8888:8888 jupyter/base-notebook \
-       start-notebook.sh --ServerApp.base_url=/customized/url/prefix/
+       start-notebook.py --ServerApp.base_url=/customized/url/prefix/
    ```
 
 ## Docker Options
 
-You may instruct the `start-notebook.sh` script to customize the container environment before launching the Server.
+You may instruct the `start-notebook.py` script to customize the container environment before launching the Server.
 You do so by passing arguments to the `docker run` command.
 
 ### User-related configurations
@@ -104,7 +104,7 @@ You do so by passing arguments to the `docker run` command.
   You do **not** need this option to allow the user to `conda` or `pip` install additional packages.
   This option is helpful for cases when you wish to give `${NB_USER}` the ability to install OS packages with `apt` or modify other root-owned files in the container.
   You **must** run the container with `--user root` for this option to take effect.
-  (The `start-notebook.sh` script will `su ${NB_USER}` after adding `${NB_USER}` to sudoers.)
+  (The `start-notebook.py` script will `su ${NB_USER}` after adding `${NB_USER}` to sudoers.)
   **You should only enable `sudo` if you trust the user or if the container runs on an isolated host.**
 
 ### Additional runtime configurations
@@ -147,7 +147,7 @@ For example, to mount a host folder containing a `notebook.key` and `notebook.cr
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder:/etc/ssl/notebook \
     jupyter/base-notebook \
-    start-notebook.sh \
+    start-notebook.py \
     --ServerApp.keyfile=/etc/ssl/notebook/notebook.key \
     --ServerApp.certfile=/etc/ssl/notebook/notebook.crt
 ```
@@ -159,7 +159,7 @@ For example:
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder/notebook.pem:/etc/ssl/notebook.pem \
     jupyter/base-notebook \
-    start-notebook.sh \
+    start-notebook.py \
     --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
 
@@ -220,7 +220,7 @@ docker run -it --rm \
 
 ### `start.sh`
 
-The `start-notebook.sh` script inherits most of its option handling capability from a more generic `start.sh` script.
+The `start-notebook.py` script inherits most of its option handling capability from a more generic `start.sh` script.
 The `start.sh` script supports all the features described above but allows you to specify an arbitrary command to execute.
 For example, to run the text-based `ipython` console in a container, do the following:",Yes
docs/using/recipes.md,docs/using/recipes.md,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index cfeb4ced..196cd425 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -375,14 +375,14 @@ Credit: [britishbadger](https://github.com/britishbadger) from [docker-stacks/is
 The default security is very good.
 There are use cases, encouraged by containers, where the jupyter container and the system it runs within lie inside the security boundary.
 It is convenient to launch the server without a password or token in these use cases.
-In this case, you should use the `start-notebook.sh` script to launch the server with no token:
+In this case, you should use the `start-notebook.py` script to launch the server with no token:
 
 For JupyterLab:
 
 ```bash
 docker run -it --rm \
     jupyter/base-notebook \
-    start-notebook.sh --IdentityProvider.token=''
+    start-notebook.py --IdentityProvider.token=''
 ```
 
 For Jupyter Notebook:
@@ -391,7 +391,7 @@ For Jupyter Notebook:
 docker run -it --rm \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
     jupyter/base-notebook \
-    start-notebook.sh --IdentityProvider.token=''
+    start-notebook.py --IdentityProvider.token=''
 ```
 
 ## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index cfeb4ced..196cd425 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -375,14 +375,14 @@ Credit: [britishbadger](https://github.com/britishbadger) from [docker-stacks/is
 The default security is very good.
 There are use cases, encouraged by containers, where the jupyter container and the system it runs within lie inside the security boundary.
 It is convenient to launch the server without a password or token in these use cases.
-In this case, you should use the `start-notebook.sh` script to launch the server with no token:
+In this case, you should use the `start-notebook.py` script to launch the server with no token:
 
 For JupyterLab:
 
 ```bash
 docker run -it --rm \
     jupyter/base-notebook \
-    start-notebook.sh --IdentityProvider.token=''
+    start-notebook.py --IdentityProvider.token=''
 ```
 
 For Jupyter Notebook:
@@ -391,7 +391,7 @@ For Jupyter Notebook:
 docker run -it --rm \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
     jupyter/base-notebook \
-    start-notebook.sh --IdentityProvider.token=''
+    start-notebook.py --IdentityProvider.token=''
 ```
 
 ## Enable nbclassic-extension spellchecker for markdown (or any other nbclassic-extension)",Yes
docs/using/running.md,docs/using/running.md,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/running.md b/docs/using/running.md
index 4e764184..b888c043 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -69,7 +69,7 @@ Any other changes made in the container will be lost.
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
 So, new notebooks will be saved there, unless you change the directory in the file browser.
 
-To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
 ### Example 3","diff --git a/docs/using/running.md b/docs/using/running.md
index 4e764184..b888c043 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -69,7 +69,7 @@ Any other changes made in the container will be lost.
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
 So, new notebooks will be saved there, unless you change the directory in the file browser.
 
-To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.sh --ServerApp.root_dir=/home/jovyan/work`.
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
 ### Example 3",Yes
docs/using/selecting.md,docs/using/selecting.md,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 450e463a..7f763fee 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -56,10 +56,17 @@ It contains:
 - Everything in `jupyter/docker-stacks-foundation`
 - Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
 - `notebook`, `jupyterhub` and `jupyterlab` packages
-- A `start-notebook.sh` script as the default command
-- A `start-singleuser.sh` script useful for launching containers in JupyterHub
+- A `start-notebook.py` script as the default command
+- A `start-singleuser.py` script useful for launching containers in JupyterHub
 - Options for a self-signed HTTPS certificate
 
+```{warning}
+`jupyter/base-notebook` also contains `start-notebook.sh` and `start-singleuser.sh` files to maintain backwards compatibility.
+External config that explicitly refers to those files should instead
+update to refer to `start-notebook.py` and `start-singleuser.py`.
+The shim `.sh` files will be removed at some future date.
+```
+
 ### jupyter/minimal-notebook
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/minimal-notebook) |","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 450e463a..7f763fee 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -56,10 +56,17 @@ It contains:
 - Everything in `jupyter/docker-stacks-foundation`
 - Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
 - `notebook`, `jupyterhub` and `jupyterlab` packages
-- A `start-notebook.sh` script as the default command
-- A `start-singleuser.sh` script useful for launching containers in JupyterHub
+- A `start-notebook.py` script as the default command
+- A `start-singleuser.py` script useful for launching containers in JupyterHub
 - Options for a self-signed HTTPS certificate
 
+```{warning}
+`jupyter/base-notebook` also contains `start-notebook.sh` and `start-singleuser.sh` files to maintain backwards compatibility.
+External config that explicitly refers to those files should instead
+update to refer to `start-notebook.py` and `start-singleuser.py`.
+The shim `.sh` files will be removed at some future date.
+```
+
 ### jupyter/minimal-notebook
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/minimal-notebook) |",Yes
examples/docker-compose/notebook/letsencrypt-notebook.yml,examples/docker-compose/notebook/letsencrypt-notebook.yml,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/examples/docker-compose/notebook/letsencrypt-notebook.yml b/examples/docker-compose/notebook/letsencrypt-notebook.yml
index 1c47c99e..06bab319 100644
--- a/examples/docker-compose/notebook/letsencrypt-notebook.yml
+++ b/examples/docker-compose/notebook/letsencrypt-notebook.yml
@@ -18,7 +18,7 @@ services:
       USE_HTTPS: ""yes""
       PASSWORD: ${PASSWORD}
     command: >
-      start-notebook.sh
+      start-notebook.py
       --ServerApp.certfile=/etc/letsencrypt/fullchain.pem
       --ServerApp.keyfile=/etc/letsencrypt/privkey.pem","diff --git a/examples/docker-compose/notebook/letsencrypt-notebook.yml b/examples/docker-compose/notebook/letsencrypt-notebook.yml
index 1c47c99e..06bab319 100644
--- a/examples/docker-compose/notebook/letsencrypt-notebook.yml
+++ b/examples/docker-compose/notebook/letsencrypt-notebook.yml
@@ -18,7 +18,7 @@ services:
       USE_HTTPS: ""yes""
       PASSWORD: ${PASSWORD}
     command: >
-      start-notebook.sh
+      start-notebook.py
       --ServerApp.certfile=/etc/letsencrypt/fullchain.pem
       --ServerApp.keyfile=/etc/letsencrypt/privkey.pem",Yes
examples/make-deploy/Makefile,examples/make-deploy/Makefile,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/examples/make-deploy/Makefile b/examples/make-deploy/Makefile
index e937621c..aa62dd0b 100644
--- a/examples/make-deploy/Makefile
+++ b/examples/make-deploy/Makefile
@@ -13,7 +13,7 @@ define RUN_NOTEBOOK
 	--name $(NAME) \
 	-v $(WORK_VOLUME):/home/jovyan/work \
 	$(DOCKER_ARGS) \
-	$(IMAGE) bash -c ""$(PRE_CMD) chown jovyan /home/jovyan/work && start-notebook.sh $(ARGS)"" > /dev/null
+	$(IMAGE) bash -c ""$(PRE_CMD) chown jovyan /home/jovyan/work && start-notebook.py $(ARGS)"" > /dev/null
 @echo ""DONE: Notebook '$(NAME)' listening on $$(docker-machine ip $$(docker-machine active)):$(PORT)""
 endef","diff --git a/examples/make-deploy/Makefile b/examples/make-deploy/Makefile
index e937621c..aa62dd0b 100644
--- a/examples/make-deploy/Makefile
+++ b/examples/make-deploy/Makefile
@@ -13,7 +13,7 @@ define RUN_NOTEBOOK
 	--name $(NAME) \
 	-v $(WORK_VOLUME):/home/jovyan/work \
 	$(DOCKER_ARGS) \
-	$(IMAGE) bash -c ""$(PRE_CMD) chown jovyan /home/jovyan/work && start-notebook.sh $(ARGS)"" > /dev/null
+	$(IMAGE) bash -c ""$(PRE_CMD) chown jovyan /home/jovyan/work && start-notebook.py $(ARGS)"" > /dev/null
 @echo ""DONE: Notebook '$(NAME)' listening on $$(docker-machine ip $$(docker-machine active)):$(PORT)""
 endef",Yes
examples/openshift/templates.json,examples/openshift/templates.json,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/examples/openshift/templates.json b/examples/openshift/templates.json
index 6c48e129..e12036ec 100644
--- a/examples/openshift/templates.json
+++ b/examples/openshift/templates.json
@@ -80,7 +80,7 @@
                 ""name"": ""jupyter-notebook"",
                 ""image"": ""${NOTEBOOK_IMAGE}"",
                 ""command"": [
-                  ""start-notebook.sh"",
+                  ""start-notebook.py"",
                   ""--config=/etc/jupyter/openshift/jupyter_server_config.py"",
                   ""--no-browser"",
                   ""--ip=0.0.0.0""","diff --git a/examples/openshift/templates.json b/examples/openshift/templates.json
index 6c48e129..e12036ec 100644
--- a/examples/openshift/templates.json
+++ b/examples/openshift/templates.json
@@ -80,7 +80,7 @@
                 ""name"": ""jupyter-notebook"",
                 ""image"": ""${NOTEBOOK_IMAGE}"",
                 ""command"": [
-                  ""start-notebook.sh"",
+                  ""start-notebook.py"",
                   ""--config=/etc/jupyter/openshift/jupyter_server_config.py"",
                   ""--no-browser"",
                   ""--ip=0.0.0.0""",Yes
examples/source-to-image/README.md,examples/source-to-image/README.md,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/examples/source-to-image/README.md b/examples/source-to-image/README.md
index 1e9d3ba9..8639c109 100644
--- a/examples/source-to-image/README.md
+++ b/examples/source-to-image/README.md
@@ -117,7 +117,7 @@ with the extra system packages, and then use that image with the S2I build to co
 The `run` script in this directory is very simple and just runs the notebook application.
 
 ```bash
-exec start-notebook.sh ""$@""
+exec start-notebook.py ""$@""
 ```
 
 ## Integration with OpenShift","diff --git a/examples/source-to-image/README.md b/examples/source-to-image/README.md
index 1e9d3ba9..8639c109 100644
--- a/examples/source-to-image/README.md
+++ b/examples/source-to-image/README.md
@@ -117,7 +117,7 @@ with the extra system packages, and then use that image with the S2I build to co
 The `run` script in this directory is very simple and just runs the notebook application.
 
 ```bash
-exec start-notebook.sh ""$@""
+exec start-notebook.py ""$@""
 ```
 
 ## Integration with OpenShift",Yes
examples/source-to-image/run,examples/source-to-image/run,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/examples/source-to-image/run b/examples/source-to-image/run
index b5b641b8..556efdda 100755
--- a/examples/source-to-image/run
+++ b/examples/source-to-image/run
@@ -2,4 +2,4 @@
 
 # Start up the notebook instance.
 
-exec start-notebook.sh ""$@""
+exec start-notebook.py ""$@""","diff --git a/examples/source-to-image/run b/examples/source-to-image/run
index b5b641b8..556efdda 100755
--- a/examples/source-to-image/run
+++ b/examples/source-to-image/run
@@ -2,4 +2,4 @@
 
 # Start up the notebook instance.
 
-exec start-notebook.sh ""$@""
+exec start-notebook.py ""$@""",Yes
examples/source-to-image/templates.json,examples/source-to-image/templates.json,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/examples/source-to-image/templates.json b/examples/source-to-image/templates.json
index e335fc68..8daa0823 100644
--- a/examples/source-to-image/templates.json
+++ b/examples/source-to-image/templates.json
@@ -274,7 +274,7 @@
                     ""name"": ""jupyter-notebook"",
                     ""image"": ""${APPLICATION_NAME}:latest"",
                     ""command"": [
-                      ""start-notebook.sh"",
+                      ""start-notebook.py"",
                       ""--config=/etc/jupyter/openshift/jupyter_server_config.py"",
                       ""--no-browser"",
                       ""--ip=0.0.0.0""","diff --git a/examples/source-to-image/templates.json b/examples/source-to-image/templates.json
index e335fc68..8daa0823 100644
--- a/examples/source-to-image/templates.json
+++ b/examples/source-to-image/templates.json
@@ -274,7 +274,7 @@
                     ""name"": ""jupyter-notebook"",
                     ""image"": ""${APPLICATION_NAME}:latest"",
                     ""command"": [
-                      ""start-notebook.sh"",
+                      ""start-notebook.py"",
                       ""--config=/etc/jupyter/openshift/jupyter_server_config.py"",
                       ""--no-browser"",
                       ""--ip=0.0.0.0""",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 5f47a5d4..03c6eed9 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -52,10 +52,10 @@ ENV JUPYTER_PORT=8888
 EXPOSE $JUPYTER_PORT
 
 # Configure container startup
-CMD [""start-notebook.sh""]
+CMD [""start-notebook.py""]
 
 # Copy local files as late as possible to avoid cache busting
-COPY start-notebook.sh start-singleuser.sh /usr/local/bin/
+COPY start-notebook.py start-notebook.sh start-singleuser.py start-singleuser.sh /usr/local/bin/
 COPY jupyter_server_config.py docker_healthcheck.py /etc/jupyter/
 
 # Fix permissions on /etc/jupyter as root","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 5f47a5d4..03c6eed9 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -52,10 +52,10 @@ ENV JUPYTER_PORT=8888
 EXPOSE $JUPYTER_PORT
 
 # Configure container startup
-CMD [""start-notebook.sh""]
+CMD [""start-notebook.py""]
 
 # Copy local files as late as possible to avoid cache busting
-COPY start-notebook.sh start-singleuser.sh /usr/local/bin/
+COPY start-notebook.py start-notebook.sh start-singleuser.py start-singleuser.sh /usr/local/bin/
 COPY jupyter_server_config.py docker_healthcheck.py /etc/jupyter/
 
 # Fix permissions on /etc/jupyter as root",Yes
,images/base-notebook/start-notebook.py,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
new file mode 100755
index 00000000..db1efc24
--- /dev/null
+++ b/images/base-notebook/start-notebook.py
@@ -0,0 +1,41 @@
+#!/usr/bin/env python
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import os
+import shlex
+import sys
+
+# If we are in a JupyterHub, we pass on to `start-singleuser.py` instead so it does the right thing
+if ""JUPYTERHUB_API_TOKEN"" in os.environ:
+    print(
+        ""WARNING: using start-singleuser.py instead of start-notebook.py to start a server associated with JupyterHub.""
+    )
+    command = [""/usr/local/bin/start-singleuser.py""] + sys.argv[1:]
+    os.execvp(command[0], command)
+
+
+# Wrap everything in start.sh, no matter what
+command = [""/usr/local/bin/start.sh""]
+
+# If we want to survive restarts, tell that to start.sh
+if os.environ.get(""RESTARTABLE"") == ""yes"":
+    command.append(""run-one-constantly"")
+
+# We always launch a jupyter subcommand from this script
+command.append(""jupyter"")
+
+# Launch the configured subcommand. Note that this should be a single string, so we don't split it
+# We default to lab
+jupyter_command = os.environ.get(""DOCKER_STACKS_JUPYTER_CMD"", ""lab"")
+command.append(jupyter_command)
+
+# Append any optional NOTEBOOK_ARGS we were passed in. This is supposed to be multiple args passed
+# on to the notebook command, so we split it correctly with shlex
+if ""NOTEBOOK_ARGS"" in os.environ:
+    command += shlex.split(os.environ[""NOTEBOOK_ARGS""])
+
+# Pass through any other args we were passed on the commandline
+command += sys.argv[1:]
+
+# Execute the command!
+os.execvp(command[0], command)","diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
new file mode 100755
index 00000000..db1efc24
--- /dev/null
+++ b/images/base-notebook/start-notebook.py
@@ -0,0 +1,41 @@
+#!/usr/bin/env python
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import os
+import shlex
+import sys
+
+# If we are in a JupyterHub, we pass on to `start-singleuser.py` instead so it does the right thing
+if ""JUPYTERHUB_API_TOKEN"" in os.environ:
+    print(
+        ""WARNING: using start-singleuser.py instead of start-notebook.py to start a server associated with JupyterHub.""
+    )
+    command = [""/usr/local/bin/start-singleuser.py""] + sys.argv[1:]
+    os.execvp(command[0], command)
+
+
+# Wrap everything in start.sh, no matter what
+command = [""/usr/local/bin/start.sh""]
+
+# If we want to survive restarts, tell that to start.sh
+if os.environ.get(""RESTARTABLE"") == ""yes"":
+    command.append(""run-one-constantly"")
+
+# We always launch a jupyter subcommand from this script
+command.append(""jupyter"")
+
+# Launch the configured subcommand. Note that this should be a single string, so we don't split it
+# We default to lab
+jupyter_command = os.environ.get(""DOCKER_STACKS_JUPYTER_CMD"", ""lab"")
+command.append(jupyter_command)
+
+# Append any optional NOTEBOOK_ARGS we were passed in. This is supposed to be multiple args passed
+# on to the notebook command, so we split it correctly with shlex
+if ""NOTEBOOK_ARGS"" in os.environ:
+    command += shlex.split(os.environ[""NOTEBOOK_ARGS""])
+
+# Pass through any other args we were passed on the commandline
+command += sys.argv[1:]
+
+# Execute the command!
+os.execvp(command[0], command)",Yes
images/base-notebook/start-notebook.sh,images/base-notebook/start-notebook.sh,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/base-notebook/start-notebook.sh b/images/base-notebook/start-notebook.sh
index 4f673d22..c47ebba3 100755
--- a/images/base-notebook/start-notebook.sh
+++ b/images/base-notebook/start-notebook.sh
@@ -1,22 +1,5 @@
 #!/bin/bash
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
+# Shim to emit warning and call start-notebook.py
+echo ""WARNING: Use start-notebook.py instead""
 
-set -e
-
-# The Jupyter command to launch
-# JupyterLab by default
-DOCKER_STACKS_JUPYTER_CMD=""${DOCKER_STACKS_JUPYTER_CMD:=lab}""
-
-if [[ -n ""${JUPYTERHUB_API_TOKEN}"" ]]; then
-    echo ""WARNING: using start-singleuser.sh instead of start-notebook.sh to start a server associated with JupyterHub.""
-    exec /usr/local/bin/start-singleuser.sh ""$@""
-fi
-
-wrapper=""""
-if [[ ""${RESTARTABLE}"" == ""yes"" ]]; then
-    wrapper=""run-one-constantly""
-fi
-
-# shellcheck disable=SC1091,SC2086
-exec /usr/local/bin/start.sh ${wrapper} jupyter ${DOCKER_STACKS_JUPYTER_CMD} ${NOTEBOOK_ARGS} ""$@""
+exec /usr/local/bin/start-notebook.py ""$@""","diff --git a/images/base-notebook/start-notebook.sh b/images/base-notebook/start-notebook.sh
index 4f673d22..c47ebba3 100755
--- a/images/base-notebook/start-notebook.sh
+++ b/images/base-notebook/start-notebook.sh
@@ -1,22 +1,5 @@
 #!/bin/bash
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
+# Shim to emit warning and call start-notebook.py
+echo ""WARNING: Use start-notebook.py instead""
 
-set -e
-
-# The Jupyter command to launch
-# JupyterLab by default
-DOCKER_STACKS_JUPYTER_CMD=""${DOCKER_STACKS_JUPYTER_CMD:=lab}""
-
-if [[ -n ""${JUPYTERHUB_API_TOKEN}"" ]]; then
-    echo ""WARNING: using start-singleuser.sh instead of start-notebook.sh to start a server associated with JupyterHub.""
-    exec /usr/local/bin/start-singleuser.sh ""$@""
-fi
-
-wrapper=""""
-if [[ ""${RESTARTABLE}"" == ""yes"" ]]; then
-    wrapper=""run-one-constantly""
-fi
-
-# shellcheck disable=SC1091,SC2086
-exec /usr/local/bin/start.sh ${wrapper} jupyter ${DOCKER_STACKS_JUPYTER_CMD} ${NOTEBOOK_ARGS} ""$@""
+exec /usr/local/bin/start-notebook.py ""$@""",Yes
,images/base-notebook/start-singleuser.py,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/base-notebook/start-singleuser.py b/images/base-notebook/start-singleuser.py
new file mode 100755
index 00000000..2dcf6c09
--- /dev/null
+++ b/images/base-notebook/start-singleuser.py
@@ -0,0 +1,23 @@
+#!/usr/bin/env python
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import os
+import shlex
+import sys
+
+command = [""/usr/local/bin/start.sh"", ""jupyterhub-singleuser""]
+
+# set default ip to 0.0.0.0
+if ""--ip="" not in os.environ.get(""NOTEBOOK_ARGS"", """"):
+    command.append(""--ip=0.0.0.0"")
+
+# Append any optional NOTEBOOK_ARGS we were passed in. This is supposed to be multiple args passed
+# on to the notebook command, so we split it correctly with shlex
+if ""NOTEBOOK_ARGS"" in os.environ:
+    command += shlex.split(os.environ[""NOTEBOOK_ARGS""])
+
+# Pass any other args we have been passed through
+command += sys.argv[1:]
+
+# Execute the command!
+os.execvp(command[0], command)","diff --git a/images/base-notebook/start-singleuser.py b/images/base-notebook/start-singleuser.py
new file mode 100755
index 00000000..2dcf6c09
--- /dev/null
+++ b/images/base-notebook/start-singleuser.py
@@ -0,0 +1,23 @@
+#!/usr/bin/env python
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import os
+import shlex
+import sys
+
+command = [""/usr/local/bin/start.sh"", ""jupyterhub-singleuser""]
+
+# set default ip to 0.0.0.0
+if ""--ip="" not in os.environ.get(""NOTEBOOK_ARGS"", """"):
+    command.append(""--ip=0.0.0.0"")
+
+# Append any optional NOTEBOOK_ARGS we were passed in. This is supposed to be multiple args passed
+# on to the notebook command, so we split it correctly with shlex
+if ""NOTEBOOK_ARGS"" in os.environ:
+    command += shlex.split(os.environ[""NOTEBOOK_ARGS""])
+
+# Pass any other args we have been passed through
+command += sys.argv[1:]
+
+# Execute the command!
+os.execvp(command[0], command)",Yes
images/base-notebook/start-singleuser.sh,images/base-notebook/start-singleuser.sh,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/base-notebook/start-singleuser.sh b/images/base-notebook/start-singleuser.sh
index a2166e2c..ecf0e068 100755
--- a/images/base-notebook/start-singleuser.sh
+++ b/images/base-notebook/start-singleuser.sh
@@ -1,13 +1,5 @@
 #!/bin/bash
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
+# Shim to emit warning and call start-singleuser.py
+echo ""WARNING: Use start-singleuser.py instead""
 
-set -e
-
-# set default ip to 0.0.0.0
-if [[ ""${NOTEBOOK_ARGS} $*"" != *""--ip=""* ]]; then
-    NOTEBOOK_ARGS=""--ip=0.0.0.0 ${NOTEBOOK_ARGS}""
-fi
-
-# shellcheck disable=SC1091,SC2086
-. /usr/local/bin/start.sh jupyterhub-singleuser ${NOTEBOOK_ARGS} ""$@""
+exec /usr/local/bin/start-singleuser.py ""$@""","diff --git a/images/base-notebook/start-singleuser.sh b/images/base-notebook/start-singleuser.sh
index a2166e2c..ecf0e068 100755
--- a/images/base-notebook/start-singleuser.sh
+++ b/images/base-notebook/start-singleuser.sh
@@ -1,13 +1,5 @@
 #!/bin/bash
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
+# Shim to emit warning and call start-singleuser.py
+echo ""WARNING: Use start-singleuser.py instead""
 
-set -e
-
-# set default ip to 0.0.0.0
-if [[ ""${NOTEBOOK_ARGS} $*"" != *""--ip=""* ]]; then
-    NOTEBOOK_ARGS=""--ip=0.0.0.0 ${NOTEBOOK_ARGS}""
-fi
-
-# shellcheck disable=SC1091,SC2086
-. /usr/local/bin/start.sh jupyterhub-singleuser ${NOTEBOOK_ARGS} ""$@""
+exec /usr/local/bin/start-singleuser.py ""$@""",Yes
tests/base-notebook/test_container_options.py,tests/base-notebook/test_container_options.py,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 5fa28d89..1ea501d8 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -15,7 +15,7 @@ def test_cli_args(container: TrackedContainer, http_client: requests.Session) ->
     """"""Image should respect command line args (e.g., disabling token security)""""""
     host_port = find_free_port()
     running_container = container.run_detached(
-        command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
+        command=[""start-notebook.py"", ""--IdentityProvider.token=''""],
         ports={""8888/tcp"": host_port},
     )
     resp = http_client.get(f""http://localhost:{host_port}"")
@@ -102,7 +102,7 @@ def test_custom_internal_port(
     host_port = find_free_port()
     internal_port = env.get(""JUPYTER_PORT"", 8888)
     running_container = container.run_detached(
-        command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
+        command=[""start-notebook.py"", ""--IdentityProvider.token=''""],
         environment=env,
         ports={internal_port: host_port},
     )","diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 5fa28d89..1ea501d8 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -15,7 +15,7 @@ def test_cli_args(container: TrackedContainer, http_client: requests.Session) ->
     """"""Image should respect command line args (e.g., disabling token security)""""""
     host_port = find_free_port()
     running_container = container.run_detached(
-        command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
+        command=[""start-notebook.py"", ""--IdentityProvider.token=''""],
         ports={""8888/tcp"": host_port},
     )
     resp = http_client.get(f""http://localhost:{host_port}"")
@@ -102,7 +102,7 @@ def test_custom_internal_port(
     host_port = find_free_port()
     internal_port = env.get(""JUPYTER_PORT"", 8888)
     running_container = container.run_detached(
-        command=[""start-notebook.sh"", ""--IdentityProvider.token=''""],
+        command=[""start-notebook.py"", ""--IdentityProvider.token=''""],
         environment=env,
         ports={internal_port: host_port},
     )",Yes
tests/base-notebook/test_healthcheck.py,tests/base-notebook/test_healthcheck.py,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 73de1003..50d83c27 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -22,23 +22,24 @@ LOGGER = logging.getLogger(__name__)
         ([""RESTARTABLE=yes""], None, None),
         ([""JUPYTER_PORT=8171""], None, None),
         ([""JUPYTER_PORT=8117"", ""DOCKER_STACKS_JUPYTER_CMD=notebook""], None, None),
-        (None, [""start-notebook.sh"", ""--ServerApp.base_url=/test""], None),
-        (None, [""start-notebook.sh"", ""--ServerApp.base_url=/test/""], None),
-        ([""GEN_CERT=1""], [""start-notebook.sh"", ""--ServerApp.base_url=/test""], None),
+        (None, [""start-notebook.sh""], None),
+        (None, [""start-notebook.py"", ""--ServerApp.base_url=/test""], None),
+        (None, [""start-notebook.py"", ""--ServerApp.base_url=/test/""], None),
+        ([""GEN_CERT=1""], [""start-notebook.py"", ""--ServerApp.base_url=/test""], None),
         (
             [""GEN_CERT=1"", ""JUPYTER_PORT=7891""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             None,
         ),
         ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, ""root""),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
     ],
@@ -85,7 +86,7 @@ def test_health(
                 ""HTTPS_PROXY=host.docker.internal"",
                 ""HTTP_PROXY=host.docker.internal"",
             ],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
     ],
@@ -122,12 +123,12 @@ def test_health_proxy(
         ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, None),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             None,
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             None,
         ),
     ],","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 73de1003..50d83c27 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -22,23 +22,24 @@ LOGGER = logging.getLogger(__name__)
         ([""RESTARTABLE=yes""], None, None),
         ([""JUPYTER_PORT=8171""], None, None),
         ([""JUPYTER_PORT=8117"", ""DOCKER_STACKS_JUPYTER_CMD=notebook""], None, None),
-        (None, [""start-notebook.sh"", ""--ServerApp.base_url=/test""], None),
-        (None, [""start-notebook.sh"", ""--ServerApp.base_url=/test/""], None),
-        ([""GEN_CERT=1""], [""start-notebook.sh"", ""--ServerApp.base_url=/test""], None),
+        (None, [""start-notebook.sh""], None),
+        (None, [""start-notebook.py"", ""--ServerApp.base_url=/test""], None),
+        (None, [""start-notebook.py"", ""--ServerApp.base_url=/test/""], None),
+        ([""GEN_CERT=1""], [""start-notebook.py"", ""--ServerApp.base_url=/test""], None),
         (
             [""GEN_CERT=1"", ""JUPYTER_PORT=7891""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             None,
         ),
         ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, ""root""),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
     ],
@@ -85,7 +86,7 @@ def test_health(
                 ""HTTPS_PROXY=host.docker.internal"",
                 ""HTTP_PROXY=host.docker.internal"",
             ],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
     ],
@@ -122,12 +123,12 @@ def test_health_proxy(
         ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, None),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             None,
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
-            [""start-notebook.sh"", ""--ServerApp.base_url=/test""],
+            [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             None,
         ),
     ],",Yes
tests/base-notebook/test_start_container.py,tests/base-notebook/test_start_container.py,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index 556f4c2c..830b36c7 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -25,7 +25,7 @@ LOGGER = logging.getLogger(__name__)
             [""JUPYTERHUB_API_TOKEN=my_token""],
             ""jupyterhub-singleuser"",
             False,
-            [""WARNING: using start-singleuser.sh""],
+            [""WARNING: using start-singleuser.py""],
         ),
     ],
 )
@@ -37,9 +37,9 @@ def test_start_notebook(
     expected_start: bool,
     expected_warnings: list[str],
 ) -> None:
-    """"""Test the notebook start-notebook script""""""
+    """"""Test the notebook start-notebook.py script""""""
     LOGGER.info(
-        f""Test that the start-notebook launches the {expected_command} server from the env {env} ...""
+        f""Test that the start-notebook.py launches the {expected_command} server from the env {env} ...""
     )
     host_port = find_free_port()
     running_container = container.run_detached(","diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index 556f4c2c..830b36c7 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -25,7 +25,7 @@ LOGGER = logging.getLogger(__name__)
             [""JUPYTERHUB_API_TOKEN=my_token""],
             ""jupyterhub-singleuser"",
             False,
-            [""WARNING: using start-singleuser.sh""],
+            [""WARNING: using start-singleuser.py""],
         ),
     ],
 )
@@ -37,9 +37,9 @@ def test_start_notebook(
     expected_start: bool,
     expected_warnings: list[str],
 ) -> None:
-    """"""Test the notebook start-notebook script""""""
+    """"""Test the notebook start-notebook.py script""""""
     LOGGER.info(
-        f""Test that the start-notebook launches the {expected_command} server from the env {env} ...""
+        f""Test that the start-notebook.py launches the {expected_command} server from the env {env} ...""
     )
     host_port = find_free_port()
     running_container = container.run_detached(",Yes
tests/pluto_check.py,tests/pluto_check.py,bceaead5d288faf8b6da09d94829041b62bf34e4,4c0c0aa1715f8f5f964192462228a84bb540ed69,"Migrate start-notebook & start-singleuser to python (#2006)

* Migrate start-notebook.sh to bash

Based on

> Stop using bash, haha 👍

from https://github.com/jupyter/docker-stacks/issues/1532.

If there's more apetite for this, I'll try to migrate
`start.sh` and `start-singleuser.sh` as well - I think they should
all be merged together. We can remove the `.sh` suffixes for
accuracy, and keep symlinks in so old config still works. Since
the shebang is what is used to launch the correct interpreter,
the `.sh` doesn't matter.

Will help fix https://github.com/jupyter/docker-stacks/issues/1532,
as I believe all those things are going to be easier to do from
python than bash

* Rename start-notebook.sh to start-notebook

* Cleanup start-notebook a little

* Fix typo

* Migrate start-singleuser as well

* Remove unused import

* Run symlink commands as root

* Combine repetitive RUN commands

* Remove multiple args to env

-u can not be set by shebang, we must set the env var
instead

* Fix conditional inversion

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Fix how start-singleuser is exec'd

* Actually call jupyterhub-singleuser in start-singleuser

* Pass through any additional args we get

* Put .py suffix on the start-* scripts

* Add .sh shims for the start-* scripts

* Document start-notebook.sh and start-singleuser.sh

* Partially test start-notebook.sh

* Reflow warning docs

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/pluto_check.py b/tests/pluto_check.py
index 5fc269de..ebb558b4 100644
--- a/tests/pluto_check.py
+++ b/tests/pluto_check.py
@@ -18,7 +18,7 @@ def check_pluto_proxy(
     token = secrets.token_hex()
     container.run_detached(
         command=[
-            ""start-notebook.sh"",
+            ""start-notebook.py"",
             f""--IdentityProvider.token={token}"",
         ],
         ports={""8888/tcp"": host_port},","diff --git a/tests/pluto_check.py b/tests/pluto_check.py
index 5fc269de..ebb558b4 100644
--- a/tests/pluto_check.py
+++ b/tests/pluto_check.py
@@ -18,7 +18,7 @@ def check_pluto_proxy(
     token = secrets.token_hex()
     container.run_detached(
         command=[
-            ""start-notebook.sh"",
+            ""start-notebook.py"",
             f""--IdentityProvider.token={token}"",
         ],
         ports={""8888/tcp"": host_port},",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index a15e8eb1..7f8c1deb 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -1,6 +1,7 @@
 name: Download parent image, build a new one and test it; then upload the image, tags and manifests to GitHub artifacts
 
 env:
+  REGISTRY: docker.io
   OWNER: ${{ github.repository_owner }}
 
 on:
@@ -60,7 +61,7 @@ jobs:
         shell: bash
 
       - name: Build image 🛠
-        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/ --build-arg OWNER=${{ env.OWNER }}
+        run: docker build --rm --force-rm --tag ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/ --build-arg REGISTRY=${{ env.REGISTRY }} --build-arg OWNER=${{ env.OWNER }}
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build
@@ -68,12 +69,12 @@ jobs:
         shell: bash
 
       - name: Run tests ✅
-        run: python3 -m tests.run_tests --short-image-name ${{ inputs.image }} --owner ${{ env.OWNER }}
+        run: python3 -m tests.run_tests --short-image-name ${{ inputs.image }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
 
       - name: Write tags file 🏷
         run: |
-          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --owner ${{ env.OWNER }}
+          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
         uses: actions/upload-artifact@v3
@@ -83,7 +84,7 @@ jobs:
           retention-days: 3
 
       - name: Write manifest and build history file 🏷
-        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ${{ env.OWNER }}
+        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
         uses: actions/upload-artifact@v3","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index a15e8eb1..7f8c1deb 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -1,6 +1,7 @@
 name: Download parent image, build a new one and test it; then upload the image, tags and manifests to GitHub artifacts
 
 env:
+  REGISTRY: docker.io
   OWNER: ${{ github.repository_owner }}
 
 on:
@@ -60,7 +61,7 @@ jobs:
         shell: bash
 
       - name: Build image 🛠
-        run: docker build --rm --force-rm --tag ${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/ --build-arg OWNER=${{ env.OWNER }}
+        run: docker build --rm --force-rm --tag ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/ --build-arg REGISTRY=${{ env.REGISTRY }} --build-arg OWNER=${{ env.OWNER }}
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build
@@ -68,12 +69,12 @@ jobs:
         shell: bash
 
       - name: Run tests ✅
-        run: python3 -m tests.run_tests --short-image-name ${{ inputs.image }} --owner ${{ env.OWNER }}
+        run: python3 -m tests.run_tests --short-image-name ${{ inputs.image }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
 
       - name: Write tags file 🏷
         run: |
-          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --owner ${{ env.OWNER }}
+          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
         uses: actions/upload-artifact@v3
@@ -83,7 +84,7 @@ jobs:
           retention-days: 3
 
       - name: Write manifest and build history file 🏷
-        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ${{ env.OWNER }}
+        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
         uses: actions/upload-artifact@v3",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index adb7f1bb..43233099 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,6 +1,7 @@
 name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to Docker Hub
 
 env:
+  REGISTRY: docker.io
   OWNER: ${{ github.repository_owner }}
 
 on:
@@ -50,7 +51,7 @@ jobs:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
-        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
 
       - name: Push Images to Docker Hub 📤
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index adb7f1bb..43233099 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,6 +1,7 @@
 name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to Docker Hub
 
 env:
+  REGISTRY: docker.io
   OWNER: ${{ github.repository_owner }}
 
 on:
@@ -50,7 +51,7 @@ jobs:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
-        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
 
       - name: Push Images to Docker Hub 📤
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')",Yes
Makefile,Makefile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/Makefile b/Makefile
index b6613794..62fd507b 100644
--- a/Makefile
+++ b/Makefile
@@ -4,6 +4,7 @@
 
 # Use bash for inline if-statements in arch_patch target
 SHELL:=bash
+REGISTRY?=docker.io
 OWNER?=jupyter
 
 # Need to list the images in build dependency order
@@ -37,9 +38,9 @@ help:
 
 build/%: DOCKER_BUILD_ARGS?=
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg OWNER=""$(OWNER)""
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)""
 	@echo -n ""Built image size: ""
-	@docker images ""$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
+	@docker images ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks
 
 
@@ -68,9 +69,9 @@ linkcheck-docs: ## check broken links
 
 
 hook/%: ## run post-build hooks for an image
-	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)"" && \
-	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --owner ""$(OWNER)""
+	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images
 
 
@@ -105,5 +106,5 @@ run-sudo-shell/%: ## run a bash in interactive mode as root in a stack
 
 
 test/%: ## run tests against a stack
-	python3 -m tests.run_tests --short-image-name ""$(notdir $@)"" --owner ""$(OWNER)""
+	python3 -m tests.run_tests --short-image-name ""$(notdir $@)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
 test-all: $(foreach I, $(ALL_IMAGES), test/$(I)) ## test all stacks","diff --git a/Makefile b/Makefile
index b6613794..62fd507b 100644
--- a/Makefile
+++ b/Makefile
@@ -4,6 +4,7 @@
 
 # Use bash for inline if-statements in arch_patch target
 SHELL:=bash
+REGISTRY?=docker.io
 OWNER?=jupyter
 
 # Need to list the images in build dependency order
@@ -37,9 +38,9 @@ help:
 
 build/%: DOCKER_BUILD_ARGS?=
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg OWNER=""$(OWNER)""
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)""
 	@echo -n ""Built image size: ""
-	@docker images ""$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
+	@docker images ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks
 
 
@@ -68,9 +69,9 @@ linkcheck-docs: ## check broken links
 
 
 hook/%: ## run post-build hooks for an image
-	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --owner ""$(OWNER)"" && \
-	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --owner ""$(OWNER)""
+	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images
 
 
@@ -105,5 +106,5 @@ run-sudo-shell/%: ## run a bash in interactive mode as root in a stack
 
 
 test/%: ## run tests against a stack
-	python3 -m tests.run_tests --short-image-name ""$(notdir $@)"" --owner ""$(OWNER)""
+	python3 -m tests.run_tests --short-image-name ""$(notdir $@)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
 test-all: $(foreach I, $(ALL_IMAGES), test/$(I)) ## test all stacks",Yes
binder/Dockerfile,binder/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 2cc9a346..ef8d005d 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -2,8 +2,9 @@
 # Distributed under the terms of the Modified BSD License.
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-09-25
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-09-25
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 2cc9a346..ef8d005d 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -2,8 +2,9 @@
 # Distributed under the terms of the Modified BSD License.
 
 # https://hub.docker.com/r/jupyter/base-notebook/tags
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook:2023-09-25
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-09-25
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
docs/using/recipe_code/custom_environment.dockerfile,docs/using/recipe_code/custom_environment.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 11bca849..a158f2a6 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Name your environment and choose the python version
 ARG env_name=python310","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 11bca849..a158f2a6 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Name your environment and choose the python version
 ARG env_name=python310",Yes
docs/using/recipe_code/dask_jupyterlab.dockerfile,docs/using/recipe_code/dask_jupyterlab.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/dask_jupyterlab.dockerfile b/docs/using/recipe_code/dask_jupyterlab.dockerfile
index e9cb281e..6d48b101 100644
--- a/docs/using/recipe_code/dask_jupyterlab.dockerfile
+++ b/docs/using/recipe_code/dask_jupyterlab.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Install the Dask dashboard
 RUN mamba install --yes 'dask-labextension' && \","diff --git a/docs/using/recipe_code/dask_jupyterlab.dockerfile b/docs/using/recipe_code/dask_jupyterlab.dockerfile
index e9cb281e..6d48b101 100644
--- a/docs/using/recipe_code/dask_jupyterlab.dockerfile
+++ b/docs/using/recipe_code/dask_jupyterlab.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Install the Dask dashboard
 RUN mamba install --yes 'dask-labextension' && \",Yes
docs/using/recipe_code/jupyterhub_version.dockerfile,docs/using/recipe_code/jupyterhub_version.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
index 8704ded1..4f9bcfb4 100644
--- a/docs/using/recipe_code/jupyterhub_version.dockerfile
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 RUN mamba install --yes 'jupyterhub==4.0.1' && \
     mamba clean --all -f -y && \","diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
index 8704ded1..4f9bcfb4 100644
--- a/docs/using/recipe_code/jupyterhub_version.dockerfile
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 RUN mamba install --yes 'jupyterhub==4.0.1' && \
     mamba clean --all -f -y && \",Yes
docs/using/recipe_code/mamba_install.dockerfile,docs/using/recipe_code/mamba_install.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/mamba_install.dockerfile b/docs/using/recipe_code/mamba_install.dockerfile
index 05e20bd9..8e79b678 100644
--- a/docs/using/recipe_code/mamba_install.dockerfile
+++ b/docs/using/recipe_code/mamba_install.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 RUN mamba install --yes 'flake8' && \
     mamba clean --all -f -y && \","diff --git a/docs/using/recipe_code/mamba_install.dockerfile b/docs/using/recipe_code/mamba_install.dockerfile
index 05e20bd9..8e79b678 100644
--- a/docs/using/recipe_code/mamba_install.dockerfile
+++ b/docs/using/recipe_code/mamba_install.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 RUN mamba install --yes 'flake8' && \
     mamba clean --all -f -y && \",Yes
docs/using/recipe_code/manpage_install.dockerfile,docs/using/recipe_code/manpage_install.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/manpage_install.dockerfile b/docs/using/recipe_code/manpage_install.dockerfile
index d3043258..e95354a3 100644
--- a/docs/using/recipe_code/manpage_install.dockerfile
+++ b/docs/using/recipe_code/manpage_install.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014","diff --git a/docs/using/recipe_code/manpage_install.dockerfile b/docs/using/recipe_code/manpage_install.dockerfile
index d3043258..e95354a3 100644
--- a/docs/using/recipe_code/manpage_install.dockerfile
+++ b/docs/using/recipe_code/manpage_install.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014",Yes
docs/using/recipe_code/microsoft_odbc.dockerfile,docs/using/recipe_code/microsoft_odbc.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index 36cfc068..2a9faaa9 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014","diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index 36cfc068..2a9faaa9 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 4614ec4e..b04acca0 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 USER root","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 4614ec4e..b04acca0 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 USER root",Yes
docs/using/recipe_code/pip_install.dockerfile,docs/using/recipe_code/pip_install.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/pip_install.dockerfile b/docs/using/recipe_code/pip_install.dockerfile
index 60fbd46d..dc855225 100644
--- a/docs/using/recipe_code/pip_install.dockerfile
+++ b/docs/using/recipe_code/pip_install.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Install in the default python3 environment
 RUN pip install --no-cache-dir 'flake8' && \","diff --git a/docs/using/recipe_code/pip_install.dockerfile b/docs/using/recipe_code/pip_install.dockerfile
index 60fbd46d..dc855225 100644
--- a/docs/using/recipe_code/pip_install.dockerfile
+++ b/docs/using/recipe_code/pip_install.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 # Install in the default python3 environment
 RUN pip install --no-cache-dir 'flake8' && \",Yes
docs/using/recipe_code/rise_jupyterlab.dockerfile,docs/using/recipe_code/rise_jupyterlab.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/rise_jupyterlab.dockerfile b/docs/using/recipe_code/rise_jupyterlab.dockerfile
index e665b8e9..2f2b9aee 100644
--- a/docs/using/recipe_code/rise_jupyterlab.dockerfile
+++ b/docs/using/recipe_code/rise_jupyterlab.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 RUN mamba install --yes 'jupyterlab_rise' && \
     mamba clean --all -f -y && \","diff --git a/docs/using/recipe_code/rise_jupyterlab.dockerfile b/docs/using/recipe_code/rise_jupyterlab.dockerfile
index e665b8e9..2f2b9aee 100644
--- a/docs/using/recipe_code/rise_jupyterlab.dockerfile
+++ b/docs/using/recipe_code/rise_jupyterlab.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 RUN mamba install --yes 'jupyterlab_rise' && \
     mamba clean --all -f -y && \",Yes
docs/using/recipe_code/spellcheck_notebookv6.dockerfile,docs/using/recipe_code/spellcheck_notebookv6.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
index 73418530..0b843485 100644
--- a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
+++ b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook:notebook-6.5.4
+FROM docker.io/jupyter/base-notebook:notebook-6.5.4
 
 RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \","diff --git a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
index 73418530..0b843485 100644
--- a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
+++ b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook:notebook-6.5.4
+FROM docker.io/jupyter/base-notebook:notebook-6.5.4
 
 RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \",Yes
docs/using/recipe_code/xgboost.dockerfile,docs/using/recipe_code/xgboost.dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipe_code/xgboost.dockerfile b/docs/using/recipe_code/xgboost.dockerfile
index 8b762ff6..b4e0788d 100644
--- a/docs/using/recipe_code/xgboost.dockerfile
+++ b/docs/using/recipe_code/xgboost.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 RUN mamba install --yes 'py-xgboost' && \
     mamba clean --all -f -y && \","diff --git a/docs/using/recipe_code/xgboost.dockerfile b/docs/using/recipe_code/xgboost.dockerfile
index 8b762ff6..b4e0788d 100644
--- a/docs/using/recipe_code/xgboost.dockerfile
+++ b/docs/using/recipe_code/xgboost.dockerfile
@@ -1,4 +1,4 @@
-FROM jupyter/base-notebook
+FROM docker.io/jupyter/base-notebook
 
 RUN mamba install --yes 'py-xgboost' && \
     mamba clean --all -f -y && \",Yes
docs/using/recipes.md,docs/using/recipes.md,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 196cd425..074ed2db 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -298,7 +298,7 @@ This recipe is not tested and might be broken.
 ```
 
 ```dockerfile
-FROM jupyter/all-spark-notebook
+FROM docker.io/jupyter/all-spark-notebook
 
 # Set env vars for pydoop
 ENV HADOOP_HOME /usr/local/hadoop-2.7.3
@@ -415,7 +415,7 @@ Please note that the [Delta Lake](https://delta.io/) packages are only available
 By adding the properties to `spark-defaults.conf`, the user no longer needs to enable Delta support in each notebook.
 
 ```dockerfile
-FROM jupyter/pyspark-notebook
+FROM docker.io/jupyter/pyspark-notebook
 
 RUN mamba install --yes 'delta-spark' && \
     mamba clean --all -f -y && \
@@ -446,7 +446,7 @@ This recipe is not tested and might be broken.
 The example below is a Dockerfile to load Source Han Sans with normal weight, usually used for the web.
 
 ```dockerfile
-FROM jupyter/scipy-notebook
+FROM docker.io/jupyter/scipy-notebook
 
 RUN PYV=$(ls ""${CONDA_DIR}/lib"" | grep ^python) && \
     MPL_DATA=""${CONDA_DIR}/lib/${PYV}/site-packages/matplotlib/mpl-data"" && \
@@ -489,7 +489,7 @@ This recipe is not tested and might be broken.
 The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
 
 ```dockerfile
-FROM jupyter/scipy-notebook
+FROM docker.io/jupyter/scipy-notebook
 
 # install ijavascript
 RUN npm install -g ijavascript","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 196cd425..074ed2db 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -298,7 +298,7 @@ This recipe is not tested and might be broken.
 ```
 
 ```dockerfile
-FROM jupyter/all-spark-notebook
+FROM docker.io/jupyter/all-spark-notebook
 
 # Set env vars for pydoop
 ENV HADOOP_HOME /usr/local/hadoop-2.7.3
@@ -415,7 +415,7 @@ Please note that the [Delta Lake](https://delta.io/) packages are only available
 By adding the properties to `spark-defaults.conf`, the user no longer needs to enable Delta support in each notebook.
 
 ```dockerfile
-FROM jupyter/pyspark-notebook
+FROM docker.io/jupyter/pyspark-notebook
 
 RUN mamba install --yes 'delta-spark' && \
     mamba clean --all -f -y && \
@@ -446,7 +446,7 @@ This recipe is not tested and might be broken.
 The example below is a Dockerfile to load Source Han Sans with normal weight, usually used for the web.
 
 ```dockerfile
-FROM jupyter/scipy-notebook
+FROM docker.io/jupyter/scipy-notebook
 
 RUN PYV=$(ls ""${CONDA_DIR}/lib"" | grep ^python) && \
     MPL_DATA=""${CONDA_DIR}/lib/${PYV}/site-packages/matplotlib/mpl-data"" && \
@@ -489,7 +489,7 @@ This recipe is not tested and might be broken.
 The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
 
 ```dockerfile
-FROM jupyter/scipy-notebook
+FROM docker.io/jupyter/scipy-notebook
 
 # install ijavascript
 RUN npm install -g ijavascript",Yes
examples/docker-compose/README.md,examples/docker-compose/README.md,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index 4d81cc1c..0b57df39 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -42,7 +42,7 @@ You can customize the docker-stack notebook image to deploy by modifying the `no
 For example, you can build and deploy a `jupyter/all-spark-notebook` by modifying the Dockerfile like so:
 
 ```dockerfile
-FROM jupyter/all-spark-notebook
+FROM docker.io/jupyter/all-spark-notebook
 # Your RUN commands and so on
 ```","diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index 4d81cc1c..0b57df39 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -42,7 +42,7 @@ You can customize the docker-stack notebook image to deploy by modifying the `no
 For example, you can build and deploy a `jupyter/all-spark-notebook` by modifying the Dockerfile like so:
 
 ```dockerfile
-FROM jupyter/all-spark-notebook
+FROM docker.io/jupyter/all-spark-notebook
 # Your RUN commands and so on
 ```",Yes
examples/docker-compose/notebook/Dockerfile,examples/docker-compose/notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/examples/docker-compose/notebook/Dockerfile b/examples/docker-compose/notebook/Dockerfile
index 13b758fd..8f21c516 100644
--- a/examples/docker-compose/notebook/Dockerfile
+++ b/examples/docker-compose/notebook/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook
+FROM docker.io/jupyter/minimal-notebook
 
 USER root","diff --git a/examples/docker-compose/notebook/Dockerfile b/examples/docker-compose/notebook/Dockerfile
index 13b758fd..8f21c516 100644
--- a/examples/docker-compose/notebook/Dockerfile
+++ b/examples/docker-compose/notebook/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook
+FROM docker.io/jupyter/minimal-notebook
 
 USER root",Yes
examples/make-deploy/Dockerfile,examples/make-deploy/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/examples/make-deploy/Dockerfile b/examples/make-deploy/Dockerfile
index 13b758fd..8f21c516 100644
--- a/examples/make-deploy/Dockerfile
+++ b/examples/make-deploy/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook
+FROM docker.io/jupyter/minimal-notebook
 
 USER root","diff --git a/examples/make-deploy/Dockerfile b/examples/make-deploy/Dockerfile
index 13b758fd..8f21c516 100644
--- a/examples/make-deploy/Dockerfile
+++ b/examples/make-deploy/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM jupyter/minimal-notebook
+FROM docker.io/jupyter/minimal-notebook
 
 USER root",Yes
images/all-spark-notebook/Dockerfile,images/all-spark-notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
index 46509fac..90e5f083 100644
--- a/images/all-spark-notebook/Dockerfile
+++ b/images/all-spark-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/pyspark-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/pyspark-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
index 46509fac..90e5f083 100644
--- a/images/all-spark-notebook/Dockerfile
+++ b/images/all-spark-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/pyspark-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/pyspark-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 03c6eed9..fdd74c15 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/docker-stacks-foundation
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/docker-stacks-foundation
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 03c6eed9..fdd74c15 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/docker-stacks-foundation
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/docker-stacks-foundation
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/datascience-notebook/Dockerfile,images/datascience-notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
index 4833fef3..192f37c1 100644
--- a/images/datascience-notebook/Dockerfile
+++ b/images/datascience-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/scipy-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
index 4833fef3..192f37c1 100644
--- a/images/datascience-notebook/Dockerfile
+++ b/images/datascience-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/scipy-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/julia-notebook/Dockerfile,images/julia-notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
index cee9aa99..94b679b8 100644
--- a/images/julia-notebook/Dockerfile
+++ b/images/julia-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/minimal-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
index cee9aa99..94b679b8 100644
--- a/images/julia-notebook/Dockerfile
+++ b/images/julia-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/minimal-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/minimal-notebook/Dockerfile,images/minimal-notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index 6511304d..bf8f92d8 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index 6511304d..bf8f92d8 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/base-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 37cceb0c..192830da 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/scipy-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 37cceb0c..192830da 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/scipy-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/r-notebook/Dockerfile,images/r-notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/images/r-notebook/Dockerfile b/images/r-notebook/Dockerfile
index 579aa8f7..3ff37777 100644
--- a/images/r-notebook/Dockerfile
+++ b/images/r-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/minimal-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/r-notebook/Dockerfile b/images/r-notebook/Dockerfile
index 579aa8f7..3ff37777 100644
--- a/images/r-notebook/Dockerfile
+++ b/images/r-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/minimal-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 82708471..2c4b1ffd 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/minimal-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 82708471..2c4b1ffd 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/minimal-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/tensorflow-notebook/Dockerfile,images/tensorflow-notebook/Dockerfile,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index 51070fdc..921af999 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/scipy-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index 51070fdc..921af999 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -1,7 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=docker.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$OWNER/scipy-notebook
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
tagging/apply_tags.py,tagging/apply_tags.py,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 64c391bd..e8129167 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -16,6 +16,7 @@ LOGGER = logging.getLogger(__name__)
 
 def apply_tags(
     short_image_name: str,
+    registry: str,
     owner: str,
     tags_dir: Path,
     platform: str,
@@ -26,7 +27,7 @@ def apply_tags(
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")
 
-    image = f""{owner}/{short_image_name}:latest""
+    image = f""{registry}/{owner}/{short_image_name}:latest""
     filename = f""{platform}-{short_image_name}.txt""
     tags = (tags_dir / filename).read_text().splitlines()
 
@@ -60,6 +61,13 @@ if __name__ == ""__main__"":
         choices=[""x86_64"", ""aarch64"", ""arm64""],
         help=""Image platform"",
     )
+    arg_parser.add_argument(
+        ""--registry"",
+        required=True,
+        type=str,
+        choices=[""docker.io"", ""quay.io""],
+        help=""Image registry"",
+    )
     arg_parser.add_argument(
         ""--owner"",
         required=True,
@@ -68,4 +76,6 @@ if __name__ == ""__main__"":
     args = arg_parser.parse_args()
     args.platform = unify_aarch64(args.platform)
 
-    apply_tags(args.short_image_name, args.owner, args.tags_dir, args.platform)
+    apply_tags(
+        args.short_image_name, args.registry, args.owner, args.tags_dir, args.platform
+    )","diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 64c391bd..e8129167 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -16,6 +16,7 @@ LOGGER = logging.getLogger(__name__)
 
 def apply_tags(
     short_image_name: str,
+    registry: str,
     owner: str,
     tags_dir: Path,
     platform: str,
@@ -26,7 +27,7 @@ def apply_tags(
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")
 
-    image = f""{owner}/{short_image_name}:latest""
+    image = f""{registry}/{owner}/{short_image_name}:latest""
     filename = f""{platform}-{short_image_name}.txt""
     tags = (tags_dir / filename).read_text().splitlines()
 
@@ -60,6 +61,13 @@ if __name__ == ""__main__"":
         choices=[""x86_64"", ""aarch64"", ""arm64""],
         help=""Image platform"",
     )
+    arg_parser.add_argument(
+        ""--registry"",
+        required=True,
+        type=str,
+        choices=[""docker.io"", ""quay.io""],
+        help=""Image registry"",
+    )
     arg_parser.add_argument(
         ""--owner"",
         required=True,
@@ -68,4 +76,6 @@ if __name__ == ""__main__"":
     args = arg_parser.parse_args()
     args.platform = unify_aarch64(args.platform)
 
-    apply_tags(args.short_image_name, args.owner, args.tags_dir, args.platform)
+    apply_tags(
+        args.short_image_name, args.registry, args.owner, args.tags_dir, args.platform
+    )",Yes
tagging/manifests.py,tagging/manifests.py,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/tagging/manifests.py b/tagging/manifests.py
index bbf1fda5..a83b20a6 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -23,13 +23,18 @@ class ManifestHeader:
     """"""ManifestHeader doesn't fall under common interface, and we run it separately""""""
 
     @staticmethod
-    def create_header(short_image_name: str, owner: str, build_timestamp: str) -> str:
+    def create_header(
+        short_image_name: str, registry: str, owner: str, build_timestamp: str
+    ) -> str:
         commit_hash = GitHelper.commit_hash()
         commit_hash_tag = GitHelper.commit_hash_tag()
         commit_message = GitHelper.commit_message()
 
         image_size = docker[
-            ""images"", f""{owner}/{short_image_name}:latest"", ""--format"", ""{{.Size}}""
+            ""images"",
+            f""{registry}/{owner}/{short_image_name}:latest"",
+            ""--format"",
+            ""{{.Size}}"",
         ]().rstrip()
 
         return ""\n"".join(
@@ -39,7 +44,7 @@ class ManifestHeader:
                 ""## Build Info"",
                 """",
                 f""* Build datetime: {build_timestamp}"",
-                f""* Docker image: {owner}/{short_image_name}:{commit_hash_tag}"",
+                f""* Docker image: {registry}/{owner}/{short_image_name}:{commit_hash_tag}"",
                 f""* Docker image size: {image_size}"",
                 f""* Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
                 ""* Git commit message:"",","diff --git a/tagging/manifests.py b/tagging/manifests.py
index bbf1fda5..a83b20a6 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -23,13 +23,18 @@ class ManifestHeader:
     """"""ManifestHeader doesn't fall under common interface, and we run it separately""""""
 
     @staticmethod
-    def create_header(short_image_name: str, owner: str, build_timestamp: str) -> str:
+    def create_header(
+        short_image_name: str, registry: str, owner: str, build_timestamp: str
+    ) -> str:
         commit_hash = GitHelper.commit_hash()
         commit_hash_tag = GitHelper.commit_hash_tag()
         commit_message = GitHelper.commit_message()
 
         image_size = docker[
-            ""images"", f""{owner}/{short_image_name}:latest"", ""--format"", ""{{.Size}}""
+            ""images"",
+            f""{registry}/{owner}/{short_image_name}:latest"",
+            ""--format"",
+            ""{{.Size}}"",
         ]().rstrip()
 
         return ""\n"".join(
@@ -39,7 +44,7 @@ class ManifestHeader:
                 ""## Build Info"",
                 """",
                 f""* Build datetime: {build_timestamp}"",
-                f""* Docker image: {owner}/{short_image_name}:{commit_hash_tag}"",
+                f""* Docker image: {registry}/{owner}/{short_image_name}:{commit_hash_tag}"",
                 f""* Docker image size: {image_size}"",
                 f""* Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
                 ""* Git commit message:"",",Yes
tagging/write_manifest.py,tagging/write_manifest.py,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index 14a01a15..ea9d41c3 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -23,6 +23,7 @@ MARKDOWN_LINE_BREAK = ""<br />""
 
 def write_build_history_line(
     short_image_name: str,
+    registry: str,
     owner: str,
     hist_line_dir: Path,
     filename: str,
@@ -32,7 +33,7 @@ def write_build_history_line(
 
     date_column = f""`{BUILD_TIMESTAMP}`""
     image_column = MARKDOWN_LINE_BREAK.join(
-        f""`{owner}/{short_image_name}:{tag_value}`"" for tag_value in all_tags
+        f""`{registry}/{owner}/{short_image_name}:{tag_value}`"" for tag_value in all_tags
     )
     commit_hash = GitHelper.commit_hash()
     links_column = MARKDOWN_LINE_BREAK.join(
@@ -49,6 +50,7 @@ def write_build_history_line(
 
 def write_manifest_file(
     short_image_name: str,
+    registry: str,
     owner: str,
     manifest_dir: Path,
     filename: str,
@@ -59,7 +61,7 @@ def write_manifest_file(
     LOGGER.info(f""Using manifests: {manifest_names}"")
 
     markdown_pieces = [
-        ManifestHeader.create_header(short_image_name, owner, BUILD_TIMESTAMP)
+        ManifestHeader.create_header(short_image_name, registry, owner, BUILD_TIMESTAMP)
     ] + [manifest.markdown_piece(container) for manifest in manifests]
     markdown_content = ""\n\n"".join(markdown_pieces) + ""\n""
 
@@ -69,6 +71,7 @@ def write_manifest_file(
 
 def write_manifest(
     short_image_name: str,
+    registry: str,
     owner: str,
     hist_line_dir: Path,
     manifest_dir: Path,
@@ -76,7 +79,7 @@ def write_manifest(
     LOGGER.info(f""Creating manifests for image: {short_image_name}"")
     taggers, manifests = get_taggers_and_manifests(short_image_name)
 
-    image = f""{owner}/{short_image_name}:latest""
+    image = f""{registry}/{owner}/{short_image_name}:latest""
 
     file_prefix = get_platform()
     commit_hash_tag = GitHelper.commit_hash_tag()
@@ -88,10 +91,16 @@ def write_manifest(
             tags_prefix + ""-"" + tagger.tag_value(container) for tagger in taggers
         ]
         write_build_history_line(
-            short_image_name, owner, hist_line_dir, filename, all_tags
+            short_image_name, registry, owner, hist_line_dir, filename, all_tags
         )
         write_manifest_file(
-            short_image_name, owner, manifest_dir, filename, manifests, container
+            short_image_name,
+            registry,
+            owner,
+            manifest_dir,
+            filename,
+            manifests,
+            container,
         )
 
 
@@ -116,6 +125,13 @@ if __name__ == ""__main__"":
         type=Path,
         help=""Directory to save manifest file"",
     )
+    arg_parser.add_argument(
+        ""--registry"",
+        required=True,
+        type=str,
+        choices=[""docker.io"", ""quay.io""],
+        help=""Image registry"",
+    )
     arg_parser.add_argument(
         ""--owner"",
         required=True,
@@ -126,5 +142,9 @@ if __name__ == ""__main__"":
     LOGGER.info(f""Current build timestamp: {BUILD_TIMESTAMP}"")
 
     write_manifest(
-        args.short_image_name, args.owner, args.hist_line_dir, args.manifest_dir
+        args.short_image_name,
+        args.registry,
+        args.owner,
+        args.hist_line_dir,
+        args.manifest_dir,
     )","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index 14a01a15..ea9d41c3 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -23,6 +23,7 @@ MARKDOWN_LINE_BREAK = ""<br />""
 
 def write_build_history_line(
     short_image_name: str,
+    registry: str,
     owner: str,
     hist_line_dir: Path,
     filename: str,
@@ -32,7 +33,7 @@ def write_build_history_line(
 
     date_column = f""`{BUILD_TIMESTAMP}`""
     image_column = MARKDOWN_LINE_BREAK.join(
-        f""`{owner}/{short_image_name}:{tag_value}`"" for tag_value in all_tags
+        f""`{registry}/{owner}/{short_image_name}:{tag_value}`"" for tag_value in all_tags
     )
     commit_hash = GitHelper.commit_hash()
     links_column = MARKDOWN_LINE_BREAK.join(
@@ -49,6 +50,7 @@ def write_build_history_line(
 
 def write_manifest_file(
     short_image_name: str,
+    registry: str,
     owner: str,
     manifest_dir: Path,
     filename: str,
@@ -59,7 +61,7 @@ def write_manifest_file(
     LOGGER.info(f""Using manifests: {manifest_names}"")
 
     markdown_pieces = [
-        ManifestHeader.create_header(short_image_name, owner, BUILD_TIMESTAMP)
+        ManifestHeader.create_header(short_image_name, registry, owner, BUILD_TIMESTAMP)
     ] + [manifest.markdown_piece(container) for manifest in manifests]
     markdown_content = ""\n\n"".join(markdown_pieces) + ""\n""
 
@@ -69,6 +71,7 @@ def write_manifest_file(
 
 def write_manifest(
     short_image_name: str,
+    registry: str,
     owner: str,
     hist_line_dir: Path,
     manifest_dir: Path,
@@ -76,7 +79,7 @@ def write_manifest(
     LOGGER.info(f""Creating manifests for image: {short_image_name}"")
     taggers, manifests = get_taggers_and_manifests(short_image_name)
 
-    image = f""{owner}/{short_image_name}:latest""
+    image = f""{registry}/{owner}/{short_image_name}:latest""
 
     file_prefix = get_platform()
     commit_hash_tag = GitHelper.commit_hash_tag()
@@ -88,10 +91,16 @@ def write_manifest(
             tags_prefix + ""-"" + tagger.tag_value(container) for tagger in taggers
         ]
         write_build_history_line(
-            short_image_name, owner, hist_line_dir, filename, all_tags
+            short_image_name, registry, owner, hist_line_dir, filename, all_tags
         )
         write_manifest_file(
-            short_image_name, owner, manifest_dir, filename, manifests, container
+            short_image_name,
+            registry,
+            owner,
+            manifest_dir,
+            filename,
+            manifests,
+            container,
         )
 
 
@@ -116,6 +125,13 @@ if __name__ == ""__main__"":
         type=Path,
         help=""Directory to save manifest file"",
     )
+    arg_parser.add_argument(
+        ""--registry"",
+        required=True,
+        type=str,
+        choices=[""docker.io"", ""quay.io""],
+        help=""Image registry"",
+    )
     arg_parser.add_argument(
         ""--owner"",
         required=True,
@@ -126,5 +142,9 @@ if __name__ == ""__main__"":
     LOGGER.info(f""Current build timestamp: {BUILD_TIMESTAMP}"")
 
     write_manifest(
-        args.short_image_name, args.owner, args.hist_line_dir, args.manifest_dir
+        args.short_image_name,
+        args.registry,
+        args.owner,
+        args.hist_line_dir,
+        args.manifest_dir,
     )",Yes
tagging/write_tags_file.py,tagging/write_tags_file.py,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index 55cbfab7..ef4e1b0b 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -14,6 +14,7 @@ LOGGER = logging.getLogger(__name__)
 
 def write_tags_file(
     short_image_name: str,
+    registry: str,
     owner: str,
     tags_dir: Path,
 ) -> None:
@@ -23,11 +24,11 @@ def write_tags_file(
     LOGGER.info(f""Tagging image: {short_image_name}"")
     taggers, _ = get_taggers_and_manifests(short_image_name)
 
-    image = f""{owner}/{short_image_name}:latest""
+    image = f""{registry}/{owner}/{short_image_name}:latest""
     tags_prefix = get_platform()
     filename = f""{tags_prefix}-{short_image_name}.txt""
 
-    tags = [f""{owner}/{short_image_name}:{tags_prefix}-latest""]
+    tags = [f""{registry}/{owner}/{short_image_name}:{tags_prefix}-latest""]
     with DockerRunner(image) as container:
         for tagger in taggers:
             tagger_name = tagger.__class__.__name__
@@ -55,6 +56,13 @@ if __name__ == ""__main__"":
         type=Path,
         help=""Directory to save tags file"",
     )
+    arg_parser.add_argument(
+        ""--registry"",
+        required=True,
+        type=str,
+        choices=[""docker.io"", ""quay.io""],
+        help=""Image registry"",
+    )
     arg_parser.add_argument(
         ""--owner"",
         required=True,
@@ -62,4 +70,4 @@ if __name__ == ""__main__"":
     )
     args = arg_parser.parse_args()
 
-    write_tags_file(args.short_image_name, args.owner, args.tags_dir)
+    write_tags_file(args.short_image_name, args.registry, args.owner, args.tags_dir)","diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index 55cbfab7..ef4e1b0b 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -14,6 +14,7 @@ LOGGER = logging.getLogger(__name__)
 
 def write_tags_file(
     short_image_name: str,
+    registry: str,
     owner: str,
     tags_dir: Path,
 ) -> None:
@@ -23,11 +24,11 @@ def write_tags_file(
     LOGGER.info(f""Tagging image: {short_image_name}"")
     taggers, _ = get_taggers_and_manifests(short_image_name)
 
-    image = f""{owner}/{short_image_name}:latest""
+    image = f""{registry}/{owner}/{short_image_name}:latest""
     tags_prefix = get_platform()
     filename = f""{tags_prefix}-{short_image_name}.txt""
 
-    tags = [f""{owner}/{short_image_name}:{tags_prefix}-latest""]
+    tags = [f""{registry}/{owner}/{short_image_name}:{tags_prefix}-latest""]
     with DockerRunner(image) as container:
         for tagger in taggers:
             tagger_name = tagger.__class__.__name__
@@ -55,6 +56,13 @@ if __name__ == ""__main__"":
         type=Path,
         help=""Directory to save tags file"",
     )
+    arg_parser.add_argument(
+        ""--registry"",
+        required=True,
+        type=str,
+        choices=[""docker.io"", ""quay.io""],
+        help=""Image registry"",
+    )
     arg_parser.add_argument(
         ""--owner"",
         required=True,
@@ -62,4 +70,4 @@ if __name__ == ""__main__"":
     )
     args = arg_parser.parse_args()
 
-    write_tags_file(args.short_image_name, args.owner, args.tags_dir)
+    write_tags_file(args.short_image_name, args.registry, args.owner, args.tags_dir)",Yes
tests/run_tests.py,tests/run_tests.py,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,bceaead5d288faf8b6da09d94829041b62bf34e4,"Add an ability to specify registry when using docker images (#2008)

* Add an ability to specify registry when using docker images

* Fix typo

* [TMP] Speedup workflow

* Revert ""[TMP] Speedup workflow""

This reverts commit 3af0055ccfb2605513f34ebcc7c1a75a3c8b5a53.","diff --git a/tests/run_tests.py b/tests/run_tests.py
index f8ab85f7..6263be6d 100755
--- a/tests/run_tests.py
+++ b/tests/run_tests.py
@@ -13,11 +13,11 @@ python3 = plumbum.local[""python3""]
 LOGGER = logging.getLogger(__name__)
 
 
-def test_image(short_image_name: str, owner: str) -> None:
+def test_image(short_image_name: str, registry: str, owner: str) -> None:
     LOGGER.info(f""Testing image: {short_image_name}"")
     test_dirs = get_test_dirs(short_image_name)
     LOGGER.info(f""Test dirs to be run: {test_dirs}"")
-    with plumbum.local.env(TEST_IMAGE=f""{owner}/{short_image_name}""):
+    with plumbum.local.env(TEST_IMAGE=f""{registry}/{owner}/{short_image_name}""):
         (
             python3[
                 ""-m"",
@@ -41,6 +41,13 @@ if __name__ == ""__main__"":
         required=True,
         help=""Short image name to run test on"",
     )
+    arg_parser.add_argument(
+        ""--registry"",
+        required=True,
+        type=str,
+        choices=[""docker.io"", ""quay.io""],
+        help=""Image registry"",
+    )
     arg_parser.add_argument(
         ""--owner"",
         required=True,
@@ -49,4 +56,4 @@ if __name__ == ""__main__"":
 
     args = arg_parser.parse_args()
 
-    test_image(args.short_image_name, args.owner)
+    test_image(args.short_image_name, args.registry, args.owner)","diff --git a/tests/run_tests.py b/tests/run_tests.py
index f8ab85f7..6263be6d 100755
--- a/tests/run_tests.py
+++ b/tests/run_tests.py
@@ -13,11 +13,11 @@ python3 = plumbum.local[""python3""]
 LOGGER = logging.getLogger(__name__)
 
 
-def test_image(short_image_name: str, owner: str) -> None:
+def test_image(short_image_name: str, registry: str, owner: str) -> None:
     LOGGER.info(f""Testing image: {short_image_name}"")
     test_dirs = get_test_dirs(short_image_name)
     LOGGER.info(f""Test dirs to be run: {test_dirs}"")
-    with plumbum.local.env(TEST_IMAGE=f""{owner}/{short_image_name}""):
+    with plumbum.local.env(TEST_IMAGE=f""{registry}/{owner}/{short_image_name}""):
         (
             python3[
                 ""-m"",
@@ -41,6 +41,13 @@ if __name__ == ""__main__"":
         required=True,
         help=""Short image name to run test on"",
     )
+    arg_parser.add_argument(
+        ""--registry"",
+        required=True,
+        type=str,
+        choices=[""docker.io"", ""quay.io""],
+        help=""Image registry"",
+    )
     arg_parser.add_argument(
         ""--owner"",
         required=True,
@@ -49,4 +56,4 @@ if __name__ == ""__main__"":
 
     args = arg_parser.parse_args()
 
-    test_image(args.short_image_name, args.owner)
+    test_image(args.short_image_name, args.registry, args.owner)",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,4adbb05073e50f82e72aa87292cb18e815b8d989,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,Add docker.io to docker run commands,"diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index aeedcf94..a0cd7c99 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -57,7 +57,7 @@ body:
         What complete docker command do you run to launch the container (omitting sensitive values)?
       placeholder: |
         Example:
-        `docker run -it --rm -p 8888:8888 jupyter/base-notebook`
+        `docker run -it --rm -p 8888:8888 docker.io/jupyter/base-notebook`
     validations:
       required: true","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index aeedcf94..a0cd7c99 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -57,7 +57,7 @@ body:
         What complete docker command do you run to launch the container (omitting sensitive values)?
       placeholder: |
         Example:
-        `docker run -it --rm -p 8888:8888 jupyter/base-notebook`
+        `docker run -it --rm -p 8888:8888 docker.io/jupyter/base-notebook`
     validations:
       required: true",Yes
Makefile,Makefile,4adbb05073e50f82e72aa87292cb18e815b8d989,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,Add docker.io to docker run commands,"diff --git a/Makefile b/Makefile
index 62fd507b..093102d3 100644
--- a/Makefile
+++ b/Makefile
@@ -99,9 +99,9 @@ push-all: $(foreach I, $(ALL_IMAGES), push/$(I)) ## push all tagged images
 
 
 run-shell/%: ## run a bash in interactive mode in a stack
-	docker run -it --rm ""$(OWNER)/$(notdir $@)"" $(SHELL)
+	docker run -it --rm ""$(REGISTRY)/$(OWNER)/$(notdir $@)"" $(SHELL)
 run-sudo-shell/%: ## run a bash in interactive mode as root in a stack
-	docker run -it --rm --user root ""$(OWNER)/$(notdir $@)"" $(SHELL)
+	docker run -it --rm --user root ""$(REGISTRY)/$(OWNER)/$(notdir $@)"" $(SHELL)","diff --git a/Makefile b/Makefile
index 62fd507b..093102d3 100644
--- a/Makefile
+++ b/Makefile
@@ -99,9 +99,9 @@ push-all: $(foreach I, $(ALL_IMAGES), push/$(I)) ## push all tagged images
 
 
 run-shell/%: ## run a bash in interactive mode in a stack
-	docker run -it --rm ""$(OWNER)/$(notdir $@)"" $(SHELL)
+	docker run -it --rm ""$(REGISTRY)/$(OWNER)/$(notdir $@)"" $(SHELL)
 run-sudo-shell/%: ## run a bash in interactive mode as root in a stack
-	docker run -it --rm --user root ""$(OWNER)/$(notdir $@)"" $(SHELL)
+	docker run -it --rm --user root ""$(REGISTRY)/$(OWNER)/$(notdir $@)"" $(SHELL)",Yes
README.md,README.md,4adbb05073e50f82e72aa87292cb18e815b8d989,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,Add docker.io to docker run commands,"diff --git a/README.md b/README.md
index 49934d91..f77406d1 100644
--- a/README.md
+++ b/README.md
@@ -30,7 +30,7 @@ This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from D
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-09-25
+docker run -p 10000:8888 docker.io/jupyter/scipy-notebook:2023-09-25
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -49,7 +49,7 @@ This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25`
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work docker.io/jupyter/datascience-notebook:2023-09-25
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index 49934d91..f77406d1 100644
--- a/README.md
+++ b/README.md
@@ -30,7 +30,7 @@ This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from D
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 jupyter/scipy-notebook:2023-09-25
+docker run -p 10000:8888 docker.io/jupyter/scipy-notebook:2023-09-25
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -49,7 +49,7 @@ This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25`
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/datascience-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work docker.io/jupyter/datascience-notebook:2023-09-25
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
docs/using/common.md,docs/using/common.md,4adbb05073e50f82e72aa87292cb18e815b8d989,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,Add docker.io to docker run commands,"diff --git a/docs/using/common.md b/docs/using/common.md
index e2fee1f5..eefc23fa 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -15,14 +15,14 @@ You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/l
    you can run the following (this hash was generated for the `my-password` password):
 
    ```bash
-   docker run -it --rm -p 8888:8888 jupyter/base-notebook \
+   docker run -it --rm -p 8888:8888 docker.io/jupyter/base-notebook \
        start-notebook.py --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
-   docker run  -it --rm -p 8888:8888 jupyter/base-notebook \
+   docker run  -it --rm -p 8888:8888 docker.io/jupyter/base-notebook \
        start-notebook.py --ServerApp.base_url=/customized/url/prefix/
    ```
 
@@ -49,7 +49,7 @@ You do so by passing arguments to the `docker run` command.
       -e NB_USER=""my-username"" \
       -e CHOWN_HOME=yes \
       -w ""/home/my-username"" \
-      jupyter/base-notebook
+      docker.io/jupyter/base-notebook
   ```
 
 - `-e NB_UID=<numeric uid>` - Instructs the startup script to switch the numeric user ID of `${NB_USER}` to the given value.
@@ -146,7 +146,7 @@ For example, to mount a host folder containing a `notebook.key` and `notebook.cr
 ```bash
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder:/etc/ssl/notebook \
-    jupyter/base-notebook \
+    docker.io/jupyter/base-notebook \
     start-notebook.py \
     --ServerApp.keyfile=/etc/ssl/notebook/notebook.key \
     --ServerApp.certfile=/etc/ssl/notebook/notebook.crt
@@ -158,7 +158,7 @@ For example:
 ```bash
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder/notebook.pem:/etc/ssl/notebook.pem \
-    jupyter/base-notebook \
+    docker.io/jupyter/base-notebook \
     start-notebook.py \
     --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
@@ -207,14 +207,14 @@ Example:
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    jupyter/base-notebook
+    docker.io/jupyter/base-notebook
 # Executing the command: jupyter notebook ...
 
 # Use Jupyter NBClassic frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=nbclassic \
-    jupyter/base-notebook
+    docker.io/jupyter/base-notebook
 # Executing the command: jupyter nbclassic ...
 ```
 
@@ -225,7 +225,7 @@ The `start.sh` script supports all the features described above but allows you t
 For example, to run the text-based `ipython` console in a container, do the following:
 
 ```bash
-docker run -it --rm jupyter/base-notebook start.sh ipython
+docker run -it --rm docker.io/jupyter/base-notebook start.sh ipython
 ```
 
 This script is handy when you derive a new Dockerfile from this image and install additional Jupyter applications with subcommands like `jupyter console`, `jupyter kernelgateway`, etc.","diff --git a/docs/using/common.md b/docs/using/common.md
index e2fee1f5..eefc23fa 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -15,14 +15,14 @@ You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/l
    you can run the following (this hash was generated for the `my-password` password):
 
    ```bash
-   docker run -it --rm -p 8888:8888 jupyter/base-notebook \
+   docker run -it --rm -p 8888:8888 docker.io/jupyter/base-notebook \
        start-notebook.py --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
-   docker run  -it --rm -p 8888:8888 jupyter/base-notebook \
+   docker run  -it --rm -p 8888:8888 docker.io/jupyter/base-notebook \
        start-notebook.py --ServerApp.base_url=/customized/url/prefix/
    ```
 
@@ -49,7 +49,7 @@ You do so by passing arguments to the `docker run` command.
       -e NB_USER=""my-username"" \
       -e CHOWN_HOME=yes \
       -w ""/home/my-username"" \
-      jupyter/base-notebook
+      docker.io/jupyter/base-notebook
   ```
 
 - `-e NB_UID=<numeric uid>` - Instructs the startup script to switch the numeric user ID of `${NB_USER}` to the given value.
@@ -146,7 +146,7 @@ For example, to mount a host folder containing a `notebook.key` and `notebook.cr
 ```bash
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder:/etc/ssl/notebook \
-    jupyter/base-notebook \
+    docker.io/jupyter/base-notebook \
     start-notebook.py \
     --ServerApp.keyfile=/etc/ssl/notebook/notebook.key \
     --ServerApp.certfile=/etc/ssl/notebook/notebook.crt
@@ -158,7 +158,7 @@ For example:
 ```bash
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder/notebook.pem:/etc/ssl/notebook.pem \
-    jupyter/base-notebook \
+    docker.io/jupyter/base-notebook \
     start-notebook.py \
     --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
@@ -207,14 +207,14 @@ Example:
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    jupyter/base-notebook
+    docker.io/jupyter/base-notebook
 # Executing the command: jupyter notebook ...
 
 # Use Jupyter NBClassic frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=nbclassic \
-    jupyter/base-notebook
+    docker.io/jupyter/base-notebook
 # Executing the command: jupyter nbclassic ...
 ```
 
@@ -225,7 +225,7 @@ The `start.sh` script supports all the features described above but allows you t
 For example, to run the text-based `ipython` console in a container, do the following:
 
 ```bash
-docker run -it --rm jupyter/base-notebook start.sh ipython
+docker run -it --rm docker.io/jupyter/base-notebook start.sh ipython
 ```
 
 This script is handy when you derive a new Dockerfile from this image and install additional Jupyter applications with subcommands like `jupyter console`, `jupyter kernelgateway`, etc.",Yes
docs/using/recipes.md,docs/using/recipes.md,4adbb05073e50f82e72aa87292cb18e815b8d989,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,Add docker.io to docker run commands,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 074ed2db..d9ea6f35 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -17,7 +17,7 @@ For example:
 docker run -it --rm \
     --user root \
     -e GRANT_SUDO=yes \
-    jupyter/base-notebook
+    docker.io/jupyter/base-notebook
 ```
 
 **You should only enable `sudo` if you trust the user and/or if the container is running on an isolated host.**
@@ -381,7 +381,7 @@ For JupyterLab:
 
 ```bash
 docker run -it --rm \
-    jupyter/base-notebook \
+    docker.io/jupyter/base-notebook \
     start-notebook.py --IdentityProvider.token=''
 ```
 
@@ -390,7 +390,7 @@ For Jupyter Notebook:
 ```bash
 docker run -it --rm \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    jupyter/base-notebook \
+    docker.io/jupyter/base-notebook \
     start-notebook.py --IdentityProvider.token=''
 ```
 
@@ -477,7 +477,7 @@ and add these options when running `docker`: `-e DISPLAY -v /tmp/.X11-unix:/tmp/
 docker run -it --rm \
     -e DISPLAY \
     -v /tmp/.X11-unix:/tmp/.X11-unix \
-    jupyter/minimal-notebook
+    docker.io/jupyter/minimal-notebook
 ```
 
 ## Add ijavascript kernel to container","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 074ed2db..d9ea6f35 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -17,7 +17,7 @@ For example:
 docker run -it --rm \
     --user root \
     -e GRANT_SUDO=yes \
-    jupyter/base-notebook
+    docker.io/jupyter/base-notebook
 ```
 
 **You should only enable `sudo` if you trust the user and/or if the container is running on an isolated host.**
@@ -381,7 +381,7 @@ For JupyterLab:
 
 ```bash
 docker run -it --rm \
-    jupyter/base-notebook \
+    docker.io/jupyter/base-notebook \
     start-notebook.py --IdentityProvider.token=''
 ```
 
@@ -390,7 +390,7 @@ For Jupyter Notebook:
 ```bash
 docker run -it --rm \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    jupyter/base-notebook \
+    docker.io/jupyter/base-notebook \
     start-notebook.py --IdentityProvider.token=''
 ```
 
@@ -477,7 +477,7 @@ and add these options when running `docker`: `-e DISPLAY -v /tmp/.X11-unix:/tmp/
 docker run -it --rm \
     -e DISPLAY \
     -v /tmp/.X11-unix:/tmp/.X11-unix \
-    jupyter/minimal-notebook
+    docker.io/jupyter/minimal-notebook
 ```
 
 ## Add ijavascript kernel to container",Yes
docs/using/running.md,docs/using/running.md,4adbb05073e50f82e72aa87292cb18e815b8d989,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,Add docker.io to docker run commands,"diff --git a/docs/using/running.md b/docs/using/running.md
index b888c043..a15492da 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -20,7 +20,7 @@ It then starts a container running Jupyter Server with the JupyterLab frontend a
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-09-25
+docker run -it -p 8888:8888 docker.io/jupyter/scipy-notebook:2023-09-25
 
 # Entered start.sh with args: jupyter lab
 
@@ -58,7 +58,7 @@ It then starts a container running Server and exposes the server on host port 10
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work docker.io/jupyter/r-notebook:2023-09-25
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -78,7 +78,7 @@ This command pulls the `jupyter/all-spark-notebook` image currently tagged `late
 It then starts a container named `notebook` running a JupyterLab server and exposes the server on a randomly selected port.
 
 ```bash
-docker run --detach -P --name notebook jupyter/all-spark-notebook
+docker run --detach -P --name notebook docker.io/jupyter/all-spark-notebook
 ```
 
 where:","diff --git a/docs/using/running.md b/docs/using/running.md
index b888c043..a15492da 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -20,7 +20,7 @@ It then starts a container running Jupyter Server with the JupyterLab frontend a
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 jupyter/scipy-notebook:2023-09-25
+docker run -it -p 8888:8888 docker.io/jupyter/scipy-notebook:2023-09-25
 
 # Entered start.sh with args: jupyter lab
 
@@ -58,7 +58,7 @@ It then starts a container running Server and exposes the server on host port 10
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work jupyter/r-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work docker.io/jupyter/r-notebook:2023-09-25
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -78,7 +78,7 @@ This command pulls the `jupyter/all-spark-notebook` image currently tagged `late
 It then starts a container named `notebook` running a JupyterLab server and exposes the server on a randomly selected port.
 
 ```bash
-docker run --detach -P --name notebook jupyter/all-spark-notebook
+docker run --detach -P --name notebook docker.io/jupyter/all-spark-notebook
 ```
 
 where:",Yes
docs/using/specifics.md,docs/using/specifics.md,4adbb05073e50f82e72aa87292cb18e815b8d989,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,Add docker.io to docker run commands,"diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 3ad16a54..300a53e5 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -14,7 +14,7 @@ This page provides details about features specific to one or more images.
   Every new spark context that is created is put onto an incrementing port (i.e. 4040, 4041, 4042, etc.), and it might be necessary to open multiple ports.
   ```
 
-  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 jupyter/pyspark-notebook`.
+  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 docker.io/jupyter/pyspark-notebook`.
 
 #### IPython low-level output capture and forward
 
@@ -72,7 +72,7 @@ docker build --rm --force-rm \
     --build-arg openjdk_version=11
 
 # Check the newly built image
-docker run -it --rm jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
+docker run -it --rm docker.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
 
 # Welcome to
 #       ____              __","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 3ad16a54..300a53e5 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -14,7 +14,7 @@ This page provides details about features specific to one or more images.
   Every new spark context that is created is put onto an incrementing port (i.e. 4040, 4041, 4042, etc.), and it might be necessary to open multiple ports.
   ```
 
-  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 jupyter/pyspark-notebook`.
+  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 docker.io/jupyter/pyspark-notebook`.
 
 #### IPython low-level output capture and forward
 
@@ -72,7 +72,7 @@ docker build --rm --force-rm \
     --build-arg openjdk_version=11
 
 # Check the newly built image
-docker run -it --rm jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
+docker run -it --rm docker.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
 
 # Welcome to
 #       ____              __",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,4adbb05073e50f82e72aa87292cb18e815b8d989,f8cd90ade13a88a9ef4558d7f3debf8a8181f70f,Add docker.io to docker run commands,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index b5d17b88..b11eacb6 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -14,7 +14,7 @@ If you are running a Docker container while mounting a local volume or host dire
 docker run -it --rm \
     -p 8888:8888 \
     -v <my-vol>:<container-dir> \
-    jupyter/minimal-notebook:latest
+    docker.io/jupyter/minimal-notebook:latest
 ```
 
 you might face permissions issues when trying to access the mounted volume:
@@ -48,7 +48,7 @@ The following sections cover a few of these scenarios and how to fix them.
        --user root \
        -e CHOWN_EXTRA=""<container-dir>"" \
        -e CHOWN_EXTRA_OPTS=""-R"" \
-       jupyter/minimal-notebook
+       docker.io/jupyter/minimal-notebook
    ```
 
    where:
@@ -95,7 +95,7 @@ The following sections cover a few of these scenarios and how to fix them.
        -e NB_UID=1234 \
        -e NB_GID=5678 \
        -v ""${PWD}""/test:/home/jovyan/work \
-       jupyter/minimal-notebook:latest
+       docker.io/jupyter/minimal-notebook:latest
 
    # you should see an output similar to this
    # Update jovyan's UID:GID to 1234:5678
@@ -144,7 +144,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
         -e CHOWN_HOME_OPTS=""-R"" \
         -w ""/home/callisto"" \
         -v ""${PWD}""/test:/home/callisto/work \
-        jupyter/minimal-notebook
+        docker.io/jupyter/minimal-notebook
 
     # Updated the jovyan user:
     # - username: jovyan       -> callisto
@@ -187,7 +187,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
        -e CHOWN_HOME_OPTS=""-R"" \
        -w ""/home/callisto"" \
        -v ""${PWD}""/test:/home/callisto/work \
-       jupyter/minimal-notebook
+       docker.io/jupyter/minimal-notebook
    ```
 
    where:
@@ -214,7 +214,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
   docker run -it --rm \
       -p 8888:8888 \
       --user ""$(id -u)"" --group-add users \
-      -v <my-vol>:/home/jovyan/work jupyter/datascience-notebook
+      -v <my-vol>:/home/jovyan/work docker.io/jupyter/datascience-notebook
   ```
 
   This command will launch the container with a specific user UID and add that user to the `users` group to modify the files in the default `/home` and `/opt/conda` directories.
@@ -318,7 +318,7 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
    You can see an example of mapping to local port `8001`:
 
    ```bash
-   docker run -it --rm -p 8001:8888 jupyter/datascience-notebook
+   docker run -it --rm -p 8001:8888 docker.io/jupyter/datascience-notebook
    ```
 
    When the terminal provides the link to access Jupyter: <http://127.0.0.1:8888/lab?token=80d45d241a1ba4c2...>,","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index b5d17b88..b11eacb6 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -14,7 +14,7 @@ If you are running a Docker container while mounting a local volume or host dire
 docker run -it --rm \
     -p 8888:8888 \
     -v <my-vol>:<container-dir> \
-    jupyter/minimal-notebook:latest
+    docker.io/jupyter/minimal-notebook:latest
 ```
 
 you might face permissions issues when trying to access the mounted volume:
@@ -48,7 +48,7 @@ The following sections cover a few of these scenarios and how to fix them.
        --user root \
        -e CHOWN_EXTRA=""<container-dir>"" \
        -e CHOWN_EXTRA_OPTS=""-R"" \
-       jupyter/minimal-notebook
+       docker.io/jupyter/minimal-notebook
    ```
 
    where:
@@ -95,7 +95,7 @@ The following sections cover a few of these scenarios and how to fix them.
        -e NB_UID=1234 \
        -e NB_GID=5678 \
        -v ""${PWD}""/test:/home/jovyan/work \
-       jupyter/minimal-notebook:latest
+       docker.io/jupyter/minimal-notebook:latest
 
    # you should see an output similar to this
    # Update jovyan's UID:GID to 1234:5678
@@ -144,7 +144,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
         -e CHOWN_HOME_OPTS=""-R"" \
         -w ""/home/callisto"" \
         -v ""${PWD}""/test:/home/callisto/work \
-        jupyter/minimal-notebook
+        docker.io/jupyter/minimal-notebook
 
     # Updated the jovyan user:
     # - username: jovyan       -> callisto
@@ -187,7 +187,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
        -e CHOWN_HOME_OPTS=""-R"" \
        -w ""/home/callisto"" \
        -v ""${PWD}""/test:/home/callisto/work \
-       jupyter/minimal-notebook
+       docker.io/jupyter/minimal-notebook
    ```
 
    where:
@@ -214,7 +214,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
   docker run -it --rm \
       -p 8888:8888 \
       --user ""$(id -u)"" --group-add users \
-      -v <my-vol>:/home/jovyan/work jupyter/datascience-notebook
+      -v <my-vol>:/home/jovyan/work docker.io/jupyter/datascience-notebook
   ```
 
   This command will launch the container with a specific user UID and add that user to the `users` group to modify the files in the default `/home` and `/opt/conda` directories.
@@ -318,7 +318,7 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
    You can see an example of mapping to local port `8001`:
 
    ```bash
-   docker run -it --rm -p 8001:8888 jupyter/datascience-notebook
+   docker run -it --rm -p 8001:8888 docker.io/jupyter/datascience-notebook
    ```
 
    When the terminal provides the link to access Jupyter: <http://127.0.0.1:8888/lab?token=80d45d241a1ba4c2...>,",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,a38f9248d245a3cea3525d5424be51152090494f,4adbb05073e50f82e72aa87292cb18e815b8d989,Use word registry in workflows where possible,"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 3e4142d4..0ff164ba 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -11,9 +11,9 @@ on:
         required: true
         type: string
     secrets:
-      DOCKERHUB_USERNAME:
+      REGISTRY_USERNAME:
         required: true
-      DOCKERHUB_TOKEN:
+      REGISTRY_TOKEN:
         required: true
 
 jobs:
@@ -52,8 +52,8 @@ jobs:
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
-          username: ${{ secrets.DOCKERHUB_USERNAME }}
-          password: ${{ secrets.DOCKERHUB_TOKEN }}
+          username: ${{ secrets.REGISTRY_USERNAME }}
+          password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Merge tags for the images 🔀
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 3e4142d4..0ff164ba 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -11,9 +11,9 @@ on:
         required: true
         type: string
     secrets:
-      DOCKERHUB_USERNAME:
+      REGISTRY_USERNAME:
         required: true
-      DOCKERHUB_TOKEN:
+      REGISTRY_TOKEN:
         required: true
 
 jobs:
@@ -52,8 +52,8 @@ jobs:
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
-          username: ${{ secrets.DOCKERHUB_USERNAME }}
-          password: ${{ secrets.DOCKERHUB_TOKEN }}
+          username: ${{ secrets.REGISTRY_USERNAME }}
+          password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Merge tags for the images 🔀
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,a38f9248d245a3cea3525d5424be51152090494f,4adbb05073e50f82e72aa87292cb18e815b8d989,Use word registry in workflows where possible,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 43233099..2b8ea018 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -16,9 +16,9 @@ on:
         required: true
         type: string
     secrets:
-      DOCKERHUB_USERNAME:
+      REGISTRY_USERNAME:
         required: true
-      DOCKERHUB_TOKEN:
+      REGISTRY_TOKEN:
         required: true
 
 jobs:
@@ -42,8 +42,8 @@ jobs:
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
-          username: ${{ secrets.DOCKERHUB_USERNAME }}
-          password: ${{ secrets.DOCKERHUB_TOKEN }}
+          username: ${{ secrets.REGISTRY_USERNAME }}
+          password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Download tags file 📥
         uses: actions/download-artifact@v3","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 43233099..2b8ea018 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -16,9 +16,9 @@ on:
         required: true
         type: string
     secrets:
-      DOCKERHUB_USERNAME:
+      REGISTRY_USERNAME:
         required: true
-      DOCKERHUB_TOKEN:
+      REGISTRY_TOKEN:
         required: true
 
 jobs:
@@ -42,8 +42,8 @@ jobs:
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
-          username: ${{ secrets.DOCKERHUB_USERNAME }}
-          password: ${{ secrets.DOCKERHUB_TOKEN }}
+          username: ${{ secrets.REGISTRY_USERNAME }}
+          password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Download tags file 📥
         uses: actions/download-artifact@v3",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,a38f9248d245a3cea3525d5424be51152090494f,4adbb05073e50f82e72aa87292cb18e815b8d989,Use word registry in workflows where possible,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 55fb9e20..e89fe915 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -246,8 +246,8 @@ jobs:
       platform: aarch64
       image: ${{ matrix.image }}
     secrets:
-      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
     strategy:
       matrix:
         image:
@@ -284,8 +284,8 @@ jobs:
       platform: x86_64
       image: ${{ matrix.image }}
     secrets:
-      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
     strategy:
       matrix:
         image:
@@ -320,8 +320,8 @@ jobs:
     with:
       image: ${{ matrix.image }}
     secrets:
-      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
     strategy:
       matrix:
         image:","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 55fb9e20..e89fe915 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -246,8 +246,8 @@ jobs:
       platform: aarch64
       image: ${{ matrix.image }}
     secrets:
-      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
     strategy:
       matrix:
         image:
@@ -284,8 +284,8 @@ jobs:
       platform: x86_64
       image: ${{ matrix.image }}
     secrets:
-      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
     strategy:
       matrix:
         image:
@@ -320,8 +320,8 @@ jobs:
     with:
       image: ${{ matrix.image }}
     secrets:
-      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
     strategy:
       matrix:
         image:",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,ebfeda100b2be58783c8acfe2fd0f425f0ab9267,a38f9248d245a3cea3525d5424be51152090494f,Use word registry in workflows where possible,"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 0ff164ba..acbeed79 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -48,7 +48,7 @@ jobs:
           sudo systemctl restart docker
         shell: bash
 
-      - name: Login to Docker Hub 🔐
+      - name: Login to Registry 🔐
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 0ff164ba..acbeed79 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -48,7 +48,7 @@ jobs:
           sudo systemctl restart docker
         shell: bash
 
-      - name: Login to Docker Hub 🔐
+      - name: Login to Registry 🔐
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,ebfeda100b2be58783c8acfe2fd0f425f0ab9267,a38f9248d245a3cea3525d5424be51152090494f,Use word registry in workflows where possible,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 2b8ea018..634746f6 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -38,7 +38,7 @@ jobs:
           image: ${{ inputs.image }}
           platform: ${{ inputs.platform }}
 
-      - name: Login to Docker Hub 🔐
+      - name: Login to Registry 🔐
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
@@ -53,7 +53,7 @@ jobs:
       - name: Apply tags to the loaded image 🏷
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
 
-      - name: Push Images to Docker Hub 📤
+      - name: Push Images to Registry 📤
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         run: docker push --all-tags ${{ env.OWNER }}/${{ inputs.image }}
         shell: bash","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 2b8ea018..634746f6 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -38,7 +38,7 @@ jobs:
           image: ${{ inputs.image }}
           platform: ${{ inputs.platform }}
 
-      - name: Login to Docker Hub 🔐
+      - name: Login to Registry 🔐
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
@@ -53,7 +53,7 @@ jobs:
       - name: Apply tags to the loaded image 🏷
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
 
-      - name: Push Images to Docker Hub 📤
+      - name: Push Images to Registry 📤
         if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
         run: docker push --all-tags ${{ env.OWNER }}/${{ inputs.image }}
         shell: bash",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,ad85d8106c47b7d3d5e35b832b33fbd67e5e349f,ebfeda100b2be58783c8acfe2fd0f425f0ab9267,Use word registry in workflows where possible,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 634746f6..dd209cc5 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,4 +1,4 @@
-name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to Docker Hub
+name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
 
 env:
   REGISTRY: docker.io","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 634746f6..dd209cc5 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,4 +1,4 @@
-name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to Docker Hub
+name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
 
 env:
   REGISTRY: docker.io",Yes
.github/workflows/hub-overview.yml,.github/workflows/hub-overview.yml,ad85d8106c47b7d3d5e35b832b33fbd67e5e349f,ebfeda100b2be58783c8acfe2fd0f425f0ab9267,Use word registry in workflows where possible,"diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
deleted file mode 100644
index 9f37eae5..00000000
--- a/.github/workflows/hub-overview.yml
+++ /dev/null
@@ -1,59 +0,0 @@
-name: Update Docker Hub overviews
-
-env:
-  OWNER: ${{ github.repository_owner }}
-
-on:
-  push:
-    branches:
-      - main
-    paths:
-      - "".github/workflows/hub-overview.yml""
-
-      - ""images/*/README.md""
-  workflow_dispatch:
-
-jobs:
-  update-overview:
-    runs-on: ubuntu-latest
-    name: update-overview (${{matrix.image}})
-    if: github.repository == 'jupyter/docker-stacks'
-
-    steps:
-      - name: Checkout Repo ⚡️
-        uses: actions/checkout@v4
-
-      - name: Push README to Docker Hub 🐳
-        uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1
-        env:
-          DOCKER_USER: ${{ secrets.DOCKERHUB_USERNAME }}
-          DOCKER_PASS: ${{ secrets.DOCKERHUB_TOKEN }}
-        with:
-          destination_container_repo: ${{ env.OWNER }}/${{ matrix.image }}
-          provider: dockerhub
-          short_description: ${{ matrix.description }}
-          readme_file: images/${{ matrix.image }}/README.md
-
-    strategy:
-      matrix:
-        include:
-          - image: docker-stacks-foundation
-            description: ""Tiny base image on which Jupyter apps can be built from https://github.com/jupyter/docker-stacks""
-          - image: base-notebook
-            description: ""Base image for Jupyter Notebook stacks from https://github.com/jupyter/docker-stacks""
-          - image: minimal-notebook
-            description: ""Minimal Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: scipy-notebook
-            description: ""Scientific Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: r-notebook
-            description: ""R Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: julia-notebook
-            description: ""Julia Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: tensorflow-notebook
-            description: ""Scientific Jupyter Notebook Python Stack w/ TensorFlow from https://github.com/jupyter/docker-stacks""
-          - image: datascience-notebook
-            description: ""Data Science Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: pyspark-notebook
-            description: ""Python and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: all-spark-notebook
-            description: ""Python, Scala, R and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""","diff --git a/.github/workflows/hub-overview.yml b/.github/workflows/hub-overview.yml
deleted file mode 100644
index 9f37eae5..00000000
--- a/.github/workflows/hub-overview.yml
+++ /dev/null
@@ -1,59 +0,0 @@
-name: Update Docker Hub overviews
-
-env:
-  OWNER: ${{ github.repository_owner }}
-
-on:
-  push:
-    branches:
-      - main
-    paths:
-      - "".github/workflows/hub-overview.yml""
-
-      - ""images/*/README.md""
-  workflow_dispatch:
-
-jobs:
-  update-overview:
-    runs-on: ubuntu-latest
-    name: update-overview (${{matrix.image}})
-    if: github.repository == 'jupyter/docker-stacks'
-
-    steps:
-      - name: Checkout Repo ⚡️
-        uses: actions/checkout@v4
-
-      - name: Push README to Docker Hub 🐳
-        uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1
-        env:
-          DOCKER_USER: ${{ secrets.DOCKERHUB_USERNAME }}
-          DOCKER_PASS: ${{ secrets.DOCKERHUB_TOKEN }}
-        with:
-          destination_container_repo: ${{ env.OWNER }}/${{ matrix.image }}
-          provider: dockerhub
-          short_description: ${{ matrix.description }}
-          readme_file: images/${{ matrix.image }}/README.md
-
-    strategy:
-      matrix:
-        include:
-          - image: docker-stacks-foundation
-            description: ""Tiny base image on which Jupyter apps can be built from https://github.com/jupyter/docker-stacks""
-          - image: base-notebook
-            description: ""Base image for Jupyter Notebook stacks from https://github.com/jupyter/docker-stacks""
-          - image: minimal-notebook
-            description: ""Minimal Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: scipy-notebook
-            description: ""Scientific Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: r-notebook
-            description: ""R Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: julia-notebook
-            description: ""Julia Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: tensorflow-notebook
-            description: ""Scientific Jupyter Notebook Python Stack w/ TensorFlow from https://github.com/jupyter/docker-stacks""
-          - image: datascience-notebook
-            description: ""Data Science Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: pyspark-notebook
-            description: ""Python and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: all-spark-notebook
-            description: ""Python, Scala, R and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""",Yes
,.github/workflows/registry-overviews.yml,72c6fafccba09cfb44526c8cda0ac53575d9fd61,ad85d8106c47b7d3d5e35b832b33fbd67e5e349f,Add missing file,"diff --git a/.github/workflows/registry-overviews.yml b/.github/workflows/registry-overviews.yml
new file mode 100644
index 00000000..b3d3a7f3
--- /dev/null
+++ b/.github/workflows/registry-overviews.yml
@@ -0,0 +1,59 @@
+name: Update Registry overviews
+
+env:
+  OWNER: ${{ github.repository_owner }}
+
+on:
+  push:
+    branches:
+      - main
+    paths:
+      - "".github/workflows/registry-overviews.yml""
+
+      - ""images/*/README.md""
+  workflow_dispatch:
+
+jobs:
+  update-overview:
+    runs-on: ubuntu-latest
+    name: update-overview (${{matrix.image}})
+    if: github.repository == 'jupyter/docker-stacks'
+
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v4
+
+      - name: Push README to Registry 🐳
+        uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1
+        env:
+          DOCKER_USER: ${{ secrets.DOCKERHUB_USERNAME }}
+          DOCKER_PASS: ${{ secrets.DOCKERHUB_TOKEN }}
+        with:
+          destination_container_repo: ${{ env.OWNER }}/${{ matrix.image }}
+          provider: dockerhub
+          short_description: ${{ matrix.description }}
+          readme_file: images/${{ matrix.image }}/README.md
+
+    strategy:
+      matrix:
+        include:
+          - image: docker-stacks-foundation
+            description: ""Tiny base image on which Jupyter apps can be built from https://github.com/jupyter/docker-stacks""
+          - image: base-notebook
+            description: ""Base image for Jupyter Notebook stacks from https://github.com/jupyter/docker-stacks""
+          - image: minimal-notebook
+            description: ""Minimal Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
+          - image: scipy-notebook
+            description: ""Scientific Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
+          - image: r-notebook
+            description: ""R Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
+          - image: julia-notebook
+            description: ""Julia Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
+          - image: tensorflow-notebook
+            description: ""Scientific Jupyter Notebook Python Stack w/ TensorFlow from https://github.com/jupyter/docker-stacks""
+          - image: datascience-notebook
+            description: ""Data Science Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
+          - image: pyspark-notebook
+            description: ""Python and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
+          - image: all-spark-notebook
+            description: ""Python, Scala, R and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""","diff --git a/.github/workflows/registry-overviews.yml b/.github/workflows/registry-overviews.yml
new file mode 100644
index 00000000..b3d3a7f3
--- /dev/null
+++ b/.github/workflows/registry-overviews.yml
@@ -0,0 +1,59 @@
+name: Update Registry overviews
+
+env:
+  OWNER: ${{ github.repository_owner }}
+
+on:
+  push:
+    branches:
+      - main
+    paths:
+      - "".github/workflows/registry-overviews.yml""
+
+      - ""images/*/README.md""
+  workflow_dispatch:
+
+jobs:
+  update-overview:
+    runs-on: ubuntu-latest
+    name: update-overview (${{matrix.image}})
+    if: github.repository == 'jupyter/docker-stacks'
+
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v4
+
+      - name: Push README to Registry 🐳
+        uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1
+        env:
+          DOCKER_USER: ${{ secrets.DOCKERHUB_USERNAME }}
+          DOCKER_PASS: ${{ secrets.DOCKERHUB_TOKEN }}
+        with:
+          destination_container_repo: ${{ env.OWNER }}/${{ matrix.image }}
+          provider: dockerhub
+          short_description: ${{ matrix.description }}
+          readme_file: images/${{ matrix.image }}/README.md
+
+    strategy:
+      matrix:
+        include:
+          - image: docker-stacks-foundation
+            description: ""Tiny base image on which Jupyter apps can be built from https://github.com/jupyter/docker-stacks""
+          - image: base-notebook
+            description: ""Base image for Jupyter Notebook stacks from https://github.com/jupyter/docker-stacks""
+          - image: minimal-notebook
+            description: ""Minimal Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
+          - image: scipy-notebook
+            description: ""Scientific Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
+          - image: r-notebook
+            description: ""R Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
+          - image: julia-notebook
+            description: ""Julia Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
+          - image: tensorflow-notebook
+            description: ""Scientific Jupyter Notebook Python Stack w/ TensorFlow from https://github.com/jupyter/docker-stacks""
+          - image: datascience-notebook
+            description: ""Data Science Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
+          - image: pyspark-notebook
+            description: ""Python and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
+          - image: all-spark-notebook
+            description: ""Python, Scala, R and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index d420df43..6a962521 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -2,7 +2,7 @@
 
 ## Merging Pull Requests
 
-To build new images and publish them to the Docker Hub registry, do the following:
+To build new images and publish them to the Registry, do the following:
 
 1. Make sure GitHub Actions status checks pass for the PR.
 2. Merge the PR.
@@ -11,7 +11,7 @@ To build new images and publish them to the Docker Hub registry, do the followin
    ```{note}
    GitHub Actions are pretty reliable, so please investigate if some error occurs.
    Building Docker images in PRs is the same as building them in default branch,
-   except single-platform images are pushed to Docker Hub and then tags are merged for `x86_64` and `aarch64`.
+   except single-platform images are pushed to Registry and then tags are merged for `x86_64` and `aarch64`.
    ```
 
 4. Avoid merging another PR to the main branch until all pending builds are complete.
@@ -35,7 +35,7 @@ We rebuild our images automatically each week, which means they frequently recei
 When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger images rebuild [from the GitHub actions workflow UI](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml).
 Pushing the `Run Workflow` button will trigger this process.
 
-## Adding a New Core Image to Docker Hub
+## Adding a New Core Image to the Registry
 
 ```{note}
 In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
@@ -50,14 +50,14 @@ When there's a new stack definition, check before merging the PR:
    The image links to the [blockdiag source](http://interactive.blockdiag.com/) used to create it.
 2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
 3. Necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
-4. A new repository is created in the `jupyter` org on Docker Hub,
+4. A new repository is created in the `jupyter` org in the Registry,
    and it's named after the stack folder in the git repo.
 5. Grant the `stacks` team permission to write to this repo.
 
 ## Adding a New Maintainer Account
 
 1. Visit <https://hub.docker.com/orgs/jupyter/teams/stacks/members>
-2. Add the maintainer's Docker Hub username.
+2. Add the maintainer's username.
 3. Visit <https://github.com/orgs/jupyter/teams/docker-image-maintainers/members>
 4. Add the maintainer's GitHub username.","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index d420df43..6a962521 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -2,7 +2,7 @@
 
 ## Merging Pull Requests
 
-To build new images and publish them to the Docker Hub registry, do the following:
+To build new images and publish them to the Registry, do the following:
 
 1. Make sure GitHub Actions status checks pass for the PR.
 2. Merge the PR.
@@ -11,7 +11,7 @@ To build new images and publish them to the Docker Hub registry, do the followin
    ```{note}
    GitHub Actions are pretty reliable, so please investigate if some error occurs.
    Building Docker images in PRs is the same as building them in default branch,
-   except single-platform images are pushed to Docker Hub and then tags are merged for `x86_64` and `aarch64`.
+   except single-platform images are pushed to Registry and then tags are merged for `x86_64` and `aarch64`.
    ```
 
 4. Avoid merging another PR to the main branch until all pending builds are complete.
@@ -35,7 +35,7 @@ We rebuild our images automatically each week, which means they frequently recei
 When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger images rebuild [from the GitHub actions workflow UI](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml).
 Pushing the `Run Workflow` button will trigger this process.
 
-## Adding a New Core Image to Docker Hub
+## Adding a New Core Image to the Registry
 
 ```{note}
 In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
@@ -50,14 +50,14 @@ When there's a new stack definition, check before merging the PR:
    The image links to the [blockdiag source](http://interactive.blockdiag.com/) used to create it.
 2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
 3. Necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
-4. A new repository is created in the `jupyter` org on Docker Hub,
+4. A new repository is created in the `jupyter` org in the Registry,
    and it's named after the stack folder in the git repo.
 5. Grant the `stacks` team permission to write to this repo.
 
 ## Adding a New Maintainer Account
 
 1. Visit <https://hub.docker.com/orgs/jupyter/teams/stacks/members>
-2. Add the maintainer's Docker Hub username.
+2. Add the maintainer's username.
 3. Visit <https://github.com/orgs/jupyter/teams/docker-image-maintainers/members>
 4. Add the maintainer's GitHub username.",Yes
images/all-spark-notebook/README.md,images/all-spark-notebook/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/all-spark-notebook/README.md b/images/all-spark-notebook/README.md
index 898aca6a..9d208f93 100644
--- a/images/all-spark-notebook/README.md
+++ b/images/all-spark-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/all-spark-notebook/latest)](https://hub.docker.com/r/jupyter/all-spark-notebook/ ""jupyter/all-spark-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/all-spark-notebook/README.md b/images/all-spark-notebook/README.md
index 898aca6a..9d208f93 100644
--- a/images/all-spark-notebook/README.md
+++ b/images/all-spark-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/all-spark-notebook/latest)](https://hub.docker.com/r/jupyter/all-spark-notebook/ ""jupyter/all-spark-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
images/base-notebook/README.md,images/base-notebook/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/base-notebook/README.md b/images/base-notebook/README.md
index 618da14d..1638d7cf 100644
--- a/images/base-notebook/README.md
+++ b/images/base-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/base-notebook/latest)](https://hub.docker.com/r/jupyter/base-notebook/ ""jupyter/base-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/base-notebook/README.md b/images/base-notebook/README.md
index 618da14d..1638d7cf 100644
--- a/images/base-notebook/README.md
+++ b/images/base-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/base-notebook/latest)](https://hub.docker.com/r/jupyter/base-notebook/ ""jupyter/base-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
images/datascience-notebook/README.md,images/datascience-notebook/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/datascience-notebook/README.md b/images/datascience-notebook/README.md
index 64ef2007..f3201761 100644
--- a/images/datascience-notebook/README.md
+++ b/images/datascience-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/datascience-notebook/latest)](https://hub.docker.com/r/jupyter/datascience-notebook/ ""jupyter/datascience-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/datascience-notebook/README.md b/images/datascience-notebook/README.md
index 64ef2007..f3201761 100644
--- a/images/datascience-notebook/README.md
+++ b/images/datascience-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/datascience-notebook/latest)](https://hub.docker.com/r/jupyter/datascience-notebook/ ""jupyter/datascience-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
images/docker-stacks-foundation/README.md,images/docker-stacks-foundation/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/docker-stacks-foundation/README.md b/images/docker-stacks-foundation/README.md
index b4e4d2db..449fe058 100644
--- a/images/docker-stacks-foundation/README.md
+++ b/images/docker-stacks-foundation/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/docker-stacks-foundation/latest)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/ ""jupyter/docker-stacks-foundation image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/docker-stacks-foundation/README.md b/images/docker-stacks-foundation/README.md
index b4e4d2db..449fe058 100644
--- a/images/docker-stacks-foundation/README.md
+++ b/images/docker-stacks-foundation/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/docker-stacks-foundation/latest)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/ ""jupyter/docker-stacks-foundation image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
images/julia-notebook/README.md,images/julia-notebook/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/julia-notebook/README.md b/images/julia-notebook/README.md
index dfca913b..fc611b37 100644
--- a/images/julia-notebook/README.md
+++ b/images/julia-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/julia-notebook/latest)](https://hub.docker.com/r/jupyter/julia-notebook/ ""jupyter/julia-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/julia-notebook/README.md b/images/julia-notebook/README.md
index dfca913b..fc611b37 100644
--- a/images/julia-notebook/README.md
+++ b/images/julia-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/julia-notebook/latest)](https://hub.docker.com/r/jupyter/julia-notebook/ ""jupyter/julia-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
images/minimal-notebook/README.md,images/minimal-notebook/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/minimal-notebook/README.md b/images/minimal-notebook/README.md
index 40697fa1..fbedc520 100644
--- a/images/minimal-notebook/README.md
+++ b/images/minimal-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/minimal-notebook/latest)](https://hub.docker.com/r/jupyter/minimal-notebook/ ""jupyter/minimal-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/minimal-notebook/README.md b/images/minimal-notebook/README.md
index 40697fa1..fbedc520 100644
--- a/images/minimal-notebook/README.md
+++ b/images/minimal-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/minimal-notebook/latest)](https://hub.docker.com/r/jupyter/minimal-notebook/ ""jupyter/minimal-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
images/pyspark-notebook/README.md,images/pyspark-notebook/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/pyspark-notebook/README.md b/images/pyspark-notebook/README.md
index 1be04343..d88bc815 100644
--- a/images/pyspark-notebook/README.md
+++ b/images/pyspark-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/pyspark-notebook/latest)](https://hub.docker.com/r/jupyter/pyspark-notebook/ ""jupyter/pyspark-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/pyspark-notebook/README.md b/images/pyspark-notebook/README.md
index 1be04343..d88bc815 100644
--- a/images/pyspark-notebook/README.md
+++ b/images/pyspark-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/pyspark-notebook/latest)](https://hub.docker.com/r/jupyter/pyspark-notebook/ ""jupyter/pyspark-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
images/r-notebook/README.md,images/r-notebook/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
index 045ed123..bfc6fb1e 100644
--- a/images/r-notebook/README.md
+++ b/images/r-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/r-notebook/latest)](https://hub.docker.com/r/jupyter/r-notebook/ ""jupyter/r-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
index 045ed123..bfc6fb1e 100644
--- a/images/r-notebook/README.md
+++ b/images/r-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/r-notebook/latest)](https://hub.docker.com/r/jupyter/r-notebook/ ""jupyter/r-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
images/scipy-notebook/README.md,images/scipy-notebook/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/scipy-notebook/README.md b/images/scipy-notebook/README.md
index e34693d1..33330c0b 100644
--- a/images/scipy-notebook/README.md
+++ b/images/scipy-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/scipy-notebook/latest)](https://hub.docker.com/r/jupyter/scipy-notebook/ ""jupyter/scipy-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/scipy-notebook/README.md b/images/scipy-notebook/README.md
index e34693d1..33330c0b 100644
--- a/images/scipy-notebook/README.md
+++ b/images/scipy-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/scipy-notebook/latest)](https://hub.docker.com/r/jupyter/scipy-notebook/ ""jupyter/scipy-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
images/tensorflow-notebook/README.md,images/tensorflow-notebook/README.md,814219407b1f52eb778df06255e8dd9ec468fb9e,72c6fafccba09cfb44526c8cda0ac53575d9fd61,Remove some Docker Hub usage,"diff --git a/images/tensorflow-notebook/README.md b/images/tensorflow-notebook/README.md
index 5f896fd6..58c2a5fe 100644
--- a/images/tensorflow-notebook/README.md
+++ b/images/tensorflow-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/tensorflow-notebook/latest)](https://hub.docker.com/r/jupyter/tensorflow-notebook/ ""jupyter/tensorflow-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.","diff --git a/images/tensorflow-notebook/README.md b/images/tensorflow-notebook/README.md
index 5f896fd6..58c2a5fe 100644
--- a/images/tensorflow-notebook/README.md
+++ b/images/tensorflow-notebook/README.md
@@ -4,7 +4,7 @@
 [![docker stars](https://img.shields.io/docker/stars/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/tensorflow-notebook/latest)](https://hub.docker.com/r/jupyter/tensorflow-notebook/ ""jupyter/tensorflow-notebook image size"")
 
-GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to Docker Hub.
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
 
 Please visit the project documentation site for help to use and contribute to this image and others.",Yes
examples/openshift/README.md,examples/openshift/README.md,00e591fcf01ecd22179fa2d1b3f4bb3452a6e392,814219407b1f52eb778df06255e8dd9ec468fb9e,Add docker.io to more places,"diff --git a/examples/openshift/README.md b/examples/openshift/README.md
index 4f743f1d..65928d4a 100644
--- a/examples/openshift/README.md
+++ b/examples/openshift/README.md
@@ -52,7 +52,7 @@ The output will be similar to:
 
      * With parameters:
         * APPLICATION_NAME=notebook
-        * NOTEBOOK_IMAGE=jupyter/minimal-notebook:latest
+        * NOTEBOOK_IMAGE=docker.io/jupyter/minimal-notebook:latest
         * NOTEBOOK_PASSWORD=ded4d7cada554aa48e0db612e1ed1080 # generated
 
 --> Creating resources ...
@@ -69,7 +69,7 @@ When no template parameters are provided, the name of the deployed notebook will
 The image used will be:
 
 ```lang-none
-jupyter/minimal-notebook:latest
+docker.io/jupyter/minimal-notebook:latest
 ```
 
 A password you can use when accessing the notebook will be auto generated and is displayed in the output from running `oc new-app`.
@@ -102,7 +102,7 @@ To override the name for the notebook, the image used, and the password, you can
 ```bash
 oc new-app --template jupyter-notebook \
     --param APPLICATION_NAME=mynotebook \
-    --param NOTEBOOK_IMAGE=jupyter/scipy-notebook:latest \
+    --param NOTEBOOK_IMAGE=docker.io/jupyter/scipy-notebook:latest \
     --param NOTEBOOK_PASSWORD=mypassword
 ```
 
@@ -213,7 +213,7 @@ you can use the name of the image stream for the image name, including any image
 This can be illustrated by first importing an image into the OpenShift project.
 
 ```bash
-oc import-image jupyter/datascience-notebook:latest --confirm
+oc import-image docker.io/jupyter/datascience-notebook:latest --confirm
 ```
 
 Then deploy it using the name of the image stream created.","diff --git a/examples/openshift/README.md b/examples/openshift/README.md
index 4f743f1d..65928d4a 100644
--- a/examples/openshift/README.md
+++ b/examples/openshift/README.md
@@ -52,7 +52,7 @@ The output will be similar to:
 
      * With parameters:
         * APPLICATION_NAME=notebook
-        * NOTEBOOK_IMAGE=jupyter/minimal-notebook:latest
+        * NOTEBOOK_IMAGE=docker.io/jupyter/minimal-notebook:latest
         * NOTEBOOK_PASSWORD=ded4d7cada554aa48e0db612e1ed1080 # generated
 
 --> Creating resources ...
@@ -69,7 +69,7 @@ When no template parameters are provided, the name of the deployed notebook will
 The image used will be:
 
 ```lang-none
-jupyter/minimal-notebook:latest
+docker.io/jupyter/minimal-notebook:latest
 ```
 
 A password you can use when accessing the notebook will be auto generated and is displayed in the output from running `oc new-app`.
@@ -102,7 +102,7 @@ To override the name for the notebook, the image used, and the password, you can
 ```bash
 oc new-app --template jupyter-notebook \
     --param APPLICATION_NAME=mynotebook \
-    --param NOTEBOOK_IMAGE=jupyter/scipy-notebook:latest \
+    --param NOTEBOOK_IMAGE=docker.io/jupyter/scipy-notebook:latest \
     --param NOTEBOOK_PASSWORD=mypassword
 ```
 
@@ -213,7 +213,7 @@ you can use the name of the image stream for the image name, including any image
 This can be illustrated by first importing an image into the OpenShift project.
 
 ```bash
-oc import-image jupyter/datascience-notebook:latest --confirm
+oc import-image docker.io/jupyter/datascience-notebook:latest --confirm
 ```
 
 Then deploy it using the name of the image stream created.",Yes
examples/openshift/templates.json,examples/openshift/templates.json,00e591fcf01ecd22179fa2d1b3f4bb3452a6e392,814219407b1f52eb778df06255e8dd9ec468fb9e,Add docker.io to more places,"diff --git a/examples/openshift/templates.json b/examples/openshift/templates.json
index e12036ec..ebcd6cb2 100644
--- a/examples/openshift/templates.json
+++ b/examples/openshift/templates.json
@@ -18,7 +18,7 @@
     },
     {
       ""name"": ""NOTEBOOK_IMAGE"",
-      ""value"": ""jupyter/minimal-notebook:latest"",
+      ""value"": ""docker.io/jupyter/minimal-notebook:latest"",
       ""required"": true
     },
     {
@@ -85,7 +85,6 @@
                   ""--no-browser"",
                   ""--ip=0.0.0.0""
                 ],
-
                 ""ports"": [
                   {
                     ""containerPort"": 8888,","diff --git a/examples/openshift/templates.json b/examples/openshift/templates.json
index e12036ec..ebcd6cb2 100644
--- a/examples/openshift/templates.json
+++ b/examples/openshift/templates.json
@@ -18,7 +18,7 @@
     },
     {
       ""name"": ""NOTEBOOK_IMAGE"",
-      ""value"": ""jupyter/minimal-notebook:latest"",
+      ""value"": ""docker.io/jupyter/minimal-notebook:latest"",
       ""required"": true
     },
     {
@@ -85,7 +85,6 @@
                   ""--no-browser"",
                   ""--ip=0.0.0.0""
                 ],
-
                 ""ports"": [
                   {
                     ""containerPort"": 8888,",Yes
examples/source-to-image/README.md,examples/source-to-image/README.md,00e591fcf01ecd22179fa2d1b3f4bb3452a6e392,814219407b1f52eb778df06255e8dd9ec468fb9e,Add docker.io to more places,"diff --git a/examples/source-to-image/README.md b/examples/source-to-image/README.md
index 8639c109..6d4bcb82 100644
--- a/examples/source-to-image/README.md
+++ b/examples/source-to-image/README.md
@@ -34,13 +34,13 @@ s2i build \
     --scripts-url https://raw.githubusercontent.com/jupyter/docker-stacks/main/examples/source-to-image \
     --context-dir docs/source/examples/Notebook \
     https://github.com/jupyter/notebook \
-    jupyter/minimal-notebook:latest \
+    docker.io/jupyter/minimal-notebook:latest \
     notebook-examples
 ```
 
 This example command will pull down the Git repository <https://github.com/jupyter/notebook>
 and build the image `notebook-examples` using the files contained in the `docs/source/examples/Notebook` directory of that Git repository.
-The base image which the files will be combined with is `jupyter/minimal-notebook:latest`, but you can specify any of the Jupyter Project `docker-stacks` images as the base image.
+The base image which the files will be combined with is `docker.io/jupyter/minimal-notebook:latest`, but you can specify any of the Jupyter Project `docker-stacks` images as the base image.
 
 The resulting image from running the command can be seen by running `docker images` command:
 
@@ -147,7 +147,7 @@ oc new-app --template jupyter-notebook-quickstart \
     --param APPLICATION_NAME=notebook-examples \
     --param GIT_REPOSITORY_URL=https://github.com/jupyter/notebook \
     --param CONTEXT_DIR=docs/source/examples/Notebook \
-    --param BUILDER_IMAGE=jupyter/minimal-notebook:latest \
+    --param BUILDER_IMAGE=docker.io/jupyter/minimal-notebook:latest \
     --param NOTEBOOK_PASSWORD=mypassword
 ```","diff --git a/examples/source-to-image/README.md b/examples/source-to-image/README.md
index 8639c109..6d4bcb82 100644
--- a/examples/source-to-image/README.md
+++ b/examples/source-to-image/README.md
@@ -34,13 +34,13 @@ s2i build \
     --scripts-url https://raw.githubusercontent.com/jupyter/docker-stacks/main/examples/source-to-image \
     --context-dir docs/source/examples/Notebook \
     https://github.com/jupyter/notebook \
-    jupyter/minimal-notebook:latest \
+    docker.io/jupyter/minimal-notebook:latest \
     notebook-examples
 ```
 
 This example command will pull down the Git repository <https://github.com/jupyter/notebook>
 and build the image `notebook-examples` using the files contained in the `docs/source/examples/Notebook` directory of that Git repository.
-The base image which the files will be combined with is `jupyter/minimal-notebook:latest`, but you can specify any of the Jupyter Project `docker-stacks` images as the base image.
+The base image which the files will be combined with is `docker.io/jupyter/minimal-notebook:latest`, but you can specify any of the Jupyter Project `docker-stacks` images as the base image.
 
 The resulting image from running the command can be seen by running `docker images` command:
 
@@ -147,7 +147,7 @@ oc new-app --template jupyter-notebook-quickstart \
     --param APPLICATION_NAME=notebook-examples \
     --param GIT_REPOSITORY_URL=https://github.com/jupyter/notebook \
     --param CONTEXT_DIR=docs/source/examples/Notebook \
-    --param BUILDER_IMAGE=jupyter/minimal-notebook:latest \
+    --param BUILDER_IMAGE=docker.io/jupyter/minimal-notebook:latest \
     --param NOTEBOOK_PASSWORD=mypassword
 ```",Yes
examples/source-to-image/templates.json,examples/source-to-image/templates.json,00e591fcf01ecd22179fa2d1b3f4bb3452a6e392,814219407b1f52eb778df06255e8dd9ec468fb9e,Add docker.io to more places,"diff --git a/examples/source-to-image/templates.json b/examples/source-to-image/templates.json
index 8daa0823..aa677668 100644
--- a/examples/source-to-image/templates.json
+++ b/examples/source-to-image/templates.json
@@ -22,7 +22,7 @@
         },
         {
           ""name"": ""BUILDER_IMAGE"",
-          ""value"": ""jupyter/minimal-notebook:latest"",
+          ""value"": ""docker.io/jupyter/minimal-notebook:latest"",
           ""required"": true
         },
         {
@@ -125,7 +125,7 @@
         },
         {
           ""name"": ""BUILDER_IMAGE"",
-          ""value"": ""jupyter/minimal-notebook:latest"",
+          ""value"": ""docker.io/jupyter/minimal-notebook:latest"",
           ""required"": true
         },
         {
@@ -279,7 +279,6 @@
                       ""--no-browser"",
                       ""--ip=0.0.0.0""
                     ],
-
                     ""ports"": [
                       {
                         ""containerPort"": 8888,","diff --git a/examples/source-to-image/templates.json b/examples/source-to-image/templates.json
index 8daa0823..aa677668 100644
--- a/examples/source-to-image/templates.json
+++ b/examples/source-to-image/templates.json
@@ -22,7 +22,7 @@
         },
         {
           ""name"": ""BUILDER_IMAGE"",
-          ""value"": ""jupyter/minimal-notebook:latest"",
+          ""value"": ""docker.io/jupyter/minimal-notebook:latest"",
           ""required"": true
         },
         {
@@ -125,7 +125,7 @@
         },
         {
           ""name"": ""BUILDER_IMAGE"",
-          ""value"": ""jupyter/minimal-notebook:latest"",
+          ""value"": ""docker.io/jupyter/minimal-notebook:latest"",
           ""required"": true
         },
         {
@@ -279,7 +279,6 @@
                       ""--no-browser"",
                       ""--ip=0.0.0.0""
                     ],
-
                     ""ports"": [
                       {
                         ""containerPort"": 8888,",Yes
tagging/README.md,tagging/README.md,00e591fcf01ecd22179fa2d1b3f4bb3452a6e392,814219407b1f52eb778df06255e8dd9ec468fb9e,Add docker.io to more places,"diff --git a/tagging/README.md b/tagging/README.md
index 743e447e..f3d2a9fb 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -4,7 +4,7 @@ The main purpose of the source code in this folder is to properly tag all the im
 These two processes are closely related, so the source code is widely reused.
 
 A basic example of a tag is a `python` version tag.
-For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a tag `jupyter/base-notebook:python-3.10.5`.
+For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a full image name `docker.io/jupyter/base-notebook:python-3.10.5`.
 This tag (and all the other tags) are pushed to Docker Hub.
 
 Manifest is a description of some important part of the image in a `markdown`.","diff --git a/tagging/README.md b/tagging/README.md
index 743e447e..f3d2a9fb 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -4,7 +4,7 @@ The main purpose of the source code in this folder is to properly tag all the im
 These two processes are closely related, so the source code is widely reused.
 
 A basic example of a tag is a `python` version tag.
-For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a tag `jupyter/base-notebook:python-3.10.5`.
+For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a full image name `docker.io/jupyter/base-notebook:python-3.10.5`.
 This tag (and all the other tags) are pushed to Docker Hub.
 
 Manifest is a description of some important part of the image in a `markdown`.",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,0d5a6b016480b0eb85a9a30ad75b68293fbac579,00e591fcf01ecd22179fa2d1b3f4bb3452a6e392,Do not run full rebuild on tagging/README.md changes,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index e89fe915..17a60bef 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -23,6 +23,7 @@ on:
       - ""images/**""
       - ""!images/*/README.md""
       - ""tagging/**""
+      - ""!tagging/README.md""
       - ""tests/**""
       - ""requirements-dev.txt""
   push:
@@ -42,6 +43,7 @@ on:
       - ""images/**""
       - ""!images/*/README.md""
       - ""tagging/**""
+      - ""!tagging/README.md""
       - ""tests/**""
       - ""requirements-dev.txt""
   workflow_dispatch:","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index e89fe915..17a60bef 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -23,6 +23,7 @@ on:
       - ""images/**""
       - ""!images/*/README.md""
       - ""tagging/**""
+      - ""!tagging/README.md""
       - ""tests/**""
       - ""requirements-dev.txt""
   push:
@@ -42,6 +43,7 @@ on:
       - ""images/**""
       - ""!images/*/README.md""
       - ""tagging/**""
+      - ""!tagging/README.md""
       - ""tests/**""
       - ""requirements-dev.txt""
   workflow_dispatch:",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,94ab69dde0adbe65225925e4d3174a2d783eccd0,0d5a6b016480b0eb85a9a30ad75b68293fbac579,Use registry during docker save,"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 7f8c1deb..e5709891 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -102,7 +102,7 @@ jobs:
       - name: Save image as a tar for later use 💾
         run: |
           mkdir -p /tmp/jupyter/images/
-          docker save ${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
+          docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
         uses: actions/upload-artifact@v3","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 7f8c1deb..e5709891 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -102,7 +102,7 @@ jobs:
       - name: Save image as a tar for later use 💾
         run: |
           mkdir -p /tmp/jupyter/images/
-          docker save ${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
+          docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
         uses: actions/upload-artifact@v3",Yes
README.md,README.md,189df18e9a6dd4faa972700abe2c7eb028f95966,94ab69dde0adbe65225925e4d3174a2d783eccd0,Better badge url,"diff --git a/README.md b/README.md
index f77406d1..749a5f1c 100644
--- a/README.md
+++ b/README.md
@@ -1,6 +1,7 @@
 # Jupyter Docker Stacks
 
-[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml ""Docker images build status"")
+[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)]
+(<https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain> ""Docker images build status"")
 [![Read the Docs badge](https://img.shields.io/readthedocs/jupyter-docker-stacks.svg)](https://jupyter-docker-stacks.readthedocs.io/en/latest/ ""Documentation build status"")
 [![pre-commit.ci status](https://results.pre-commit.ci/badge/github/jupyter/docker-stacks/main.svg)](https://results.pre-commit.ci/latest/github/jupyter/docker-stacks/main ""pre-commit.ci build status"")
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")","diff --git a/README.md b/README.md
index f77406d1..749a5f1c 100644
--- a/README.md
+++ b/README.md
@@ -1,6 +1,7 @@
 # Jupyter Docker Stacks
 
-[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml ""Docker images build status"")
+[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)]
+(<https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain> ""Docker images build status"")
 [![Read the Docs badge](https://img.shields.io/readthedocs/jupyter-docker-stacks.svg)](https://jupyter-docker-stacks.readthedocs.io/en/latest/ ""Documentation build status"")
 [![pre-commit.ci status](https://results.pre-commit.ci/badge/github/jupyter/docker-stacks/main.svg)](https://results.pre-commit.ci/latest/github/jupyter/docker-stacks/main ""pre-commit.ci build status"")
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")",Yes
README.md,README.md,f1a18d515cb6a0e752cbfe603b1092cd61acac87,189df18e9a6dd4faa972700abe2c7eb028f95966,Better badge url,"diff --git a/README.md b/README.md
index 749a5f1c..afae154d 100644
--- a/README.md
+++ b/README.md
@@ -1,7 +1,7 @@
 # Jupyter Docker Stacks
 
-[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)]
-(<https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain> ""Docker images build status"")
+[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)
+](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain ""Docker images build status"")
 [![Read the Docs badge](https://img.shields.io/readthedocs/jupyter-docker-stacks.svg)](https://jupyter-docker-stacks.readthedocs.io/en/latest/ ""Documentation build status"")
 [![pre-commit.ci status](https://results.pre-commit.ci/badge/github/jupyter/docker-stacks/main.svg)](https://results.pre-commit.ci/latest/github/jupyter/docker-stacks/main ""pre-commit.ci build status"")
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")","diff --git a/README.md b/README.md
index 749a5f1c..afae154d 100644
--- a/README.md
+++ b/README.md
@@ -1,7 +1,7 @@
 # Jupyter Docker Stacks
 
-[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)]
-(<https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain> ""Docker images build status"")
+[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)
+](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain ""Docker images build status"")
 [![Read the Docs badge](https://img.shields.io/readthedocs/jupyter-docker-stacks.svg)](https://jupyter-docker-stacks.readthedocs.io/en/latest/ ""Documentation build status"")
 [![pre-commit.ci status](https://results.pre-commit.ci/badge/github/jupyter/docker-stacks/main.svg)](https://results.pre-commit.ci/latest/github/jupyter/docker-stacks/main ""pre-commit.ci build status"")
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")",Yes
.github/actions/create-dev-env/action.yml,.github/actions/create-dev-env/action.yml,2a6a10a7815ec48b138640e69a32778238448b9a,f1a18d515cb6a0e752cbfe603b1092cd61acac87,Simplify create-dev-env by using runner.arch (#2011),"diff --git a/.github/actions/create-dev-env/action.yml b/.github/actions/create-dev-env/action.yml
index cdf7130e..27746891 100644
--- a/.github/actions/create-dev-env/action.yml
+++ b/.github/actions/create-dev-env/action.yml
@@ -1,12 +1,6 @@
 name: Build environment
 description: Create build environment
 
-inputs:
-  platform:
-    description: Platform to be run on
-    required: true
-    type: string
-
 runs:
   using: composite
   steps:
@@ -17,7 +11,7 @@ runs:
       uses: actions/setup-python@v4
       with:
         python-version: 3.x
-      if: ${{ inputs.platform == 'x86_64' }}
+      if: ${{ runner.arch == 'X64' }}
 
     - name: Install Dev Dependencies 📦
       run: |","diff --git a/.github/actions/create-dev-env/action.yml b/.github/actions/create-dev-env/action.yml
index cdf7130e..27746891 100644
--- a/.github/actions/create-dev-env/action.yml
+++ b/.github/actions/create-dev-env/action.yml
@@ -1,12 +1,6 @@
 name: Build environment
 description: Create build environment
 
-inputs:
-  platform:
-    description: Platform to be run on
-    required: true
-    type: string
-
 runs:
   using: composite
   steps:
@@ -17,7 +11,7 @@ runs:
       uses: actions/setup-python@v4
       with:
         python-version: 3.x
-      if: ${{ inputs.platform == 'x86_64' }}
+      if: ${{ runner.arch == 'X64' }}
 
     - name: Install Dev Dependencies 📦
       run: |",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,2a6a10a7815ec48b138640e69a32778238448b9a,f1a18d515cb6a0e752cbfe603b1092cd61acac87,Simplify create-dev-env by using runner.arch (#2011),"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index e5709891..3e5fce2d 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -33,8 +33,6 @@ jobs:
         uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
-        with:
-          platform: ${{ inputs.platform }}
 
       # Self-hosted runners share a state (whole VM) between runs
       # Also, they might have running or stopped containers,","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index e5709891..3e5fce2d 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -33,8 +33,6 @@ jobs:
         uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
-        with:
-          platform: ${{ inputs.platform }}
 
       # Self-hosted runners share a state (whole VM) between runs
       # Also, they might have running or stopped containers,",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,2a6a10a7815ec48b138640e69a32778238448b9a,f1a18d515cb6a0e752cbfe603b1092cd61acac87,Simplify create-dev-env by using runner.arch (#2011),"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index acbeed79..1c45747d 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -25,8 +25,6 @@ jobs:
         uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
-        with:
-          platform: x86_64
 
       - name: Download x86_64 tags file 📥
         uses: actions/download-artifact@v3","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index acbeed79..1c45747d 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -25,8 +25,6 @@ jobs:
         uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
-        with:
-          platform: x86_64
 
       - name: Download x86_64 tags file 📥
         uses: actions/download-artifact@v3",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,2a6a10a7815ec48b138640e69a32778238448b9a,f1a18d515cb6a0e752cbfe603b1092cd61acac87,Simplify create-dev-env by using runner.arch (#2011),"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index dd209cc5..a41ac3a7 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -30,8 +30,6 @@ jobs:
         uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
-        with:
-          platform: x86_64
       - name: Load image to Docker 📥
         uses: ./.github/actions/load-image
         with:","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index dd209cc5..a41ac3a7 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -30,8 +30,6 @@ jobs:
         uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
-        with:
-          platform: x86_64
       - name: Load image to Docker 📥
         uses: ./.github/actions/load-image
         with:",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,2a6a10a7815ec48b138640e69a32778238448b9a,f1a18d515cb6a0e752cbfe603b1092cd61acac87,Simplify create-dev-env by using runner.arch (#2011),"diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 24d931ae..bf07a5b4 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -14,8 +14,6 @@ jobs:
         uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
-        with:
-          platform: x86_64
 
       - name: Download all manifests and history lines 📥
         uses: ./.github/actions/download-manifests","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 24d931ae..bf07a5b4 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -14,8 +14,6 @@ jobs:
         uses: actions/checkout@v4
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
-        with:
-          platform: x86_64
 
       - name: Download all manifests and history lines 📥
         uses: ./.github/actions/download-manifests",Yes
tagging/manifests.py,tagging/manifests.py,848a8267479239ab1b7e5b6d1e762d63e1b15da8,2a6a10a7815ec48b138640e69a32778238448b9a,Fix build manifest image size and improve name,"diff --git a/tagging/manifests.py b/tagging/manifests.py
index a83b20a6..12e98020 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -30,9 +30,12 @@ class ManifestHeader:
         commit_hash_tag = GitHelper.commit_hash_tag()
         commit_message = GitHelper.commit_message()
 
+        # Unfortunately, docker images doesn't work when specifying `docker.io` as registry
+        fixed_registry = registry + ""/"" if registry != ""docker.io"" else """"
+
         image_size = docker[
             ""images"",
-            f""{registry}/{owner}/{short_image_name}:latest"",
+            f""{fixed_registry}{owner}/{short_image_name}:latest"",
             ""--format"",
             ""{{.Size}}"",
         ]().rstrip()
@@ -44,7 +47,7 @@ class ManifestHeader:
                 ""## Build Info"",
                 """",
                 f""* Build datetime: {build_timestamp}"",
-                f""* Docker image: {registry}/{owner}/{short_image_name}:{commit_hash_tag}"",
+                f""* Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`"",
                 f""* Docker image size: {image_size}"",
                 f""* Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
                 ""* Git commit message:"",","diff --git a/tagging/manifests.py b/tagging/manifests.py
index a83b20a6..12e98020 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -30,9 +30,12 @@ class ManifestHeader:
         commit_hash_tag = GitHelper.commit_hash_tag()
         commit_message = GitHelper.commit_message()
 
+        # Unfortunately, docker images doesn't work when specifying `docker.io` as registry
+        fixed_registry = registry + ""/"" if registry != ""docker.io"" else """"
+
         image_size = docker[
             ""images"",
-            f""{registry}/{owner}/{short_image_name}:latest"",
+            f""{fixed_registry}{owner}/{short_image_name}:latest"",
             ""--format"",
             ""{{.Size}}"",
         ]().rstrip()
@@ -44,7 +47,7 @@ class ManifestHeader:
                 ""## Build Info"",
                 """",
                 f""* Build datetime: {build_timestamp}"",
-                f""* Docker image: {registry}/{owner}/{short_image_name}:{commit_hash_tag}"",
+                f""* Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`"",
                 f""* Docker image size: {image_size}"",
                 f""* Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
                 ""* Git commit message:"",",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,a55db53d96e54e9f6eeb7acfa8c138d0fbdf4021,848a8267479239ab1b7e5b6d1e762d63e1b15da8,Improve docs,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 9da623d8..d75c0303 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -136,8 +136,8 @@ to get a feel for what's possible and the best practices.
 
 [Submit pull requests](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)
 to your project repository on GitHub.
-Ensure your image builds correctly on GitHub actions before merging to the main branch.
-Refer to Docker Hub to build the main branch that you can `docker pull`.
+Ensure your image builds correctly on GitHub Actions before merging to the main branch.
+After merging to the main branch, your image will be built and pushed to the Docker Hub automatically.
 
 ## Sharing Your Image","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 9da623d8..d75c0303 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -136,8 +136,8 @@ to get a feel for what's possible and the best practices.
 
 [Submit pull requests](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)
 to your project repository on GitHub.
-Ensure your image builds correctly on GitHub actions before merging to the main branch.
-Refer to Docker Hub to build the main branch that you can `docker pull`.
+Ensure your image builds correctly on GitHub Actions before merging to the main branch.
+After merging to the main branch, your image will be built and pushed to the Docker Hub automatically.
 
 ## Sharing Your Image",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,7de6ac7b6818c8011a4cf3a97b3c2e1cc2ec11e3,a55db53d96e54e9f6eeb7acfa8c138d0fbdf4021,"Build all workflows in my fork (#2012)

* Build all workflows in my fork

* Build contributed recipes only in jupyter, because I don't have aarch64 runners","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 59938180..2f8eeb44 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -35,7 +35,7 @@ jobs:
   test-recipes:
     runs-on: ${{ matrix.runsOn }}
     needs: generate-matrix
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
     steps:
       - name: Checkout Repo ⚡️","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 59938180..2f8eeb44 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -35,7 +35,7 @@ jobs:
   test-recipes:
     runs-on: ${{ matrix.runsOn }}
     needs: generate-matrix
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
     steps:
       - name: Checkout Repo ⚡️",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,7de6ac7b6818c8011a4cf3a97b3c2e1cc2ec11e3,a55db53d96e54e9f6eeb7acfa8c138d0fbdf4021,"Build all workflows in my fork (#2012)

* Build all workflows in my fork

* Build contributed recipes only in jupyter, because I don't have aarch64 runners","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 1c45747d..96434848 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -2,6 +2,7 @@ name: Download images tags from GitHub artifacts and create multi-platform manif
 
 env:
   OWNER: ${{ github.repository_owner }}
+  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
 
 on:
   workflow_call:
@@ -47,13 +48,13 @@ jobs:
         shell: bash
 
       - name: Login to Registry 🔐
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           username: ${{ secrets.REGISTRY_USERNAME }}
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Merge tags for the images 🔀
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/
         shell: bash","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 1c45747d..96434848 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -2,6 +2,7 @@ name: Download images tags from GitHub artifacts and create multi-platform manif
 
 env:
   OWNER: ${{ github.repository_owner }}
+  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
 
 on:
   workflow_call:
@@ -47,13 +48,13 @@ jobs:
         shell: bash
 
       - name: Login to Registry 🔐
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           username: ${{ secrets.REGISTRY_USERNAME }}
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Merge tags for the images 🔀
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/
         shell: bash",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,7de6ac7b6818c8011a4cf3a97b3c2e1cc2ec11e3,a55db53d96e54e9f6eeb7acfa8c138d0fbdf4021,"Build all workflows in my fork (#2012)

* Build all workflows in my fork

* Build contributed recipes only in jupyter, because I don't have aarch64 runners","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index a41ac3a7..179dce1e 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -3,6 +3,7 @@ name: Download Docker image and its tags from GitHub artifacts, apply them and p
 env:
   REGISTRY: docker.io
   OWNER: ${{ github.repository_owner }}
+  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
 
 on:
   workflow_call:
@@ -37,7 +38,7 @@ jobs:
           platform: ${{ inputs.platform }}
 
       - name: Login to Registry 🔐
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           username: ${{ secrets.REGISTRY_USERNAME }}
@@ -52,6 +53,6 @@ jobs:
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
 
       - name: Push Images to Registry 📤
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         run: docker push --all-tags ${{ env.OWNER }}/${{ inputs.image }}
         shell: bash","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index a41ac3a7..179dce1e 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -3,6 +3,7 @@ name: Download Docker image and its tags from GitHub artifacts, apply them and p
 env:
   REGISTRY: docker.io
   OWNER: ${{ github.repository_owner }}
+  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
 
 on:
   workflow_call:
@@ -37,7 +38,7 @@ jobs:
           platform: ${{ inputs.platform }}
 
       - name: Login to Registry 🔐
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           username: ${{ secrets.REGISTRY_USERNAME }}
@@ -52,6 +53,6 @@ jobs:
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
 
       - name: Push Images to Registry 📤
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         run: docker push --all-tags ${{ env.OWNER }}/${{ inputs.image }}
         shell: bash",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,7de6ac7b6818c8011a4cf3a97b3c2e1cc2ec11e3,a55db53d96e54e9f6eeb7acfa8c138d0fbdf4021,"Build all workflows in my fork (#2012)

* Build all workflows in my fork

* Build contributed recipes only in jupyter, because I don't have aarch64 runners","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index bf07a5b4..4098747b 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -2,6 +2,9 @@ name: Download build manifests from GitHub artifacts and push them to GitHub wik
 # We're doing everything in one workflow on purpose
 # This way we make sure we don't access wiki pages from several jobs simultaneously
 
+env:
+  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+
 on:
   workflow_call:
 
@@ -37,7 +40,7 @@ jobs:
         shell: bash
 
       - name: Push Wiki to GitHub 📤
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         uses: stefanzweifel/git-auto-commit-action@8756aa072ef5b4a080af5dc8fef36c5d586e521d # v5.0.0
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index bf07a5b4..4098747b 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -2,6 +2,9 @@ name: Download build manifests from GitHub artifacts and push them to GitHub wik
 # We're doing everything in one workflow on purpose
 # This way we make sure we don't access wiki pages from several jobs simultaneously
 
+env:
+  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+
 on:
   workflow_call:
 
@@ -37,7 +40,7 @@ jobs:
         shell: bash
 
       - name: Push Wiki to GitHub 📤
-        if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+        if: env.PUSH_TO_REGISTRY
         uses: stefanzweifel/git-auto-commit-action@8756aa072ef5b4a080af5dc8fef36c5d586e521d # v5.0.0
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""",Yes
.github/workflows/registry-overviews.yml,.github/workflows/registry-overviews.yml,7de6ac7b6818c8011a4cf3a97b3c2e1cc2ec11e3,a55db53d96e54e9f6eeb7acfa8c138d0fbdf4021,"Build all workflows in my fork (#2012)

* Build all workflows in my fork

* Build contributed recipes only in jupyter, because I don't have aarch64 runners","diff --git a/.github/workflows/registry-overviews.yml b/.github/workflows/registry-overviews.yml
index b3d3a7f3..025d75ff 100644
--- a/.github/workflows/registry-overviews.yml
+++ b/.github/workflows/registry-overviews.yml
@@ -17,7 +17,7 @@ jobs:
   update-overview:
     runs-on: ubuntu-latest
     name: update-overview (${{matrix.image}})
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
 
     steps:
       - name: Checkout Repo ⚡️","diff --git a/.github/workflows/registry-overviews.yml b/.github/workflows/registry-overviews.yml
index b3d3a7f3..025d75ff 100644
--- a/.github/workflows/registry-overviews.yml
+++ b/.github/workflows/registry-overviews.yml
@@ -17,7 +17,7 @@ jobs:
   update-overview:
     runs-on: ubuntu-latest
     name: update-overview (${{matrix.image}})
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
 
     steps:
       - name: Checkout Repo ⚡️",Yes
.github/workflows/sphinx.yml,.github/workflows/sphinx.yml,7de6ac7b6818c8011a4cf3a97b3c2e1cc2ec11e3,a55db53d96e54e9f6eeb7acfa8c138d0fbdf4021,"Build all workflows in my fork (#2012)

* Build all workflows in my fork

* Build contributed recipes only in jupyter, because I don't have aarch64 runners","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index 78f1b950..fde0d4ea 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -26,7 +26,7 @@ jobs:
   build-docs:
     permissions:
       contents: write
-    if: github.repository == 'jupyter/docker-stacks' || github.event_name != 'schedule'
+    if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru' || github.event_name != 'schedule'
     runs-on: ubuntu-latest
 
     steps:","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index 78f1b950..fde0d4ea 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -26,7 +26,7 @@ jobs:
   build-docs:
     permissions:
       contents: write
-    if: github.repository == 'jupyter/docker-stacks' || github.event_name != 'schedule'
+    if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru' || github.event_name != 'schedule'
     runs-on: ubuntu-latest
 
     steps:",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,5a9ef502d4132c2b4ef9ecbccdee6ab77e0e620e,7de6ac7b6818c8011a4cf3a97b3c2e1cc2ec11e3,Use github.repository_owner where possible,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 17a60bef..885b0864 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -62,7 +62,7 @@ jobs:
       image: docker-stacks-foundation
       platform: aarch64
       runsOn: ARM64
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-foundation:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -80,7 +80,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-foundation]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-base:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -99,7 +99,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-base]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-minimal:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -118,7 +118,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -137,7 +137,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -156,7 +156,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -193,7 +193,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -212,7 +212,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -231,7 +231,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-pyspark]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -278,7 +278,7 @@ jobs:
         aarch64-pyspark,
         aarch64-all-spark,
       ]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-images-tag-push:
     uses: ./.github/workflows/docker-tag-push.yml
@@ -340,16 +340,16 @@ jobs:
             all-spark-notebook,
           ]
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   wiki-update:
     uses: ./.github/workflows/docker-wiki-update.yml
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
     permissions:
       contents: write
 
   contributed-recipes:
     uses: ./.github/workflows/contributed-recipes.yml
     needs: [merge-tags]
-    if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+    if: github.repository_owner == 'jupyter' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 17a60bef..885b0864 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -62,7 +62,7 @@ jobs:
       image: docker-stacks-foundation
       platform: aarch64
       runsOn: ARM64
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-foundation:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -80,7 +80,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-foundation]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-base:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -99,7 +99,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-base]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-minimal:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -118,7 +118,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -137,7 +137,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -156,7 +156,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -193,7 +193,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -212,7 +212,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -231,7 +231,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-pyspark]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -278,7 +278,7 @@ jobs:
         aarch64-pyspark,
         aarch64-all-spark,
       ]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   x86_64-images-tag-push:
     uses: ./.github/workflows/docker-tag-push.yml
@@ -340,16 +340,16 @@ jobs:
             all-spark-notebook,
           ]
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
 
   wiki-update:
     uses: ./.github/workflows/docker-wiki-update.yml
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository == 'jupyter/docker-stacks'
+    if: github.repository_owner == 'jupyter'
     permissions:
       contents: write
 
   contributed-recipes:
     uses: ./.github/workflows/contributed-recipes.yml
     needs: [merge-tags]
-    if: github.repository == 'jupyter/docker-stacks' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+    if: github.repository_owner == 'jupyter' && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,7cce21edff8298c4662ec9d707ca89ff230bbb07,5a9ef502d4132c2b4ef9ecbccdee6ab77e0e620e,Add registry to `docker push` commands,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 179dce1e..92cb3cdd 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -54,5 +54,5 @@ jobs:
 
       - name: Push Images to Registry 📤
         if: env.PUSH_TO_REGISTRY
-        run: docker push --all-tags ${{ env.OWNER }}/${{ inputs.image }}
+        run: docker push --all-tags ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}
         shell: bash","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 179dce1e..92cb3cdd 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -54,5 +54,5 @@ jobs:
 
       - name: Push Images to Registry 📤
         if: env.PUSH_TO_REGISTRY
-        run: docker push --all-tags ${{ env.OWNER }}/${{ inputs.image }}
+        run: docker push --all-tags ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}
         shell: bash",Yes
Makefile,Makefile,7cce21edff8298c4662ec9d707ca89ff230bbb07,5a9ef502d4132c2b4ef9ecbccdee6ab77e0e620e,Add registry to `docker push` commands,"diff --git a/Makefile b/Makefile
index 093102d3..319ab440 100644
--- a/Makefile
+++ b/Makefile
@@ -93,7 +93,7 @@ pull/%: ## pull a jupyter image
 	docker pull ""$(OWNER)/$(notdir $@)""
 pull-all: $(foreach I, $(ALL_IMAGES), pull/$(I)) ## pull all images
 push/%: ## push all tags for a jupyter image
-	docker push --all-tags ""$(OWNER)/$(notdir $@)""
+	docker push --all-tags ""$(REGISTRY)/$(OWNER)/$(notdir $@)""
 push-all: $(foreach I, $(ALL_IMAGES), push/$(I)) ## push all tagged images","diff --git a/Makefile b/Makefile
index 093102d3..319ab440 100644
--- a/Makefile
+++ b/Makefile
@@ -93,7 +93,7 @@ pull/%: ## pull a jupyter image
 	docker pull ""$(OWNER)/$(notdir $@)""
 pull-all: $(foreach I, $(ALL_IMAGES), pull/$(I)) ## pull all images
 push/%: ## push all tags for a jupyter image
-	docker push --all-tags ""$(OWNER)/$(notdir $@)""
+	docker push --all-tags ""$(REGISTRY)/$(OWNER)/$(notdir $@)""
 push-all: $(foreach I, $(ALL_IMAGES), push/$(I)) ## push all tagged images",Yes
Makefile,Makefile,e4e2f6ad6051202e822f52f712a6c5d01d97d3d8,7cce21edff8298c4662ec9d707ca89ff230bbb07,Fix Makefile when using registry,"diff --git a/Makefile b/Makefile
index 319ab440..9d4ab710 100644
--- a/Makefile
+++ b/Makefile
@@ -4,7 +4,7 @@
 
 # Use bash for inline if-statements in arch_patch target
 SHELL:=bash
-REGISTRY?=docker.io
+REGISTRY?=quay.io
 OWNER?=jupyter
 
 # Need to list the images in build dependency order
@@ -46,7 +46,7 @@ build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks
 
 
 check-outdated/%: ## check the outdated mamba/conda packages in a stack and produce a report
-	@TEST_IMAGE=""$(OWNER)/$(notdir $@)"" pytest tests/docker-stacks-foundation/test_outdated.py
+	@TEST_IMAGE=""$(REGISTRY)/$(OWNER)/$(notdir $@)"" pytest tests/docker-stacks-foundation/test_outdated.py
 check-outdated-all: $(foreach I, $(ALL_IMAGES), check-outdated/$(I)) ## check all the stacks for outdated packages
 
 
@@ -80,9 +80,11 @@ img-clean: img-rm-dang img-rm ## clean dangling and jupyter images
 img-list: ## list jupyter images
 	@echo ""Listing $(OWNER) images ...""
 	docker images ""$(OWNER)/*""
+	docker images ""*/$(OWNER)/*""
 img-rm: ## remove jupyter images
 	@echo ""Removing $(OWNER) images ...""
 	-docker rmi --force $(shell docker images --quiet ""$(OWNER)/*"") 2> /dev/null
+	-docker rmi --force $(shell docker images --quiet ""*/$(OWNER)/*"") 2> /dev/null
 img-rm-dang: ## remove dangling images (tagged None)
 	@echo ""Removing dangling images ...""
 	-docker rmi --force $(shell docker images -f ""dangling=true"" --quiet) 2> /dev/null
@@ -90,7 +92,7 @@ img-rm-dang: ## remove dangling images (tagged None)
 
 
 pull/%: ## pull a jupyter image
-	docker pull ""$(OWNER)/$(notdir $@)""
+	docker pull ""$(REGISTRY)/$(OWNER)/$(notdir $@)""
 pull-all: $(foreach I, $(ALL_IMAGES), pull/$(I)) ## pull all images
 push/%: ## push all tags for a jupyter image
 	docker push --all-tags ""$(REGISTRY)/$(OWNER)/$(notdir $@)""","diff --git a/Makefile b/Makefile
index 319ab440..9d4ab710 100644
--- a/Makefile
+++ b/Makefile
@@ -4,7 +4,7 @@
 
 # Use bash for inline if-statements in arch_patch target
 SHELL:=bash
-REGISTRY?=docker.io
+REGISTRY?=quay.io
 OWNER?=jupyter
 
 # Need to list the images in build dependency order
@@ -46,7 +46,7 @@ build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks
 
 
 check-outdated/%: ## check the outdated mamba/conda packages in a stack and produce a report
-	@TEST_IMAGE=""$(OWNER)/$(notdir $@)"" pytest tests/docker-stacks-foundation/test_outdated.py
+	@TEST_IMAGE=""$(REGISTRY)/$(OWNER)/$(notdir $@)"" pytest tests/docker-stacks-foundation/test_outdated.py
 check-outdated-all: $(foreach I, $(ALL_IMAGES), check-outdated/$(I)) ## check all the stacks for outdated packages
 
 
@@ -80,9 +80,11 @@ img-clean: img-rm-dang img-rm ## clean dangling and jupyter images
 img-list: ## list jupyter images
 	@echo ""Listing $(OWNER) images ...""
 	docker images ""$(OWNER)/*""
+	docker images ""*/$(OWNER)/*""
 img-rm: ## remove jupyter images
 	@echo ""Removing $(OWNER) images ...""
 	-docker rmi --force $(shell docker images --quiet ""$(OWNER)/*"") 2> /dev/null
+	-docker rmi --force $(shell docker images --quiet ""*/$(OWNER)/*"") 2> /dev/null
 img-rm-dang: ## remove dangling images (tagged None)
 	@echo ""Removing dangling images ...""
 	-docker rmi --force $(shell docker images -f ""dangling=true"" --quiet) 2> /dev/null
@@ -90,7 +92,7 @@ img-rm-dang: ## remove dangling images (tagged None)
 
 
 pull/%: ## pull a jupyter image
-	docker pull ""$(OWNER)/$(notdir $@)""
+	docker pull ""$(REGISTRY)/$(OWNER)/$(notdir $@)""
 pull-all: $(foreach I, $(ALL_IMAGES), pull/$(I)) ## pull all images
 push/%: ## push all tags for a jupyter image
 	docker push --all-tags ""$(REGISTRY)/$(OWNER)/$(notdir $@)""",Yes
Makefile,Makefile,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,e4e2f6ad6051202e822f52f712a6c5d01d97d3d8,Fix Makefile,"diff --git a/Makefile b/Makefile
index 9d4ab710..44bb3e13 100644
--- a/Makefile
+++ b/Makefile
@@ -4,7 +4,7 @@
 
 # Use bash for inline if-statements in arch_patch target
 SHELL:=bash
-REGISTRY?=quay.io
+REGISTRY?=docker.io
 OWNER?=jupyter
 
 # Need to list the images in build dependency order","diff --git a/Makefile b/Makefile
index 9d4ab710..44bb3e13 100644
--- a/Makefile
+++ b/Makefile
@@ -4,7 +4,7 @@
 
 # Use bash for inline if-statements in arch_patch target
 SHELL:=bash
-REGISTRY?=quay.io
+REGISTRY?=docker.io
 OWNER?=jupyter
 
 # Need to list the images in build dependency order",Yes
images/all-spark-notebook/README.md,images/all-spark-notebook/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/all-spark-notebook/README.md b/images/all-spark-notebook/README.md
index 9d208f93..1619e779 100644
--- a/images/all-spark-notebook/README.md
+++ b/images/all-spark-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Python, R, Spark Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/all-spark-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/all-spark-notebook/latest)](https://hub.docker.com/r/jupyter/all-spark-notebook/ ""jupyter/all-spark-notebook image size"")","diff --git a/images/all-spark-notebook/README.md b/images/all-spark-notebook/README.md
index 9d208f93..1619e779 100644
--- a/images/all-spark-notebook/README.md
+++ b/images/all-spark-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Python, R, Spark Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/all-spark-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/all-spark-notebook.svg)](https://hub.docker.com/r/jupyter/all-spark-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/all-spark-notebook/latest)](https://hub.docker.com/r/jupyter/all-spark-notebook/ ""jupyter/all-spark-notebook image size"")",Yes
images/base-notebook/README.md,images/base-notebook/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/base-notebook/README.md b/images/base-notebook/README.md
index 1638d7cf..67135996 100644
--- a/images/base-notebook/README.md
+++ b/images/base-notebook/README.md
@@ -1,5 +1,7 @@
 # Base Jupyter Notebook Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/base-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/base-notebook/latest)](https://hub.docker.com/r/jupyter/base-notebook/ ""jupyter/base-notebook image size"")","diff --git a/images/base-notebook/README.md b/images/base-notebook/README.md
index 1638d7cf..67135996 100644
--- a/images/base-notebook/README.md
+++ b/images/base-notebook/README.md
@@ -1,5 +1,7 @@
 # Base Jupyter Notebook Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/base-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/base-notebook.svg)](https://hub.docker.com/r/jupyter/base-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/base-notebook/latest)](https://hub.docker.com/r/jupyter/base-notebook/ ""jupyter/base-notebook image size"")",Yes
images/datascience-notebook/README.md,images/datascience-notebook/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/datascience-notebook/README.md b/images/datascience-notebook/README.md
index f3201761..42f1e047 100644
--- a/images/datascience-notebook/README.md
+++ b/images/datascience-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Data Science Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/datascience-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/datascience-notebook/latest)](https://hub.docker.com/r/jupyter/datascience-notebook/ ""jupyter/datascience-notebook image size"")","diff --git a/images/datascience-notebook/README.md b/images/datascience-notebook/README.md
index f3201761..42f1e047 100644
--- a/images/datascience-notebook/README.md
+++ b/images/datascience-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Data Science Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/datascience-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/datascience-notebook.svg)](https://hub.docker.com/r/jupyter/datascience-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/datascience-notebook/latest)](https://hub.docker.com/r/jupyter/datascience-notebook/ ""jupyter/datascience-notebook image size"")",Yes
images/docker-stacks-foundation/README.md,images/docker-stacks-foundation/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/docker-stacks-foundation/README.md b/images/docker-stacks-foundation/README.md
index 449fe058..66657521 100644
--- a/images/docker-stacks-foundation/README.md
+++ b/images/docker-stacks-foundation/README.md
@@ -1,5 +1,7 @@
 # Foundation Jupyter Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/docker-stacks-foundation)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/docker-stacks-foundation/latest)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/ ""jupyter/docker-stacks-foundation image size"")","diff --git a/images/docker-stacks-foundation/README.md b/images/docker-stacks-foundation/README.md
index 449fe058..66657521 100644
--- a/images/docker-stacks-foundation/README.md
+++ b/images/docker-stacks-foundation/README.md
@@ -1,5 +1,7 @@
 # Foundation Jupyter Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/docker-stacks-foundation)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/docker-stacks-foundation.svg)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/docker-stacks-foundation/latest)](https://hub.docker.com/r/jupyter/docker-stacks-foundation/ ""jupyter/docker-stacks-foundation image size"")",Yes
images/julia-notebook/README.md,images/julia-notebook/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/julia-notebook/README.md b/images/julia-notebook/README.md
index fc611b37..46720670 100644
--- a/images/julia-notebook/README.md
+++ b/images/julia-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Julia Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/julia-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/julia-notebook/latest)](https://hub.docker.com/r/jupyter/julia-notebook/ ""jupyter/julia-notebook image size"")","diff --git a/images/julia-notebook/README.md b/images/julia-notebook/README.md
index fc611b37..46720670 100644
--- a/images/julia-notebook/README.md
+++ b/images/julia-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Julia Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/julia-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/julia-notebook.svg)](https://hub.docker.com/r/jupyter/julia-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/julia-notebook/latest)](https://hub.docker.com/r/jupyter/julia-notebook/ ""jupyter/julia-notebook image size"")",Yes
images/minimal-notebook/README.md,images/minimal-notebook/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/minimal-notebook/README.md b/images/minimal-notebook/README.md
index fbedc520..0d0f44f6 100644
--- a/images/minimal-notebook/README.md
+++ b/images/minimal-notebook/README.md
@@ -1,5 +1,7 @@
 # Minimal Jupyter Notebook Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/minimal-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/minimal-notebook/latest)](https://hub.docker.com/r/jupyter/minimal-notebook/ ""jupyter/minimal-notebook image size"")","diff --git a/images/minimal-notebook/README.md b/images/minimal-notebook/README.md
index fbedc520..0d0f44f6 100644
--- a/images/minimal-notebook/README.md
+++ b/images/minimal-notebook/README.md
@@ -1,5 +1,7 @@
 # Minimal Jupyter Notebook Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/minimal-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/minimal-notebook.svg)](https://hub.docker.com/r/jupyter/minimal-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/minimal-notebook/latest)](https://hub.docker.com/r/jupyter/minimal-notebook/ ""jupyter/minimal-notebook image size"")",Yes
images/pyspark-notebook/README.md,images/pyspark-notebook/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/pyspark-notebook/README.md b/images/pyspark-notebook/README.md
index d88bc815..c1c5e9aa 100644
--- a/images/pyspark-notebook/README.md
+++ b/images/pyspark-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Python, Spark Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/pyspark-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/pyspark-notebook/latest)](https://hub.docker.com/r/jupyter/pyspark-notebook/ ""jupyter/pyspark-notebook image size"")","diff --git a/images/pyspark-notebook/README.md b/images/pyspark-notebook/README.md
index d88bc815..c1c5e9aa 100644
--- a/images/pyspark-notebook/README.md
+++ b/images/pyspark-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Python, Spark Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/pyspark-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/pyspark-notebook.svg)](https://hub.docker.com/r/jupyter/pyspark-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/pyspark-notebook/latest)](https://hub.docker.com/r/jupyter/pyspark-notebook/ ""jupyter/pyspark-notebook image size"")",Yes
images/r-notebook/README.md,images/r-notebook/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
index bfc6fb1e..4d5fc894 100644
--- a/images/r-notebook/README.md
+++ b/images/r-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook R Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/r-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/r-notebook/latest)](https://hub.docker.com/r/jupyter/r-notebook/ ""jupyter/r-notebook image size"")","diff --git a/images/r-notebook/README.md b/images/r-notebook/README.md
index bfc6fb1e..4d5fc894 100644
--- a/images/r-notebook/README.md
+++ b/images/r-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook R Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/r-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/r-notebook.svg)](https://hub.docker.com/r/jupyter/r-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/r-notebook/latest)](https://hub.docker.com/r/jupyter/r-notebook/ ""jupyter/r-notebook image size"")",Yes
images/scipy-notebook/README.md,images/scipy-notebook/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/scipy-notebook/README.md b/images/scipy-notebook/README.md
index 33330c0b..68d56ec9 100644
--- a/images/scipy-notebook/README.md
+++ b/images/scipy-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Scientific Python Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/scipy-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/scipy-notebook/latest)](https://hub.docker.com/r/jupyter/scipy-notebook/ ""jupyter/scipy-notebook image size"")","diff --git a/images/scipy-notebook/README.md b/images/scipy-notebook/README.md
index 33330c0b..68d56ec9 100644
--- a/images/scipy-notebook/README.md
+++ b/images/scipy-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Scientific Python Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/scipy-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/scipy-notebook.svg)](https://hub.docker.com/r/jupyter/scipy-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/scipy-notebook/latest)](https://hub.docker.com/r/jupyter/scipy-notebook/ ""jupyter/scipy-notebook image size"")",Yes
images/tensorflow-notebook/README.md,images/tensorflow-notebook/README.md,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,fe7dbdd1a23461eb9e9ef73f8cc43d5d7d969b3d,Add DockerHub warning (#2009),"diff --git a/images/tensorflow-notebook/README.md b/images/tensorflow-notebook/README.md
index 58c2a5fe..41e7e2b2 100644
--- a/images/tensorflow-notebook/README.md
+++ b/images/tensorflow-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Deep Learning Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/tensorflow-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/tensorflow-notebook/latest)](https://hub.docker.com/r/jupyter/tensorflow-notebook/ ""jupyter/tensorflow-notebook image size"")","diff --git a/images/tensorflow-notebook/README.md b/images/tensorflow-notebook/README.md
index 58c2a5fe..41e7e2b2 100644
--- a/images/tensorflow-notebook/README.md
+++ b/images/tensorflow-notebook/README.md
@@ -1,5 +1,7 @@
 # Jupyter Notebook Deep Learning Stack
 
+> **Images hosted on Docker Hub are no longer updated. Please, use [quay.io image](https://quay.io/repository/jupyter/tensorflow-notebook)**
+
 [![docker pulls](https://img.shields.io/docker/pulls/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
 [![docker stars](https://img.shields.io/docker/stars/jupyter/tensorflow-notebook.svg)](https://hub.docker.com/r/jupyter/tensorflow-notebook/)
 [![image size](https://img.shields.io/docker/image-size/jupyter/tensorflow-notebook/latest)](https://hub.docker.com/r/jupyter/tensorflow-notebook/ ""jupyter/tensorflow-notebook image size"")",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index a0cd7c99..af7aa187 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -57,7 +57,7 @@ body:
         What complete docker command do you run to launch the container (omitting sensitive values)?
       placeholder: |
         Example:
-        `docker run -it --rm -p 8888:8888 docker.io/jupyter/base-notebook`
+        `docker run -it --rm -p 8888:8888 quay.io/jupyter/base-notebook`
     validations:
       required: true","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index a0cd7c99..af7aa187 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -57,7 +57,7 @@ body:
         What complete docker command do you run to launch the container (omitting sensitive values)?
       placeholder: |
         Example:
-        `docker run -it --rm -p 8888:8888 docker.io/jupyter/base-notebook`
+        `docker run -it --rm -p 8888:8888 quay.io/jupyter/base-notebook`
     validations:
       required: true",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 3e5fce2d..f06889d1 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -1,7 +1,7 @@
 name: Download parent image, build a new one and test it; then upload the image, tags and manifests to GitHub artifacts
 
 env:
-  REGISTRY: docker.io
+  REGISTRY: quay.io
   OWNER: ${{ github.repository_owner }}
 
 on:","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 3e5fce2d..f06889d1 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -1,7 +1,7 @@
 name: Download parent image, build a new one and test it; then upload the image, tags and manifests to GitHub artifacts
 
 env:
-  REGISTRY: docker.io
+  REGISTRY: quay.io
   OWNER: ${{ github.repository_owner }}
 
 on:",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 96434848..f8e3d999 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -51,6 +51,7 @@ jobs:
         if: env.PUSH_TO_REGISTRY
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
+          registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}
           password: ${{ secrets.REGISTRY_TOKEN }}","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 96434848..f8e3d999 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -51,6 +51,7 @@ jobs:
         if: env.PUSH_TO_REGISTRY
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
+          registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}
           password: ${{ secrets.REGISTRY_TOKEN }}",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 92cb3cdd..b131144a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,7 +1,7 @@
 name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
 
 env:
-  REGISTRY: docker.io
+  REGISTRY: quay.io
   OWNER: ${{ github.repository_owner }}
   PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
 
@@ -41,6 +41,7 @@ jobs:
         if: env.PUSH_TO_REGISTRY
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
+          registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}
           password: ${{ secrets.REGISTRY_TOKEN }}","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 92cb3cdd..b131144a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,7 +1,7 @@
 name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
 
 env:
-  REGISTRY: docker.io
+  REGISTRY: quay.io
   OWNER: ${{ github.repository_owner }}
   PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
 
@@ -41,6 +41,7 @@ jobs:
         if: env.PUSH_TO_REGISTRY
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
+          registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}
           password: ${{ secrets.REGISTRY_TOKEN }}",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 885b0864..97b67769 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -248,8 +248,8 @@ jobs:
       platform: aarch64
       image: ${{ matrix.image }}
     secrets:
-      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
         image:
@@ -286,8 +286,8 @@ jobs:
       platform: x86_64
       image: ${{ matrix.image }}
     secrets:
-      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
         image:
@@ -322,8 +322,8 @@ jobs:
     with:
       image: ${{ matrix.image }}
     secrets:
-      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
         image:","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 885b0864..97b67769 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -248,8 +248,8 @@ jobs:
       platform: aarch64
       image: ${{ matrix.image }}
     secrets:
-      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
         image:
@@ -286,8 +286,8 @@ jobs:
       platform: x86_64
       image: ${{ matrix.image }}
     secrets:
-      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
         image:
@@ -322,8 +322,8 @@ jobs:
     with:
       image: ${{ matrix.image }}
     secrets:
-      REGISTRY_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
-      REGISTRY_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
         image:",Yes
.github/workflows/registry-overviews.yml,.github/workflows/registry-overviews.yml,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/.github/workflows/registry-overviews.yml b/.github/workflows/registry-overviews.yml
index 025d75ff..f4914300 100644
--- a/.github/workflows/registry-overviews.yml
+++ b/.github/workflows/registry-overviews.yml
@@ -16,7 +16,6 @@ on:
 jobs:
   update-overview:
     runs-on: ubuntu-latest
-    name: update-overview (${{matrix.image}})
     if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
 
     steps:
@@ -26,34 +25,24 @@ jobs:
       - name: Push README to Registry 🐳
         uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1
         env:
-          DOCKER_USER: ${{ secrets.DOCKERHUB_USERNAME }}
-          DOCKER_PASS: ${{ secrets.DOCKERHUB_TOKEN }}
+          DOCKER_APIKEY: ${{ secrets.APIKEY__QUAY_IO }}
         with:
-          destination_container_repo: ${{ env.OWNER }}/${{ matrix.image }}
-          provider: dockerhub
-          short_description: ${{ matrix.description }}
+          destination_container_repo: quay.io/${{ env.OWNER }}/${{ matrix.image }}
+          provider: quay
           readme_file: images/${{ matrix.image }}/README.md
 
     strategy:
       matrix:
-        include:
-          - image: docker-stacks-foundation
-            description: ""Tiny base image on which Jupyter apps can be built from https://github.com/jupyter/docker-stacks""
-          - image: base-notebook
-            description: ""Base image for Jupyter Notebook stacks from https://github.com/jupyter/docker-stacks""
-          - image: minimal-notebook
-            description: ""Minimal Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: scipy-notebook
-            description: ""Scientific Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: r-notebook
-            description: ""R Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: julia-notebook
-            description: ""Julia Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: tensorflow-notebook
-            description: ""Scientific Jupyter Notebook Python Stack w/ TensorFlow from https://github.com/jupyter/docker-stacks""
-          - image: datascience-notebook
-            description: ""Data Science Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: pyspark-notebook
-            description: ""Python and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: all-spark-notebook
-            description: ""Python, Scala, R and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
+        image:
+          [
+            docker-stacks-foundation,
+            base-notebook,
+            minimal-notebook,
+            scipy-notebook,
+            r-notebook,
+            julia-notebook,
+            tensorflow-notebook,
+            datascience-notebook,
+            pyspark-notebook,
+            all-spark-notebook,
+          ]","diff --git a/.github/workflows/registry-overviews.yml b/.github/workflows/registry-overviews.yml
index 025d75ff..f4914300 100644
--- a/.github/workflows/registry-overviews.yml
+++ b/.github/workflows/registry-overviews.yml
@@ -16,7 +16,6 @@ on:
 jobs:
   update-overview:
     runs-on: ubuntu-latest
-    name: update-overview (${{matrix.image}})
     if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
 
     steps:
@@ -26,34 +25,24 @@ jobs:
       - name: Push README to Registry 🐳
         uses: christian-korneck/update-container-description-action@d36005551adeaba9698d8d67a296bd16fa91f8e8 # v1
         env:
-          DOCKER_USER: ${{ secrets.DOCKERHUB_USERNAME }}
-          DOCKER_PASS: ${{ secrets.DOCKERHUB_TOKEN }}
+          DOCKER_APIKEY: ${{ secrets.APIKEY__QUAY_IO }}
         with:
-          destination_container_repo: ${{ env.OWNER }}/${{ matrix.image }}
-          provider: dockerhub
-          short_description: ${{ matrix.description }}
+          destination_container_repo: quay.io/${{ env.OWNER }}/${{ matrix.image }}
+          provider: quay
           readme_file: images/${{ matrix.image }}/README.md
 
     strategy:
       matrix:
-        include:
-          - image: docker-stacks-foundation
-            description: ""Tiny base image on which Jupyter apps can be built from https://github.com/jupyter/docker-stacks""
-          - image: base-notebook
-            description: ""Base image for Jupyter Notebook stacks from https://github.com/jupyter/docker-stacks""
-          - image: minimal-notebook
-            description: ""Minimal Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: scipy-notebook
-            description: ""Scientific Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: r-notebook
-            description: ""R Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: julia-notebook
-            description: ""Julia Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: tensorflow-notebook
-            description: ""Scientific Jupyter Notebook Python Stack w/ TensorFlow from https://github.com/jupyter/docker-stacks""
-          - image: datascience-notebook
-            description: ""Data Science Jupyter Notebook Python Stack from https://github.com/jupyter/docker-stacks""
-          - image: pyspark-notebook
-            description: ""Python and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
-          - image: all-spark-notebook
-            description: ""Python, Scala, R and Spark Jupyter Notebook Stack from https://github.com/jupyter/docker-stacks""
+        image:
+          [
+            docker-stacks-foundation,
+            base-notebook,
+            minimal-notebook,
+            scipy-notebook,
+            r-notebook,
+            julia-notebook,
+            tensorflow-notebook,
+            datascience-notebook,
+            pyspark-notebook,
+            all-spark-notebook,
+          ]",Yes
Makefile,Makefile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/Makefile b/Makefile
index 44bb3e13..9d4ab710 100644
--- a/Makefile
+++ b/Makefile
@@ -4,7 +4,7 @@
 
 # Use bash for inline if-statements in arch_patch target
 SHELL:=bash
-REGISTRY?=docker.io
+REGISTRY?=quay.io
 OWNER?=jupyter
 
 # Need to list the images in build dependency order","diff --git a/Makefile b/Makefile
index 44bb3e13..9d4ab710 100644
--- a/Makefile
+++ b/Makefile
@@ -4,7 +4,7 @@
 
 # Use bash for inline if-statements in arch_patch target
 SHELL:=bash
-REGISTRY?=docker.io
+REGISTRY?=quay.io
 OWNER?=jupyter
 
 # Need to list the images in build dependency order",Yes
README.md,README.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/README.md b/README.md
index afae154d..2330076b 100644
--- a/README.md
+++ b/README.md
@@ -7,7 +7,7 @@
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")
 [![Binder badge](https://static.mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb ""Launch a jupyter/base-notebook container on mybinder.org"")
 
-Jupyter Docker Stacks are a set of ready-to-run [Docker images](https://hub.docker.com/u/jupyter) containing Jupyter applications and interactive computing tools.
+Jupyter Docker Stacks are a set of ready-to-run [Docker images](https://quay.io/organization/jupyter) containing Jupyter applications and interactive computing tools.
 You can use a stack image to do any of the following (and more):
 
 - Start a personal Jupyter Server with the JupyterLab frontend (default)
@@ -27,11 +27,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 docker.io/jupyter/scipy-notebook:2023-09-25
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-09-25
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -46,11 +46,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work docker.io/jupyter/datascience-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-09-25
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -113,7 +113,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - [Issue Tracker on GitHub](https://github.com/jupyter/docker-stacks/issues)
 - [Jupyter Discourse Forum](https://discourse.jupyter.org/)
 - [Jupyter Website](https://jupyter.org)
-- [Images on Docker Hub](https://hub.docker.com/u/jupyter)
+- [Images on Quay.io](https://quay.io/organization/jupyter)
 
 ## CPU Architectures","diff --git a/README.md b/README.md
index afae154d..2330076b 100644
--- a/README.md
+++ b/README.md
@@ -7,7 +7,7 @@
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")
 [![Binder badge](https://static.mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb ""Launch a jupyter/base-notebook container on mybinder.org"")
 
-Jupyter Docker Stacks are a set of ready-to-run [Docker images](https://hub.docker.com/u/jupyter) containing Jupyter applications and interactive computing tools.
+Jupyter Docker Stacks are a set of ready-to-run [Docker images](https://quay.io/organization/jupyter) containing Jupyter applications and interactive computing tools.
 You can use a stack image to do any of the following (and more):
 
 - Start a personal Jupyter Server with the JupyterLab frontend (default)
@@ -27,11 +27,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 docker.io/jupyter/scipy-notebook:2023-09-25
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-09-25
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -46,11 +46,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work docker.io/jupyter/datascience-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-09-25
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -113,7 +113,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - [Issue Tracker on GitHub](https://github.com/jupyter/docker-stacks/issues)
 - [Jupyter Discourse Forum](https://discourse.jupyter.org/)
 - [Jupyter Website](https://jupyter.org)
-- [Images on Docker Hub](https://hub.docker.com/u/jupyter)
+- [Images on Quay.io](https://quay.io/organization/jupyter)
 
 ## CPU Architectures",Yes
binder/Dockerfile,binder/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/binder/Dockerfile b/binder/Dockerfile
index ef8d005d..9c2a7616 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -1,8 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 
-# https://hub.docker.com/r/jupyter/base-notebook/tags
-ARG REGISTRY=docker.io
+# https://quay.io/repository/jupyter/base-notebook?tab=tags
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-09-25
 FROM $BASE_CONTAINER","diff --git a/binder/Dockerfile b/binder/Dockerfile
index ef8d005d..9c2a7616 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -1,8 +1,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 
-# https://hub.docker.com/r/jupyter/base-notebook/tags
-ARG REGISTRY=docker.io
+# https://quay.io/repository/jupyter/base-notebook?tab=tags
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-09-25
 FROM $BASE_CONTAINER",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index d75c0303..422a5d2a 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -8,7 +8,7 @@ Following these steps will:
 
 1. Set up a project on GitHub containing a Dockerfile based on any image we provide.
 2. Configure GitHub Actions to build and test your image when users submit pull requests to your repository.
-3. Configure Docker Hub to host your images for others to use.
+3. Configure Quay.io to host your images for others to use.
 4. Update the [list of community stacks](../using/selecting.md#community-stacks) in this documentation to include your image.
 
 This approach mirrors how we build and share the core stack images.
@@ -35,8 +35,8 @@ This will serve as both the git repository name and the part of the Docker image
 stack_name [my-jupyter-stack]:
 ```
 
-Enter the user or organization name under which this stack will reside on Docker Hub.
-You must have access to manage this Docker Hub organization to push images here.
+Enter the user or organization name under which this stack will reside on Quay.io.
+You must have access to manage this Quay.io organization to push images here.
 
 ```text
 stack_org [my-project]:
@@ -89,6 +89,10 @@ git push -u origin main
 
 ## Configuring Docker Hub
 
+```{note}
+Jupyter Docker Stacks are hosted on Quay.io, but in this example, we show you how to host your image on Docker Hub.
+```
+
 Now, configure Docker Hub to build your stack image and push it to the Docker Hub repository whenever
 you merge a GitHub pull request to the main branch of your project.","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index d75c0303..422a5d2a 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -8,7 +8,7 @@ Following these steps will:
 
 1. Set up a project on GitHub containing a Dockerfile based on any image we provide.
 2. Configure GitHub Actions to build and test your image when users submit pull requests to your repository.
-3. Configure Docker Hub to host your images for others to use.
+3. Configure Quay.io to host your images for others to use.
 4. Update the [list of community stacks](../using/selecting.md#community-stacks) in this documentation to include your image.
 
 This approach mirrors how we build and share the core stack images.
@@ -35,8 +35,8 @@ This will serve as both the git repository name and the part of the Docker image
 stack_name [my-jupyter-stack]:
 ```
 
-Enter the user or organization name under which this stack will reside on Docker Hub.
-You must have access to manage this Docker Hub organization to push images here.
+Enter the user or organization name under which this stack will reside on Quay.io.
+You must have access to manage this Quay.io organization to push images here.
 
 ```text
 stack_org [my-project]:
@@ -89,6 +89,10 @@ git push -u origin main
 
 ## Configuring Docker Hub
 
+```{note}
+Jupyter Docker Stacks are hosted on Quay.io, but in this example, we show you how to host your image on Docker Hub.
+```
+
 Now, configure Docker Hub to build your stack image and push it to the Docker Hub repository whenever
 you merge a GitHub pull request to the main branch of your project.",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 6a962521..4bc1fc0d 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -56,7 +56,7 @@ When there's a new stack definition, check before merging the PR:
 
 ## Adding a New Maintainer Account
 
-1. Visit <https://hub.docker.com/orgs/jupyter/teams/stacks/members>
+1. Visit <https://quay.io/organization/jupyter/teams/owners>
 2. Add the maintainer's username.
 3. Visit <https://github.com/orgs/jupyter/teams/docker-image-maintainers/members>
 4. Add the maintainer's GitHub username.","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 6a962521..4bc1fc0d 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -56,7 +56,7 @@ When there's a new stack definition, check before merging the PR:
 
 ## Adding a New Maintainer Account
 
-1. Visit <https://hub.docker.com/orgs/jupyter/teams/stacks/members>
+1. Visit <https://quay.io/organization/jupyter/teams/owners>
 2. Add the maintainer's username.
 3. Visit <https://github.com/orgs/jupyter/teams/docker-image-maintainers/members>
 4. Add the maintainer's GitHub username.",Yes
docs/using/common.md,docs/using/common.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/common.md b/docs/using/common.md
index eefc23fa..e0097dac 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -15,14 +15,14 @@ You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/l
    you can run the following (this hash was generated for the `my-password` password):
 
    ```bash
-   docker run -it --rm -p 8888:8888 docker.io/jupyter/base-notebook \
+   docker run -it --rm -p 8888:8888 quay.io/jupyter/base-notebook \
        start-notebook.py --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
-   docker run  -it --rm -p 8888:8888 docker.io/jupyter/base-notebook \
+   docker run  -it --rm -p 8888:8888 quay.io/jupyter/base-notebook \
        start-notebook.py --ServerApp.base_url=/customized/url/prefix/
    ```
 
@@ -49,7 +49,7 @@ You do so by passing arguments to the `docker run` command.
       -e NB_USER=""my-username"" \
       -e CHOWN_HOME=yes \
       -w ""/home/my-username"" \
-      docker.io/jupyter/base-notebook
+      quay.io/jupyter/base-notebook
   ```
 
 - `-e NB_UID=<numeric uid>` - Instructs the startup script to switch the numeric user ID of `${NB_USER}` to the given value.
@@ -146,7 +146,7 @@ For example, to mount a host folder containing a `notebook.key` and `notebook.cr
 ```bash
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder:/etc/ssl/notebook \
-    docker.io/jupyter/base-notebook \
+    quay.io/jupyter/base-notebook \
     start-notebook.py \
     --ServerApp.keyfile=/etc/ssl/notebook/notebook.key \
     --ServerApp.certfile=/etc/ssl/notebook/notebook.crt
@@ -158,7 +158,7 @@ For example:
 ```bash
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder/notebook.pem:/etc/ssl/notebook.pem \
-    docker.io/jupyter/base-notebook \
+    quay.io/jupyter/base-notebook \
     start-notebook.py \
     --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
@@ -207,14 +207,14 @@ Example:
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    docker.io/jupyter/base-notebook
+    quay.io/jupyter/base-notebook
 # Executing the command: jupyter notebook ...
 
 # Use Jupyter NBClassic frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=nbclassic \
-    docker.io/jupyter/base-notebook
+    quay.io/jupyter/base-notebook
 # Executing the command: jupyter nbclassic ...
 ```
 
@@ -225,7 +225,7 @@ The `start.sh` script supports all the features described above but allows you t
 For example, to run the text-based `ipython` console in a container, do the following:
 
 ```bash
-docker run -it --rm docker.io/jupyter/base-notebook start.sh ipython
+docker run -it --rm quay.io/jupyter/base-notebook start.sh ipython
 ```
 
 This script is handy when you derive a new Dockerfile from this image and install additional Jupyter applications with subcommands like `jupyter console`, `jupyter kernelgateway`, etc.","diff --git a/docs/using/common.md b/docs/using/common.md
index eefc23fa..e0097dac 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -15,14 +15,14 @@ You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/l
    you can run the following (this hash was generated for the `my-password` password):
 
    ```bash
-   docker run -it --rm -p 8888:8888 docker.io/jupyter/base-notebook \
+   docker run -it --rm -p 8888:8888 quay.io/jupyter/base-notebook \
        start-notebook.py --PasswordIdentityProvider.hashed_password='argon2:$argon2id$v=19$m=10240,t=10,p=8$JdAN3fe9J45NvK/EPuGCvA$O/tbxglbwRpOFuBNTYrymAEH6370Q2z+eS1eF4GM6Do'
    ```
 
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
-   docker run  -it --rm -p 8888:8888 docker.io/jupyter/base-notebook \
+   docker run  -it --rm -p 8888:8888 quay.io/jupyter/base-notebook \
        start-notebook.py --ServerApp.base_url=/customized/url/prefix/
    ```
 
@@ -49,7 +49,7 @@ You do so by passing arguments to the `docker run` command.
       -e NB_USER=""my-username"" \
       -e CHOWN_HOME=yes \
       -w ""/home/my-username"" \
-      docker.io/jupyter/base-notebook
+      quay.io/jupyter/base-notebook
   ```
 
 - `-e NB_UID=<numeric uid>` - Instructs the startup script to switch the numeric user ID of `${NB_USER}` to the given value.
@@ -146,7 +146,7 @@ For example, to mount a host folder containing a `notebook.key` and `notebook.cr
 ```bash
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder:/etc/ssl/notebook \
-    docker.io/jupyter/base-notebook \
+    quay.io/jupyter/base-notebook \
     start-notebook.py \
     --ServerApp.keyfile=/etc/ssl/notebook/notebook.key \
     --ServerApp.certfile=/etc/ssl/notebook/notebook.crt
@@ -158,7 +158,7 @@ For example:
 ```bash
 docker run -it --rm -p 8888:8888 \
     -v /some/host/folder/notebook.pem:/etc/ssl/notebook.pem \
-    docker.io/jupyter/base-notebook \
+    quay.io/jupyter/base-notebook \
     start-notebook.py \
     --ServerApp.certfile=/etc/ssl/notebook.pem
 ```
@@ -207,14 +207,14 @@ Example:
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    docker.io/jupyter/base-notebook
+    quay.io/jupyter/base-notebook
 # Executing the command: jupyter notebook ...
 
 # Use Jupyter NBClassic frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=nbclassic \
-    docker.io/jupyter/base-notebook
+    quay.io/jupyter/base-notebook
 # Executing the command: jupyter nbclassic ...
 ```
 
@@ -225,7 +225,7 @@ The `start.sh` script supports all the features described above but allows you t
 For example, to run the text-based `ipython` console in a container, do the following:
 
 ```bash
-docker run -it --rm docker.io/jupyter/base-notebook start.sh ipython
+docker run -it --rm quay.io/jupyter/base-notebook start.sh ipython
 ```
 
 This script is handy when you derive a new Dockerfile from this image and install additional Jupyter applications with subcommands like `jupyter console`, `jupyter kernelgateway`, etc.",Yes
docs/using/recipe_code/custom_environment.dockerfile,docs/using/recipe_code/custom_environment.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index a158f2a6..4a63cfaf 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Name your environment and choose the python version
 ARG env_name=python310","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index a158f2a6..4a63cfaf 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Name your environment and choose the python version
 ARG env_name=python310",Yes
docs/using/recipe_code/dask_jupyterlab.dockerfile,docs/using/recipe_code/dask_jupyterlab.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/dask_jupyterlab.dockerfile b/docs/using/recipe_code/dask_jupyterlab.dockerfile
index 6d48b101..f1cd0e68 100644
--- a/docs/using/recipe_code/dask_jupyterlab.dockerfile
+++ b/docs/using/recipe_code/dask_jupyterlab.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Install the Dask dashboard
 RUN mamba install --yes 'dask-labextension' && \","diff --git a/docs/using/recipe_code/dask_jupyterlab.dockerfile b/docs/using/recipe_code/dask_jupyterlab.dockerfile
index 6d48b101..f1cd0e68 100644
--- a/docs/using/recipe_code/dask_jupyterlab.dockerfile
+++ b/docs/using/recipe_code/dask_jupyterlab.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Install the Dask dashboard
 RUN mamba install --yes 'dask-labextension' && \",Yes
docs/using/recipe_code/jupyterhub_version.dockerfile,docs/using/recipe_code/jupyterhub_version.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
index 4f9bcfb4..7fd53018 100644
--- a/docs/using/recipe_code/jupyterhub_version.dockerfile
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 RUN mamba install --yes 'jupyterhub==4.0.1' && \
     mamba clean --all -f -y && \","diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
index 4f9bcfb4..7fd53018 100644
--- a/docs/using/recipe_code/jupyterhub_version.dockerfile
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 RUN mamba install --yes 'jupyterhub==4.0.1' && \
     mamba clean --all -f -y && \",Yes
docs/using/recipe_code/mamba_install.dockerfile,docs/using/recipe_code/mamba_install.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/mamba_install.dockerfile b/docs/using/recipe_code/mamba_install.dockerfile
index 8e79b678..2c4d2c4e 100644
--- a/docs/using/recipe_code/mamba_install.dockerfile
+++ b/docs/using/recipe_code/mamba_install.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 RUN mamba install --yes 'flake8' && \
     mamba clean --all -f -y && \","diff --git a/docs/using/recipe_code/mamba_install.dockerfile b/docs/using/recipe_code/mamba_install.dockerfile
index 8e79b678..2c4d2c4e 100644
--- a/docs/using/recipe_code/mamba_install.dockerfile
+++ b/docs/using/recipe_code/mamba_install.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 RUN mamba install --yes 'flake8' && \
     mamba clean --all -f -y && \",Yes
docs/using/recipe_code/manpage_install.dockerfile,docs/using/recipe_code/manpage_install.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/manpage_install.dockerfile b/docs/using/recipe_code/manpage_install.dockerfile
index e95354a3..ed8d91d1 100644
--- a/docs/using/recipe_code/manpage_install.dockerfile
+++ b/docs/using/recipe_code/manpage_install.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014","diff --git a/docs/using/recipe_code/manpage_install.dockerfile b/docs/using/recipe_code/manpage_install.dockerfile
index e95354a3..ed8d91d1 100644
--- a/docs/using/recipe_code/manpage_install.dockerfile
+++ b/docs/using/recipe_code/manpage_install.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014",Yes
docs/using/recipe_code/microsoft_odbc.dockerfile,docs/using/recipe_code/microsoft_odbc.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index 2a9faaa9..1138d69f 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014","diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index 2a9faaa9..1138d69f 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index b04acca0..ff2e437d 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 USER root","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index b04acca0..ff2e437d 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 USER root",Yes
docs/using/recipe_code/pip_install.dockerfile,docs/using/recipe_code/pip_install.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/pip_install.dockerfile b/docs/using/recipe_code/pip_install.dockerfile
index dc855225..fc6508bc 100644
--- a/docs/using/recipe_code/pip_install.dockerfile
+++ b/docs/using/recipe_code/pip_install.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Install in the default python3 environment
 RUN pip install --no-cache-dir 'flake8' && \","diff --git a/docs/using/recipe_code/pip_install.dockerfile b/docs/using/recipe_code/pip_install.dockerfile
index dc855225..fc6508bc 100644
--- a/docs/using/recipe_code/pip_install.dockerfile
+++ b/docs/using/recipe_code/pip_install.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 # Install in the default python3 environment
 RUN pip install --no-cache-dir 'flake8' && \",Yes
docs/using/recipe_code/rise_jupyterlab.dockerfile,docs/using/recipe_code/rise_jupyterlab.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/rise_jupyterlab.dockerfile b/docs/using/recipe_code/rise_jupyterlab.dockerfile
index 2f2b9aee..7d796ca9 100644
--- a/docs/using/recipe_code/rise_jupyterlab.dockerfile
+++ b/docs/using/recipe_code/rise_jupyterlab.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 RUN mamba install --yes 'jupyterlab_rise' && \
     mamba clean --all -f -y && \","diff --git a/docs/using/recipe_code/rise_jupyterlab.dockerfile b/docs/using/recipe_code/rise_jupyterlab.dockerfile
index 2f2b9aee..7d796ca9 100644
--- a/docs/using/recipe_code/rise_jupyterlab.dockerfile
+++ b/docs/using/recipe_code/rise_jupyterlab.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 RUN mamba install --yes 'jupyterlab_rise' && \
     mamba clean --all -f -y && \",Yes
docs/using/recipe_code/spellcheck_notebookv6.dockerfile,docs/using/recipe_code/spellcheck_notebookv6.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
index 0b843485..36e374cb 100644
--- a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
+++ b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook:notebook-6.5.4
+FROM quay.io/jupyter/base-notebook:notebook-6.5.4
 
 RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \","diff --git a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
index 0b843485..36e374cb 100644
--- a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
+++ b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook:notebook-6.5.4
+FROM quay.io/jupyter/base-notebook:notebook-6.5.4
 
 RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \",Yes
docs/using/recipe_code/xgboost.dockerfile,docs/using/recipe_code/xgboost.dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipe_code/xgboost.dockerfile b/docs/using/recipe_code/xgboost.dockerfile
index b4e0788d..14afc79e 100644
--- a/docs/using/recipe_code/xgboost.dockerfile
+++ b/docs/using/recipe_code/xgboost.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 RUN mamba install --yes 'py-xgboost' && \
     mamba clean --all -f -y && \","diff --git a/docs/using/recipe_code/xgboost.dockerfile b/docs/using/recipe_code/xgboost.dockerfile
index b4e0788d..14afc79e 100644
--- a/docs/using/recipe_code/xgboost.dockerfile
+++ b/docs/using/recipe_code/xgboost.dockerfile
@@ -1,4 +1,4 @@
-FROM docker.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook
 
 RUN mamba install --yes 'py-xgboost' && \
     mamba clean --all -f -y && \",Yes
docs/using/recipes.md,docs/using/recipes.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index d9ea6f35..5df119d8 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -17,7 +17,7 @@ For example:
 docker run -it --rm \
     --user root \
     -e GRANT_SUDO=yes \
-    docker.io/jupyter/base-notebook
+    quay.io/jupyter/base-notebook
 ```
 
 **You should only enable `sudo` if you trust the user and/or if the container is running on an isolated host.**
@@ -298,7 +298,7 @@ This recipe is not tested and might be broken.
 ```
 
 ```dockerfile
-FROM docker.io/jupyter/all-spark-notebook
+FROM quay.io/jupyter/all-spark-notebook
 
 # Set env vars for pydoop
 ENV HADOOP_HOME /usr/local/hadoop-2.7.3
@@ -381,7 +381,7 @@ For JupyterLab:
 
 ```bash
 docker run -it --rm \
-    docker.io/jupyter/base-notebook \
+    quay.io/jupyter/base-notebook \
     start-notebook.py --IdentityProvider.token=''
 ```
 
@@ -390,7 +390,7 @@ For Jupyter Notebook:
 ```bash
 docker run -it --rm \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    docker.io/jupyter/base-notebook \
+    quay.io/jupyter/base-notebook \
     start-notebook.py --IdentityProvider.token=''
 ```
 
@@ -415,7 +415,7 @@ Please note that the [Delta Lake](https://delta.io/) packages are only available
 By adding the properties to `spark-defaults.conf`, the user no longer needs to enable Delta support in each notebook.
 
 ```dockerfile
-FROM docker.io/jupyter/pyspark-notebook
+FROM quay.io/jupyter/pyspark-notebook
 
 RUN mamba install --yes 'delta-spark' && \
     mamba clean --all -f -y && \
@@ -446,7 +446,7 @@ This recipe is not tested and might be broken.
 The example below is a Dockerfile to load Source Han Sans with normal weight, usually used for the web.
 
 ```dockerfile
-FROM docker.io/jupyter/scipy-notebook
+FROM quay.io/jupyter/scipy-notebook
 
 RUN PYV=$(ls ""${CONDA_DIR}/lib"" | grep ^python) && \
     MPL_DATA=""${CONDA_DIR}/lib/${PYV}/site-packages/matplotlib/mpl-data"" && \
@@ -477,7 +477,7 @@ and add these options when running `docker`: `-e DISPLAY -v /tmp/.X11-unix:/tmp/
 docker run -it --rm \
     -e DISPLAY \
     -v /tmp/.X11-unix:/tmp/.X11-unix \
-    docker.io/jupyter/minimal-notebook
+    quay.io/jupyter/minimal-notebook
 ```
 
 ## Add ijavascript kernel to container
@@ -489,7 +489,7 @@ This recipe is not tested and might be broken.
 The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
 
 ```dockerfile
-FROM docker.io/jupyter/scipy-notebook
+FROM quay.io/jupyter/scipy-notebook
 
 # install ijavascript
 RUN npm install -g ijavascript","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index d9ea6f35..5df119d8 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -17,7 +17,7 @@ For example:
 docker run -it --rm \
     --user root \
     -e GRANT_SUDO=yes \
-    docker.io/jupyter/base-notebook
+    quay.io/jupyter/base-notebook
 ```
 
 **You should only enable `sudo` if you trust the user and/or if the container is running on an isolated host.**
@@ -298,7 +298,7 @@ This recipe is not tested and might be broken.
 ```
 
 ```dockerfile
-FROM docker.io/jupyter/all-spark-notebook
+FROM quay.io/jupyter/all-spark-notebook
 
 # Set env vars for pydoop
 ENV HADOOP_HOME /usr/local/hadoop-2.7.3
@@ -381,7 +381,7 @@ For JupyterLab:
 
 ```bash
 docker run -it --rm \
-    docker.io/jupyter/base-notebook \
+    quay.io/jupyter/base-notebook \
     start-notebook.py --IdentityProvider.token=''
 ```
 
@@ -390,7 +390,7 @@ For Jupyter Notebook:
 ```bash
 docker run -it --rm \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
-    docker.io/jupyter/base-notebook \
+    quay.io/jupyter/base-notebook \
     start-notebook.py --IdentityProvider.token=''
 ```
 
@@ -415,7 +415,7 @@ Please note that the [Delta Lake](https://delta.io/) packages are only available
 By adding the properties to `spark-defaults.conf`, the user no longer needs to enable Delta support in each notebook.
 
 ```dockerfile
-FROM docker.io/jupyter/pyspark-notebook
+FROM quay.io/jupyter/pyspark-notebook
 
 RUN mamba install --yes 'delta-spark' && \
     mamba clean --all -f -y && \
@@ -446,7 +446,7 @@ This recipe is not tested and might be broken.
 The example below is a Dockerfile to load Source Han Sans with normal weight, usually used for the web.
 
 ```dockerfile
-FROM docker.io/jupyter/scipy-notebook
+FROM quay.io/jupyter/scipy-notebook
 
 RUN PYV=$(ls ""${CONDA_DIR}/lib"" | grep ^python) && \
     MPL_DATA=""${CONDA_DIR}/lib/${PYV}/site-packages/matplotlib/mpl-data"" && \
@@ -477,7 +477,7 @@ and add these options when running `docker`: `-e DISPLAY -v /tmp/.X11-unix:/tmp/
 docker run -it --rm \
     -e DISPLAY \
     -v /tmp/.X11-unix:/tmp/.X11-unix \
-    docker.io/jupyter/minimal-notebook
+    quay.io/jupyter/minimal-notebook
 ```
 
 ## Add ijavascript kernel to container
@@ -489,7 +489,7 @@ This recipe is not tested and might be broken.
 The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
 
 ```dockerfile
-FROM docker.io/jupyter/scipy-notebook
+FROM quay.io/jupyter/scipy-notebook
 
 # install ijavascript
 RUN npm install -g ijavascript",Yes
docs/using/running.md,docs/using/running.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/running.md b/docs/using/running.md
index a15492da..77b05c6c 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 docker.io/jupyter/scipy-notebook:2023-09-25
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-09-25
 
 # Entered start.sh with args: jupyter lab
 
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work docker.io/jupyter/r-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-09-25
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -74,11 +74,11 @@ To change the default directory, you will need to specify `ServerApp.root_dir` b
 
 ### Example 3
 
-This command pulls the `jupyter/all-spark-notebook` image currently tagged `latest` from Docker Hub if an image tagged `latest` is not already present on the local host.
+This command pulls the `jupyter/all-spark-notebook` image currently tagged `latest` from Quay.io if an image tagged `latest` is not already present on the local host.
 It then starts a container named `notebook` running a JupyterLab server and exposes the server on a randomly selected port.
 
 ```bash
-docker run --detach -P --name notebook docker.io/jupyter/all-spark-notebook
+docker run --detach -P --name notebook quay.io/jupyter/all-spark-notebook
 ```
 
 where:
@@ -137,7 +137,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -146,7 +146,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-09-25
+    quay.io/jupyter/r-notebook:2023-09-25
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index a15492da..77b05c6c 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 docker.io/jupyter/scipy-notebook:2023-09-25
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-09-25
 
 # Entered start.sh with args: jupyter lab
 
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work docker.io/jupyter/r-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-09-25
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -74,11 +74,11 @@ To change the default directory, you will need to specify `ServerApp.root_dir` b
 
 ### Example 3
 
-This command pulls the `jupyter/all-spark-notebook` image currently tagged `latest` from Docker Hub if an image tagged `latest` is not already present on the local host.
+This command pulls the `jupyter/all-spark-notebook` image currently tagged `latest` from Quay.io if an image tagged `latest` is not already present on the local host.
 It then starts a container named `notebook` running a JupyterLab server and exposes the server on a randomly selected port.
 
 ```bash
-docker run --detach -P --name notebook docker.io/jupyter/all-spark-notebook
+docker run --detach -P --name notebook quay.io/jupyter/all-spark-notebook
 ```
 
 where:
@@ -137,7 +137,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `docker.io/jupyter/r-notebook` image tagged `2023-09-25` from Docker Hub if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -146,7 +146,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    docker.io/jupyter/r-notebook:2023-09-25
+    quay.io/jupyter/r-notebook:2023-09-25
 ```
 
 ```{warning}",Yes
docs/using/selecting.md,docs/using/selecting.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 7f763fee..b335b5af 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -20,7 +20,7 @@ The following sections describe these images, including their contents, relation
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/docker-stacks-foundation) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/docker-stacks-foundation/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/docker-stacks-foundation/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/docker-stacks-foundation?tab=tags)
 
 `jupyter/docker-stacks-foundation` is a small image supporting a majority of [options common across all core stacks](common.md).
 It is the basis for all other stacks on which Jupyter-related applications can be built
@@ -46,7 +46,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/base-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/base-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/base-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/base-notebook?tab=tags)
 
 `jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
 and serves as the basis for all other stacks besides `jupyter/docker-stacks-foundation`.
@@ -71,7 +71,7 @@ The shim `.sh` files will be removed at some future date.
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/minimal-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/minimal-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/minimal-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/minimal-notebook?tab=tags)
 
 `jupyter/minimal-notebook` adds command-line tools useful when working in Jupyter applications.
 
@@ -91,7 +91,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/r-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/r-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/r-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/t-notebook?tab=tags)
 
 `jupyter/r-notebook` includes popular packages from the R ecosystem listed below:
 
@@ -122,7 +122,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/julia-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/julia-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/julia-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/julia-notebook?tab=tags)
 
 `jupyter/julia-notebook` includes popular packages from the Julia ecosystem listed below:
 
@@ -136,7 +136,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/scipy-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/scipy-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/scipy-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/scipy-notebook?tab=tags)
 
 `jupyter/scipy-notebook` includes popular packages from the scientific Python ecosystem.
 
@@ -180,7 +180,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/tensorflow-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/tensorflow-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/tensorflow-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/tensorflow-notebook?tab=tags)
 
 `jupyter/tensorflow-notebook` includes popular Python deep learning libraries.
 
@@ -191,7 +191,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/datascience-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/datascience-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/datascience-notebook?tab=tags)
 
 `jupyter/datascience-notebook` includes libraries for data analysis from the Python, and R, and Julia communities.
 
@@ -203,7 +203,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/pyspark-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/pyspark-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/pyspark-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/pyspark-notebook?tab=tags)
 
 `jupyter/pyspark-notebook` includes Python support for Apache Spark.
 
@@ -215,7 +215,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/all-spark-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/all-spark-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/all-spark-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/all-spark-notebook?tab=tags)
 
 `jupyter/all-spark-notebook` includes Python and R support for Apache Spark.
 
@@ -236,7 +236,7 @@ diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=d
 
 ### Builds
 
-Every Monday and whenever a pull request is merged, images are rebuilt and pushed to [the public container registry](https://hub.docker.com/u/jupyter).
+Every Monday and whenever a pull request is merged, images are rebuilt and pushed to [the public container registry](https://quay.io/organization/jupyter).
 
 ### Versioning via image tags","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 7f763fee..b335b5af 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -20,7 +20,7 @@ The following sections describe these images, including their contents, relation
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/docker-stacks-foundation) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/docker-stacks-foundation/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/docker-stacks-foundation/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/docker-stacks-foundation?tab=tags)
 
 `jupyter/docker-stacks-foundation` is a small image supporting a majority of [options common across all core stacks](common.md).
 It is the basis for all other stacks on which Jupyter-related applications can be built
@@ -46,7 +46,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/base-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/base-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/base-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/base-notebook?tab=tags)
 
 `jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
 and serves as the basis for all other stacks besides `jupyter/docker-stacks-foundation`.
@@ -71,7 +71,7 @@ The shim `.sh` files will be removed at some future date.
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/minimal-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/minimal-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/minimal-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/minimal-notebook?tab=tags)
 
 `jupyter/minimal-notebook` adds command-line tools useful when working in Jupyter applications.
 
@@ -91,7 +91,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/r-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/r-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/r-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/t-notebook?tab=tags)
 
 `jupyter/r-notebook` includes popular packages from the R ecosystem listed below:
 
@@ -122,7 +122,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/julia-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/julia-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/julia-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/julia-notebook?tab=tags)
 
 `jupyter/julia-notebook` includes popular packages from the Julia ecosystem listed below:
 
@@ -136,7 +136,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/scipy-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/scipy-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/scipy-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/scipy-notebook?tab=tags)
 
 `jupyter/scipy-notebook` includes popular packages from the scientific Python ecosystem.
 
@@ -180,7 +180,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/tensorflow-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/tensorflow-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/tensorflow-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/tensorflow-notebook?tab=tags)
 
 `jupyter/tensorflow-notebook` includes popular Python deep learning libraries.
 
@@ -191,7 +191,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/datascience-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/datascience-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/datascience-notebook?tab=tags)
 
 `jupyter/datascience-notebook` includes libraries for data analysis from the Python, and R, and Julia communities.
 
@@ -203,7 +203,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/pyspark-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/pyspark-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/pyspark-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/pyspark-notebook?tab=tags)
 
 `jupyter/pyspark-notebook` includes Python support for Apache Spark.
 
@@ -215,7 +215,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/all-spark-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/all-spark-notebook/Dockerfile) |
-[Docker Hub image tags](https://hub.docker.com/r/jupyter/all-spark-notebook/tags/)
+[Quay.io image tags](https://quay.io/repository/jupyter/all-spark-notebook?tab=tags)
 
 `jupyter/all-spark-notebook` includes Python and R support for Apache Spark.
 
@@ -236,7 +236,7 @@ diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=d
 
 ### Builds
 
-Every Monday and whenever a pull request is merged, images are rebuilt and pushed to [the public container registry](https://hub.docker.com/u/jupyter).
+Every Monday and whenever a pull request is merged, images are rebuilt and pushed to [the public container registry](https://quay.io/organization/jupyter).
 
 ### Versioning via image tags",Yes
docs/using/specifics.md,docs/using/specifics.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 300a53e5..39776551 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -14,7 +14,7 @@ This page provides details about features specific to one or more images.
   Every new spark context that is created is put onto an incrementing port (i.e. 4040, 4041, 4042, etc.), and it might be necessary to open multiple ports.
   ```
 
-  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 docker.io/jupyter/pyspark-notebook`.
+  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 quay.io/jupyter/pyspark-notebook`.
 
 #### IPython low-level output capture and forward
 
@@ -72,7 +72,7 @@ docker build --rm --force-rm \
     --build-arg openjdk_version=11
 
 # Check the newly built image
-docker run -it --rm docker.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
+docker run -it --rm quay.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
 
 # Welcome to
 #       ____              __","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 300a53e5..39776551 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -14,7 +14,7 @@ This page provides details about features specific to one or more images.
   Every new spark context that is created is put onto an incrementing port (i.e. 4040, 4041, 4042, etc.), and it might be necessary to open multiple ports.
   ```
 
-  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 docker.io/jupyter/pyspark-notebook`.
+  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 quay.io/jupyter/pyspark-notebook`.
 
 #### IPython low-level output capture and forward
 
@@ -72,7 +72,7 @@ docker build --rm --force-rm \
     --build-arg openjdk_version=11
 
 # Check the newly built image
-docker run -it --rm docker.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
+docker run -it --rm quay.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
 
 # Welcome to
 #       ____              __",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index b11eacb6..d23b8777 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -14,7 +14,7 @@ If you are running a Docker container while mounting a local volume or host dire
 docker run -it --rm \
     -p 8888:8888 \
     -v <my-vol>:<container-dir> \
-    docker.io/jupyter/minimal-notebook:latest
+    quay.io/jupyter/minimal-notebook:latest
 ```
 
 you might face permissions issues when trying to access the mounted volume:
@@ -48,7 +48,7 @@ The following sections cover a few of these scenarios and how to fix them.
        --user root \
        -e CHOWN_EXTRA=""<container-dir>"" \
        -e CHOWN_EXTRA_OPTS=""-R"" \
-       docker.io/jupyter/minimal-notebook
+       quay.io/jupyter/minimal-notebook
    ```
 
    where:
@@ -95,7 +95,7 @@ The following sections cover a few of these scenarios and how to fix them.
        -e NB_UID=1234 \
        -e NB_GID=5678 \
        -v ""${PWD}""/test:/home/jovyan/work \
-       docker.io/jupyter/minimal-notebook:latest
+       quay.io/jupyter/minimal-notebook:latest
 
    # you should see an output similar to this
    # Update jovyan's UID:GID to 1234:5678
@@ -144,7 +144,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
         -e CHOWN_HOME_OPTS=""-R"" \
         -w ""/home/callisto"" \
         -v ""${PWD}""/test:/home/callisto/work \
-        docker.io/jupyter/minimal-notebook
+        quay.io/jupyter/minimal-notebook
 
     # Updated the jovyan user:
     # - username: jovyan       -> callisto
@@ -187,7 +187,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
        -e CHOWN_HOME_OPTS=""-R"" \
        -w ""/home/callisto"" \
        -v ""${PWD}""/test:/home/callisto/work \
-       docker.io/jupyter/minimal-notebook
+       quay.io/jupyter/minimal-notebook
    ```
 
    where:
@@ -214,7 +214,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
   docker run -it --rm \
       -p 8888:8888 \
       --user ""$(id -u)"" --group-add users \
-      -v <my-vol>:/home/jovyan/work docker.io/jupyter/datascience-notebook
+      -v <my-vol>:/home/jovyan/work quay.io/jupyter/datascience-notebook
   ```
 
   This command will launch the container with a specific user UID and add that user to the `users` group to modify the files in the default `/home` and `/opt/conda` directories.
@@ -318,7 +318,7 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
    You can see an example of mapping to local port `8001`:
 
    ```bash
-   docker run -it --rm -p 8001:8888 docker.io/jupyter/datascience-notebook
+   docker run -it --rm -p 8001:8888 quay.io/jupyter/datascience-notebook
    ```
 
    When the terminal provides the link to access Jupyter: <http://127.0.0.1:8888/lab?token=80d45d241a1ba4c2...>,","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index b11eacb6..d23b8777 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -14,7 +14,7 @@ If you are running a Docker container while mounting a local volume or host dire
 docker run -it --rm \
     -p 8888:8888 \
     -v <my-vol>:<container-dir> \
-    docker.io/jupyter/minimal-notebook:latest
+    quay.io/jupyter/minimal-notebook:latest
 ```
 
 you might face permissions issues when trying to access the mounted volume:
@@ -48,7 +48,7 @@ The following sections cover a few of these scenarios and how to fix them.
        --user root \
        -e CHOWN_EXTRA=""<container-dir>"" \
        -e CHOWN_EXTRA_OPTS=""-R"" \
-       docker.io/jupyter/minimal-notebook
+       quay.io/jupyter/minimal-notebook
    ```
 
    where:
@@ -95,7 +95,7 @@ The following sections cover a few of these scenarios and how to fix them.
        -e NB_UID=1234 \
        -e NB_GID=5678 \
        -v ""${PWD}""/test:/home/jovyan/work \
-       docker.io/jupyter/minimal-notebook:latest
+       quay.io/jupyter/minimal-notebook:latest
 
    # you should see an output similar to this
    # Update jovyan's UID:GID to 1234:5678
@@ -144,7 +144,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
         -e CHOWN_HOME_OPTS=""-R"" \
         -w ""/home/callisto"" \
         -v ""${PWD}""/test:/home/callisto/work \
-        docker.io/jupyter/minimal-notebook
+        quay.io/jupyter/minimal-notebook
 
     # Updated the jovyan user:
     # - username: jovyan       -> callisto
@@ -187,7 +187,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
        -e CHOWN_HOME_OPTS=""-R"" \
        -w ""/home/callisto"" \
        -v ""${PWD}""/test:/home/callisto/work \
-       docker.io/jupyter/minimal-notebook
+       quay.io/jupyter/minimal-notebook
    ```
 
    where:
@@ -214,7 +214,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
   docker run -it --rm \
       -p 8888:8888 \
       --user ""$(id -u)"" --group-add users \
-      -v <my-vol>:/home/jovyan/work docker.io/jupyter/datascience-notebook
+      -v <my-vol>:/home/jovyan/work quay.io/jupyter/datascience-notebook
   ```
 
   This command will launch the container with a specific user UID and add that user to the `users` group to modify the files in the default `/home` and `/opt/conda` directories.
@@ -318,7 +318,7 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
    You can see an example of mapping to local port `8001`:
 
    ```bash
-   docker run -it --rm -p 8001:8888 docker.io/jupyter/datascience-notebook
+   docker run -it --rm -p 8001:8888 quay.io/jupyter/datascience-notebook
    ```
 
    When the terminal provides the link to access Jupyter: <http://127.0.0.1:8888/lab?token=80d45d241a1ba4c2...>,",Yes
examples/docker-compose/README.md,examples/docker-compose/README.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index 0b57df39..d2c2e3ee 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -42,7 +42,7 @@ You can customize the docker-stack notebook image to deploy by modifying the `no
 For example, you can build and deploy a `jupyter/all-spark-notebook` by modifying the Dockerfile like so:
 
 ```dockerfile
-FROM docker.io/jupyter/all-spark-notebook
+FROM quay.io/jupyter/all-spark-notebook
 # Your RUN commands and so on
 ```","diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index 0b57df39..d2c2e3ee 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -42,7 +42,7 @@ You can customize the docker-stack notebook image to deploy by modifying the `no
 For example, you can build and deploy a `jupyter/all-spark-notebook` by modifying the Dockerfile like so:
 
 ```dockerfile
-FROM docker.io/jupyter/all-spark-notebook
+FROM quay.io/jupyter/all-spark-notebook
 # Your RUN commands and so on
 ```",Yes
examples/docker-compose/notebook/Dockerfile,examples/docker-compose/notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/examples/docker-compose/notebook/Dockerfile b/examples/docker-compose/notebook/Dockerfile
index 8f21c516..056c22fb 100644
--- a/examples/docker-compose/notebook/Dockerfile
+++ b/examples/docker-compose/notebook/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM docker.io/jupyter/minimal-notebook
+FROM quay.io/jupyter/minimal-notebook
 
 USER root","diff --git a/examples/docker-compose/notebook/Dockerfile b/examples/docker-compose/notebook/Dockerfile
index 8f21c516..056c22fb 100644
--- a/examples/docker-compose/notebook/Dockerfile
+++ b/examples/docker-compose/notebook/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM docker.io/jupyter/minimal-notebook
+FROM quay.io/jupyter/minimal-notebook
 
 USER root",Yes
examples/make-deploy/Dockerfile,examples/make-deploy/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/examples/make-deploy/Dockerfile b/examples/make-deploy/Dockerfile
index 8f21c516..056c22fb 100644
--- a/examples/make-deploy/Dockerfile
+++ b/examples/make-deploy/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM docker.io/jupyter/minimal-notebook
+FROM quay.io/jupyter/minimal-notebook
 
 USER root","diff --git a/examples/make-deploy/Dockerfile b/examples/make-deploy/Dockerfile
index 8f21c516..056c22fb 100644
--- a/examples/make-deploy/Dockerfile
+++ b/examples/make-deploy/Dockerfile
@@ -2,7 +2,7 @@
 # Distributed under the terms of the Modified BSD License.
 
 # Pick your favorite docker-stacks image
-FROM docker.io/jupyter/minimal-notebook
+FROM quay.io/jupyter/minimal-notebook
 
 USER root",Yes
images/all-spark-notebook/Dockerfile,images/all-spark-notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
index 90e5f083..1a97294b 100644
--- a/images/all-spark-notebook/Dockerfile
+++ b/images/all-spark-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/pyspark-notebook
 FROM $BASE_CONTAINER","diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
index 90e5f083..1a97294b 100644
--- a/images/all-spark-notebook/Dockerfile
+++ b/images/all-spark-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/pyspark-notebook
 FROM $BASE_CONTAINER",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index fdd74c15..3ac6a8cd 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/docker-stacks-foundation
 FROM $BASE_CONTAINER","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index fdd74c15..3ac6a8cd 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/docker-stacks-foundation
 FROM $BASE_CONTAINER",Yes
images/datascience-notebook/Dockerfile,images/datascience-notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
index 192f37c1..2d49e559 100644
--- a/images/datascience-notebook/Dockerfile
+++ b/images/datascience-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER","diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
index 192f37c1..2d49e559 100644
--- a/images/datascience-notebook/Dockerfile
+++ b/images/datascience-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER",Yes
images/julia-notebook/Dockerfile,images/julia-notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
index 94b679b8..2c982a8b 100644
--- a/images/julia-notebook/Dockerfile
+++ b/images/julia-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER","diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
index 94b679b8..2c982a8b 100644
--- a/images/julia-notebook/Dockerfile
+++ b/images/julia-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER",Yes
images/minimal-notebook/Dockerfile,images/minimal-notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index bf8f92d8..228509aa 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook
 FROM $BASE_CONTAINER","diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index bf8f92d8..228509aa 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook
 FROM $BASE_CONTAINER",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 192830da..c50701ef 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 192830da..c50701ef 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER",Yes
images/r-notebook/Dockerfile,images/r-notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/images/r-notebook/Dockerfile b/images/r-notebook/Dockerfile
index 3ff37777..bb7f0955 100644
--- a/images/r-notebook/Dockerfile
+++ b/images/r-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER","diff --git a/images/r-notebook/Dockerfile b/images/r-notebook/Dockerfile
index 3ff37777..bb7f0955 100644
--- a/images/r-notebook/Dockerfile
+++ b/images/r-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER",Yes
images/scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 2c4b1ffd..bc0f80b9 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 2c4b1ffd..bc0f80b9 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
 FROM $BASE_CONTAINER",Yes
images/tensorflow-notebook/Dockerfile,images/tensorflow-notebook/Dockerfile,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index 921af999..7038f084 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index 921af999..7038f084 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -1,6 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-ARG REGISTRY=docker.io
+ARG REGISTRY=quay.io
 ARG OWNER=jupyter
 ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
 FROM $BASE_CONTAINER",Yes
tagging/README.md,tagging/README.md,00a67281613254de8a253a292313eb7187c83982,3e04ded3a3662b24b7ea5019b6b7bd075e2097ad,"Move from Docker Hub to quay.io (#2010)

* Move from Docker Hub to quay.io

* Fix http->https

* Update registry-overviews

* Remove Docker Hub name","diff --git a/tagging/README.md b/tagging/README.md
index f3d2a9fb..bb7edcca 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -4,8 +4,8 @@ The main purpose of the source code in this folder is to properly tag all the im
 These two processes are closely related, so the source code is widely reused.
 
 A basic example of a tag is a `python` version tag.
-For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a full image name `docker.io/jupyter/base-notebook:python-3.10.5`.
-This tag (and all the other tags) are pushed to Docker Hub.
+For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a full image name `quay.io/jupyter/base-notebook:python-3.10.5`.
+This tag (and all the other tags) are pushed to Quay.io.
 
 Manifest is a description of some important part of the image in a `markdown`.
 For example, we dump all the `conda` packages, including their versions.","diff --git a/tagging/README.md b/tagging/README.md
index f3d2a9fb..bb7edcca 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -4,8 +4,8 @@ The main purpose of the source code in this folder is to properly tag all the im
 These two processes are closely related, so the source code is widely reused.
 
 A basic example of a tag is a `python` version tag.
-For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a full image name `docker.io/jupyter/base-notebook:python-3.10.5`.
-This tag (and all the other tags) are pushed to Docker Hub.
+For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a full image name `quay.io/jupyter/base-notebook:python-3.10.5`.
+This tag (and all the other tags) are pushed to Quay.io.
 
 Manifest is a description of some important part of the image in a `markdown`.
 For example, we dump all the `conda` packages, including their versions.",Yes
tagging/write_tags_file.py,tagging/write_tags_file.py,542eae692c33e885fa5957a3fea989f7852c130d,00a67281613254de8a253a292313eb7187c83982,Write registry to a file with all tags,"diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index ef4e1b0b..cfdea2ac 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -36,7 +36,9 @@ def write_tags_file(
             LOGGER.info(
                 f""Calculated tag, tagger_name: {tagger_name} tag_value: {tag_value}""
             )
-            tags.append(f""{owner}/{short_image_name}:{tags_prefix}-{tag_value}"")
+            tags.append(
+                f""{registry}/{owner}/{short_image_name}:{tags_prefix}-{tag_value}""
+            )
     tags_dir.mkdir(parents=True, exist_ok=True)
     (tags_dir / filename).write_text(""\n"".join(tags))","diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index ef4e1b0b..cfdea2ac 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -36,7 +36,9 @@ def write_tags_file(
             LOGGER.info(
                 f""Calculated tag, tagger_name: {tagger_name} tag_value: {tag_value}""
             )
-            tags.append(f""{owner}/{short_image_name}:{tags_prefix}-{tag_value}"")
+            tags.append(
+                f""{registry}/{owner}/{short_image_name}:{tags_prefix}-{tag_value}""
+            )
     tags_dir.mkdir(parents=True, exist_ok=True)
     (tags_dir / filename).write_text(""\n"".join(tags))",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,ee7b9133fb42eaad86aed4e59e6ba4bf3acc486e,542eae692c33e885fa5957a3fea989f7852c130d,Use quay.io for cookiecutter,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 422a5d2a..f2570bfb 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -45,7 +45,7 @@ stack_org [my-project]:
 Select an image from the `jupyter/docker-stacks` project that will serve as the base for your new image.
 
 ```text
-stack_base_image [jupyter/base-notebook]:
+stack_base_image [quay.io/jupyter/base-notebook]:
 ```
 
 Enter a longer description of the stack for your README.","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 422a5d2a..f2570bfb 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -45,7 +45,7 @@ stack_org [my-project]:
 Select an image from the `jupyter/docker-stacks` project that will serve as the base for your new image.
 
 ```text
-stack_base_image [jupyter/base-notebook]:
+stack_base_image [quay.io/jupyter/base-notebook]:
 ```
 
 Enter a longer description of the stack for your README.",Yes
docs/using/recipe_code/spellcheck_notebookv6.dockerfile,docs/using/recipe_code/spellcheck_notebookv6.dockerfile,119766df2973b669561efae4f832dbb6b499042f,ee7b9133fb42eaad86aed4e59e6ba4bf3acc486e,Use Docker Hub for an old image,"diff --git a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
index 36e374cb..1e12b562 100644
--- a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
+++ b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
@@ -1,4 +1,5 @@
-FROM quay.io/jupyter/base-notebook:notebook-6.5.4
+# Using Docker Hub here, because this image is old and not pushed to Quay.io
+FROM docker.io/jupyter/base-notebook:notebook-6.5.4
 
 RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \","diff --git a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
index 36e374cb..1e12b562 100644
--- a/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
+++ b/docs/using/recipe_code/spellcheck_notebookv6.dockerfile
@@ -1,4 +1,5 @@
-FROM quay.io/jupyter/base-notebook:notebook-6.5.4
+# Using Docker Hub here, because this image is old and not pushed to Quay.io
+FROM docker.io/jupyter/base-notebook:notebook-6.5.4
 
 RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
     jupyter contrib nbextension install --user && \",Yes
README.md,README.md,52f79605f30e126e610ea8fa8032e517e1a4a419,119766df2973b669561efae4f832dbb6b499042f,Update example date,"diff --git a/README.md b/README.md
index 2330076b..6da06fc6 100644
--- a/README.md
+++ b/README.md
@@ -27,11 +27,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-09-25
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-10-20
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -46,11 +46,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-10-20
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -120,7 +120,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-09-25`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-10-20`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images","diff --git a/README.md b/README.md
index 2330076b..6da06fc6 100644
--- a/README.md
+++ b/README.md
@@ -27,11 +27,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-09-25
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-10-20
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -46,11 +46,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-10-20
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -120,7 +120,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-09-25`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-10-20`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images",Yes
binder/Dockerfile,binder/Dockerfile,52f79605f30e126e610ea8fa8032e517e1a4a419,119766df2973b669561efae4f832dbb6b499042f,Update example date,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 9c2a7616..250246ce 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-09-25
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-10-20
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-09-25""
+ENV TAG=""2023-10-20""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 9c2a7616..250246ce 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-09-25
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-10-20
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-09-25""
+ENV TAG=""2023-10-20""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,52f79605f30e126e610ea8fa8032e517e1a4a419,119766df2973b669561efae4f832dbb6b499042f,Update example date,"diff --git a/docs/using/running.md b/docs/using/running.md
index 77b05c6c..030c54f6 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-09-25
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-20
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-09-25                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-10-20                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-10-20
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -137,7 +137,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -146,7 +146,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2023-09-25
+    quay.io/jupyter/r-notebook:2023-10-20
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 77b05c6c..030c54f6 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-09-25
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-20
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-09-25                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-10-20                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-09-25
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-10-20
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -137,7 +137,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-09-25` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -146,7 +146,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2023-09-25
+    quay.io/jupyter/r-notebook:2023-10-20
 ```
 
 ```{warning}",Yes
README.md,README.md,65be44707a9a99acd433ac00320ae0142ba299dc,52f79605f30e126e610ea8fa8032e517e1a4a419,Add registry to old images,"diff --git a/README.md b/README.md
index 6da06fc6..273bdcc1 100644
--- a/README.md
+++ b/README.md
@@ -127,14 +127,14 @@ more information is available in the [documentation](https://jupyter-docker-stac
 This project only builds one set of images at a time.
 If you want to use older `Ubuntu` and/or `python` version, you can use following images:
 
-| Build Date   | Ubuntu | Python | Tag            |
-| ------------ | ------ | ------ | -------------- |
-| 2022-10-09   | 20.04  | 3.7    | `1aac87eb7fa5` |
-| 2022-10-09   | 20.04  | 3.8    | `a374cab4fcb6` |
-| 2022-10-09   | 20.04  | 3.9    | `5ae537728c69` |
-| 2022-10-09   | 20.04  | 3.10   | `f3079808ca8c` |
-| 2022-10-09   | 22.04  | 3.7    | `b86753318aa1` |
-| 2022-10-09   | 22.04  | 3.8    | `7285848c0a11` |
-| 2022-10-09   | 22.04  | 3.9    | `ed2908bbb62e` |
-| 2023-05-30   | 22.04  | 3.10   | `4d70cf8da953` |
-| weekly build | 22.04  | 3.11   | `latest`       |
+| Build Date   | Ubuntu | Python | Registry  | Tag            |
+| ------------ | ------ | ------ | --------- | -------------- |
+| 2022-10-09   | 20.04  | 3.7    | docker.io | `1aac87eb7fa5` |
+| 2022-10-09   | 20.04  | 3.8    | docker.io | `a374cab4fcb6` |
+| 2022-10-09   | 20.04  | 3.9    | docker.io | `5ae537728c69` |
+| 2022-10-09   | 20.04  | 3.10   | docker.io | `f3079808ca8c` |
+| 2022-10-09   | 22.04  | 3.7    | docker.io | `b86753318aa1` |
+| 2022-10-09   | 22.04  | 3.8    | docker.io | `7285848c0a11` |
+| 2022-10-09   | 22.04  | 3.9    | docker.io | `ed2908bbb62e` |
+| 2023-05-30   | 22.04  | 3.10   | docker.io | `4d70cf8da953` |
+| weekly build | 22.04  | 3.11   | quay.io   | `latest`       |","diff --git a/README.md b/README.md
index 6da06fc6..273bdcc1 100644
--- a/README.md
+++ b/README.md
@@ -127,14 +127,14 @@ more information is available in the [documentation](https://jupyter-docker-stac
 This project only builds one set of images at a time.
 If you want to use older `Ubuntu` and/or `python` version, you can use following images:
 
-| Build Date   | Ubuntu | Python | Tag            |
-| ------------ | ------ | ------ | -------------- |
-| 2022-10-09   | 20.04  | 3.7    | `1aac87eb7fa5` |
-| 2022-10-09   | 20.04  | 3.8    | `a374cab4fcb6` |
-| 2022-10-09   | 20.04  | 3.9    | `5ae537728c69` |
-| 2022-10-09   | 20.04  | 3.10   | `f3079808ca8c` |
-| 2022-10-09   | 22.04  | 3.7    | `b86753318aa1` |
-| 2022-10-09   | 22.04  | 3.8    | `7285848c0a11` |
-| 2022-10-09   | 22.04  | 3.9    | `ed2908bbb62e` |
-| 2023-05-30   | 22.04  | 3.10   | `4d70cf8da953` |
-| weekly build | 22.04  | 3.11   | `latest`       |
+| Build Date   | Ubuntu | Python | Registry  | Tag            |
+| ------------ | ------ | ------ | --------- | -------------- |
+| 2022-10-09   | 20.04  | 3.7    | docker.io | `1aac87eb7fa5` |
+| 2022-10-09   | 20.04  | 3.8    | docker.io | `a374cab4fcb6` |
+| 2022-10-09   | 20.04  | 3.9    | docker.io | `5ae537728c69` |
+| 2022-10-09   | 20.04  | 3.10   | docker.io | `f3079808ca8c` |
+| 2022-10-09   | 22.04  | 3.7    | docker.io | `b86753318aa1` |
+| 2022-10-09   | 22.04  | 3.8    | docker.io | `7285848c0a11` |
+| 2022-10-09   | 22.04  | 3.9    | docker.io | `ed2908bbb62e` |
+| 2023-05-30   | 22.04  | 3.10   | docker.io | `4d70cf8da953` |
+| weekly build | 22.04  | 3.11   | quay.io   | `latest`       |",Yes
aarch64-runner/setup.sh,aarch64-runner/setup.sh,f8c232a9d96dce30e019a98ba5e1d3f0d79982cd,65be44707a9a99acd433ac00320ae0142ba299dc,Use apt-get update --yes,"diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index dd8d40a0..2d3956be 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -23,14 +23,14 @@ curl -sS https://bootstrap.pypa.io/get-pip.py | python3
 
 echo ""Setting up docker""
 apt-get remove --yes docker.io docker-doc docker-compose podman-docker containerd runc
-apt-get update
+apt-get update --yes
 apt-get install --yes ca-certificates curl gnupg
 install -m 0755 -d /etc/apt/keyrings
 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
 chmod a+r /etc/apt/keyrings/docker.gpg
 echo ""deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"" | \
     tee /etc/apt/sources.list.d/docker.list > /dev/null
-apt-get update
+apt-get update --yes
 apt-get install --yes docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
 
 usermod -aG docker ${GITHUB_RUNNER_USER}","diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index dd8d40a0..2d3956be 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -23,14 +23,14 @@ curl -sS https://bootstrap.pypa.io/get-pip.py | python3
 
 echo ""Setting up docker""
 apt-get remove --yes docker.io docker-doc docker-compose podman-docker containerd runc
-apt-get update
+apt-get update --yes
 apt-get install --yes ca-certificates curl gnupg
 install -m 0755 -d /etc/apt/keyrings
 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
 chmod a+r /etc/apt/keyrings/docker.gpg
 echo ""deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"" | \
     tee /etc/apt/sources.list.d/docker.list > /dev/null
-apt-get update
+apt-get update --yes
 apt-get install --yes docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
 
 usermod -aG docker ${GITHUB_RUNNER_USER}",Yes
docs/contributing/features.md,docs/contributing/features.md,5d62545ea2d723fdbbb44550d0e9d2471826a571,f8c232a9d96dce30e019a98ba5e1d3f0d79982cd,Update issue links,"diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 86c6289e..83684174 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -8,7 +8,7 @@ community with the cost of maintaining the images over time.
 
 Please follow the process below to suggest a new feature for inclusion in one of the core stacks:
 
-1. Open a [GitHub feature request issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3AEnhancement&template=feature_request.md&title=)
+1. Open a [GitHub feature request issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3AEnhancement&projects=&template=feature_request.yml)
    describing the feature you'd like to contribute.
 2. Discuss with the maintainers whether the addition makes sense in
    [one of the core stacks](../using/selecting.md#core-stacks), as a","diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 86c6289e..83684174 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -8,7 +8,7 @@ community with the cost of maintaining the images over time.
 
 Please follow the process below to suggest a new feature for inclusion in one of the core stacks:
 
-1. Open a [GitHub feature request issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3AEnhancement&template=feature_request.md&title=)
+1. Open a [GitHub feature request issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3AEnhancement&projects=&template=feature_request.yml)
    describing the feature you'd like to contribute.
 2. Discuss with the maintainers whether the addition makes sense in
    [one of the core stacks](../using/selecting.md#core-stacks), as a",Yes
docs/contributing/issues.md,docs/contributing/issues.md,5d62545ea2d723fdbbb44550d0e9d2471826a571,f8c232a9d96dce30e019a98ba5e1d3f0d79982cd,Update issue links,"diff --git a/docs/contributing/issues.md b/docs/contributing/issues.md
index 0f133c09..680d584b 100644
--- a/docs/contributing/issues.md
+++ b/docs/contributing/issues.md
@@ -9,7 +9,7 @@ Please review the following guidelines when reporting your problem.
 - If you think your problem is unique to the Jupyter Docker Stacks images,
   please search the [jupyter/docker-stacks issue tracker](https://github.com/jupyter/docker-stacks/issues)
   to see if someone else has already reported the same problem.
-  If not, please open a [GitHub bug report issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3ABug&template=bug_report.md&title=)
+  If not, please open a [GitHub bug report issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3ABug&projects=&template=bug_report.yml)
   and provide all the information requested in the issue template.
   Additionally, check the [Troubleshooting Common Problems](../using/troubleshooting.md) page in the documentation before submitting an issue.
 - If the issue you're seeing is with one of the open-source libraries included in the Docker images and is reproducible outside the images,","diff --git a/docs/contributing/issues.md b/docs/contributing/issues.md
index 0f133c09..680d584b 100644
--- a/docs/contributing/issues.md
+++ b/docs/contributing/issues.md
@@ -9,7 +9,7 @@ Please review the following guidelines when reporting your problem.
 - If you think your problem is unique to the Jupyter Docker Stacks images,
   please search the [jupyter/docker-stacks issue tracker](https://github.com/jupyter/docker-stacks/issues)
   to see if someone else has already reported the same problem.
-  If not, please open a [GitHub bug report issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3ABug&template=bug_report.md&title=)
+  If not, please open a [GitHub bug report issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3ABug&projects=&template=bug_report.yml)
   and provide all the information requested in the issue template.
   Additionally, check the [Troubleshooting Common Problems](../using/troubleshooting.md) page in the documentation before submitting an issue.
 - If the issue you're seeing is with one of the open-source libraries included in the Docker images and is reproducible outside the images,",Yes
docs/contributing/features.md,docs/contributing/features.md,e1ad1e302b132c842c4bbbc7cd6918f1fe8e822f,5d62545ea2d723fdbbb44550d0e9d2471826a571,Make features.md source code more readable,"diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 83684174..376a7c9b 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -1,8 +1,8 @@
 # New Features
 
-Thank you for contributing to the Jupyter Docker Stacks! We review pull requests for new features
-(e.g., new packages, new scripts, new flags) to balance the value of the images to the Jupyter
-community with the cost of maintaining the images over time.
+Thank you for contributing to the Jupyter Docker Stacks!
+We review pull requests for new features (e.g., new packages, new scripts, new flags)
+to balance the value of the images to the Jupyter community with the cost of maintaining the images over time.
 
 ## Suggesting a New Feature
 
@@ -10,27 +10,33 @@ Please follow the process below to suggest a new feature for inclusion in one of
 
 1. Open a [GitHub feature request issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3AEnhancement&projects=&template=feature_request.yml)
    describing the feature you'd like to contribute.
-2. Discuss with the maintainers whether the addition makes sense in
-   [one of the core stacks](../using/selecting.md#core-stacks), as a
-   [recipe in the documentation](recipes.md), as a [community stack](stacks.md), or as something
-   else entirely.
+2. Discuss with the maintainers whether the addition makes sense
+   in [one of the core stacks](../using/selecting.md#core-stacks),
+   as a [recipe in the documentation](recipes.md),
+   as a [community stack](stacks.md),
+   or as something else entirely.
 
 ## Selection Criteria
 
 Roughly speaking, we evaluate new features based on the following criteria:
 
-- **Usefulness to Jupyter users**: Is the feature generally applicable across domains? Does it work
-  with JupyterLab, Jupyter Notebook, JupyterHub, etc.?
-- **Fit with the image purpose**: Does the feature match the theme of the stack in which it will be
-  added? Would it fit better in a new community stack?
-- **Complexity of build/runtime configuration**: How many lines of code does the feature require
-  in one of the Dockerfiles or startup scripts? Does it require new scripts entirely? Do users need
-  to adjust how they use the images?
-- **Impact on image metrics**: How many bytes does the feature and its dependencies add to the
-  image(s)? How many minutes do they add to the build time?
-- **Ability to support the addition**: Can existing maintainers answer user questions and address
-  future build issues? Are the contributors interested in helping with long-term maintenance? Can we
-  write tests to ensure the feature continues to work over time?
+- **Usefulness to Jupyter users**:
+  Is the feature generally applicable across domains?
+  Does it work with JupyterLab, Jupyter Notebook, JupyterHub, etc.?
+- **Fit with the image purpose**:
+  Does the feature match the theme of the stack in which it will be added?
+  Would it fit better in a new community stack?
+- **Complexity of build/runtime configuration**:
+  How many lines of code does the feature require in one of the Dockerfiles or startup scripts?
+  Does it require new scripts entirely?
+  Do users need to adjust how they use the images?
+- **Impact on image metrics**:
+  How many bytes does the feature and its dependencies add to the image(s)?
+  How many minutes do they add to the build time?
+- **Ability to support the addition**:
+  Can existing maintainers answer user questions and address future build issues?
+  Are the contributors interested in helping with long-term maintenance?
+  Can we write tests to ensure the feature continues to work over time?
 
 ## Submitting a Pull Request
 
@@ -43,7 +49,7 @@ If there's agreement that the feature belongs in one or more of the core stacks:
    If you use `make`, call:
 
    ```bash
-   make build/somestack-notebook
+   make build/<somestack>-notebook
    ```
 
 3. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)(PR) with your changes.","diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 83684174..376a7c9b 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -1,8 +1,8 @@
 # New Features
 
-Thank you for contributing to the Jupyter Docker Stacks! We review pull requests for new features
-(e.g., new packages, new scripts, new flags) to balance the value of the images to the Jupyter
-community with the cost of maintaining the images over time.
+Thank you for contributing to the Jupyter Docker Stacks!
+We review pull requests for new features (e.g., new packages, new scripts, new flags)
+to balance the value of the images to the Jupyter community with the cost of maintaining the images over time.
 
 ## Suggesting a New Feature
 
@@ -10,27 +10,33 @@ Please follow the process below to suggest a new feature for inclusion in one of
 
 1. Open a [GitHub feature request issue](https://github.com/jupyter/docker-stacks/issues/new?assignees=&labels=type%3AEnhancement&projects=&template=feature_request.yml)
    describing the feature you'd like to contribute.
-2. Discuss with the maintainers whether the addition makes sense in
-   [one of the core stacks](../using/selecting.md#core-stacks), as a
-   [recipe in the documentation](recipes.md), as a [community stack](stacks.md), or as something
-   else entirely.
+2. Discuss with the maintainers whether the addition makes sense
+   in [one of the core stacks](../using/selecting.md#core-stacks),
+   as a [recipe in the documentation](recipes.md),
+   as a [community stack](stacks.md),
+   or as something else entirely.
 
 ## Selection Criteria
 
 Roughly speaking, we evaluate new features based on the following criteria:
 
-- **Usefulness to Jupyter users**: Is the feature generally applicable across domains? Does it work
-  with JupyterLab, Jupyter Notebook, JupyterHub, etc.?
-- **Fit with the image purpose**: Does the feature match the theme of the stack in which it will be
-  added? Would it fit better in a new community stack?
-- **Complexity of build/runtime configuration**: How many lines of code does the feature require
-  in one of the Dockerfiles or startup scripts? Does it require new scripts entirely? Do users need
-  to adjust how they use the images?
-- **Impact on image metrics**: How many bytes does the feature and its dependencies add to the
-  image(s)? How many minutes do they add to the build time?
-- **Ability to support the addition**: Can existing maintainers answer user questions and address
-  future build issues? Are the contributors interested in helping with long-term maintenance? Can we
-  write tests to ensure the feature continues to work over time?
+- **Usefulness to Jupyter users**:
+  Is the feature generally applicable across domains?
+  Does it work with JupyterLab, Jupyter Notebook, JupyterHub, etc.?
+- **Fit with the image purpose**:
+  Does the feature match the theme of the stack in which it will be added?
+  Would it fit better in a new community stack?
+- **Complexity of build/runtime configuration**:
+  How many lines of code does the feature require in one of the Dockerfiles or startup scripts?
+  Does it require new scripts entirely?
+  Do users need to adjust how they use the images?
+- **Impact on image metrics**:
+  How many bytes does the feature and its dependencies add to the image(s)?
+  How many minutes do they add to the build time?
+- **Ability to support the addition**:
+  Can existing maintainers answer user questions and address future build issues?
+  Are the contributors interested in helping with long-term maintenance?
+  Can we write tests to ensure the feature continues to work over time?
 
 ## Submitting a Pull Request
 
@@ -43,7 +49,7 @@ If there's agreement that the feature belongs in one or more of the core stacks:
    If you use `make`, call:
 
    ```bash
-   make build/somestack-notebook
+   make build/<somestack>-notebook
    ```
 
 3. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)(PR) with your changes.",Yes
docs/contributing/features.md,docs/contributing/features.md,02e70622502dc127957797932b7db06d8ca2175e,e1ad1e302b132c842c4bbbc7cd6918f1fe8e822f,Unify <somestack> usage,"diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 376a7c9b..82d268df 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -49,7 +49,7 @@ If there's agreement that the feature belongs in one or more of the core stacks:
    If you use `make`, call:
 
    ```bash
-   make build/<somestack>-notebook
+   make build/<somestack>
    ```
 
 3. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)(PR) with your changes.","diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 376a7c9b..82d268df 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -49,7 +49,7 @@ If there's agreement that the feature belongs in one or more of the core stacks:
    If you use `make`, call:
 
    ```bash
-   make build/<somestack>-notebook
+   make build/<somestack>
    ```
 
 3. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)(PR) with your changes.",Yes
tests/docker-stacks-foundation/test_units.py,tests/docker-stacks-foundation/test_units.py,02e70622502dc127957797932b7db06d8ca2175e,e1ad1e302b132c842c4bbbc7cd6918f1fe8e822f,Unify <somestack> usage,"diff --git a/tests/docker-stacks-foundation/test_units.py b/tests/docker-stacks-foundation/test_units.py
index 85d07862..84844498 100644
--- a/tests/docker-stacks-foundation/test_units.py
+++ b/tests/docker-stacks-foundation/test_units.py
@@ -10,7 +10,7 @@ LOGGER = logging.getLogger(__name__)
 
 def test_units(container: TrackedContainer) -> None:
     """"""Various units tests
-    Add a py file in the `tests/{somestack}-notebook/units` dir, and it will be automatically tested
+    Add a py file in the `tests/<somestack>/units` dir, and it will be automatically tested
     """"""
     short_image_name = container.image_name[container.image_name.rfind(""/"") + 1 :]
     LOGGER.info(f""Running unit tests for: {short_image_name}"")","diff --git a/tests/docker-stacks-foundation/test_units.py b/tests/docker-stacks-foundation/test_units.py
index 85d07862..84844498 100644
--- a/tests/docker-stacks-foundation/test_units.py
+++ b/tests/docker-stacks-foundation/test_units.py
@@ -10,7 +10,7 @@ LOGGER = logging.getLogger(__name__)
 
 def test_units(container: TrackedContainer) -> None:
     """"""Various units tests
-    Add a py file in the `tests/{somestack}-notebook/units` dir, and it will be automatically tested
+    Add a py file in the `tests/<somestack>/units` dir, and it will be automatically tested
     """"""
     short_image_name = container.image_name[container.image_name.rfind(""/"") + 1 :]
     LOGGER.info(f""Running unit tests for: {short_image_name}"")",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,3aed21ef441f6b45633a745b56b96a6f1c80a8fa,02e70622502dc127957797932b7db06d8ca2175e,Improve wording in tasks.md,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 4bc1fc0d..536601e3 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -14,12 +14,13 @@ To build new images and publish them to the Registry, do the following:
    except single-platform images are pushed to Registry and then tags are merged for `x86_64` and `aarch64`.
    ```
 
-4. Avoid merging another PR to the main branch until all pending builds are complete.
-   This way, you will know which commit might have broken the build and also have the correct tags for moving tags (like the `python` version).
+4. Avoid merging another PR to the main branch until all pending builds in the main branch are complete.
+   This way, you will know which commit might have broken the build
+   and also have the correct tags for moving tags (like the `python` version).
 
 ## Updating Python version
 
-When a new `Python` version is released, we wait for two things:
+When a new `Python` version is released, we wait for:
 
 - all the dependencies to be available (as wheels or in `conda-forge`).
 - the first `python` patch release for this version.
@@ -27,18 +28,20 @@ When a new `Python` version is released, we wait for two things:
 
 ## Updating the Ubuntu Base Image
 
-`docker-stacks-foundation` is based on the LTS Ubuntu docker image.
+`jupyter/docker-stacks-foundation` is based on the LTS Ubuntu docker image.
 We wait for the first point release of the new LTS Ubuntu before updating the version.
 Other images are directly or indirectly inherited from `docker-stacks-foundation`.
 We rebuild our images automatically each week, which means they frequently receive updates.
 
-When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger images rebuild [from the GitHub actions workflow UI](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml).
+When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger images rebuild
+[from the GitHub actions workflow UI](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml).
 Pushing the `Run Workflow` button will trigger this process.
 
 ## Adding a New Core Image to the Registry
 
 ```{note}
-In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
+In general, we do not add new core images and ask contributors to either
+create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
 ```
 
 You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1936/files).
@@ -46,20 +49,19 @@ You can see an example of adding a new image [here](https://github.com/jupyter/d
 When there's a new stack definition, check before merging the PR:
 
 1. PR includes an update to the stack overview diagram
-   [in the documentation](https://github.com/jupyter/docker-stacks/blob/main/docs/using/selecting.md#image-relationships).
+   [in the documentation](../using/selecting.md#image-relationships).
    The image links to the [blockdiag source](http://interactive.blockdiag.com/) used to create it.
-2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
-3. Necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
-4. A new repository is created in the `jupyter` org in the Registry,
+2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile),
+   which is used to build the stacks in order on GitHub Actions.
+3. Necessary Tagger(s)/Manifest(s) are added for the new image
+   in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
+4. A new repository is created in the `jupyter` organization in the Registry,
    and it's named after the stack folder in the git repo.
-5. Grant the `stacks` team permission to write to this repo.
 
-## Adding a New Maintainer Account
+## Adding a New Registry Owner Account
 
 1. Visit <https://quay.io/organization/jupyter/teams/owners>
 2. Add the maintainer's username.
-3. Visit <https://github.com/orgs/jupyter/teams/docker-image-maintainers/members>
-4. Add the maintainer's GitHub username.
 
 ## Restarting a failed build","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 4bc1fc0d..536601e3 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -14,12 +14,13 @@ To build new images and publish them to the Registry, do the following:
    except single-platform images are pushed to Registry and then tags are merged for `x86_64` and `aarch64`.
    ```
 
-4. Avoid merging another PR to the main branch until all pending builds are complete.
-   This way, you will know which commit might have broken the build and also have the correct tags for moving tags (like the `python` version).
+4. Avoid merging another PR to the main branch until all pending builds in the main branch are complete.
+   This way, you will know which commit might have broken the build
+   and also have the correct tags for moving tags (like the `python` version).
 
 ## Updating Python version
 
-When a new `Python` version is released, we wait for two things:
+When a new `Python` version is released, we wait for:
 
 - all the dependencies to be available (as wheels or in `conda-forge`).
 - the first `python` patch release for this version.
@@ -27,18 +28,20 @@ When a new `Python` version is released, we wait for two things:
 
 ## Updating the Ubuntu Base Image
 
-`docker-stacks-foundation` is based on the LTS Ubuntu docker image.
+`jupyter/docker-stacks-foundation` is based on the LTS Ubuntu docker image.
 We wait for the first point release of the new LTS Ubuntu before updating the version.
 Other images are directly or indirectly inherited from `docker-stacks-foundation`.
 We rebuild our images automatically each week, which means they frequently receive updates.
 
-When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger images rebuild [from the GitHub actions workflow UI](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml).
+When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger images rebuild
+[from the GitHub actions workflow UI](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml).
 Pushing the `Run Workflow` button will trigger this process.
 
 ## Adding a New Core Image to the Registry
 
 ```{note}
-In general, we do not add new core images and ask contributors to either create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
+In general, we do not add new core images and ask contributors to either
+create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
 ```
 
 You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1936/files).
@@ -46,20 +49,19 @@ You can see an example of adding a new image [here](https://github.com/jupyter/d
 When there's a new stack definition, check before merging the PR:
 
 1. PR includes an update to the stack overview diagram
-   [in the documentation](https://github.com/jupyter/docker-stacks/blob/main/docs/using/selecting.md#image-relationships).
+   [in the documentation](../using/selecting.md#image-relationships).
    The image links to the [blockdiag source](http://interactive.blockdiag.com/) used to create it.
-2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile), which is used to build the stacks in order on GitHub Actions.
-3. Necessary tags/manifests are added for the new image in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
-4. A new repository is created in the `jupyter` org in the Registry,
+2. PR updates the [Makefile](https://github.com/jupyter/docker-stacks/blob/main/Makefile),
+   which is used to build the stacks in order on GitHub Actions.
+3. Necessary Tagger(s)/Manifest(s) are added for the new image
+   in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
+4. A new repository is created in the `jupyter` organization in the Registry,
    and it's named after the stack folder in the git repo.
-5. Grant the `stacks` team permission to write to this repo.
 
-## Adding a New Maintainer Account
+## Adding a New Registry Owner Account
 
 1. Visit <https://quay.io/organization/jupyter/teams/owners>
 2. Add the maintainer's username.
-3. Visit <https://github.com/orgs/jupyter/teams/docker-image-maintainers/members>
-4. Add the maintainer's GitHub username.
 
 ## Restarting a failed build",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,ad28158ab11114cdfe7326c88bedd4a904396fd1,3aed21ef441f6b45633a745b56b96a6f1c80a8fa,Make troubleshooting.md source code more readable,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index d23b8777..89ef2298 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -1,10 +1,10 @@
 # Troubleshooting Common Problems
 
 When troubleshooting, you may see unexpected behaviors or receive an error message.
-This section provides advice on
-how to identify and fix some of the most commonly encountered issues.
+This section provides advice on how to identify and fix some of the most commonly encountered issues.
 
-Most of the `docker run` flags used in this document are explained in detail in the [Common Features, Docker Options section](common.md#docker-options) of the documentation.
+Most of the `docker run` flags used in this document are explained in detail in the
+[Common Features, Docker Options section](common.md#docker-options) of the documentation.
 
 ## Permission denied when mounting volumes
 
@@ -29,14 +29,16 @@ touch stagingarea/kale.txt
 # touch: cannot touch 'stagingarea/kale.txt': Permission denied
 ```
 
-In this case, the user of the container (`jovyan`) and the owner of the mounted volume (`root`) have different permission levels and ownership over the container's directories and mounts.
+In this case, the user of the container (`jovyan`) and the owner of the mounted volume (`root`)
+have different permission levels and ownership over the container's directories and mounts.
 The following sections cover a few of these scenarios and how to fix them.
 
 **Some things to try:**
 
 1. **Change ownership of the volume mount**
 
-   You can change the ownership of the volume mount using the `chown` command. In the case of the docker-stacks images, you can set the `CHOWN_EXTRA` and `CHOWN_EXTRA_OPTS` environment variables.
+   You can change the ownership of the volume mount using the `chown` command.
+   In the case of the docker-stacks images, you can set the `CHOWN_EXTRA` and `CHOWN_EXTRA_OPTS` environment variables.
 
    For example, to change the ownership of the volume mount to the jovyan user (non-privileged default user in the Docker images):
 
@@ -53,7 +55,8 @@ The following sections cover a few of these scenarios and how to fix them.
 
    where:
 
-   - `CHOWN_EXTRA=<some-dir>,<some-other-dir>`: will change the ownership and group of the specified container directory (non-recursive by default). You need to provide full paths starting with `/`.
+   - `CHOWN_EXTRA=<some-dir>,<some-other-dir>`: will change the ownership and group of the specified container directory (non-recursive by default).
+     You need to provide full paths starting with `/`.
    - `CHOWN_EXTRA_OPTS=""-R""`: will recursively change the ownership and group of the directory specified in `CHOWN_EXTRA`.
    - `--user root`: you **must** run the container with the root user to change ownership at runtime.
 
@@ -85,8 +88,9 @@ The following sections cover a few of these scenarios and how to fix them.
    Therefore, the permissions and ownership are copied over and will be **the same** as the ones in your local host
    (including user ids) which may result in permissions errors when trying to access directories or create/modify files inside.
 
-   Suppose your local user has a `UID` and `GID` of `1234` and `5678`, respectively. To fix the UID discrepancies between your local directories and the container's
-   directories, you can run the container with an explicit `NB_UID` and `NB_GID` to match that of the local user:
+   Suppose your local user has a `UID` and `GID` of `1234` and `5678`, respectively.
+   To fix the UID discrepancies between your local directories and the container's directories,
+   you can run the container with an explicit `NB_UID` and `NB_GID` to match that of the local user:
 
    ```bash
    docker run -it --rm \
@@ -108,10 +112,12 @@ The following sections cover a few of these scenarios and how to fix them.
    - You **must** use `--user root` to ensure that the `UID` and `GID` are updated at runtime.
 
 ````{admonition} Additional notes
-- The caveat with this approach is that since these changes are applied at runtime, you will need to re-run the same command
-   with the appropriate flags and environment variables if you need to recreate the container (i.e. after removing/destroying it).
+- The caveat with this approach is that since these changes are applied at runtime,
+   you will need to re-run the same command with the appropriate flags and environment variables
+   if you need to recreate the container (i.e. after removing/destroying it).
  - If you pass a numeric UID, it **must** be in the range of 0-2147483647
- - This approach only updates the UID and GID of the **existing `jovyan` user** instead of creating a new user. From the above example:
+ - This approach only updates the UID and GID of the **existing `jovyan` user** instead of creating a new user.
+   From the above example:
    ```bash
    id
    # uid=1234(jovyan) gid=5678(jovyan) groups=5678(jovyan),100(users)
@@ -167,14 +173,16 @@ If you have also **created a new user**, you might be experiencing any of the fo
    ```{admonition} Additional notes
     In the example above, the `-v` flag is used to mount the local volume onto the new user's `/home` directory.
 
-    However, if you are mounting a volume elsewhere, you also need to use the `-e CHOWN_EXTRA=<some-dir>` flag to avoid any permission
-    issues (see the section [Permission denied when mounting volumes](#permission-denied-when-mounting-volumes) on this page).
+    However, if you are mounting a volume elsewhere,
+    you also need to use the `-e CHOWN_EXTRA=<some-dir>` flag to avoid any permission issues
+    (see the section [Permission denied when mounting volumes](#permission-denied-when-mounting-volumes) on this page).
    ```
 
 2. **Dynamically assign the user ID and GID**
 
    The above case ensures that the `/home` directory is owned by a newly created user with a specific `UID` and `GID`,
-   but if you want to assign the `UID` and `GID` of the new user dynamically, you can make the following adjustments:
+   but if you want to assign the `UID` and `GID` of the new user dynamically,
+   you can make the following adjustments:
 
    ```bash
    docker run -it --rm \
@@ -202,8 +210,8 @@ If you have also **created a new user**, you might be experiencing any of the fo
   -v ""${PWD}""/<my-vol>:/home/jovyan/work
   ```
 
-  This example uses the syntax `${PWD}`, which is replaced with the full path to the current directory at runtime. The destination
-  path should also be an absolute path starting with a `/` such as `/home/jovyan/work`.
+  This example uses the syntax `${PWD}`, which is replaced with the full path to the current directory at runtime.
+  The destination path should also be an absolute path starting with a `/` such as `/home/jovyan/work`.
 
 - You might want to consider using the Docker native `--user <UID>` and `--group-add users` flags instead of `-e NB_UID` and `-e NB_GID`:
 
@@ -217,10 +225,12 @@ If you have also **created a new user**, you might be experiencing any of the fo
       -v <my-vol>:/home/jovyan/work quay.io/jupyter/datascience-notebook
   ```
 
-  This command will launch the container with a specific user UID and add that user to the `users` group to modify the files in the default `/home` and `/opt/conda` directories.
+  This command will launch the container with a specific user UID and add that user to the `users` group
+  to modify the files in the default `/home` and `/opt/conda` directories.
   Further avoiding issues when trying to `conda install` additional packages.
 
-- Use `docker inspect <container_id>` and look for the [`Mounts` section](https://docs.docker.com/storage/volumes/#start-a-container-with-a-volume) to verify that the volume was created and mounted accordingly:
+- Use `docker inspect <container_id>` and look for the [`Mounts` section](https://docs.docker.com/storage/volumes/#start-a-container-with-a-volume)
+  to verify that the volume was created and mounted accordingly:
 
   ```json
   {
@@ -241,7 +251,8 @@ If you have also **created a new user**, you might be experiencing any of the fo
 
 ## Problems installing conda packages from specific channels
 
-By default, the docker-stacks images have the conda channels priority set to `strict`. This may cause problems when trying to install packages from a channel with lower priority.
+By default, the docker-stacks images have the conda channels priority set to `strict`.
+This may cause problems when trying to install packages from a channel with lower priority.
 
 ```bash
 conda config --show | grep priority
@@ -270,7 +281,8 @@ Additional details are provided in the [Using alternative channels](../using/com
 
 ## Tokens are being rejected
 
-If you are a regular user of VSCode and the Jupyter extension, you might experience either of these issues when using any of the docker-stacks images:
+If you are a regular user of VSCode and the Jupyter extension,
+you might experience either of these issues when using any of the docker-stacks images:
 
 - when clicking on the URL displayed on your command line logs, you face a ""This site cannot be reached"" page on your web browser
 - using the produced token and/or URL results in an ""Invalid credentials"" error on the Jupyter ""Token authentication is enabled"" page
@@ -326,4 +338,5 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
 
    In this example, we use 8001, so the edited link would be: <http://127.0.0.1:8001/lab?token=80d45d241a1ba4c2...>.
 
-   Note: Port mapping for Jupyter has other applications outside of Docker. For example, it can be used to allow multiple Jupyter instances when using SSH to control cloud devices.
+   Note: Port mapping for Jupyter has other applications outside of Docker.
+   For example, it can be used to allow multiple Jupyter instances when using SSH to control cloud devices.","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index d23b8777..89ef2298 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -1,10 +1,10 @@
 # Troubleshooting Common Problems
 
 When troubleshooting, you may see unexpected behaviors or receive an error message.
-This section provides advice on
-how to identify and fix some of the most commonly encountered issues.
+This section provides advice on how to identify and fix some of the most commonly encountered issues.
 
-Most of the `docker run` flags used in this document are explained in detail in the [Common Features, Docker Options section](common.md#docker-options) of the documentation.
+Most of the `docker run` flags used in this document are explained in detail in the
+[Common Features, Docker Options section](common.md#docker-options) of the documentation.
 
 ## Permission denied when mounting volumes
 
@@ -29,14 +29,16 @@ touch stagingarea/kale.txt
 # touch: cannot touch 'stagingarea/kale.txt': Permission denied
 ```
 
-In this case, the user of the container (`jovyan`) and the owner of the mounted volume (`root`) have different permission levels and ownership over the container's directories and mounts.
+In this case, the user of the container (`jovyan`) and the owner of the mounted volume (`root`)
+have different permission levels and ownership over the container's directories and mounts.
 The following sections cover a few of these scenarios and how to fix them.
 
 **Some things to try:**
 
 1. **Change ownership of the volume mount**
 
-   You can change the ownership of the volume mount using the `chown` command. In the case of the docker-stacks images, you can set the `CHOWN_EXTRA` and `CHOWN_EXTRA_OPTS` environment variables.
+   You can change the ownership of the volume mount using the `chown` command.
+   In the case of the docker-stacks images, you can set the `CHOWN_EXTRA` and `CHOWN_EXTRA_OPTS` environment variables.
 
    For example, to change the ownership of the volume mount to the jovyan user (non-privileged default user in the Docker images):
 
@@ -53,7 +55,8 @@ The following sections cover a few of these scenarios and how to fix them.
 
    where:
 
-   - `CHOWN_EXTRA=<some-dir>,<some-other-dir>`: will change the ownership and group of the specified container directory (non-recursive by default). You need to provide full paths starting with `/`.
+   - `CHOWN_EXTRA=<some-dir>,<some-other-dir>`: will change the ownership and group of the specified container directory (non-recursive by default).
+     You need to provide full paths starting with `/`.
    - `CHOWN_EXTRA_OPTS=""-R""`: will recursively change the ownership and group of the directory specified in `CHOWN_EXTRA`.
    - `--user root`: you **must** run the container with the root user to change ownership at runtime.
 
@@ -85,8 +88,9 @@ The following sections cover a few of these scenarios and how to fix them.
    Therefore, the permissions and ownership are copied over and will be **the same** as the ones in your local host
    (including user ids) which may result in permissions errors when trying to access directories or create/modify files inside.
 
-   Suppose your local user has a `UID` and `GID` of `1234` and `5678`, respectively. To fix the UID discrepancies between your local directories and the container's
-   directories, you can run the container with an explicit `NB_UID` and `NB_GID` to match that of the local user:
+   Suppose your local user has a `UID` and `GID` of `1234` and `5678`, respectively.
+   To fix the UID discrepancies between your local directories and the container's directories,
+   you can run the container with an explicit `NB_UID` and `NB_GID` to match that of the local user:
 
    ```bash
    docker run -it --rm \
@@ -108,10 +112,12 @@ The following sections cover a few of these scenarios and how to fix them.
    - You **must** use `--user root` to ensure that the `UID` and `GID` are updated at runtime.
 
 ````{admonition} Additional notes
-- The caveat with this approach is that since these changes are applied at runtime, you will need to re-run the same command
-   with the appropriate flags and environment variables if you need to recreate the container (i.e. after removing/destroying it).
+- The caveat with this approach is that since these changes are applied at runtime,
+   you will need to re-run the same command with the appropriate flags and environment variables
+   if you need to recreate the container (i.e. after removing/destroying it).
  - If you pass a numeric UID, it **must** be in the range of 0-2147483647
- - This approach only updates the UID and GID of the **existing `jovyan` user** instead of creating a new user. From the above example:
+ - This approach only updates the UID and GID of the **existing `jovyan` user** instead of creating a new user.
+   From the above example:
    ```bash
    id
    # uid=1234(jovyan) gid=5678(jovyan) groups=5678(jovyan),100(users)
@@ -167,14 +173,16 @@ If you have also **created a new user**, you might be experiencing any of the fo
    ```{admonition} Additional notes
     In the example above, the `-v` flag is used to mount the local volume onto the new user's `/home` directory.
 
-    However, if you are mounting a volume elsewhere, you also need to use the `-e CHOWN_EXTRA=<some-dir>` flag to avoid any permission
-    issues (see the section [Permission denied when mounting volumes](#permission-denied-when-mounting-volumes) on this page).
+    However, if you are mounting a volume elsewhere,
+    you also need to use the `-e CHOWN_EXTRA=<some-dir>` flag to avoid any permission issues
+    (see the section [Permission denied when mounting volumes](#permission-denied-when-mounting-volumes) on this page).
    ```
 
 2. **Dynamically assign the user ID and GID**
 
    The above case ensures that the `/home` directory is owned by a newly created user with a specific `UID` and `GID`,
-   but if you want to assign the `UID` and `GID` of the new user dynamically, you can make the following adjustments:
+   but if you want to assign the `UID` and `GID` of the new user dynamically,
+   you can make the following adjustments:
 
    ```bash
    docker run -it --rm \
@@ -202,8 +210,8 @@ If you have also **created a new user**, you might be experiencing any of the fo
   -v ""${PWD}""/<my-vol>:/home/jovyan/work
   ```
 
-  This example uses the syntax `${PWD}`, which is replaced with the full path to the current directory at runtime. The destination
-  path should also be an absolute path starting with a `/` such as `/home/jovyan/work`.
+  This example uses the syntax `${PWD}`, which is replaced with the full path to the current directory at runtime.
+  The destination path should also be an absolute path starting with a `/` such as `/home/jovyan/work`.
 
 - You might want to consider using the Docker native `--user <UID>` and `--group-add users` flags instead of `-e NB_UID` and `-e NB_GID`:
 
@@ -217,10 +225,12 @@ If you have also **created a new user**, you might be experiencing any of the fo
       -v <my-vol>:/home/jovyan/work quay.io/jupyter/datascience-notebook
   ```
 
-  This command will launch the container with a specific user UID and add that user to the `users` group to modify the files in the default `/home` and `/opt/conda` directories.
+  This command will launch the container with a specific user UID and add that user to the `users` group
+  to modify the files in the default `/home` and `/opt/conda` directories.
   Further avoiding issues when trying to `conda install` additional packages.
 
-- Use `docker inspect <container_id>` and look for the [`Mounts` section](https://docs.docker.com/storage/volumes/#start-a-container-with-a-volume) to verify that the volume was created and mounted accordingly:
+- Use `docker inspect <container_id>` and look for the [`Mounts` section](https://docs.docker.com/storage/volumes/#start-a-container-with-a-volume)
+  to verify that the volume was created and mounted accordingly:
 
   ```json
   {
@@ -241,7 +251,8 @@ If you have also **created a new user**, you might be experiencing any of the fo
 
 ## Problems installing conda packages from specific channels
 
-By default, the docker-stacks images have the conda channels priority set to `strict`. This may cause problems when trying to install packages from a channel with lower priority.
+By default, the docker-stacks images have the conda channels priority set to `strict`.
+This may cause problems when trying to install packages from a channel with lower priority.
 
 ```bash
 conda config --show | grep priority
@@ -270,7 +281,8 @@ Additional details are provided in the [Using alternative channels](../using/com
 
 ## Tokens are being rejected
 
-If you are a regular user of VSCode and the Jupyter extension, you might experience either of these issues when using any of the docker-stacks images:
+If you are a regular user of VSCode and the Jupyter extension,
+you might experience either of these issues when using any of the docker-stacks images:
 
 - when clicking on the URL displayed on your command line logs, you face a ""This site cannot be reached"" page on your web browser
 - using the produced token and/or URL results in an ""Invalid credentials"" error on the Jupyter ""Token authentication is enabled"" page
@@ -326,4 +338,5 @@ If you are a regular user of VSCode and the Jupyter extension, you might experie
 
    In this example, we use 8001, so the edited link would be: <http://127.0.0.1:8001/lab?token=80d45d241a1ba4c2...>.
 
-   Note: Port mapping for Jupyter has other applications outside of Docker. For example, it can be used to allow multiple Jupyter instances when using SSH to control cloud devices.
+   Note: Port mapping for Jupyter has other applications outside of Docker.
+   For example, it can be used to allow multiple Jupyter instances when using SSH to control cloud devices.",Yes
docs/using/running.md,docs/using/running.md,b33174154062e33318b9b421b5aada8d46dcdc12,ad28158ab11114cdfe7326c88bedd4a904396fd1,Start new sentences on a new line in markdown,"diff --git a/docs/using/running.md b/docs/using/running.md
index 030c54f6..1a22172b 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -116,7 +116,8 @@ docker rm notebook
 
 ## Using the Podman CLI
 
-An alternative to using the Docker CLI is to use the Podman CLI. Podman is mostly compatible with Docker.
+An alternative to using the Docker CLI is to use the Podman CLI.
+Podman is mostly compatible with Docker.
 
 ### Podman example","diff --git a/docs/using/running.md b/docs/using/running.md
index 030c54f6..1a22172b 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -116,7 +116,8 @@ docker rm notebook
 
 ## Using the Podman CLI
 
-An alternative to using the Docker CLI is to use the Podman CLI. Podman is mostly compatible with Docker.
+An alternative to using the Docker CLI is to use the Podman CLI.
+Podman is mostly compatible with Docker.
 
 ### Podman example",Yes
docs/using/selecting.md,docs/using/selecting.md,b33174154062e33318b9b421b5aada8d46dcdc12,ad28158ab11114cdfe7326c88bedd4a904396fd1,Start new sentences on a new line in markdown,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index b335b5af..f85ab474 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -249,7 +249,8 @@ Whenever a docker image is pushed to the container registry, it is tagged with:
 - a set of software version tags like `python-3.10.8` and `lab-3.5.3`
 
 ```{warning}
-- Tags before `2022-07-05` were sometimes incorrect. Please, do not rely on them.
+- Tags before `2022-07-05` were sometimes incorrect.
+  Please, do not rely on them.
 - Single-platform images have either `aarch64` or `x86_64` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 ```","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index b335b5af..f85ab474 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -249,7 +249,8 @@ Whenever a docker image is pushed to the container registry, it is tagged with:
 - a set of software version tags like `python-3.10.8` and `lab-3.5.3`
 
 ```{warning}
-- Tags before `2022-07-05` were sometimes incorrect. Please, do not rely on them.
+- Tags before `2022-07-05` were sometimes incorrect.
+  Please, do not rely on them.
 - Single-platform images have either `aarch64` or `x86_64` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 ```",Yes
tagging/README.md,tagging/README.md,b33174154062e33318b9b421b5aada8d46dcdc12,ad28158ab11114cdfe7326c88bedd4a904396fd1,Start new sentences on a new line in markdown,"diff --git a/tagging/README.md b/tagging/README.md
index bb7edcca..11c2e758 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -12,10 +12,12 @@ For example, we dump all the `conda` packages, including their versions.
 
 ## Main principles
 
-- All the images are located in a hierarchical tree. More info on [image relationships](../docs/using/selecting.md#image-relationships).
+- All the images are located in a hierarchical tree.
+  More info on [image relationships](../docs/using/selecting.md#image-relationships).
 - We have `tagger` and `manifest` classes, which can be run inside docker containers to obtain tags and build manifest pieces.
 - These classes are inherited from the parent image to all the children images.
-- Because manifests and tags might change from parent to children, `taggers` and `manifests` are reevaluated on each image. So, the values are not inherited.
+- Because manifests and tags might change from parent to children, `taggers` and `manifests` are reevaluated on each image.
+  So, the values are not inherited.
 - To tag an image and create a manifest, run `make hook/base-notebook` (or another image of your choice).
 
 ## Source code description","diff --git a/tagging/README.md b/tagging/README.md
index bb7edcca..11c2e758 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -12,10 +12,12 @@ For example, we dump all the `conda` packages, including their versions.
 
 ## Main principles
 
-- All the images are located in a hierarchical tree. More info on [image relationships](../docs/using/selecting.md#image-relationships).
+- All the images are located in a hierarchical tree.
+  More info on [image relationships](../docs/using/selecting.md#image-relationships).
 - We have `tagger` and `manifest` classes, which can be run inside docker containers to obtain tags and build manifest pieces.
 - These classes are inherited from the parent image to all the children images.
-- Because manifests and tags might change from parent to children, `taggers` and `manifests` are reevaluated on each image. So, the values are not inherited.
+- Because manifests and tags might change from parent to children, `taggers` and `manifests` are reevaluated on each image.
+  So, the values are not inherited.
 - To tag an image and create a manifest, run `make hook/base-notebook` (or another image of your choice).
 
 ## Source code description",Yes
README.md,README.md,343ef3d174ea167e2e59f259fcd3f401c8ae9658,b33174154062e33318b9b421b5aada8d46dcdc12,Rearrange parts in README.md to and remove call for maintainers (#2013),"diff --git a/README.md b/README.md
index 273bdcc1..ee02477e 100644
--- a/README.md
+++ b/README.md
@@ -69,28 +69,6 @@ So, new notebooks will be saved there, unless you change the directory in the fi
 To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
-## Contributing
-
-Please see the [Contributor Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)
-for information about how to contribute recipes, features, tests, and community maintained stacks.
-
-## Maintainer Help Wanted
-
-We value all positive contributions to the Docker stacks project,
-from [bug reports](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/issues.html)
-to [pull requests](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/features.html#submitting-a-pull-request)
-to help with answering questions.
-We'd also like to invite members of the community to help with two maintainer activities:
-
-- **Issue triaging**: Reading and providing a first response to issues, labeling issues appropriately,
-  redirecting cross-project questions to Jupyter Discourse
-- **Pull request reviews**: Reading proposed documentation and code changes, working with the submitter
-  to improve the contribution, deciding if the contribution should take another form (e.g., a recipe
-  instead of a permanent change to the images)
-
-Anyone in the community can jump in and help with these activities anytime.
-We will happily grant additional permissions (e.g., the ability to merge PRs) to anyone who shows an ongoing interest in working on the project.
-
 ## Choosing Jupyter frontend
 
 JupyterLab is the default for all the Jupyter Docker Stacks images.
@@ -98,15 +76,6 @@ It is still possible to switch back to Jupyter Notebook (or to launch a differen
 You can achieve this by passing the environment variable `DOCKER_STACKS_JUPYTER_CMD=notebook` (or any other valid `jupyter` subcommand) at container startup;
 more information is available in the [documentation](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#alternative-commands).
 
-## Alternatives
-
-- [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) - Turn git repositories into
-  Jupyter-enabled Docker Images
-- [openshift/source-to-image](https://github.com/openshift/source-to-image) - A tool for
-  building artifacts from source and injecting them into docker images
-- [jupyter-on-openshift/jupyter-notebooks](https://github.com/jupyter-on-openshift/jupyter-notebooks) -
-  OpenShift compatible S2I builder for basic notebook images
-
 ## Resources
 
 - [Documentation on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)
@@ -138,3 +107,17 @@ If you want to use older `Ubuntu` and/or `python` version, you can use following
 | 2022-10-09   | 22.04  | 3.9    | docker.io | `ed2908bbb62e` |
 | 2023-05-30   | 22.04  | 3.10   | docker.io | `4d70cf8da953` |
 | weekly build | 22.04  | 3.11   | quay.io   | `latest`       |
+
+## Contributing
+
+Please see the [Contributor Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)
+for information about how to contribute recipes, features, tests, and community maintained stacks.
+
+## Alternatives
+
+- [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) -
+  Turn git repositories into Jupyter-enabled Docker Images
+- [openshift/source-to-image](https://github.com/openshift/source-to-image) -
+  A tool for building artifacts from source and injecting them into docker images
+- [jupyter-on-openshift/jupyter-notebooks](https://github.com/jupyter-on-openshift/jupyter-notebooks) -
+  OpenShift compatible S2I builder for basic notebook images","diff --git a/README.md b/README.md
index 273bdcc1..ee02477e 100644
--- a/README.md
+++ b/README.md
@@ -69,28 +69,6 @@ So, new notebooks will be saved there, unless you change the directory in the fi
 To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
-## Contributing
-
-Please see the [Contributor Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)
-for information about how to contribute recipes, features, tests, and community maintained stacks.
-
-## Maintainer Help Wanted
-
-We value all positive contributions to the Docker stacks project,
-from [bug reports](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/issues.html)
-to [pull requests](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/features.html#submitting-a-pull-request)
-to help with answering questions.
-We'd also like to invite members of the community to help with two maintainer activities:
-
-- **Issue triaging**: Reading and providing a first response to issues, labeling issues appropriately,
-  redirecting cross-project questions to Jupyter Discourse
-- **Pull request reviews**: Reading proposed documentation and code changes, working with the submitter
-  to improve the contribution, deciding if the contribution should take another form (e.g., a recipe
-  instead of a permanent change to the images)
-
-Anyone in the community can jump in and help with these activities anytime.
-We will happily grant additional permissions (e.g., the ability to merge PRs) to anyone who shows an ongoing interest in working on the project.
-
 ## Choosing Jupyter frontend
 
 JupyterLab is the default for all the Jupyter Docker Stacks images.
@@ -98,15 +76,6 @@ It is still possible to switch back to Jupyter Notebook (or to launch a differen
 You can achieve this by passing the environment variable `DOCKER_STACKS_JUPYTER_CMD=notebook` (or any other valid `jupyter` subcommand) at container startup;
 more information is available in the [documentation](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#alternative-commands).
 
-## Alternatives
-
-- [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) - Turn git repositories into
-  Jupyter-enabled Docker Images
-- [openshift/source-to-image](https://github.com/openshift/source-to-image) - A tool for
-  building artifacts from source and injecting them into docker images
-- [jupyter-on-openshift/jupyter-notebooks](https://github.com/jupyter-on-openshift/jupyter-notebooks) -
-  OpenShift compatible S2I builder for basic notebook images
-
 ## Resources
 
 - [Documentation on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)
@@ -138,3 +107,17 @@ If you want to use older `Ubuntu` and/or `python` version, you can use following
 | 2022-10-09   | 22.04  | 3.9    | docker.io | `ed2908bbb62e` |
 | 2023-05-30   | 22.04  | 3.10   | docker.io | `4d70cf8da953` |
 | weekly build | 22.04  | 3.11   | quay.io   | `latest`       |
+
+## Contributing
+
+Please see the [Contributor Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)
+for information about how to contribute recipes, features, tests, and community maintained stacks.
+
+## Alternatives
+
+- [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) -
+  Turn git repositories into Jupyter-enabled Docker Images
+- [openshift/source-to-image](https://github.com/openshift/source-to-image) -
+  A tool for building artifacts from source and injecting them into docker images
+- [jupyter-on-openshift/jupyter-notebooks](https://github.com/jupyter-on-openshift/jupyter-notebooks) -
+  OpenShift compatible S2I builder for basic notebook images",Yes
docs/conf.py,docs/conf.py,df0464cf4e78c525d23e95ded66907ae2ffc9255,343ef3d174ea167e2e59f259fcd3f401c8ae9658,Add navigation_with_keys: False and sort options,"diff --git a/docs/conf.py b/docs/conf.py
index 7ef2b342..cacfe3d0 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -37,16 +37,17 @@ html_theme = ""sphinx_book_theme""
 html_title = ""Docker Stacks documentation""
 html_logo = ""_static/jupyter-logo.svg""
 html_theme_options = {
+    ""logo"": {
+        ""text"": html_title,
+    },
+    ""navigation_with_keys"": False,
     ""path_to_docs"": ""docs"",
-    ""repository_url"": ""https://github.com/jupyter/docker-stacks"",
     ""repository_branch"": ""main"",
+    ""repository_url"": ""https://github.com/jupyter/docker-stacks"",
+    ""use_download_button"": True,
     ""use_edit_page_button"": True,
     ""use_issues_button"": True,
     ""use_repository_button"": True,
-    ""use_download_button"": True,
-    ""logo"": {
-        ""text"": html_title,
-    },
 }
 html_last_updated_fmt = ""%Y-%m-%d""","diff --git a/docs/conf.py b/docs/conf.py
index 7ef2b342..cacfe3d0 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -37,16 +37,17 @@ html_theme = ""sphinx_book_theme""
 html_title = ""Docker Stacks documentation""
 html_logo = ""_static/jupyter-logo.svg""
 html_theme_options = {
-    ""path_to_docs"": ""docs"",
-    ""repository_url"": ""https://github.com/jupyter/docker-stacks"",
-    ""repository_branch"": ""main"",
-    ""use_edit_page_button"": True,
-    ""use_issues_button"": True,
-    ""use_repository_button"": True,
-    ""use_download_button"": True,
     ""logo"": {
         ""text"": html_title,
     },
+    ""navigation_with_keys"": False,
+    ""path_to_docs"": ""docs"",
+    ""repository_branch"": ""main"",
+    ""repository_url"": ""https://github.com/jupyter/docker-stacks"",
+    ""use_download_button"": True,
+    ""use_edit_page_button"": True,
+    ""use_issues_button"": True,
+    ""use_repository_button"": True,
 }
 html_last_updated_fmt = ""%Y-%m-%d""",No
docs/index.rst,docs/index.rst,2e35c52f83ed062052029acb9626f34a4cc19e51,df0464cf4e78c525d23e95ded66907ae2ffc9255,"Introduce policy for new images/packages (#2016)

* Introduce policy for new images/packages

* Fix GitHub links

* Upadte list","diff --git a/docs/index.rst b/docs/index.rst
index 875ea2c5..896ca0f7 100644
--- a/docs/index.rst
+++ b/docs/index.rst
@@ -32,6 +32,7 @@ Table of Contents
    :maxdepth: 2
    :caption: Maintainer Guide
 
+   maintaining/new-images-and-packages-policy
    maintaining/tasks
    maintaining/aarch64-runner","diff --git a/docs/index.rst b/docs/index.rst
index 875ea2c5..896ca0f7 100644
--- a/docs/index.rst
+++ b/docs/index.rst
@@ -32,6 +32,7 @@ Table of Contents
    :maxdepth: 2
    :caption: Maintainer Guide
 
+   maintaining/new-images-and-packages-policy
    maintaining/tasks
    maintaining/aarch64-runner",Yes
,docs/maintaining/new-images-and-packages-policy.md,2e35c52f83ed062052029acb9626f34a4cc19e51,df0464cf4e78c525d23e95ded66907ae2ffc9255,"Introduce policy for new images/packages (#2016)

* Introduce policy for new images/packages

* Fix GitHub links

* Upadte list","diff --git a/docs/maintaining/new-images-and-packages-policy.md b/docs/maintaining/new-images-and-packages-policy.md
new file mode 100644
index 00000000..b6e75314
--- /dev/null
+++ b/docs/maintaining/new-images-and-packages-policy.md
@@ -0,0 +1,35 @@
+# Policy on adding new images and packages
+
+There are many things we consider, while adding new images and packages.
+
+Here is a non exhaustive list of things we do care about:
+
+1. **Software health**, details, and maintenance status
+   - reasonable versioning is adopted, and the version is considered to be stable
+   - has been around for several years
+   - the package maintains documentation
+   - a changelog is actively maintained
+   - a release procedure with helpful automation is established
+   - multiple people are involved in the maintenance of the project
+   - provides a `conda-forge` package besides a `pypi` package, where both are kept up to date
+   - supports both `x86_64` and `aarch64` architectures
+2. **Installation consequences**
+   - GitHub Actions build time
+   - Image sizes
+   - All requirements should be installed as well
+3. Jupyter Docker Stacks _**image fit**_
+   - new package or stack is changing (or inherits from) the most suitable stack
+4. **Software impact** for users of docker-stacks images
+   - How this image can help existing users, or maybe reduce the need to build new images
+5. Why it shouldn't just be a documented **recipe**
+6. Impact on **security**
+   - Does the package open additional ports, or add new web endpoints, that could be exploited?
+
+With all this in mind, we have a voting group, which consists of
+[mathbunnyru](https://github.com/mathbunnyru),
+[consideRatio](https://github.com/consideRatio),
+[yuvipanda](https://github.com/yuvipanda) and
+[manics](https://github.com/manics).
+
+This voting group is responsible for accepting or declining new packages and stacks.
+The change is accepted, if there are **at least 2 positive votes**.","diff --git a/docs/maintaining/new-images-and-packages-policy.md b/docs/maintaining/new-images-and-packages-policy.md
new file mode 100644
index 00000000..b6e75314
--- /dev/null
+++ b/docs/maintaining/new-images-and-packages-policy.md
@@ -0,0 +1,35 @@
+# Policy on adding new images and packages
+
+There are many things we consider, while adding new images and packages.
+
+Here is a non exhaustive list of things we do care about:
+
+1. **Software health**, details, and maintenance status
+   - reasonable versioning is adopted, and the version is considered to be stable
+   - has been around for several years
+   - the package maintains documentation
+   - a changelog is actively maintained
+   - a release procedure with helpful automation is established
+   - multiple people are involved in the maintenance of the project
+   - provides a `conda-forge` package besides a `pypi` package, where both are kept up to date
+   - supports both `x86_64` and `aarch64` architectures
+2. **Installation consequences**
+   - GitHub Actions build time
+   - Image sizes
+   - All requirements should be installed as well
+3. Jupyter Docker Stacks _**image fit**_
+   - new package or stack is changing (or inherits from) the most suitable stack
+4. **Software impact** for users of docker-stacks images
+   - How this image can help existing users, or maybe reduce the need to build new images
+5. Why it shouldn't just be a documented **recipe**
+6. Impact on **security**
+   - Does the package open additional ports, or add new web endpoints, that could be exploited?
+
+With all this in mind, we have a voting group, which consists of
+[mathbunnyru](https://github.com/mathbunnyru),
+[consideRatio](https://github.com/consideRatio),
+[yuvipanda](https://github.com/yuvipanda) and
+[manics](https://github.com/manics).
+
+This voting group is responsible for accepting or declining new packages and stacks.
+The change is accepted, if there are **at least 2 positive votes**.",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,2e35c52f83ed062052029acb9626f34a4cc19e51,df0464cf4e78c525d23e95ded66907ae2ffc9255,"Introduce policy for new images/packages (#2016)

* Introduce policy for new images/packages

* Fix GitHub links

* Upadte list","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 536601e3..c6a577ae 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -42,6 +42,7 @@ Pushing the `Run Workflow` button will trigger this process.
 ```{note}
 In general, we do not add new core images and ask contributors to either
 create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
+We have a [policy](./new-images-and-packages-policy.md), which we consider when adding new images or new packages to existing images.
 ```
 
 You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1936/files).","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index 536601e3..c6a577ae 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -42,6 +42,7 @@ Pushing the `Run Workflow` button will trigger this process.
 ```{note}
 In general, we do not add new core images and ask contributors to either
 create a [recipe](../using/recipes.md) or [community stack](../contributing/stacks.md).
+We have a [policy](./new-images-and-packages-policy.md), which we consider when adding new images or new packages to existing images.
 ```
 
 You can see an example of adding a new image [here](https://github.com/jupyter/docker-stacks/pull/1936/files).",Yes
.readthedocs.yaml,.readthedocs.yaml,fb105c935511b137f0eafe0b1339f2906c51d890,2e35c52f83ed062052029acb9626f34a4cc19e51,Fix .readthedocs.yaml style,"diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index f6a12ce2..7cc5786e 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -24,8 +24,8 @@ sphinx:
 
 # Optionally build your docs in additional formats such as PDF and ePub
 # formats:
-#    - pdf
-#    - epub
+#   - pdf
+#   - epub
 
 # Optional but recommended, declare the Python requirements required
 # to build your documentation","diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index f6a12ce2..7cc5786e 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -24,8 +24,8 @@ sphinx:
 
 # Optionally build your docs in additional formats such as PDF and ePub
 # formats:
-#    - pdf
-#    - epub
+#   - pdf
+#   - epub
 
 # Optional but recommended, declare the Python requirements required
 # to build your documentation",Yes
docs/using/selecting.md,docs/using/selecting.md,66f7beff16dd71f976e44555afe8bfe4c236abe2,fb105c935511b137f0eafe0b1339f2906c51d890,"add grpcio grpcio-status to support spark connect (#2017)

* add grpcio grpcio_status to support spark connect

* Sort install list

* Fix package name

* Update pyspark docs with new deps grpcio and grpcio-status

* set grpcio and grpcio-status version as 1.56

* exclude grpcio and grpcio-status in test_packages.py

* Update selecting.md

* Update test_packages.py

* Update Dockerfile

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index f85ab474..26290c4a 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -209,7 +209,9 @@ It contains:
 
 - Everything in `jupyter/scipy-notebook` and its ancestor images
 - [Apache Spark](https://spark.apache.org/) with Hadoop binaries
-- [pyarrow](https://arrow.apache.org/docs/python/) library
+- [grpcio-status](https://github.com/grpc/grpc/tree/master/src/python/grpcio_status)
+- [grpcio](https://grpc.io/docs/languages/python/quickstart/)
+- [pyarrow](https://arrow.apache.org/docs/python/)
 
 ### jupyter/all-spark-notebook","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index f85ab474..26290c4a 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -209,7 +209,9 @@ It contains:
 
 - Everything in `jupyter/scipy-notebook` and its ancestor images
 - [Apache Spark](https://spark.apache.org/) with Hadoop binaries
-- [pyarrow](https://arrow.apache.org/docs/python/) library
+- [grpcio-status](https://github.com/grpc/grpc/tree/master/src/python/grpcio_status)
+- [grpcio](https://grpc.io/docs/languages/python/quickstart/)
+- [pyarrow](https://arrow.apache.org/docs/python/)
 
 ### jupyter/all-spark-notebook",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,66f7beff16dd71f976e44555afe8bfe4c236abe2,fb105c935511b137f0eafe0b1339f2906c51d890,"add grpcio grpcio-status to support spark connect (#2017)

* add grpcio grpcio_status to support spark connect

* Sort install list

* Fix package name

* Update pyspark docs with new deps grpcio and grpcio-status

* set grpcio and grpcio-status version as 1.56

* exclude grpcio and grpcio-status in test_packages.py

* Update selecting.md

* Update test_packages.py

* Update Dockerfile

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index c50701ef..28d40dc2 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -74,6 +74,8 @@ USER ${NB_UID}
 # 1. Check out the Spark branch you are on.
 # 2. Find the pandas version in the file spark/dev/infra/Dockerfile.
 RUN mamba install --yes \
+    'grpcio-status' \
+    'grpcio' \
     'pandas=2.0.3' \
     'pyarrow' && \
     mamba clean --all -f -y && \","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index c50701ef..28d40dc2 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -74,6 +74,8 @@ USER ${NB_UID}
 # 1. Check out the Spark branch you are on.
 # 2. Find the pandas version in the file spark/dev/infra/Dockerfile.
 RUN mamba install --yes \
+    'grpcio-status' \
+    'grpcio' \
     'pandas=2.0.3' \
     'pyarrow' && \
     mamba clean --all -f -y && \",Yes
tests/base-notebook/test_packages.py,tests/base-notebook/test_packages.py,66f7beff16dd71f976e44555afe8bfe4c236abe2,fb105c935511b137f0eafe0b1339f2906c51d890,"add grpcio grpcio-status to support spark connect (#2017)

* add grpcio grpcio_status to support spark connect

* Sort install list

* Fix package name

* Update pyspark docs with new deps grpcio and grpcio-status

* set grpcio and grpcio-status version as 1.56

* exclude grpcio and grpcio-status in test_packages.py

* Update selecting.md

* Update test_packages.py

* Update Dockerfile

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index b56d6120..ae4fa3f1 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -69,6 +69,8 @@ EXCLUDED_PACKAGES = [
     ""bzip2"",
     ""ca-certificates"",
     ""conda-forge::blas[build=openblas]"",
+    ""grpcio-status"",
+    ""grpcio"",
     ""hdf5"",
     ""jupyterlab-git"",
     ""openssl"",","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index b56d6120..ae4fa3f1 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -69,6 +69,8 @@ EXCLUDED_PACKAGES = [
     ""bzip2"",
     ""ca-certificates"",
     ""conda-forge::blas[build=openblas]"",
+    ""grpcio-status"",
+    ""grpcio"",
     ""hdf5"",
     ""jupyterlab-git"",
     ""openssl"",",Yes
tests/all-spark-notebook/test_spark_notebooks.py,tests/all-spark-notebook/test_spark_notebooks.py,64248b85c6734ac7250011a2f7fe7d5ff98a2df5,66f7beff16dd71f976e44555afe8bfe4c236abe2,Increase timeout in test_spark_notebooks,"diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index b49b1cb2..0d1537ae 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -20,7 +20,7 @@ def test_nbconvert(container: TrackedContainer, test_file: str) -> None:
     host_data_dir = THIS_DIR / ""data""
     cont_data_dir = ""/home/jovyan/data""
     output_dir = ""/tmp""
-    conversion_timeout_ms = 600
+    conversion_timeout_ms = 5000
     LOGGER.info(f""Test that {test_file} notebook can be executed ..."")
     command = (
         ""jupyter nbconvert --to markdown ""","diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index b49b1cb2..0d1537ae 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -20,7 +20,7 @@ def test_nbconvert(container: TrackedContainer, test_file: str) -> None:
     host_data_dir = THIS_DIR / ""data""
     cont_data_dir = ""/home/jovyan/data""
     output_dir = ""/tmp""
-    conversion_timeout_ms = 600
+    conversion_timeout_ms = 5000
     LOGGER.info(f""Test that {test_file} notebook can be executed ..."")
     command = (
         ""jupyter nbconvert --to markdown """,Yes
README.md,README.md,7b57f14014eed4a3fa7bb09637b4b3985e587591,64248b85c6734ac7250011a2f7fe7d5ff98a2df5,Fix README info,"diff --git a/README.md b/README.md
index ee02477e..aec6ee17 100644
--- a/README.md
+++ b/README.md
@@ -89,7 +89,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-10-20`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-06-01`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images","diff --git a/README.md b/README.md
index ee02477e..aec6ee17 100644
--- a/README.md
+++ b/README.md
@@ -89,7 +89,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-10-20`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-06-01`, we create multi-platform `tensorflow-notebook` image as well
 
 ## Using old images",Yes
README.md,README.md,463ced7e4f5f66b93ae0cee97345be8d6adb0055,7b57f14014eed4a3fa7bb09637b4b3985e587591,Update tag example,"diff --git a/README.md b/README.md
index aec6ee17..0649bb00 100644
--- a/README.md
+++ b/README.md
@@ -27,11 +27,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-10-20
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-10-31
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -46,11 +46,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-10-20
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-10-31
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index aec6ee17..0649bb00 100644
--- a/README.md
+++ b/README.md
@@ -27,11 +27,11 @@ The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-10-20
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-10-31
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -46,11 +46,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-10-20
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-10-31
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,463ced7e4f5f66b93ae0cee97345be8d6adb0055,7b57f14014eed4a3fa7bb09637b4b3985e587591,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 250246ce..a183da42 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-10-20
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-10-31
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-10-20""
+ENV TAG=""2023-10-31""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 250246ce..a183da42 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-10-20
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-10-31
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-10-20""
+ENV TAG=""2023-10-31""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,463ced7e4f5f66b93ae0cee97345be8d6adb0055,7b57f14014eed4a3fa7bb09637b4b3985e587591,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index 1a22172b..05394291 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-20
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-31
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-10-20                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-10-31                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-10-20
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-10-31
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2023-10-20
+    quay.io/jupyter/r-notebook:2023-10-31
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 1a22172b..05394291 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-20
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-31
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-10-20                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# 221331c047c4   jupyter/scipy-notebook:2023-10-31                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
 
 # start the stopped container
 docker start --attach 221331c047c4
@@ -53,12 +53,12 @@ docker rm 221331c047c4
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-10-20
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-10-31
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-10-20` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2023-10-20
+    quay.io/jupyter/r-notebook:2023-10-31
 ```
 
 ```{warning}",Yes
docs/using/running.md,docs/using/running.md,e9bb9c14b295ef9842fd6ca28c59addddaaac907,463ced7e4f5f66b93ae0cee97345be8d6adb0055,Update first example,"diff --git a/docs/using/running.md b/docs/using/running.md
index 05394291..b00d4932 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -29,8 +29,8 @@ docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-31
 #     To access the server, open this file in a browser:
 #         file:///home/jovyan/.local/share/jupyter/runtime/jpserver-7-open.html
 #     Or copy and paste one of these URLs:
-#         http://042fc8ac2b0c:8888/lab?token=f31f2625f13d131f578fced0fc76b81d10f6c629e92c7099
-#      or http://127.0.0.1:8888/lab?token=f31f2625f13d131f578fced0fc76b81d10f6c629e92c7099
+#         http://eca4aa01751c:8888/lab?token=d4ac9278f5f5388e88097a3a8ebbe9401be206cfa0b83099
+#         http://127.0.0.1:8888/lab?token=d4ac9278f5f5388e88097a3a8ebbe9401be206cfa0b83099
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on disk for later restart or permanent deletion using commands like the following:
@@ -38,17 +38,17 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 ```bash
 # list containers
 docker ps --all
-# CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-10-31                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2023-10-31   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
-docker start --attach 221331c047c4
+docker start --attach -i eca4aa01751c
 # Entered start.sh with args: jupyter lab
 # ...
 
 # remove the stopped container
-docker rm 221331c047c4
-# 221331c047c4
+docker rm eca4aa01751c
+# eca4aa01751c
 ```
 
 ### Example 2","diff --git a/docs/using/running.md b/docs/using/running.md
index 05394291..b00d4932 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -29,8 +29,8 @@ docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-31
 #     To access the server, open this file in a browser:
 #         file:///home/jovyan/.local/share/jupyter/runtime/jpserver-7-open.html
 #     Or copy and paste one of these URLs:
-#         http://042fc8ac2b0c:8888/lab?token=f31f2625f13d131f578fced0fc76b81d10f6c629e92c7099
-#      or http://127.0.0.1:8888/lab?token=f31f2625f13d131f578fced0fc76b81d10f6c629e92c7099
+#         http://eca4aa01751c:8888/lab?token=d4ac9278f5f5388e88097a3a8ebbe9401be206cfa0b83099
+#         http://127.0.0.1:8888/lab?token=d4ac9278f5f5388e88097a3a8ebbe9401be206cfa0b83099
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on disk for later restart or permanent deletion using commands like the following:
@@ -38,17 +38,17 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 ```bash
 # list containers
 docker ps --all
-# CONTAINER ID   IMAGE                                                 COMMAND                  CREATED          STATUS                     PORTS     NAMES
-# 221331c047c4   jupyter/scipy-notebook:2023-10-31                   ""tini -g -- start-no…""   11 seconds ago   Exited (0) 8 seconds ago             cranky_benz
+# CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2023-10-31   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
-docker start --attach 221331c047c4
+docker start --attach -i eca4aa01751c
 # Entered start.sh with args: jupyter lab
 # ...
 
 # remove the stopped container
-docker rm 221331c047c4
-# 221331c047c4
+docker rm eca4aa01751c
+# eca4aa01751c
 ```
 
 ### Example 2",Yes
docs/conf.py,docs/conf.py,154343498e5cf03f697d6214ee3c514015055051,e9bb9c14b295ef9842fd6ca28c59addddaaac907,[TMP] Disable mybinder linkcheck,"diff --git a/docs/conf.py b/docs/conf.py
index cacfe3d0..dd46367c 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -66,6 +66,7 @@ linkcheck_ignore = [
     r""https://github\.com/jupyter/docker-stacks/settings/actions/runners/new\?arch=arm64\&amp;os=linux"",  # only works for users with permissions to change runners
     r""http://127\.0\.0\.1:.*"",  # various examples
     r""https://mybinder\.org/v2/gh/.*"",  # lots of 500 errors
+    r""https://mybinder.org"",  # mybinder is down
 ]
 
 linkcheck_allowed_redirects = {","diff --git a/docs/conf.py b/docs/conf.py
index cacfe3d0..dd46367c 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -66,6 +66,7 @@ linkcheck_ignore = [
     r""https://github\.com/jupyter/docker-stacks/settings/actions/runners/new\?arch=arm64\&amp;os=linux"",  # only works for users with permissions to change runners
     r""http://127\.0\.0\.1:.*"",  # various examples
     r""https://mybinder\.org/v2/gh/.*"",  # lots of 500 errors
+    r""https://mybinder.org"",  # mybinder is down
 ]
 
 linkcheck_allowed_redirects = {",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,65618ec1a190bcb4a134e12df09c87843db8cda4,154343498e5cf03f697d6214ee3c514015055051,Add missing condition on running aarch64-tensorflow build,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 97b67769..5eb0cb0e 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -175,6 +175,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
+    if: github.repository_owner == 'jupyter'
 
   x86_64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 97b67769..5eb0cb0e 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -175,6 +175,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
+    if: github.repository_owner == 'jupyter'
 
   x86_64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,7bdc64f5a1c85cc71eedd354d4d629a4efed4490,65618ec1a190bcb4a134e12df09c87843db8cda4,Always use expression inside env,"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index f8e3d999..fb20c967 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -2,7 +2,7 @@ name: Download images tags from GitHub artifacts and create multi-platform manif
 
 env:
   OWNER: ${{ github.repository_owner }}
-  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+  PUSH_TO_REGISTRY: ${{ (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule') }}
 
 on:
   workflow_call:","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index f8e3d999..fb20c967 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -2,7 +2,7 @@ name: Download images tags from GitHub artifacts and create multi-platform manif
 
 env:
   OWNER: ${{ github.repository_owner }}
-  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+  PUSH_TO_REGISTRY: ${{ (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule') }}
 
 on:
   workflow_call:",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,7bdc64f5a1c85cc71eedd354d4d629a4efed4490,65618ec1a190bcb4a134e12df09c87843db8cda4,Always use expression inside env,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index b131144a..aa54bf1d 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -3,7 +3,7 @@ name: Download Docker image and its tags from GitHub artifacts, apply them and p
 env:
   REGISTRY: quay.io
   OWNER: ${{ github.repository_owner }}
-  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+  PUSH_TO_REGISTRY: ${{ (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule') }}
 
 on:
   workflow_call:","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index b131144a..aa54bf1d 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -3,7 +3,7 @@ name: Download Docker image and its tags from GitHub artifacts, apply them and p
 env:
   REGISTRY: quay.io
   OWNER: ${{ github.repository_owner }}
-  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+  PUSH_TO_REGISTRY: ${{ (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule') }}
 
 on:
   workflow_call:",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,7bdc64f5a1c85cc71eedd354d4d629a4efed4490,65618ec1a190bcb4a134e12df09c87843db8cda4,Always use expression inside env,"diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 4098747b..1b97d9b4 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -3,7 +3,7 @@ name: Download build manifests from GitHub artifacts and push them to GitHub wik
 # This way we make sure we don't access wiki pages from several jobs simultaneously
 
 env:
-  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+  PUSH_TO_REGISTRY: ${{ (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule') }}
 
 on:
   workflow_call:","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 4098747b..1b97d9b4 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -3,7 +3,7 @@ name: Download build manifests from GitHub artifacts and push them to GitHub wik
 # This way we make sure we don't access wiki pages from several jobs simultaneously
 
 env:
-  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
+  PUSH_TO_REGISTRY: ${{ (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main' || github.event_name == 'schedule') }}
 
 on:
   workflow_call:",Yes
.github/actions/create-dev-env/action.yml,.github/actions/create-dev-env/action.yml,c27ab18a05d31ab559ae89d72d4d0bd89d3d4dc8,7bdc64f5a1c85cc71eedd354d4d629a4efed4490,Remove use of expressions inside if,"diff --git a/.github/actions/create-dev-env/action.yml b/.github/actions/create-dev-env/action.yml
index 27746891..5686b6d1 100644
--- a/.github/actions/create-dev-env/action.yml
+++ b/.github/actions/create-dev-env/action.yml
@@ -11,7 +11,7 @@ runs:
       uses: actions/setup-python@v4
       with:
         python-version: 3.x
-      if: ${{ runner.arch == 'X64' }}
+      if: runner.arch == 'X64'
 
     - name: Install Dev Dependencies 📦
       run: |","diff --git a/.github/actions/create-dev-env/action.yml b/.github/actions/create-dev-env/action.yml
index 27746891..5686b6d1 100644
--- a/.github/actions/create-dev-env/action.yml
+++ b/.github/actions/create-dev-env/action.yml
@@ -11,7 +11,7 @@ runs:
       uses: actions/setup-python@v4
       with:
         python-version: 3.x
-      if: ${{ runner.arch == 'X64' }}
+      if: runner.arch == 'X64'
 
     - name: Install Dev Dependencies 📦
       run: |",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,c27ab18a05d31ab559ae89d72d4d0bd89d3d4dc8,7bdc64f5a1c85cc71eedd354d4d629a4efed4490,Remove use of expressions inside if,"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index f06889d1..25f04838 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -38,7 +38,7 @@ jobs:
       # Also, they might have running or stopped containers,
       # which are not cleaned up by `docker system prun`
       - name: Reset docker state and cleanup artifacts 🗑️
-        if: ${{ inputs.platform != 'x86_64' }}
+        if: inputs.platform != 'x86_64'
         run: |
           docker kill $(docker ps --quiet) || true
           docker rm $(docker ps --all --quiet) || true
@@ -47,14 +47,14 @@ jobs:
         shell: bash
 
       - name: Load parent built image to Docker 📥
-        if: ${{ inputs.parentImage != '' }}
+        if: inputs.parentImage != ''
         uses: ./.github/actions/load-image
         with:
           image: ${{ inputs.parentImage }}
           platform: ${{ inputs.platform }}
 
       - name: Pull ubuntu:22.04 image 📥
-        if: ${{ inputs.parentImage == '' }}
+        if: inputs.parentImage == ''
         run: docker pull ubuntu:22.04
         shell: bash","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index f06889d1..25f04838 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -38,7 +38,7 @@ jobs:
       # Also, they might have running or stopped containers,
       # which are not cleaned up by `docker system prun`
       - name: Reset docker state and cleanup artifacts 🗑️
-        if: ${{ inputs.platform != 'x86_64' }}
+        if: inputs.platform != 'x86_64'
         run: |
           docker kill $(docker ps --quiet) || true
           docker rm $(docker ps --all --quiet) || true
@@ -47,14 +47,14 @@ jobs:
         shell: bash
 
       - name: Load parent built image to Docker 📥
-        if: ${{ inputs.parentImage != '' }}
+        if: inputs.parentImage != ''
         uses: ./.github/actions/load-image
         with:
           image: ${{ inputs.parentImage }}
           platform: ${{ inputs.platform }}
 
       - name: Pull ubuntu:22.04 image 📥
-        if: ${{ inputs.parentImage == '' }}
+        if: inputs.parentImage == ''
         run: docker pull ubuntu:22.04
         shell: bash",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,af37e9ced2e2fde227274e4e3b10965528f043d3,c27ab18a05d31ab559ae89d72d4d0bd89d3d4dc8,Compare env variable with string 'true' value,"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index fb20c967..d1ad9a44 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -48,7 +48,7 @@ jobs:
         shell: bash
 
       - name: Login to Registry 🔐
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           registry: quay.io
@@ -56,6 +56,6 @@ jobs:
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Merge tags for the images 🔀
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/
         shell: bash","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index fb20c967..d1ad9a44 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -48,7 +48,7 @@ jobs:
         shell: bash
 
       - name: Login to Registry 🔐
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           registry: quay.io
@@ -56,6 +56,6 @@ jobs:
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Merge tags for the images 🔀
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/
         shell: bash",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,af37e9ced2e2fde227274e4e3b10965528f043d3,c27ab18a05d31ab559ae89d72d4d0bd89d3d4dc8,Compare env variable with string 'true' value,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index aa54bf1d..450dee0a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -38,7 +38,7 @@ jobs:
           platform: ${{ inputs.platform }}
 
       - name: Login to Registry 🔐
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           registry: quay.io
@@ -54,6 +54,6 @@ jobs:
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
 
       - name: Push Images to Registry 📤
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         run: docker push --all-tags ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}
         shell: bash","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index aa54bf1d..450dee0a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -38,7 +38,7 @@ jobs:
           platform: ${{ inputs.platform }}
 
       - name: Login to Registry 🔐
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
         with:
           registry: quay.io
@@ -54,6 +54,6 @@ jobs:
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
 
       - name: Push Images to Registry 📤
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         run: docker push --all-tags ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}
         shell: bash",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,af37e9ced2e2fde227274e4e3b10965528f043d3,c27ab18a05d31ab559ae89d72d4d0bd89d3d4dc8,Compare env variable with string 'true' value,"diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 1b97d9b4..c643f5c4 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -40,7 +40,7 @@ jobs:
         shell: bash
 
       - name: Push Wiki to GitHub 📤
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         uses: stefanzweifel/git-auto-commit-action@8756aa072ef5b4a080af5dc8fef36c5d586e521d # v5.0.0
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 1b97d9b4..c643f5c4 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -40,7 +40,7 @@ jobs:
         shell: bash
 
       - name: Push Wiki to GitHub 📤
-        if: env.PUSH_TO_REGISTRY
+        if: env.PUSH_TO_REGISTRY == 'true'
         uses: stefanzweifel/git-auto-commit-action@8756aa072ef5b4a080af5dc8fef36c5d586e521d # v5.0.0
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""",Yes
tagging/manifests.py,tagging/manifests.py,61e271032d2feeeaf05be2718fc743dd7eef0f07,af37e9ced2e2fde227274e4e3b10965528f043d3,Make manifests more beautiful,"diff --git a/tagging/manifests.py b/tagging/manifests.py
index 12e98020..7bd460fb 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -13,7 +13,9 @@ def quoted_output(container: Container, cmd: str) -> str:
     return ""\n"".join(
         [
             ""```"",
-            DockerRunner.run_simple_command(container, cmd, print_result=False),
+            DockerRunner.run_simple_command(container, cmd, print_result=False).strip(
+                ""\n""
+            ),
             ""```"",
         ]
     )
@@ -46,11 +48,12 @@ class ManifestHeader:
                 """",
                 ""## Build Info"",
                 """",
-                f""* Build datetime: {build_timestamp}"",
-                f""* Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`"",
-                f""* Docker image size: {image_size}"",
-                f""* Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
-                ""* Git commit message:"",
+                f""- Build datetime: {build_timestamp}"",
+                f""- Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`"",
+                f""- Docker image size: {image_size}"",
+                f""- Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
+                ""- Git commit message:"",
+                """",
                 ""```"",
                 f""{commit_message}"",
                 ""```"",
@@ -73,10 +76,14 @@ class CondaEnvironmentManifest(ManifestInterface):
             [
                 ""## Python Packages"",
                 """",
-                quoted_output(container, ""python --version""),
+                DockerRunner.run_simple_command(container, ""python --version""),
+                """",
+                ""`mamba info --quiet`:"",
                 """",
                 quoted_output(container, ""mamba info --quiet""),
                 """",
+                ""`mamba list`:"",
+                """",
                 quoted_output(container, ""mamba list""),
             ]
         )
@@ -89,6 +96,8 @@ class AptPackagesManifest(ManifestInterface):
             [
                 ""## Apt Packages"",
                 """",
+                ""`apt list --installed`:"",
+                """",
                 quoted_output(container, ""apt list --installed""),
             ]
         )","diff --git a/tagging/manifests.py b/tagging/manifests.py
index 12e98020..7bd460fb 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -13,7 +13,9 @@ def quoted_output(container: Container, cmd: str) -> str:
     return ""\n"".join(
         [
             ""```"",
-            DockerRunner.run_simple_command(container, cmd, print_result=False),
+            DockerRunner.run_simple_command(container, cmd, print_result=False).strip(
+                ""\n""
+            ),
             ""```"",
         ]
     )
@@ -46,11 +48,12 @@ class ManifestHeader:
                 """",
                 ""## Build Info"",
                 """",
-                f""* Build datetime: {build_timestamp}"",
-                f""* Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`"",
-                f""* Docker image size: {image_size}"",
-                f""* Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
-                ""* Git commit message:"",
+                f""- Build datetime: {build_timestamp}"",
+                f""- Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`"",
+                f""- Docker image size: {image_size}"",
+                f""- Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
+                ""- Git commit message:"",
+                """",
                 ""```"",
                 f""{commit_message}"",
                 ""```"",
@@ -73,10 +76,14 @@ class CondaEnvironmentManifest(ManifestInterface):
             [
                 ""## Python Packages"",
                 """",
-                quoted_output(container, ""python --version""),
+                DockerRunner.run_simple_command(container, ""python --version""),
+                """",
+                ""`mamba info --quiet`:"",
                 """",
                 quoted_output(container, ""mamba info --quiet""),
                 """",
+                ""`mamba list`:"",
+                """",
                 quoted_output(container, ""mamba list""),
             ]
         )
@@ -89,6 +96,8 @@ class AptPackagesManifest(ManifestInterface):
             [
                 ""## Apt Packages"",
                 """",
+                ""`apt list --installed`:"",
+                """",
                 quoted_output(container, ""apt list --installed""),
             ]
         )",Yes
docs/using/selecting.md,docs/using/selecting.md,1f11f445ed9050dc8fa71102fc3a89bbdff2c88c,61e271032d2feeeaf05be2718fc743dd7eef0f07,Fix broken link to r-notebook tags on quay (#2021),"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 26290c4a..f86d576a 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -91,7 +91,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/r-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/r-notebook/Dockerfile) |
-[Quay.io image tags](https://quay.io/repository/jupyter/t-notebook?tab=tags)
+[Quay.io image tags](https://quay.io/repository/jupyter/r-notebook?tab=tags)
 
 `jupyter/r-notebook` includes popular packages from the R ecosystem listed below:","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 26290c4a..f86d576a 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -91,7 +91,7 @@ It contains:
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/r-notebook) |
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/r-notebook/Dockerfile) |
-[Quay.io image tags](https://quay.io/repository/jupyter/t-notebook?tab=tags)
+[Quay.io image tags](https://quay.io/repository/jupyter/r-notebook?tab=tags)
 
 `jupyter/r-notebook` includes popular packages from the R ecosystem listed below:",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,9df3959137247badcad97d3c73b2ddd2db3079c9,1f11f445ed9050dc8fa71102fc3a89bbdff2c88c,"[FAST_BUILD] Introduce fast build (#2014)

* [FAST_BUILD] Introduce fast build

* [FAST_BUILD] Fix

* Use pull request title, because github.event.head_commit.message is not available for PRs

* Update description

* Add some debugging

* More debug

* More debug

* Fix

* More expression contexts

* Try with old docker-tag-push.yml

* Keep simple

* Keep simple

* Do not touch parts which have worked so far

* Do not touch parts which have worked so far

* Remove ${{ }} where not needed

* Add debug code

* Remove debug logs

* Only download needed manifests and and history lines","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index c96fcd70..47caa425 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -14,6 +14,10 @@ inputs:
     description: Directory to store manifest files
     required: true
     type: string
+  fastBuild:
+    description: Only build docker-stacks-foundation and base-notebook
+    required: true
+    type: bool
 
 runs:
   using: composite
@@ -40,81 +44,97 @@ runs:
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
@@ -141,71 +161,85 @@ runs:
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: all-spark-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index c96fcd70..47caa425 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -14,6 +14,10 @@ inputs:
     description: Directory to store manifest files
     required: true
     type: string
+  fastBuild:
+    description: Only build docker-stacks-foundation and base-notebook
+    required: true
+    type: bool
 
 runs:
   using: composite
@@ -40,81 +44,97 @@ runs:
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.histLineDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.histLineDir }}
@@ -141,71 +161,85 @@ runs:
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifestDir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
+      if: ${{ !inputs.fastBuild }}
       with:
         name: all-spark-notebook-x86_64-manifest
         path: ${{ inputs.manifestDir }}",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,9df3959137247badcad97d3c73b2ddd2db3079c9,1f11f445ed9050dc8fa71102fc3a89bbdff2c88c,"[FAST_BUILD] Introduce fast build (#2014)

* [FAST_BUILD] Introduce fast build

* [FAST_BUILD] Fix

* Use pull request title, because github.event.head_commit.message is not available for PRs

* Update description

* Add some debugging

* More debug

* More debug

* Fix

* More expression contexts

* Try with old docker-tag-push.yml

* Keep simple

* Keep simple

* Do not touch parts which have worked so far

* Do not touch parts which have worked so far

* Remove ${{ }} where not needed

* Add debug code

* Remove debug logs

* Only download needed manifests and and history lines","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index c643f5c4..0f6296b8 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -23,6 +23,7 @@ jobs:
         with:
           histLineDir: /tmp/jupyter/hist_lines/
           manifestDir: /tmp/jupyter/manifests/
+          fastBuild: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
       - name: Display structure of downloaded files 🔍️
         run: |
           ls -R /tmp/jupyter/hist_lines/","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index c643f5c4..0f6296b8 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -23,6 +23,7 @@ jobs:
         with:
           histLineDir: /tmp/jupyter/hist_lines/
           manifestDir: /tmp/jupyter/manifests/
+          fastBuild: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
       - name: Display structure of downloaded files 🔍️
         run: |
           ls -R /tmp/jupyter/hist_lines/",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,9df3959137247badcad97d3c73b2ddd2db3079c9,1f11f445ed9050dc8fa71102fc3a89bbdff2c88c,"[FAST_BUILD] Introduce fast build (#2014)

* [FAST_BUILD] Introduce fast build

* [FAST_BUILD] Fix

* Use pull request title, because github.event.head_commit.message is not available for PRs

* Update description

* Add some debugging

* More debug

* More debug

* Fix

* More expression contexts

* Try with old docker-tag-push.yml

* Keep simple

* Keep simple

* Do not touch parts which have worked so far

* Do not touch parts which have worked so far

* Remove ${{ }} where not needed

* Add debug code

* Remove debug logs

* Only download needed manifests and and history lines","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 5eb0cb0e..d8cb21aa 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -1,5 +1,10 @@
 name: Build, test and push Docker Images
 
+# [FAST_BUILD] in the PR title makes this workflow only build
+# `jupyter/docker-stacks-foundation` and `/jupyter/base-notebook` in the PR
+# This allows to run CI faster in case where full build is not required
+# This only works for `pull_request` event and has no effect on `push` to the `main` branch
+
 on:
   schedule:
     # Weekly, at 03:00 on Monday UTC time
@@ -99,7 +104,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-base]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-minimal:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -109,6 +114,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-base]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -118,7 +124,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -128,6 +134,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-minimal]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -137,7 +144,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -147,6 +154,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-minimal]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -156,7 +164,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -166,6 +174,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-minimal]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -175,7 +184,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -185,6 +194,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -194,7 +204,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -204,6 +214,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -213,7 +224,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -223,6 +234,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -232,7 +244,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-pyspark]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -242,6 +254,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-pyspark]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-images-tag-push:
     uses: ./.github/workflows/docker-tag-push.yml
@@ -279,7 +292,21 @@ jobs:
         aarch64-pyspark,
         aarch64-all-spark,
       ]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+
+  aarch64-images-tag-push-fast:
+    uses: ./.github/workflows/docker-tag-push.yml
+    with:
+      platform: aarch64
+      image: ${{ matrix.image }}
+    secrets:
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
+    strategy:
+      matrix:
+        image: [docker-stacks-foundation, base-notebook]
+    needs: [aarch64-foundation, aarch64-base]
+    if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-images-tag-push:
     uses: ./.github/workflows/docker-tag-push.yml
@@ -317,6 +344,21 @@ jobs:
         x86_64-pyspark,
         x86_64-all-spark,
       ]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
+  x86_64-images-tag-push-fast:
+    uses: ./.github/workflows/docker-tag-push.yml
+    with:
+      platform: x86_64
+      image: ${{ matrix.image }}
+    secrets:
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
+    strategy:
+      matrix:
+        image: [docker-stacks-foundation, base-notebook]
+    needs: [x86_64-foundation, x86_64-base]
+    if: contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   merge-tags:
     uses: ./.github/workflows/docker-merge-tags.yml
@@ -341,12 +383,32 @@ jobs:
             all-spark-notebook,
           ]
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+
+  merge-tags-fast:
+    uses: ./.github/workflows/docker-merge-tags.yml
+    with:
+      image: ${{ matrix.image }}
+    secrets:
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
+    strategy:
+      matrix:
+        image: [docker-stacks-foundation, base-notebook]
+    needs: [aarch64-images-tag-push-fast, x86_64-images-tag-push-fast]
+    if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   wiki-update:
     uses: ./.github/workflows/docker-wiki-update.yml
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+    permissions:
+      contents: write
+
+  wiki-update-fast:
+    uses: ./.github/workflows/docker-wiki-update.yml
+    needs: [aarch64-images-tag-push-fast, x86_64-images-tag-push-fast]
+    if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
     permissions:
       contents: write","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 5eb0cb0e..d8cb21aa 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -1,5 +1,10 @@
 name: Build, test and push Docker Images
 
+# [FAST_BUILD] in the PR title makes this workflow only build
+# `jupyter/docker-stacks-foundation` and `/jupyter/base-notebook` in the PR
+# This allows to run CI faster in case where full build is not required
+# This only works for `pull_request` event and has no effect on `push` to the `main` branch
+
 on:
   schedule:
     # Weekly, at 03:00 on Monday UTC time
@@ -99,7 +104,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-base]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-minimal:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -109,6 +114,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-base]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -118,7 +124,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -128,6 +134,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-minimal]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -137,7 +144,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -147,6 +154,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-minimal]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -156,7 +164,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-minimal]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -166,6 +174,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-minimal]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -175,7 +184,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -185,6 +194,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -194,7 +204,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -204,6 +214,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -213,7 +224,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-scipy]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -223,6 +234,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -232,7 +244,7 @@ jobs:
       platform: aarch64
       runsOn: ARM64
     needs: [aarch64-pyspark]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
@@ -242,6 +254,7 @@ jobs:
       platform: x86_64
       runsOn: ubuntu-latest
     needs: [x86_64-pyspark]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-images-tag-push:
     uses: ./.github/workflows/docker-tag-push.yml
@@ -279,7 +292,21 @@ jobs:
         aarch64-pyspark,
         aarch64-all-spark,
       ]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+
+  aarch64-images-tag-push-fast:
+    uses: ./.github/workflows/docker-tag-push.yml
+    with:
+      platform: aarch64
+      image: ${{ matrix.image }}
+    secrets:
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
+    strategy:
+      matrix:
+        image: [docker-stacks-foundation, base-notebook]
+    needs: [aarch64-foundation, aarch64-base]
+    if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-images-tag-push:
     uses: ./.github/workflows/docker-tag-push.yml
@@ -317,6 +344,21 @@ jobs:
         x86_64-pyspark,
         x86_64-all-spark,
       ]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
+  x86_64-images-tag-push-fast:
+    uses: ./.github/workflows/docker-tag-push.yml
+    with:
+      platform: x86_64
+      image: ${{ matrix.image }}
+    secrets:
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
+    strategy:
+      matrix:
+        image: [docker-stacks-foundation, base-notebook]
+    needs: [x86_64-foundation, x86_64-base]
+    if: contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   merge-tags:
     uses: ./.github/workflows/docker-merge-tags.yml
@@ -341,12 +383,32 @@ jobs:
             all-spark-notebook,
           ]
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+
+  merge-tags-fast:
+    uses: ./.github/workflows/docker-merge-tags.yml
+    with:
+      image: ${{ matrix.image }}
+    secrets:
+      REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
+      REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
+    strategy:
+      matrix:
+        image: [docker-stacks-foundation, base-notebook]
+    needs: [aarch64-images-tag-push-fast, x86_64-images-tag-push-fast]
+    if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   wiki-update:
     uses: ./.github/workflows/docker-wiki-update.yml
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+    permissions:
+      contents: write
+
+  wiki-update-fast:
+    uses: ./.github/workflows/docker-wiki-update.yml
+    needs: [aarch64-images-tag-push-fast, x86_64-images-tag-push-fast]
+    if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
     permissions:
       contents: write",Yes
,tests/docker-stacks-foundation/run-hooks-unset/a.sh,d52ea4716e5eeb9597b15da8400fe2fde18d00de,9df3959137247badcad97d3c73b2ddd2db3079c9,[FAST_BUILD] Test unset in run-hooks (#2022),"diff --git a/tests/docker-stacks-foundation/run-hooks-unset/a.sh b/tests/docker-stacks-foundation/run-hooks-unset/a.sh
new file mode 100644
index 00000000..61701e2a
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-unset/a.sh
@@ -0,0 +1,6 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+export MY_VAR=123
+echo ""Inside a.sh MY_VAR variable has ${MY_VAR} value""","diff --git a/tests/docker-stacks-foundation/run-hooks-unset/a.sh b/tests/docker-stacks-foundation/run-hooks-unset/a.sh
new file mode 100644
index 00000000..61701e2a
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-unset/a.sh
@@ -0,0 +1,6 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+export MY_VAR=123
+echo ""Inside a.sh MY_VAR variable has ${MY_VAR} value""",Yes
,tests/docker-stacks-foundation/run-hooks-unset/b.sh,d52ea4716e5eeb9597b15da8400fe2fde18d00de,9df3959137247badcad97d3c73b2ddd2db3079c9,[FAST_BUILD] Test unset in run-hooks (#2022),"diff --git a/tests/docker-stacks-foundation/run-hooks-unset/b.sh b/tests/docker-stacks-foundation/run-hooks-unset/b.sh
new file mode 100644
index 00000000..ab64e932
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-unset/b.sh
@@ -0,0 +1,7 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Inside b.sh MY_VAR variable has ${MY_VAR} value""
+echo ""Unsetting MY_VAR""
+unset MY_VAR","diff --git a/tests/docker-stacks-foundation/run-hooks-unset/b.sh b/tests/docker-stacks-foundation/run-hooks-unset/b.sh
new file mode 100644
index 00000000..ab64e932
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-unset/b.sh
@@ -0,0 +1,7 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Inside b.sh MY_VAR variable has ${MY_VAR} value""
+echo ""Unsetting MY_VAR""
+unset MY_VAR",Yes
,tests/docker-stacks-foundation/run-hooks-unset/c.sh,d52ea4716e5eeb9597b15da8400fe2fde18d00de,9df3959137247badcad97d3c73b2ddd2db3079c9,[FAST_BUILD] Test unset in run-hooks (#2022),"diff --git a/tests/docker-stacks-foundation/run-hooks-unset/c.sh b/tests/docker-stacks-foundation/run-hooks-unset/c.sh
new file mode 100644
index 00000000..ef69df39
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-unset/c.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Inside c.sh MY_VAR variable has ${MY_VAR} value""","diff --git a/tests/docker-stacks-foundation/run-hooks-unset/c.sh b/tests/docker-stacks-foundation/run-hooks-unset/c.sh
new file mode 100644
index 00000000..ef69df39
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-unset/c.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Inside c.sh MY_VAR variable has ${MY_VAR} value""",Yes
tests/docker-stacks-foundation/test_run_hooks.py,tests/docker-stacks-foundation/test_run_hooks.py,d52ea4716e5eeb9597b15da8400fe2fde18d00de,9df3959137247badcad97d3c73b2ddd2db3079c9,[FAST_BUILD] Test unset in run-hooks (#2022),"diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index 0774f5f5..483b6817 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -127,3 +127,25 @@ def test_run_hooks_with_failures(container: TrackedContainer) -> None:
         )
 
     assert ""OTHER_VAR=456"" in logs
+
+
+def test_run_hooks_unset(container: TrackedContainer) -> None:
+    host_data_dir = THIS_DIR / ""run-hooks-unset""
+    cont_data_dir = ""/home/jovyan/data""
+    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
+    # Unfortunately, Docker treats all files in mounter dir as executable files
+    # So we make a copy of mounted dir inside a container
+    command = (
+        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
+        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/""
+    )
+    logs = container.run_and_wait(
+        timeout=5,
+        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
+        tty=True,
+        command=[""bash"", ""-c"", command],
+    )
+    assert ""Inside a.sh MY_VAR variable has 123 value"" in logs
+    assert ""Inside b.sh MY_VAR variable has 123 value"" in logs
+    assert ""Unsetting MY_VAR"" in logs
+    assert ""Inside c.sh MY_VAR variable has  value"" in logs","diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index 0774f5f5..483b6817 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -127,3 +127,25 @@ def test_run_hooks_with_failures(container: TrackedContainer) -> None:
         )
 
     assert ""OTHER_VAR=456"" in logs
+
+
+def test_run_hooks_unset(container: TrackedContainer) -> None:
+    host_data_dir = THIS_DIR / ""run-hooks-unset""
+    cont_data_dir = ""/home/jovyan/data""
+    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
+    # Unfortunately, Docker treats all files in mounter dir as executable files
+    # So we make a copy of mounted dir inside a container
+    command = (
+        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
+        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/""
+    )
+    logs = container.run_and_wait(
+        timeout=5,
+        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
+        tty=True,
+        command=[""bash"", ""-c"", command],
+    )
+    assert ""Inside a.sh MY_VAR variable has 123 value"" in logs
+    assert ""Inside b.sh MY_VAR variable has 123 value"" in logs
+    assert ""Unsetting MY_VAR"" in logs
+    assert ""Inside c.sh MY_VAR variable has  value"" in logs",Yes
tests/docker-stacks-foundation/test_run_hooks.py,tests/docker-stacks-foundation/test_run_hooks.py,29e6a45dd3cccec098d228c3260709ba8eefcb5f,d52ea4716e5eeb9597b15da8400fe2fde18d00de,Introduce run_source_in_dir to make run-hooks tests easier to write,"diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index 483b6817..bca61c86 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -73,45 +73,44 @@ def test_run_hooks_empty_dir(container: TrackedContainer) -> None:
     )
 
 
-def test_run_hooks_with_files(container: TrackedContainer) -> None:
-    host_data_dir = THIS_DIR / ""run-hooks-data""
+def run_source_in_dir(
+    container: TrackedContainer,
+    subdir: str,
+    command_suffix: str = """",
+    no_failure: bool = True,
+) -> str:
+    host_data_dir = THIS_DIR / subdir
     cont_data_dir = ""/home/jovyan/data""
     # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
     # Unfortunately, Docker treats all files in mounter dir as executable files
     # So we make a copy of mounted dir inside a container
     command = (
         ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
-        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/ &&""
-        ""echo SOME_VAR is ${SOME_VAR}""
+        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/"" + command_suffix
     )
-    logs = container.run_and_wait(
+    return container.run_and_wait(
         timeout=5,
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
+        no_failure=no_failure,
         command=[""bash"", ""-c"", command],
     )
+
+
+def test_run_hooks_with_files(container: TrackedContainer) -> None:
+    logs = run_source_in_dir(
+        container,
+        subdir=""run-hooks-data"",
+        command_suffix=""&& echo SOME_VAR is ${SOME_VAR}"",
+    )
+
     assert ""Executable python file was successfully"" in logs
     assert ""Ignoring non-executable: /home/jovyan/data-copy//non_executable.py"" in logs
     assert ""SOME_VAR is 123"" in logs
 
 
 def test_run_hooks_with_failures(container: TrackedContainer) -> None:
-    host_data_dir = THIS_DIR / ""run-hooks-failures""
-    cont_data_dir = ""/home/jovyan/data""
-    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
-    # Unfortunately, Docker treats all files in mounter dir as executable files
-    # So we make a copy of mounted dir inside a container
-    command = (
-        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
-        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/""
-    )
-    logs = container.run_and_wait(
-        timeout=5,
-        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
-        tty=True,
-        no_failure=False,
-        command=[""bash"", ""-c"", command],
-    )
+    logs = run_source_in_dir(container, subdir=""run-hooks-failures"", no_failure=False)
 
     for file in [""a.sh"", ""b.py"", ""c.sh"", ""d.sh""]:
         assert f""Started: {file}"" in logs
@@ -130,21 +129,8 @@ def test_run_hooks_with_failures(container: TrackedContainer) -> None:
 
 
 def test_run_hooks_unset(container: TrackedContainer) -> None:
-    host_data_dir = THIS_DIR / ""run-hooks-unset""
-    cont_data_dir = ""/home/jovyan/data""
-    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
-    # Unfortunately, Docker treats all files in mounter dir as executable files
-    # So we make a copy of mounted dir inside a container
-    command = (
-        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
-        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/""
-    )
-    logs = container.run_and_wait(
-        timeout=5,
-        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
-        tty=True,
-        command=[""bash"", ""-c"", command],
-    )
+    logs = run_source_in_dir(container, subdir=""run-hooks-unset"")
+
     assert ""Inside a.sh MY_VAR variable has 123 value"" in logs
     assert ""Inside b.sh MY_VAR variable has 123 value"" in logs
     assert ""Unsetting MY_VAR"" in logs","diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index 483b6817..bca61c86 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -73,45 +73,44 @@ def test_run_hooks_empty_dir(container: TrackedContainer) -> None:
     )
 
 
-def test_run_hooks_with_files(container: TrackedContainer) -> None:
-    host_data_dir = THIS_DIR / ""run-hooks-data""
+def run_source_in_dir(
+    container: TrackedContainer,
+    subdir: str,
+    command_suffix: str = """",
+    no_failure: bool = True,
+) -> str:
+    host_data_dir = THIS_DIR / subdir
     cont_data_dir = ""/home/jovyan/data""
     # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
     # Unfortunately, Docker treats all files in mounter dir as executable files
     # So we make a copy of mounted dir inside a container
     command = (
         ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
-        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/ &&""
-        ""echo SOME_VAR is ${SOME_VAR}""
+        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/"" + command_suffix
     )
-    logs = container.run_and_wait(
+    return container.run_and_wait(
         timeout=5,
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
+        no_failure=no_failure,
         command=[""bash"", ""-c"", command],
     )
+
+
+def test_run_hooks_with_files(container: TrackedContainer) -> None:
+    logs = run_source_in_dir(
+        container,
+        subdir=""run-hooks-data"",
+        command_suffix=""&& echo SOME_VAR is ${SOME_VAR}"",
+    )
+
     assert ""Executable python file was successfully"" in logs
     assert ""Ignoring non-executable: /home/jovyan/data-copy//non_executable.py"" in logs
     assert ""SOME_VAR is 123"" in logs
 
 
 def test_run_hooks_with_failures(container: TrackedContainer) -> None:
-    host_data_dir = THIS_DIR / ""run-hooks-failures""
-    cont_data_dir = ""/home/jovyan/data""
-    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
-    # Unfortunately, Docker treats all files in mounter dir as executable files
-    # So we make a copy of mounted dir inside a container
-    command = (
-        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
-        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/""
-    )
-    logs = container.run_and_wait(
-        timeout=5,
-        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
-        tty=True,
-        no_failure=False,
-        command=[""bash"", ""-c"", command],
-    )
+    logs = run_source_in_dir(container, subdir=""run-hooks-failures"", no_failure=False)
 
     for file in [""a.sh"", ""b.py"", ""c.sh"", ""d.sh""]:
         assert f""Started: {file}"" in logs
@@ -130,21 +129,8 @@ def test_run_hooks_with_failures(container: TrackedContainer) -> None:
 
 
 def test_run_hooks_unset(container: TrackedContainer) -> None:
-    host_data_dir = THIS_DIR / ""run-hooks-unset""
-    cont_data_dir = ""/home/jovyan/data""
-    # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
-    # Unfortunately, Docker treats all files in mounter dir as executable files
-    # So we make a copy of mounted dir inside a container
-    command = (
-        ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
-        ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/""
-    )
-    logs = container.run_and_wait(
-        timeout=5,
-        volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
-        tty=True,
-        command=[""bash"", ""-c"", command],
-    )
+    logs = run_source_in_dir(container, subdir=""run-hooks-unset"")
+
     assert ""Inside a.sh MY_VAR variable has 123 value"" in logs
     assert ""Inside b.sh MY_VAR variable has 123 value"" in logs
     assert ""Unsetting MY_VAR"" in logs",Yes
,tests/docker-stacks-foundation/run-hooks-change/a.sh,0ad837af8f3beae51b9987b7637fabc294680851,29e6a45dd3cccec098d228c3260709ba8eefcb5f,[FAST_BUILD] Test change variable value in run-hooks (#2023),"diff --git a/tests/docker-stacks-foundation/run-hooks-change/a.sh b/tests/docker-stacks-foundation/run-hooks-change/a.sh
new file mode 100644
index 00000000..61701e2a
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-change/a.sh
@@ -0,0 +1,6 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+export MY_VAR=123
+echo ""Inside a.sh MY_VAR variable has ${MY_VAR} value""","diff --git a/tests/docker-stacks-foundation/run-hooks-change/a.sh b/tests/docker-stacks-foundation/run-hooks-change/a.sh
new file mode 100644
index 00000000..61701e2a
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-change/a.sh
@@ -0,0 +1,6 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+export MY_VAR=123
+echo ""Inside a.sh MY_VAR variable has ${MY_VAR} value""",Yes
,tests/docker-stacks-foundation/run-hooks-change/b.sh,0ad837af8f3beae51b9987b7637fabc294680851,29e6a45dd3cccec098d228c3260709ba8eefcb5f,[FAST_BUILD] Test change variable value in run-hooks (#2023),"diff --git a/tests/docker-stacks-foundation/run-hooks-change/b.sh b/tests/docker-stacks-foundation/run-hooks-change/b.sh
new file mode 100644
index 00000000..fdca9748
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-change/b.sh
@@ -0,0 +1,8 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Inside b.sh MY_VAR variable has ${MY_VAR} value""
+echo ""Changing value of MY_VAR""
+export MY_VAR=456
+echo ""After change inside b.sh MY_VAR variable has ${MY_VAR} value""","diff --git a/tests/docker-stacks-foundation/run-hooks-change/b.sh b/tests/docker-stacks-foundation/run-hooks-change/b.sh
new file mode 100644
index 00000000..fdca9748
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-change/b.sh
@@ -0,0 +1,8 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Inside b.sh MY_VAR variable has ${MY_VAR} value""
+echo ""Changing value of MY_VAR""
+export MY_VAR=456
+echo ""After change inside b.sh MY_VAR variable has ${MY_VAR} value""",Yes
,tests/docker-stacks-foundation/run-hooks-change/c.sh,0ad837af8f3beae51b9987b7637fabc294680851,29e6a45dd3cccec098d228c3260709ba8eefcb5f,[FAST_BUILD] Test change variable value in run-hooks (#2023),"diff --git a/tests/docker-stacks-foundation/run-hooks-change/c.sh b/tests/docker-stacks-foundation/run-hooks-change/c.sh
new file mode 100644
index 00000000..ef69df39
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-change/c.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Inside c.sh MY_VAR variable has ${MY_VAR} value""","diff --git a/tests/docker-stacks-foundation/run-hooks-change/c.sh b/tests/docker-stacks-foundation/run-hooks-change/c.sh
new file mode 100644
index 00000000..ef69df39
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-change/c.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+echo ""Inside c.sh MY_VAR variable has ${MY_VAR} value""",Yes
tests/docker-stacks-foundation/test_run_hooks.py,tests/docker-stacks-foundation/test_run_hooks.py,0ad837af8f3beae51b9987b7637fabc294680851,29e6a45dd3cccec098d228c3260709ba8eefcb5f,[FAST_BUILD] Test change variable value in run-hooks (#2023),"diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index bca61c86..2ed8b1f2 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -135,3 +135,13 @@ def test_run_hooks_unset(container: TrackedContainer) -> None:
     assert ""Inside b.sh MY_VAR variable has 123 value"" in logs
     assert ""Unsetting MY_VAR"" in logs
     assert ""Inside c.sh MY_VAR variable has  value"" in logs
+
+
+def test_run_hooks_change(container: TrackedContainer) -> None:
+    logs = run_source_in_dir(container, subdir=""run-hooks-change"")
+
+    assert ""Inside a.sh MY_VAR variable has 123 value"" in logs
+    assert ""Inside b.sh MY_VAR variable has 123 value"" in logs
+    assert ""Changing value of MY_VAR"" in logs
+    assert ""After change inside b.sh MY_VAR variable has 456 value"" in logs
+    assert ""Inside c.sh MY_VAR variable has 456 value"" in logs","diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index bca61c86..2ed8b1f2 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -135,3 +135,13 @@ def test_run_hooks_unset(container: TrackedContainer) -> None:
     assert ""Inside b.sh MY_VAR variable has 123 value"" in logs
     assert ""Unsetting MY_VAR"" in logs
     assert ""Inside c.sh MY_VAR variable has  value"" in logs
+
+
+def test_run_hooks_change(container: TrackedContainer) -> None:
+    logs = run_source_in_dir(container, subdir=""run-hooks-change"")
+
+    assert ""Inside a.sh MY_VAR variable has 123 value"" in logs
+    assert ""Inside b.sh MY_VAR variable has 123 value"" in logs
+    assert ""Changing value of MY_VAR"" in logs
+    assert ""After change inside b.sh MY_VAR variable has 456 value"" in logs
+    assert ""Inside c.sh MY_VAR variable has 456 value"" in logs",Yes
tests/docker-stacks-foundation/run-hooks-data/executable.py,tests/docker-stacks-foundation/run-hooks-executables/executable.py,8c874a1cb4992fb6ec6de8d536d98db48f96078d,0ad837af8f3beae51b9987b7637fabc294680851,Rename run-hooks subdir to better show the test meaning,"diff --git a/tests/docker-stacks-foundation/run-hooks-executables/executable.py b/tests/docker-stacks-foundation/run-hooks-executables/executable.py
new file mode 100755
index 00000000..5fb2b9a3
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-executables/executable.py
@@ -0,0 +1,5 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+print(""Executable python file was successfully run"")","diff --git a/tests/docker-stacks-foundation/run-hooks-executables/executable.py b/tests/docker-stacks-foundation/run-hooks-executables/executable.py
new file mode 100755
index 00000000..5fb2b9a3
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-executables/executable.py
@@ -0,0 +1,5 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+print(""Executable python file was successfully run"")",Yes
tests/docker-stacks-foundation/run-hooks-data/non_executable.py,tests/docker-stacks-foundation/run-hooks-executables/non_executable.py,8c874a1cb4992fb6ec6de8d536d98db48f96078d,0ad837af8f3beae51b9987b7637fabc294680851,Rename run-hooks subdir to better show the test meaning,"diff --git a/tests/docker-stacks-foundation/run-hooks-executables/non_executable.py b/tests/docker-stacks-foundation/run-hooks-executables/non_executable.py
new file mode 100644
index 00000000..19c8d0b7
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-executables/non_executable.py
@@ -0,0 +1,5 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+assert False","diff --git a/tests/docker-stacks-foundation/run-hooks-executables/non_executable.py b/tests/docker-stacks-foundation/run-hooks-executables/non_executable.py
new file mode 100644
index 00000000..19c8d0b7
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-executables/non_executable.py
@@ -0,0 +1,5 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+assert False",Yes
tests/docker-stacks-foundation/run-hooks-data/run-me.sh,tests/docker-stacks-foundation/run-hooks-executables/run-me.sh,8c874a1cb4992fb6ec6de8d536d98db48f96078d,0ad837af8f3beae51b9987b7637fabc294680851,Rename run-hooks subdir to better show the test meaning,"diff --git a/tests/docker-stacks-foundation/run-hooks-executables/run-me.sh b/tests/docker-stacks-foundation/run-hooks-executables/run-me.sh
new file mode 100644
index 00000000..f4dc08aa
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-executables/run-me.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+export SOME_VAR=123","diff --git a/tests/docker-stacks-foundation/run-hooks-executables/run-me.sh b/tests/docker-stacks-foundation/run-hooks-executables/run-me.sh
new file mode 100644
index 00000000..f4dc08aa
--- /dev/null
+++ b/tests/docker-stacks-foundation/run-hooks-executables/run-me.sh
@@ -0,0 +1,5 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+export SOME_VAR=123",Yes
tests/docker-stacks-foundation/test_run_hooks.py,tests/docker-stacks-foundation/test_run_hooks.py,8c874a1cb4992fb6ec6de8d536d98db48f96078d,0ad837af8f3beae51b9987b7637fabc294680851,Rename run-hooks subdir to better show the test meaning,"diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index 2ed8b1f2..6bcbaf8c 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -97,14 +97,14 @@ def run_source_in_dir(
     )
 
 
-def test_run_hooks_with_files(container: TrackedContainer) -> None:
+def test_run_hooks_executables(container: TrackedContainer) -> None:
     logs = run_source_in_dir(
         container,
-        subdir=""run-hooks-data"",
+        subdir=""run-hooks-executables"",
         command_suffix=""&& echo SOME_VAR is ${SOME_VAR}"",
     )
 
-    assert ""Executable python file was successfully"" in logs
+    assert ""Executable python file was successfully run"" in logs
     assert ""Ignoring non-executable: /home/jovyan/data-copy//non_executable.py"" in logs
     assert ""SOME_VAR is 123"" in logs","diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index 2ed8b1f2..6bcbaf8c 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -97,14 +97,14 @@ def run_source_in_dir(
     )
 
 
-def test_run_hooks_with_files(container: TrackedContainer) -> None:
+def test_run_hooks_executables(container: TrackedContainer) -> None:
     logs = run_source_in_dir(
         container,
-        subdir=""run-hooks-data"",
+        subdir=""run-hooks-executables"",
         command_suffix=""&& echo SOME_VAR is ${SOME_VAR}"",
     )
 
-    assert ""Executable python file was successfully"" in logs
+    assert ""Executable python file was successfully run"" in logs
     assert ""Ignoring non-executable: /home/jovyan/data-copy//non_executable.py"" in logs
     assert ""SOME_VAR is 123"" in logs",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,0a0e833fcbcafa4262e9ab10d15a33df3a1abc11,8c874a1cb4992fb6ec6de8d536d98db48f96078d,Fix quay.io naming,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index d8cb21aa..a65280d8 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -1,8 +1,8 @@
 name: Build, test and push Docker Images
 
 # [FAST_BUILD] in the PR title makes this workflow only build
-# `jupyter/docker-stacks-foundation` and `/jupyter/base-notebook` in the PR
-# This allows to run CI faster in case where full build is not required
+# `jupyter/docker-stacks-foundation` and `jupyter/base-notebook`
+# This allows to run CI faster if full build is not required
 # This only works for `pull_request` event and has no effect on `push` to the `main` branch
 
 on:","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index d8cb21aa..a65280d8 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -1,8 +1,8 @@
 name: Build, test and push Docker Images
 
 # [FAST_BUILD] in the PR title makes this workflow only build
-# `jupyter/docker-stacks-foundation` and `/jupyter/base-notebook` in the PR
-# This allows to run CI faster in case where full build is not required
+# `jupyter/docker-stacks-foundation` and `jupyter/base-notebook`
+# This allows to run CI faster if full build is not required
 # This only works for `pull_request` event and has no effect on `push` to the `main` branch
 
 on:",Yes
README.md,README.md,0a0e833fcbcafa4262e9ab10d15a33df3a1abc11,8c874a1cb4992fb6ec6de8d536d98db48f96078d,Fix quay.io naming,"diff --git a/README.md b/README.md
index 0649bb00..1fd05eb2 100644
--- a/README.md
+++ b/README.md
@@ -5,7 +5,7 @@
 [![Read the Docs badge](https://img.shields.io/readthedocs/jupyter-docker-stacks.svg)](https://jupyter-docker-stacks.readthedocs.io/en/latest/ ""Documentation build status"")
 [![pre-commit.ci status](https://results.pre-commit.ci/badge/github/jupyter/docker-stacks/main.svg)](https://results.pre-commit.ci/latest/github/jupyter/docker-stacks/main ""pre-commit.ci build status"")
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")
-[![Binder badge](https://static.mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb ""Launch a jupyter/base-notebook container on mybinder.org"")
+[![Binder badge](https://static.mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb ""Launch a quay.io/jupyter/base-notebook container on mybinder.org"")
 
 Jupyter Docker Stacks are a set of ready-to-run [Docker images](https://quay.io/organization/jupyter) containing Jupyter applications and interactive computing tools.
 You can use a stack image to do any of the following (and more):
@@ -17,7 +17,7 @@ You can use a stack image to do any of the following (and more):
 
 ## Quick Start
 
-You can try a [relatively recent build of the jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb)
+You can try a [relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb)
 by simply clicking the preceding link.
 Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
 know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use
@@ -87,7 +87,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 ## CPU Architectures
 
 - We publish containers for both `x86_64` and `aarch64` platforms
-- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
+- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create multi-platform `tensorflow-notebook` image as well","diff --git a/README.md b/README.md
index 0649bb00..1fd05eb2 100644
--- a/README.md
+++ b/README.md
@@ -5,7 +5,7 @@
 [![Read the Docs badge](https://img.shields.io/readthedocs/jupyter-docker-stacks.svg)](https://jupyter-docker-stacks.readthedocs.io/en/latest/ ""Documentation build status"")
 [![pre-commit.ci status](https://results.pre-commit.ci/badge/github/jupyter/docker-stacks/main.svg)](https://results.pre-commit.ci/latest/github/jupyter/docker-stacks/main ""pre-commit.ci build status"")
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")
-[![Binder badge](https://static.mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb ""Launch a jupyter/base-notebook container on mybinder.org"")
+[![Binder badge](https://static.mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb ""Launch a quay.io/jupyter/base-notebook container on mybinder.org"")
 
 Jupyter Docker Stacks are a set of ready-to-run [Docker images](https://quay.io/organization/jupyter) containing Jupyter applications and interactive computing tools.
 You can use a stack image to do any of the following (and more):
@@ -17,7 +17,7 @@ You can use a stack image to do any of the following (and more):
 
 ## Quick Start
 
-You can try a [relatively recent build of the jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb)
+You can try a [relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb)
 by simply clicking the preceding link.
 Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
 know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use
@@ -87,7 +87,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 ## CPU Architectures
 
 - We publish containers for both `x86_64` and `aarch64` platforms
-- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
+- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create multi-platform `tensorflow-notebook` image as well",Yes
tests/base-notebook/test_packages.py,tests/base-notebook/test_packages.py,0a0e833fcbcafa4262e9ab10d15a33df3a1abc11,8c874a1cb4992fb6ec6de8d536d98db48f96078d,Fix quay.io naming,"diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index ae4fa3f1..a049c9c3 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -24,15 +24,14 @@ Example:
     $ make test/base-notebook
 
     # [...]
-    # test/test_packages.py::test_python_packages
     # tests/base-notebook/test_packages.py::test_python_packages
     # ---------------------------------------------------------------------------------------------- live log setup ----------------------------------------------------------------------------------------------
-    # 2022-02-17 16:44:36 [    INFO] Starting container jupyter/base-notebook ... (package_helper.py:55)
-    # 2022-02-17 16:44:36 [    INFO] Running jupyter/base-notebook with args {'detach': True, 'tty': True, 'command': ['start.sh', 'bash', '-c', 'sleep infinity']} ... (conftest.py:95)
-    # 2022-02-17 16:44:37 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
+    # 2023-11-04 23:59:01 [    INFO] Starting container quay.io/jupyter/base-notebook ... (package_helper.py:55)
+    # 2023-11-04 23:59:01 [    INFO] Running quay.io/jupyter/base-notebook with args {'detach': True, 'tty': True, 'command': ['start.sh', 'bash', '-c', 'sleep infinity']} ... (conftest.py:99)
+    # 2023-11-04 23:59:01 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
     # ---------------------------------------------------------------------------------------------- live log call -----------------------------------------------------------------------------------------------
-    # 2022-02-17 16:44:38 [    INFO] Testing the import of packages ... (test_packages.py:144)
-    # 2022-02-17 16:44:38 [    INFO] Trying to import mamba (test_packages.py:146)
+    # 2023-11-04 23:59:02 [    INFO] Testing the import of packages ... (test_packages.py:152)
+    # 2023-11-04 23:59:02 [    INFO] Trying to import mamba (test_packages.py:154)
     # [...]
 
 """"""","diff --git a/tests/base-notebook/test_packages.py b/tests/base-notebook/test_packages.py
index ae4fa3f1..a049c9c3 100644
--- a/tests/base-notebook/test_packages.py
+++ b/tests/base-notebook/test_packages.py
@@ -24,15 +24,14 @@ Example:
     $ make test/base-notebook
 
     # [...]
-    # test/test_packages.py::test_python_packages
     # tests/base-notebook/test_packages.py::test_python_packages
     # ---------------------------------------------------------------------------------------------- live log setup ----------------------------------------------------------------------------------------------
-    # 2022-02-17 16:44:36 [    INFO] Starting container jupyter/base-notebook ... (package_helper.py:55)
-    # 2022-02-17 16:44:36 [    INFO] Running jupyter/base-notebook with args {'detach': True, 'tty': True, 'command': ['start.sh', 'bash', '-c', 'sleep infinity']} ... (conftest.py:95)
-    # 2022-02-17 16:44:37 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
+    # 2023-11-04 23:59:01 [    INFO] Starting container quay.io/jupyter/base-notebook ... (package_helper.py:55)
+    # 2023-11-04 23:59:01 [    INFO] Running quay.io/jupyter/base-notebook with args {'detach': True, 'tty': True, 'command': ['start.sh', 'bash', '-c', 'sleep infinity']} ... (conftest.py:99)
+    # 2023-11-04 23:59:01 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
     # ---------------------------------------------------------------------------------------------- live log call -----------------------------------------------------------------------------------------------
-    # 2022-02-17 16:44:38 [    INFO] Testing the import of packages ... (test_packages.py:144)
-    # 2022-02-17 16:44:38 [    INFO] Trying to import mamba (test_packages.py:146)
+    # 2023-11-04 23:59:02 [    INFO] Testing the import of packages ... (test_packages.py:152)
+    # 2023-11-04 23:59:02 [    INFO] Trying to import mamba (test_packages.py:154)
     # [...]
 
 """"""",Yes
tests/base-notebook/test_packages.py,tests/docker-stacks-foundation/test_packages.py,dc5ec3d08b3f5270a007a303a980b12c67535136,0a0e833fcbcafa4262e9ab10d15a33df3a1abc11,Move test_packages.py to docker-stacks-foundation tests,"diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
new file mode 100644
index 00000000..a049c9c3
--- /dev/null
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -0,0 +1,190 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+""""""
+test_packages
+~~~~~~~~~~~~~~~
+This test module tests if R and Python packages installed can be imported.
+It's a basic test aiming to prove that the package is working properly.
+
+The goal is to detect import errors that can be caused by incompatibilities between packages, for example:
+
+- #1012: issue importing `sympy`
+- #966: issue importing `pyarrow`
+
+This module checks dynamically, through the `CondaPackageHelper`,
+only the requested packages i.e. packages requested by `mamba install` in the `Dockerfile`s.
+This means that it does not check dependencies.
+This choice is a tradeoff to cover the main requirements while achieving reasonable test duration.
+However it could be easily changed (or completed) to cover also dependencies.
+Use `package_helper.installed_packages()` instead of `package_helper.requested_packages()`.
+
+Example:
+
+    $ make test/base-notebook
+
+    # [...]
+    # tests/base-notebook/test_packages.py::test_python_packages
+    # ---------------------------------------------------------------------------------------------- live log setup ----------------------------------------------------------------------------------------------
+    # 2023-11-04 23:59:01 [    INFO] Starting container quay.io/jupyter/base-notebook ... (package_helper.py:55)
+    # 2023-11-04 23:59:01 [    INFO] Running quay.io/jupyter/base-notebook with args {'detach': True, 'tty': True, 'command': ['start.sh', 'bash', '-c', 'sleep infinity']} ... (conftest.py:99)
+    # 2023-11-04 23:59:01 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
+    # ---------------------------------------------------------------------------------------------- live log call -----------------------------------------------------------------------------------------------
+    # 2023-11-04 23:59:02 [    INFO] Testing the import of packages ... (test_packages.py:152)
+    # 2023-11-04 23:59:02 [    INFO] Trying to import mamba (test_packages.py:154)
+    # [...]
+
+""""""
+
+import logging
+from collections.abc import Iterable
+from typing import Callable
+
+import pytest  # type: ignore
+
+from tests.conftest import TrackedContainer
+from tests.package_helper import CondaPackageHelper
+
+LOGGER = logging.getLogger(__name__)
+
+# Mapping between package and module name
+PACKAGE_MAPPING = {
+    # Python
+    ""beautifulsoup4"": ""bs4"",
+    ""jupyter-pluto-proxy"": ""jupyter_pluto_proxy"",
+    ""matplotlib-base"": ""matplotlib"",
+    ""pytables"": ""tables"",
+    ""scikit-image"": ""skimage"",
+    ""scikit-learn"": ""sklearn"",
+    # R
+    ""randomforest"": ""randomForest"",
+    ""rcurl"": ""RCurl"",
+    ""rodbc"": ""RODBC"",
+    ""rsqlite"": ""DBI"",
+}
+
+# List of packages that cannot be tested in a standard way
+EXCLUDED_PACKAGES = [
+    ""bzip2"",
+    ""ca-certificates"",
+    ""conda-forge::blas[build=openblas]"",
+    ""grpcio-status"",
+    ""grpcio"",
+    ""hdf5"",
+    ""jupyterlab-git"",
+    ""openssl"",
+    ""pandas[version='>"",
+    ""protobuf"",
+    ""python"",
+    ""r-irkernel"",
+    ""unixodbc"",
+]
+
+
+@pytest.fixture(scope=""function"")
+def package_helper(container: TrackedContainer) -> CondaPackageHelper:
+    """"""Return a package helper object that can be used to perform tests on installed packages""""""
+    return CondaPackageHelper(container)
+
+
+@pytest.fixture(scope=""function"")
+def packages(package_helper: CondaPackageHelper) -> dict[str, set[str]]:
+    """"""Return the list of requested packages (i.e. packages explicitly installed excluding dependencies)""""""
+    return package_helper.requested_packages()
+
+
+def get_package_import_name(package: str) -> str:
+    """"""Perform a mapping between the python package name and the name used for the import""""""
+    return PACKAGE_MAPPING.get(package, package)
+
+
+def excluded_package_predicate(package: str) -> bool:
+    """"""Return whether a package is excluded from the list
+    (i.e. a package that cannot be tested with standard imports)""""""
+    return package in EXCLUDED_PACKAGES
+
+
+def python_package_predicate(package: str) -> bool:
+    """"""Predicate matching python packages""""""
+    return not excluded_package_predicate(package) and not r_package_predicate(package)
+
+
+def r_package_predicate(package: str) -> bool:
+    """"""Predicate matching R packages""""""
+    return not excluded_package_predicate(package) and package.startswith(""r-"")
+
+
+def _check_import_package(
+    package_helper: CondaPackageHelper, command: list[str]
+) -> None:
+    """"""Generic function executing a command""""""
+    LOGGER.debug(f""Trying to import a package with [{command}] ..."")
+    exec_result = package_helper.running_container.exec_run(command)
+    assert (
+        exec_result.exit_code == 0
+    ), f""Import package failed, output: {exec_result.output}""
+
+
+def check_import_python_package(
+    package_helper: CondaPackageHelper, package: str
+) -> None:
+    """"""Try to import a Python package from the command line""""""
+    _check_import_package(package_helper, [""python"", ""-c"", f""import {package}""])
+
+
+def check_import_r_package(package_helper: CondaPackageHelper, package: str) -> None:
+    """"""Try to import an R package from the command line""""""
+    _check_import_package(package_helper, [""R"", ""--slave"", ""-e"", f""library({package})""])
+
+
+def _check_import_packages(
+    package_helper: CondaPackageHelper,
+    packages_to_check: Iterable[str],
+    check_function: Callable[[CondaPackageHelper, str], None],
+) -> None:
+    """"""Test if packages can be imported
+
+    Note: using a list of packages instead of a fixture for the list of packages
+    since pytest prevents use of multiple yields
+    """"""
+    failures = {}
+    LOGGER.info(""Testing the import of packages ..."")
+    for package in packages_to_check:
+        LOGGER.info(f""Trying to import {package}"")
+        try:
+            check_function(package_helper, package)
+        except AssertionError as err:
+            failures[package] = err
+    if len(failures) > 0:
+        raise AssertionError(failures)
+
+
+@pytest.fixture(scope=""function"")
+def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
+    """"""Return an iterable of R packages""""""
+    # package[2:] is to remove the leading ""r-"" appended on R packages
+    return map(
+        lambda package: get_package_import_name(package[2:]),
+        filter(r_package_predicate, packages),
+    )
+
+
+def test_r_packages(
+    package_helper: CondaPackageHelper, r_packages: Iterable[str]
+) -> None:
+    """"""Test the import of specified R packages""""""
+    _check_import_packages(package_helper, r_packages, check_import_r_package)
+
+
+@pytest.fixture(scope=""function"")
+def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
+    """"""Return an iterable of Python packages""""""
+    return map(get_package_import_name, filter(python_package_predicate, packages))
+
+
+def test_python_packages(
+    package_helper: CondaPackageHelper,
+    python_packages: Iterable[str],
+) -> None:
+    """"""Test the import of specified python packages""""""
+    _check_import_packages(package_helper, python_packages, check_import_python_package)","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
new file mode 100644
index 00000000..a049c9c3
--- /dev/null
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -0,0 +1,190 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+""""""
+test_packages
+~~~~~~~~~~~~~~~
+This test module tests if R and Python packages installed can be imported.
+It's a basic test aiming to prove that the package is working properly.
+
+The goal is to detect import errors that can be caused by incompatibilities between packages, for example:
+
+- #1012: issue importing `sympy`
+- #966: issue importing `pyarrow`
+
+This module checks dynamically, through the `CondaPackageHelper`,
+only the requested packages i.e. packages requested by `mamba install` in the `Dockerfile`s.
+This means that it does not check dependencies.
+This choice is a tradeoff to cover the main requirements while achieving reasonable test duration.
+However it could be easily changed (or completed) to cover also dependencies.
+Use `package_helper.installed_packages()` instead of `package_helper.requested_packages()`.
+
+Example:
+
+    $ make test/base-notebook
+
+    # [...]
+    # tests/base-notebook/test_packages.py::test_python_packages
+    # ---------------------------------------------------------------------------------------------- live log setup ----------------------------------------------------------------------------------------------
+    # 2023-11-04 23:59:01 [    INFO] Starting container quay.io/jupyter/base-notebook ... (package_helper.py:55)
+    # 2023-11-04 23:59:01 [    INFO] Running quay.io/jupyter/base-notebook with args {'detach': True, 'tty': True, 'command': ['start.sh', 'bash', '-c', 'sleep infinity']} ... (conftest.py:99)
+    # 2023-11-04 23:59:01 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
+    # ---------------------------------------------------------------------------------------------- live log call -----------------------------------------------------------------------------------------------
+    # 2023-11-04 23:59:02 [    INFO] Testing the import of packages ... (test_packages.py:152)
+    # 2023-11-04 23:59:02 [    INFO] Trying to import mamba (test_packages.py:154)
+    # [...]
+
+""""""
+
+import logging
+from collections.abc import Iterable
+from typing import Callable
+
+import pytest  # type: ignore
+
+from tests.conftest import TrackedContainer
+from tests.package_helper import CondaPackageHelper
+
+LOGGER = logging.getLogger(__name__)
+
+# Mapping between package and module name
+PACKAGE_MAPPING = {
+    # Python
+    ""beautifulsoup4"": ""bs4"",
+    ""jupyter-pluto-proxy"": ""jupyter_pluto_proxy"",
+    ""matplotlib-base"": ""matplotlib"",
+    ""pytables"": ""tables"",
+    ""scikit-image"": ""skimage"",
+    ""scikit-learn"": ""sklearn"",
+    # R
+    ""randomforest"": ""randomForest"",
+    ""rcurl"": ""RCurl"",
+    ""rodbc"": ""RODBC"",
+    ""rsqlite"": ""DBI"",
+}
+
+# List of packages that cannot be tested in a standard way
+EXCLUDED_PACKAGES = [
+    ""bzip2"",
+    ""ca-certificates"",
+    ""conda-forge::blas[build=openblas]"",
+    ""grpcio-status"",
+    ""grpcio"",
+    ""hdf5"",
+    ""jupyterlab-git"",
+    ""openssl"",
+    ""pandas[version='>"",
+    ""protobuf"",
+    ""python"",
+    ""r-irkernel"",
+    ""unixodbc"",
+]
+
+
+@pytest.fixture(scope=""function"")
+def package_helper(container: TrackedContainer) -> CondaPackageHelper:
+    """"""Return a package helper object that can be used to perform tests on installed packages""""""
+    return CondaPackageHelper(container)
+
+
+@pytest.fixture(scope=""function"")
+def packages(package_helper: CondaPackageHelper) -> dict[str, set[str]]:
+    """"""Return the list of requested packages (i.e. packages explicitly installed excluding dependencies)""""""
+    return package_helper.requested_packages()
+
+
+def get_package_import_name(package: str) -> str:
+    """"""Perform a mapping between the python package name and the name used for the import""""""
+    return PACKAGE_MAPPING.get(package, package)
+
+
+def excluded_package_predicate(package: str) -> bool:
+    """"""Return whether a package is excluded from the list
+    (i.e. a package that cannot be tested with standard imports)""""""
+    return package in EXCLUDED_PACKAGES
+
+
+def python_package_predicate(package: str) -> bool:
+    """"""Predicate matching python packages""""""
+    return not excluded_package_predicate(package) and not r_package_predicate(package)
+
+
+def r_package_predicate(package: str) -> bool:
+    """"""Predicate matching R packages""""""
+    return not excluded_package_predicate(package) and package.startswith(""r-"")
+
+
+def _check_import_package(
+    package_helper: CondaPackageHelper, command: list[str]
+) -> None:
+    """"""Generic function executing a command""""""
+    LOGGER.debug(f""Trying to import a package with [{command}] ..."")
+    exec_result = package_helper.running_container.exec_run(command)
+    assert (
+        exec_result.exit_code == 0
+    ), f""Import package failed, output: {exec_result.output}""
+
+
+def check_import_python_package(
+    package_helper: CondaPackageHelper, package: str
+) -> None:
+    """"""Try to import a Python package from the command line""""""
+    _check_import_package(package_helper, [""python"", ""-c"", f""import {package}""])
+
+
+def check_import_r_package(package_helper: CondaPackageHelper, package: str) -> None:
+    """"""Try to import an R package from the command line""""""
+    _check_import_package(package_helper, [""R"", ""--slave"", ""-e"", f""library({package})""])
+
+
+def _check_import_packages(
+    package_helper: CondaPackageHelper,
+    packages_to_check: Iterable[str],
+    check_function: Callable[[CondaPackageHelper, str], None],
+) -> None:
+    """"""Test if packages can be imported
+
+    Note: using a list of packages instead of a fixture for the list of packages
+    since pytest prevents use of multiple yields
+    """"""
+    failures = {}
+    LOGGER.info(""Testing the import of packages ..."")
+    for package in packages_to_check:
+        LOGGER.info(f""Trying to import {package}"")
+        try:
+            check_function(package_helper, package)
+        except AssertionError as err:
+            failures[package] = err
+    if len(failures) > 0:
+        raise AssertionError(failures)
+
+
+@pytest.fixture(scope=""function"")
+def r_packages(packages: dict[str, set[str]]) -> Iterable[str]:
+    """"""Return an iterable of R packages""""""
+    # package[2:] is to remove the leading ""r-"" appended on R packages
+    return map(
+        lambda package: get_package_import_name(package[2:]),
+        filter(r_package_predicate, packages),
+    )
+
+
+def test_r_packages(
+    package_helper: CondaPackageHelper, r_packages: Iterable[str]
+) -> None:
+    """"""Test the import of specified R packages""""""
+    _check_import_packages(package_helper, r_packages, check_import_r_package)
+
+
+@pytest.fixture(scope=""function"")
+def python_packages(packages: dict[str, set[str]]) -> Iterable[str]:
+    """"""Return an iterable of Python packages""""""
+    return map(get_package_import_name, filter(python_package_predicate, packages))
+
+
+def test_python_packages(
+    package_helper: CondaPackageHelper,
+    python_packages: Iterable[str],
+) -> None:
+    """"""Test the import of specified python packages""""""
+    _check_import_packages(package_helper, python_packages, check_import_python_package)",Yes
tests/scipy-notebook/test_extensions.py,tests/scipy-notebook/test_extensions.py,7866050bafa140149c2561902e2ca3413a6ecf64,dc5ec3d08b3f5270a007a303a980b12c67535136,Improve wording in test_extensions.py,"diff --git a/tests/scipy-notebook/test_extensions.py b/tests/scipy-notebook/test_extensions.py
index b77dc89f..d95f7ae5 100644
--- a/tests/scipy-notebook/test_extensions.py
+++ b/tests/scipy-notebook/test_extensions.py
@@ -9,7 +9,7 @@ from tests.conftest import TrackedContainer
 LOGGER = logging.getLogger(__name__)
 
 
-@pytest.mark.skip(reason=""Not yet compliant with JupyterLab 3"")
+@pytest.mark.skip(reason=""Not yet compliant with JupyterLab 4"")
 @pytest.mark.parametrize(
     ""extension"",
     [
@@ -21,7 +21,7 @@ LOGGER = logging.getLogger(__name__)
 def test_check_extension(container: TrackedContainer, extension: str) -> None:
     """"""Basic check of each extension
 
-    The list of extensions can be obtained through this command
+    The list of installed extensions can be obtained through this command:
 
     $ jupyter labextension list","diff --git a/tests/scipy-notebook/test_extensions.py b/tests/scipy-notebook/test_extensions.py
index b77dc89f..d95f7ae5 100644
--- a/tests/scipy-notebook/test_extensions.py
+++ b/tests/scipy-notebook/test_extensions.py
@@ -9,7 +9,7 @@ from tests.conftest import TrackedContainer
 LOGGER = logging.getLogger(__name__)
 
 
-@pytest.mark.skip(reason=""Not yet compliant with JupyterLab 3"")
+@pytest.mark.skip(reason=""Not yet compliant with JupyterLab 4"")
 @pytest.mark.parametrize(
     ""extension"",
     [
@@ -21,7 +21,7 @@ LOGGER = logging.getLogger(__name__)
 def test_check_extension(container: TrackedContainer, extension: str) -> None:
     """"""Basic check of each extension
 
-    The list of extensions can be obtained through this command
+    The list of installed extensions can be obtained through this command:
 
     $ jupyter labextension list",Yes
requirements-dev.txt,requirements-dev.txt,e6f89ded6e1b183c1bf2cadb1c5d1028473abf4c,7866050bafa140149c2561902e2ca3413a6ecf64,Mark test_nbconvert as a flaky test,"diff --git a/requirements-dev.txt b/requirements-dev.txt
index 34dba9f3..3ab2be95 100644
--- a/requirements-dev.txt
+++ b/requirements-dev.txt
@@ -2,6 +2,7 @@ docker
 plumbum
 pre-commit
 pytest
+pytest-retry
 # `pytest-xdist` is a plugin that provides the `--numprocesses` flag,
 # allowing us to run `pytest` tests in parallel
 pytest-xdist","diff --git a/requirements-dev.txt b/requirements-dev.txt
index 34dba9f3..3ab2be95 100644
--- a/requirements-dev.txt
+++ b/requirements-dev.txt
@@ -2,6 +2,7 @@ docker
 plumbum
 pre-commit
 pytest
+pytest-retry
 # `pytest-xdist` is a plugin that provides the `--numprocesses` flag,
 # allowing us to run `pytest` tests in parallel
 pytest-xdist",Yes
tests/all-spark-notebook/test_spark_notebooks.py,tests/all-spark-notebook/test_spark_notebooks.py,e6f89ded6e1b183c1bf2cadb1c5d1028473abf4c,7866050bafa140149c2561902e2ca3413a6ecf64,Mark test_nbconvert as a flaky test,"diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index 0d1537ae..4b2559e7 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -11,6 +11,7 @@ LOGGER = logging.getLogger(__name__)
 THIS_DIR = Path(__file__).parent.resolve()
 
 
+@pytest.mark.flaky(retries=3, delay=1)
 @pytest.mark.parametrize(
     ""test_file"",
     [""issue_1168"", ""local_pyspark"", ""local_sparklyr"", ""local_sparkR""],","diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index 0d1537ae..4b2559e7 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -11,6 +11,7 @@ LOGGER = logging.getLogger(__name__)
 THIS_DIR = Path(__file__).parent.resolve()
 
 
+@pytest.mark.flaky(retries=3, delay=1)
 @pytest.mark.parametrize(
     ""test_file"",
     [""issue_1168"", ""local_pyspark"", ""local_sparklyr"", ""local_sparkR""],",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,eac75714c5cbaabdcf92acf92685c6045b4d2306,e6f89ded6e1b183c1bf2cadb1c5d1028473abf4c,Fix bool -> boolean,"diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 47caa425..759c20ab 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -17,7 +17,7 @@ inputs:
   fastBuild:
     description: Only build docker-stacks-foundation and base-notebook
     required: true
-    type: bool
+    type: boolean
 
 runs:
   using: composite","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 47caa425..759c20ab 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -17,7 +17,7 @@ inputs:
   fastBuild:
     description: Only build docker-stacks-foundation and base-notebook
     required: true
-    type: bool
+    type: boolean
 
 runs:
   using: composite",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,2d640b3cfc3f326d2a2d1b707b3f2fe2490cb5fd,eac75714c5cbaabdcf92acf92685c6045b4d2306,"Fix using inputs in actions: use lowercase input ids, remove types, fix bool checks","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 759c20ab..05b5db39 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -6,18 +6,15 @@ description: Download all manifests and history lines
 # https://github.com/actions/download-artifact/issues/6
 
 inputs:
-  histLineDir:
+  hist-line-dir:
     description: Directory to store history lines
     required: true
-    type: string
-  manifestDir:
+  manifest-dir:
     description: Directory to store manifest files
     required: true
-    type: string
-  fastBuild:
+  fast-build:
     description: Only build docker-stacks-foundation and base-notebook
     required: true
-    type: boolean
 
 runs:
   using: composite
@@ -26,220 +23,220 @@ runs:
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: minimal-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: minimal-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: scipy-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: scipy-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: r-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: r-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: julia-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: julia-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: tensorflow-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: tensorflow-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: datascience-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: datascience-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: pyspark-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: pyspark-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: all-spark-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: all-spark-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
 
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: minimal-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: minimal-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: scipy-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: scipy-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: r-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: r-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: tensorflow-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: tensorflow-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: datascience-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: datascience-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: pyspark-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: pyspark-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: all-spark-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: all-spark-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 759c20ab..05b5db39 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -6,18 +6,15 @@ description: Download all manifests and history lines
 # https://github.com/actions/download-artifact/issues/6
 
 inputs:
-  histLineDir:
+  hist-line-dir:
     description: Directory to store history lines
     required: true
-    type: string
-  manifestDir:
+  manifest-dir:
     description: Directory to store manifest files
     required: true
-    type: string
-  fastBuild:
+  fast-build:
     description: Only build docker-stacks-foundation and base-notebook
     required: true
-    type: boolean
 
 runs:
   using: composite
@@ -26,220 +23,220 @@ runs:
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: minimal-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: minimal-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: scipy-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: scipy-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: r-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: r-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: julia-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: julia-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: tensorflow-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: tensorflow-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: datascience-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: datascience-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: pyspark-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: pyspark-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: all-spark-notebook-aarch64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: all-spark-notebook-x86_64-history_line
-        path: ${{ inputs.histLineDir }}
+        path: ${{ inputs.hist-line-dir }}
 
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: minimal-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: minimal-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: scipy-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: scipy-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: r-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: r-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: tensorflow-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: tensorflow-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: datascience-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: datascience-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: pyspark-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: pyspark-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: all-spark-notebook-aarch64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fastBuild }}
+      if: ${{ !inputs.fast-build == 'true' }}
       with:
         name: all-spark-notebook-x86_64-manifest
-        path: ${{ inputs.manifestDir }}
+        path: ${{ inputs.manifest-dir }}",Yes
.github/actions/load-image/action.yml,.github/actions/load-image/action.yml,2d640b3cfc3f326d2a2d1b707b3f2fe2490cb5fd,eac75714c5cbaabdcf92acf92685c6045b4d2306,"Fix using inputs in actions: use lowercase input ids, remove types, fix bool checks","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index a28ffe17..23195a01 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -5,11 +5,9 @@ inputs:
   image:
     description: Image name
     required: true
-    type: string
   platform:
     description: Image platform
     required: true
-    type: string
 
 runs:
   using: composite","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index a28ffe17..23195a01 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -5,11 +5,9 @@ inputs:
   image:
     description: Image name
     required: true
-    type: string
   platform:
     description: Image platform
     required: true
-    type: string
 
 runs:
   using: composite",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,2d640b3cfc3f326d2a2d1b707b3f2fe2490cb5fd,eac75714c5cbaabdcf92acf92685c6045b4d2306,"Fix using inputs in actions: use lowercase input ids, remove types, fix bool checks","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 0f6296b8..645b6b71 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -21,9 +21,9 @@ jobs:
       - name: Download all manifests and history lines 📥
         uses: ./.github/actions/download-manifests
         with:
-          histLineDir: /tmp/jupyter/hist_lines/
-          manifestDir: /tmp/jupyter/manifests/
-          fastBuild: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+          hist-line-dir: /tmp/jupyter/hist_lines/
+          manifest-dir: /tmp/jupyter/manifests/
+          fast-build: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
       - name: Display structure of downloaded files 🔍️
         run: |
           ls -R /tmp/jupyter/hist_lines/","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 0f6296b8..645b6b71 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -21,9 +21,9 @@ jobs:
       - name: Download all manifests and history lines 📥
         uses: ./.github/actions/download-manifests
         with:
-          histLineDir: /tmp/jupyter/hist_lines/
-          manifestDir: /tmp/jupyter/manifests/
-          fastBuild: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+          hist-line-dir: /tmp/jupyter/hist_lines/
+          manifest-dir: /tmp/jupyter/manifests/
+          fast-build: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
       - name: Display structure of downloaded files 🔍️
         run: |
           ls -R /tmp/jupyter/hist_lines/",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,29a79fc9f46397ae68af291359b056f9822402f4,2d640b3cfc3f326d2a2d1b707b3f2fe2490cb5fd,Fix handling boolean variable in the action,"diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 05b5db39..dd5855f1 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -41,97 +41,97 @@ runs:
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
@@ -158,85 +158,85 @@ runs:
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 05b5db39..dd5855f1 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -41,97 +41,97 @@ runs:
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.hist-line-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.hist-line-dir }}
@@ -158,85 +158,85 @@ runs:
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
-      if: ${{ !inputs.fast-build == 'true' }}
+      if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}",Yes
tagging/manifests.py,tagging/manifests.py,a73ba5a76d31c7488d6c2821e8d2704ff5aa1084,29a79fc9f46397ae68af291359b056f9822402f4,Specify code blocks in manifests,"diff --git a/tagging/manifests.py b/tagging/manifests.py
index 7bd460fb..6c4531e7 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -12,7 +12,7 @@ docker = plumbum.local[""docker""]
 def quoted_output(container: Container, cmd: str) -> str:
     return ""\n"".join(
         [
-            ""```"",
+            ""```text"",
             DockerRunner.run_simple_command(container, cmd, print_result=False).strip(
                 ""\n""
             ),
@@ -54,7 +54,7 @@ class ManifestHeader:
                 f""- Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
                 ""- Git commit message:"",
                 """",
-                ""```"",
+                ""```text"",
                 f""{commit_message}"",
                 ""```"",
             ]","diff --git a/tagging/manifests.py b/tagging/manifests.py
index 7bd460fb..6c4531e7 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -12,7 +12,7 @@ docker = plumbum.local[""docker""]
 def quoted_output(container: Container, cmd: str) -> str:
     return ""\n"".join(
         [
-            ""```"",
+            ""```text"",
             DockerRunner.run_simple_command(container, cmd, print_result=False).strip(
                 ""\n""
             ),
@@ -54,7 +54,7 @@ class ManifestHeader:
                 f""- Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
                 ""- Git commit message:"",
                 """",
-                ""```"",
+                ""```text"",
                 f""{commit_message}"",
                 ""```"",
             ]",Yes
tagging/manifests.py,tagging/manifests.py,2401290ab3bc6606ed4805e8d06947d32af24e29,a73ba5a76d31c7488d6c2821e8d2704ff5aa1084,Make manifests and manifests.py itself more beautiful,"diff --git a/tagging/manifests.py b/tagging/manifests.py
index 6c4531e7..200cab22 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -10,15 +10,15 @@ docker = plumbum.local[""docker""]
 
 
 def quoted_output(container: Container, cmd: str) -> str:
-    return ""\n"".join(
-        [
-            ""```text"",
-            DockerRunner.run_simple_command(container, cmd, print_result=False).strip(
-                ""\n""
-            ),
-            ""```"",
-        ]
-    )
+    cmd_output = DockerRunner.run_simple_command(container, cmd, print_result=False)
+    # For example, `mamba info --quiet` adds redundant empty lines
+    cmd_output = cmd_output.strip(""\n"")
+    # For example, R packages list contains trailing backspaces
+    cmd_output = ""\n"".join(line.rstrip() for line in cmd_output.split(""\n""))
+    return f""""""\
+```text
+{cmd_output}
+```""""""
 
 
 class ManifestHeader:
@@ -32,7 +32,7 @@ class ManifestHeader:
         commit_hash_tag = GitHelper.commit_hash_tag()
         commit_message = GitHelper.commit_message()
 
-        # Unfortunately, docker images doesn't work when specifying `docker.io` as registry
+        # Unfortunately, `docker images` doesn't work when specifying `docker.io` as registry
         fixed_registry = registry + ""/"" if registry != ""docker.io"" else """"
 
         image_size = docker[
@@ -42,23 +42,20 @@ class ManifestHeader:
             ""{{.Size}}"",
         ]().rstrip()
 
-        return ""\n"".join(
-            [
-                f""# Build manifest for image: {short_image_name}:{commit_hash_tag}"",
-                """",
-                ""## Build Info"",
-                """",
-                f""- Build datetime: {build_timestamp}"",
-                f""- Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`"",
-                f""- Docker image size: {image_size}"",
-                f""- Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
-                ""- Git commit message:"",
-                """",
-                ""```text"",
-                f""{commit_message}"",
-                ""```"",
-            ]
-        )
+        return f""""""\
+# Build manifest for image: {short_image_name}:{commit_hash_tag}
+
+## Build Info
+
+- Build datetime: {build_timestamp}
+- Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`
+- Docker image size: {image_size}
+- Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})
+- Git commit message:
+
+```text
+{commit_message}
+```""""""
 
 
 class ManifestInterface:
@@ -72,78 +69,57 @@ class ManifestInterface:
 class CondaEnvironmentManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## Python Packages"",
-                """",
-                DockerRunner.run_simple_command(container, ""python --version""),
-                """",
-                ""`mamba info --quiet`:"",
-                """",
-                quoted_output(container, ""mamba info --quiet""),
-                """",
-                ""`mamba list`:"",
-                """",
-                quoted_output(container, ""mamba list""),
-            ]
-        )
+        return f""""""\
+## Python Packages
+
+{DockerRunner.run_simple_command(container, ""python --version"")}
+
+`mamba info --quiet`:
+
+{quoted_output(container, ""mamba info --quiet"")}
+
+`mamba list`:
+
+{quoted_output(container, ""mamba list"")}""""""
 
 
 class AptPackagesManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## Apt Packages"",
-                """",
-                ""`apt list --installed`:"",
-                """",
-                quoted_output(container, ""apt list --installed""),
-            ]
-        )
+        return f""""""\
+## Apt Packages
+
+`apt list --installed`:
+
+{quoted_output(container, ""apt list --installed"")}""""""
 
 
 class RPackagesManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## R Packages"",
-                """",
-                quoted_output(container, ""R --version""),
-                """",
-                quoted_output(
-                    container,
-                    ""R --silent -e 'installed.packages(.Library)[, c(1,3)]'"",
-                ),
-            ]
-        )
+        return f""""""\
+## R Packages
+
+{quoted_output(container, ""R --version"")}
+
+{quoted_output(container, ""R --silent -e 'installed.packages(.Library)[, c(1,3)]'"")}""""""
 
 
 class JuliaPackagesManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## Julia Packages"",
-                """",
-                quoted_output(
-                    container,
-                    ""julia -E 'using InteractiveUtils; versioninfo()'"",
-                ),
-                """",
-                quoted_output(container, ""julia -E 'import Pkg; Pkg.status()'""),
-            ]
-        )
+        return f""""""\
+## Julia Packages
+
+{quoted_output(container, ""julia -E 'using InteractiveUtils; versioninfo()'"")}
+
+{quoted_output(container, ""julia -E 'import Pkg; Pkg.status()'"")}""""""
 
 
 class SparkInfoManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## Apache Spark"",
-                """",
-                quoted_output(container, ""/usr/local/spark/bin/spark-submit --version""),
-            ]
-        )
+        return f""""""\
+## Apache Spark
+
+{quoted_output(container, ""/usr/local/spark/bin/spark-submit --version"")}""""""","diff --git a/tagging/manifests.py b/tagging/manifests.py
index 6c4531e7..200cab22 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -10,15 +10,15 @@ docker = plumbum.local[""docker""]
 
 
 def quoted_output(container: Container, cmd: str) -> str:
-    return ""\n"".join(
-        [
-            ""```text"",
-            DockerRunner.run_simple_command(container, cmd, print_result=False).strip(
-                ""\n""
-            ),
-            ""```"",
-        ]
-    )
+    cmd_output = DockerRunner.run_simple_command(container, cmd, print_result=False)
+    # For example, `mamba info --quiet` adds redundant empty lines
+    cmd_output = cmd_output.strip(""\n"")
+    # For example, R packages list contains trailing backspaces
+    cmd_output = ""\n"".join(line.rstrip() for line in cmd_output.split(""\n""))
+    return f""""""\
+```text
+{cmd_output}
+```""""""
 
 
 class ManifestHeader:
@@ -32,7 +32,7 @@ class ManifestHeader:
         commit_hash_tag = GitHelper.commit_hash_tag()
         commit_message = GitHelper.commit_message()
 
-        # Unfortunately, docker images doesn't work when specifying `docker.io` as registry
+        # Unfortunately, `docker images` doesn't work when specifying `docker.io` as registry
         fixed_registry = registry + ""/"" if registry != ""docker.io"" else """"
 
         image_size = docker[
@@ -42,23 +42,20 @@ class ManifestHeader:
             ""{{.Size}}"",
         ]().rstrip()
 
-        return ""\n"".join(
-            [
-                f""# Build manifest for image: {short_image_name}:{commit_hash_tag}"",
-                """",
-                ""## Build Info"",
-                """",
-                f""- Build datetime: {build_timestamp}"",
-                f""- Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`"",
-                f""- Docker image size: {image_size}"",
-                f""- Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})"",
-                ""- Git commit message:"",
-                """",
-                ""```text"",
-                f""{commit_message}"",
-                ""```"",
-            ]
-        )
+        return f""""""\
+# Build manifest for image: {short_image_name}:{commit_hash_tag}
+
+## Build Info
+
+- Build datetime: {build_timestamp}
+- Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`
+- Docker image size: {image_size}
+- Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})
+- Git commit message:
+
+```text
+{commit_message}
+```""""""
 
 
 class ManifestInterface:
@@ -72,78 +69,57 @@ class ManifestInterface:
 class CondaEnvironmentManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## Python Packages"",
-                """",
-                DockerRunner.run_simple_command(container, ""python --version""),
-                """",
-                ""`mamba info --quiet`:"",
-                """",
-                quoted_output(container, ""mamba info --quiet""),
-                """",
-                ""`mamba list`:"",
-                """",
-                quoted_output(container, ""mamba list""),
-            ]
-        )
+        return f""""""\
+## Python Packages
+
+{DockerRunner.run_simple_command(container, ""python --version"")}
+
+`mamba info --quiet`:
+
+{quoted_output(container, ""mamba info --quiet"")}
+
+`mamba list`:
+
+{quoted_output(container, ""mamba list"")}""""""
 
 
 class AptPackagesManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## Apt Packages"",
-                """",
-                ""`apt list --installed`:"",
-                """",
-                quoted_output(container, ""apt list --installed""),
-            ]
-        )
+        return f""""""\
+## Apt Packages
+
+`apt list --installed`:
+
+{quoted_output(container, ""apt list --installed"")}""""""
 
 
 class RPackagesManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## R Packages"",
-                """",
-                quoted_output(container, ""R --version""),
-                """",
-                quoted_output(
-                    container,
-                    ""R --silent -e 'installed.packages(.Library)[, c(1,3)]'"",
-                ),
-            ]
-        )
+        return f""""""\
+## R Packages
+
+{quoted_output(container, ""R --version"")}
+
+{quoted_output(container, ""R --silent -e 'installed.packages(.Library)[, c(1,3)]'"")}""""""
 
 
 class JuliaPackagesManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## Julia Packages"",
-                """",
-                quoted_output(
-                    container,
-                    ""julia -E 'using InteractiveUtils; versioninfo()'"",
-                ),
-                """",
-                quoted_output(container, ""julia -E 'import Pkg; Pkg.status()'""),
-            ]
-        )
+        return f""""""\
+## Julia Packages
+
+{quoted_output(container, ""julia -E 'using InteractiveUtils; versioninfo()'"")}
+
+{quoted_output(container, ""julia -E 'import Pkg; Pkg.status()'"")}""""""
 
 
 class SparkInfoManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container: Container) -> str:
-        return ""\n"".join(
-            [
-                ""## Apache Spark"",
-                """",
-                quoted_output(container, ""/usr/local/spark/bin/spark-submit --version""),
-            ]
-        )
+        return f""""""\
+## Apache Spark
+
+{quoted_output(container, ""/usr/local/spark/bin/spark-submit --version"")}""""""",Yes
tagging/README.md,tagging/README.md,641e13e933cef8cfd157053668e4510441a02aaa,2401290ab3bc6606ed4805e8d06947d32af24e29,Add command which was run to the markdown piece,"diff --git a/tagging/README.md b/tagging/README.md
index 11c2e758..5d62917a 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -108,12 +108,14 @@ from tagging.manifests import ManifestInterface, quoted_output
 class AptPackagesManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container) -> str:
-        return ""\n"".join(
-            [""## Apt Packages"", """", quoted_output(container, ""apt list --installed"")]
-        )
+        return f""""""\
+## Apt Packages
+
+{quoted_output(container, ""apt list --installed"")}""""""
 ```
 
 - `quoted_output` simply runs the command inside a container using `DockerRunner.run_simple_command` and wraps it to triple quotes to create a valid markdown piece.
+  It also adds the command which was run to the markdown piece.
 - `manifests.py` contains all the manifests.
 - `write_manifest.py` is a python executable which is used to create the build manifest and history line for an image.","diff --git a/tagging/README.md b/tagging/README.md
index 11c2e758..5d62917a 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -108,12 +108,14 @@ from tagging.manifests import ManifestInterface, quoted_output
 class AptPackagesManifest(ManifestInterface):
     @staticmethod
     def markdown_piece(container) -> str:
-        return ""\n"".join(
-            [""## Apt Packages"", """", quoted_output(container, ""apt list --installed"")]
-        )
+        return f""""""\
+## Apt Packages
+
+{quoted_output(container, ""apt list --installed"")}""""""
 ```
 
 - `quoted_output` simply runs the command inside a container using `DockerRunner.run_simple_command` and wraps it to triple quotes to create a valid markdown piece.
+  It also adds the command which was run to the markdown piece.
 - `manifests.py` contains all the manifests.
 - `write_manifest.py` is a python executable which is used to create the build manifest and history line for an image.",Yes
tagging/manifests.py,tagging/manifests.py,641e13e933cef8cfd157053668e4510441a02aaa,2401290ab3bc6606ed4805e8d06947d32af24e29,Add command which was run to the markdown piece,"diff --git a/tagging/manifests.py b/tagging/manifests.py
index 200cab22..8ed6bc19 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -16,6 +16,8 @@ def quoted_output(container: Container, cmd: str) -> str:
     # For example, R packages list contains trailing backspaces
     cmd_output = ""\n"".join(line.rstrip() for line in cmd_output.split(""\n""))
     return f""""""\
+`{cmd}`:
+
 ```text
 {cmd_output}
 ```""""""
@@ -74,12 +76,8 @@ class CondaEnvironmentManifest(ManifestInterface):
 
 {DockerRunner.run_simple_command(container, ""python --version"")}
 
-`mamba info --quiet`:
-
 {quoted_output(container, ""mamba info --quiet"")}
 
-`mamba list`:
-
 {quoted_output(container, ""mamba list"")}""""""
 
 
@@ -89,8 +87,6 @@ class AptPackagesManifest(ManifestInterface):
         return f""""""\
 ## Apt Packages
 
-`apt list --installed`:
-
 {quoted_output(container, ""apt list --installed"")}""""""","diff --git a/tagging/manifests.py b/tagging/manifests.py
index 200cab22..8ed6bc19 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -16,6 +16,8 @@ def quoted_output(container: Container, cmd: str) -> str:
     # For example, R packages list contains trailing backspaces
     cmd_output = ""\n"".join(line.rstrip() for line in cmd_output.split(""\n""))
     return f""""""\
+`{cmd}`:
+
 ```text
 {cmd_output}
 ```""""""
@@ -74,12 +76,8 @@ class CondaEnvironmentManifest(ManifestInterface):
 
 {DockerRunner.run_simple_command(container, ""python --version"")}
 
-`mamba info --quiet`:
-
 {quoted_output(container, ""mamba info --quiet"")}
 
-`mamba list`:
-
 {quoted_output(container, ""mamba list"")}""""""
 
 
@@ -89,8 +87,6 @@ class AptPackagesManifest(ManifestInterface):
         return f""""""\
 ## Apt Packages
 
-`apt list --installed`:
-
 {quoted_output(container, ""apt list --installed"")}""""""",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,3f5cc4fdf23ef346d3b26fdc067f1c3a0a4c660e,641e13e933cef8cfd157053668e4510441a02aaa,Refactor wiki page to put everything in monthly files,"diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 645b6b71..13aa2bcf 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -36,8 +36,8 @@ jobs:
           repository: ${{ github.repository }}.wiki
           path: wiki/
 
-      - name: Update wiki page 🏷
-        run: python3 -m tagging.update_wiki_page --wiki-dir wiki/ --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/
+      - name: Update wiki 🏷
+        run: python3 -m tagging.update_wiki --wiki-dir wiki/ --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/
         shell: bash
 
       - name: Push Wiki to GitHub 📤","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 645b6b71..13aa2bcf 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -36,8 +36,8 @@ jobs:
           repository: ${{ github.repository }}.wiki
           path: wiki/
 
-      - name: Update wiki page 🏷
-        run: python3 -m tagging.update_wiki_page --wiki-dir wiki/ --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/
+      - name: Update wiki 🏷
+        run: python3 -m tagging.update_wiki --wiki-dir wiki/ --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/
         shell: bash
 
       - name: Push Wiki to GitHub 📤",Yes
,tagging/update_wiki.py,3f5cc4fdf23ef346d3b26fdc067f1c3a0a4c660e,641e13e933cef8cfd157053668e4510441a02aaa,Refactor wiki page to put everything in monthly files,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
new file mode 100755
index 00000000..200b02e2
--- /dev/null
+++ b/tagging/update_wiki.py
@@ -0,0 +1,85 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import argparse
+import logging
+import shutil
+from pathlib import Path
+
+LOGGER = logging.getLogger(__name__)
+
+
+def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
+    TABLE_BEGINNING = ""| - | - |\n""
+    wiki_home_file = wiki_dir / ""Home.md""
+    wiki_home_content = wiki_home_file.read_text()
+    month_line = f""| `{month}` | [`link`](./{month}) |\n""
+    if month_line not in wiki_home_content:
+        wiki_home_content = wiki_home_content.replace(
+            TABLE_BEGINNING, TABLE_BEGINNING + month_line
+        )
+        wiki_home_file.write_text(wiki_home_content)
+        LOGGER.info(""Wiki home file updated"")
+
+
+def update_monthly_wiki_page(
+    wiki_dir: Path, month: str, build_history_line: str
+) -> None:
+    MONTHLY_PAGE_HEADER = f""""""\
+# Images built during {month}
+
+| Date | Image | Links |
+| - | - | - |
+""""""
+    monthly_page = wiki_dir / (month + "".md"")
+    if not monthly_page.exists():
+        LOGGER.info(""Creating monthly page"")
+        monthly_page.write_text(MONTHLY_PAGE_HEADER)
+
+    monthly_page_content = monthly_page.read_text().replace(
+        MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""
+    )
+    monthly_page.write_text(monthly_page_content)
+
+
+def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
+    LOGGER.info(""Updating wiki"")
+
+    LOGGER.info(""Copying manifest files"")
+    for manifest_file in manifest_dir.glob(""*.md""):
+        shutil.copy(manifest_file, wiki_dir / ""manifests"" / manifest_file.name)
+        LOGGER.info(f""Manifest file added: {manifest_file.name}"")
+
+    for build_history_line_file in sorted(hist_line_dir.glob(""*.txt"")):
+        build_history_line = build_history_line_file.read_text()
+        assert build_history_line.startswith(""| `"")
+        month = build_history_line[3:10]
+        update_home_wiki_page(wiki_dir, month)
+        update_monthly_wiki_page(wiki_dir, month, build_history_line)
+
+
+if __name__ == ""__main__"":
+    logging.basicConfig(level=logging.INFO)
+
+    arg_parser = argparse.ArgumentParser()
+    arg_parser.add_argument(
+        ""--wiki-dir"",
+        required=True,
+        type=Path,
+        help=""Directory for wiki repo"",
+    )
+    arg_parser.add_argument(
+        ""--hist-line-dir"",
+        required=True,
+        type=Path,
+        help=""Directory to save history line"",
+    )
+    arg_parser.add_argument(
+        ""--manifest-dir"",
+        required=True,
+        type=Path,
+        help=""Directory to save manifest file"",
+    )
+    args = arg_parser.parse_args()
+
+    update_wiki(args.wiki_dir, args.hist_line_dir, args.manifest_dir)","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
new file mode 100755
index 00000000..200b02e2
--- /dev/null
+++ b/tagging/update_wiki.py
@@ -0,0 +1,85 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import argparse
+import logging
+import shutil
+from pathlib import Path
+
+LOGGER = logging.getLogger(__name__)
+
+
+def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
+    TABLE_BEGINNING = ""| - | - |\n""
+    wiki_home_file = wiki_dir / ""Home.md""
+    wiki_home_content = wiki_home_file.read_text()
+    month_line = f""| `{month}` | [`link`](./{month}) |\n""
+    if month_line not in wiki_home_content:
+        wiki_home_content = wiki_home_content.replace(
+            TABLE_BEGINNING, TABLE_BEGINNING + month_line
+        )
+        wiki_home_file.write_text(wiki_home_content)
+        LOGGER.info(""Wiki home file updated"")
+
+
+def update_monthly_wiki_page(
+    wiki_dir: Path, month: str, build_history_line: str
+) -> None:
+    MONTHLY_PAGE_HEADER = f""""""\
+# Images built during {month}
+
+| Date | Image | Links |
+| - | - | - |
+""""""
+    monthly_page = wiki_dir / (month + "".md"")
+    if not monthly_page.exists():
+        LOGGER.info(""Creating monthly page"")
+        monthly_page.write_text(MONTHLY_PAGE_HEADER)
+
+    monthly_page_content = monthly_page.read_text().replace(
+        MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""
+    )
+    monthly_page.write_text(monthly_page_content)
+
+
+def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
+    LOGGER.info(""Updating wiki"")
+
+    LOGGER.info(""Copying manifest files"")
+    for manifest_file in manifest_dir.glob(""*.md""):
+        shutil.copy(manifest_file, wiki_dir / ""manifests"" / manifest_file.name)
+        LOGGER.info(f""Manifest file added: {manifest_file.name}"")
+
+    for build_history_line_file in sorted(hist_line_dir.glob(""*.txt"")):
+        build_history_line = build_history_line_file.read_text()
+        assert build_history_line.startswith(""| `"")
+        month = build_history_line[3:10]
+        update_home_wiki_page(wiki_dir, month)
+        update_monthly_wiki_page(wiki_dir, month, build_history_line)
+
+
+if __name__ == ""__main__"":
+    logging.basicConfig(level=logging.INFO)
+
+    arg_parser = argparse.ArgumentParser()
+    arg_parser.add_argument(
+        ""--wiki-dir"",
+        required=True,
+        type=Path,
+        help=""Directory for wiki repo"",
+    )
+    arg_parser.add_argument(
+        ""--hist-line-dir"",
+        required=True,
+        type=Path,
+        help=""Directory to save history line"",
+    )
+    arg_parser.add_argument(
+        ""--manifest-dir"",
+        required=True,
+        type=Path,
+        help=""Directory to save manifest file"",
+    )
+    args = arg_parser.parse_args()
+
+    update_wiki(args.wiki_dir, args.hist_line_dir, args.manifest_dir)",Yes
tagging/update_wiki_page.py,tagging/update_wiki_page.py,3f5cc4fdf23ef346d3b26fdc067f1c3a0a4c660e,641e13e933cef8cfd157053668e4510441a02aaa,Refactor wiki page to put everything in monthly files,"diff --git a/tagging/update_wiki_page.py b/tagging/update_wiki_page.py
deleted file mode 100755
index 597e8f7c..00000000
--- a/tagging/update_wiki_page.py
+++ /dev/null
@@ -1,57 +0,0 @@
-#!/usr/bin/env python3
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
-import argparse
-import logging
-import shutil
-from pathlib import Path
-
-LOGGER = logging.getLogger(__name__)
-TABLE_BEGINNING = ""|-|-|-|\n""
-
-
-def update_wiki_page(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
-    LOGGER.info(""Updating wiki page"")
-
-    wiki_home_file = wiki_dir / ""Home.md""
-    wiki_home_content = wiki_home_file.read_text()
-    build_history_line_files = sorted(hist_line_dir.rglob(""*.txt""))
-    build_history_lines = ""\n"".join(
-        hist_line_file.read_text() for hist_line_file in build_history_line_files
-    )
-    wiki_home_content = wiki_home_content.replace(
-        TABLE_BEGINNING, TABLE_BEGINNING + build_history_lines + ""\n""
-    )
-    wiki_home_file.write_text(wiki_home_content)
-    LOGGER.info(""Wiki home file updated"")
-
-    for manifest_file in sorted(manifest_dir.rglob(""*.md"")):
-        shutil.copy(manifest_file, wiki_dir / ""manifests"" / manifest_file.name)
-        LOGGER.info(f""Manifest file added: {manifest_file.name}"")
-
-
-if __name__ == ""__main__"":
-    logging.basicConfig(level=logging.INFO)
-
-    arg_parser = argparse.ArgumentParser()
-    arg_parser.add_argument(
-        ""--wiki-dir"",
-        required=True,
-        type=Path,
-        help=""Directory for wiki repo"",
-    )
-    arg_parser.add_argument(
-        ""--hist-line-dir"",
-        required=True,
-        type=Path,
-        help=""Directory to save history line"",
-    )
-    arg_parser.add_argument(
-        ""--manifest-dir"",
-        required=True,
-        type=Path,
-        help=""Directory to save manifest file"",
-    )
-    args = arg_parser.parse_args()
-
-    update_wiki_page(args.wiki_dir, args.hist_line_dir, args.manifest_dir)","diff --git a/tagging/update_wiki_page.py b/tagging/update_wiki_page.py
deleted file mode 100755
index 597e8f7c..00000000
--- a/tagging/update_wiki_page.py
+++ /dev/null
@@ -1,57 +0,0 @@
-#!/usr/bin/env python3
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
-import argparse
-import logging
-import shutil
-from pathlib import Path
-
-LOGGER = logging.getLogger(__name__)
-TABLE_BEGINNING = ""|-|-|-|\n""
-
-
-def update_wiki_page(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
-    LOGGER.info(""Updating wiki page"")
-
-    wiki_home_file = wiki_dir / ""Home.md""
-    wiki_home_content = wiki_home_file.read_text()
-    build_history_line_files = sorted(hist_line_dir.rglob(""*.txt""))
-    build_history_lines = ""\n"".join(
-        hist_line_file.read_text() for hist_line_file in build_history_line_files
-    )
-    wiki_home_content = wiki_home_content.replace(
-        TABLE_BEGINNING, TABLE_BEGINNING + build_history_lines + ""\n""
-    )
-    wiki_home_file.write_text(wiki_home_content)
-    LOGGER.info(""Wiki home file updated"")
-
-    for manifest_file in sorted(manifest_dir.rglob(""*.md"")):
-        shutil.copy(manifest_file, wiki_dir / ""manifests"" / manifest_file.name)
-        LOGGER.info(f""Manifest file added: {manifest_file.name}"")
-
-
-if __name__ == ""__main__"":
-    logging.basicConfig(level=logging.INFO)
-
-    arg_parser = argparse.ArgumentParser()
-    arg_parser.add_argument(
-        ""--wiki-dir"",
-        required=True,
-        type=Path,
-        help=""Directory for wiki repo"",
-    )
-    arg_parser.add_argument(
-        ""--hist-line-dir"",
-        required=True,
-        type=Path,
-        help=""Directory to save history line"",
-    )
-    arg_parser.add_argument(
-        ""--manifest-dir"",
-        required=True,
-        type=Path,
-        help=""Directory to save manifest file"",
-    )
-    args = arg_parser.parse_args()
-
-    update_wiki_page(args.wiki_dir, args.hist_line_dir, args.manifest_dir)",Yes
tagging/write_manifest.py,tagging/write_manifest.py,3f5cc4fdf23ef346d3b26fdc067f1c3a0a4c660e,641e13e933cef8cfd157053668e4510441a02aaa,Refactor wiki page to put everything in monthly files,"diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index ea9d41c3..589906dc 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -43,7 +43,7 @@ def write_build_history_line(
             f""[Build manifest](./{filename})"",
         ]
     )
-    build_history_line = ""|"".join([date_column, image_column, links_column]) + ""|""
+    build_history_line = f""| {date_column} | {image_column} | {links_column} |""
     hist_line_dir.mkdir(parents=True, exist_ok=True)
     (hist_line_dir / f""{filename}.txt"").write_text(build_history_line)","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index ea9d41c3..589906dc 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -43,7 +43,7 @@ def write_build_history_line(
             f""[Build manifest](./{filename})"",
         ]
     )
-    build_history_line = ""|"".join([date_column, image_column, links_column]) + ""|""
+    build_history_line = f""| {date_column} | {image_column} | {links_column} |""
     hist_line_dir.mkdir(parents=True, exist_ok=True)
     (hist_line_dir / f""{filename}.txt"").write_text(build_history_line)",Yes
tagging/update_wiki.py,tagging/update_wiki.py,156cc18dd8034b21185f43c8caa9a1c25fd35103,3f5cc4fdf23ef346d3b26fdc067f1c3a0a4c660e,Improve update_wiki.py,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 200b02e2..e5ffc75b 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -10,7 +10,10 @@ LOGGER = logging.getLogger(__name__)
 
 
 def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
-    TABLE_BEGINNING = ""| - | - |\n""
+    TABLE_BEGINNING = """"""\
+| Month | File |
+| - | - |
+""""""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
     month_line = f""| `{month}` | [`link`](./{month}) |\n""
@@ -19,7 +22,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
             TABLE_BEGINNING, TABLE_BEGINNING + month_line
         )
         wiki_home_file.write_text(wiki_home_content)
-        LOGGER.info(""Wiki home file updated"")
+        LOGGER.info(f""Wiki home file updated with month: {month}"")
 
 
 def update_monthly_wiki_page(
@@ -33,8 +36,8 @@ def update_monthly_wiki_page(
 """"""
     monthly_page = wiki_dir / (month + "".md"")
     if not monthly_page.exists():
-        LOGGER.info(""Creating monthly page"")
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
+        LOGGER.info(f""Created monthly page: {month}"")
 
     monthly_page_content = monthly_page.read_text().replace(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 200b02e2..e5ffc75b 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -10,7 +10,10 @@ LOGGER = logging.getLogger(__name__)
 
 
 def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
-    TABLE_BEGINNING = ""| - | - |\n""
+    TABLE_BEGINNING = """"""\
+| Month | File |
+| - | - |
+""""""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
     month_line = f""| `{month}` | [`link`](./{month}) |\n""
@@ -19,7 +22,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
             TABLE_BEGINNING, TABLE_BEGINNING + month_line
         )
         wiki_home_file.write_text(wiki_home_content)
-        LOGGER.info(""Wiki home file updated"")
+        LOGGER.info(f""Wiki home file updated with month: {month}"")
 
 
 def update_monthly_wiki_page(
@@ -33,8 +36,8 @@ def update_monthly_wiki_page(
 """"""
     monthly_page = wiki_dir / (month + "".md"")
     if not monthly_page.exists():
-        LOGGER.info(""Creating monthly page"")
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
+        LOGGER.info(f""Created monthly page: {month}"")
 
     monthly_page_content = monthly_page.read_text().replace(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""",Yes
tagging/update_wiki.py,tagging/update_wiki.py,8521680eb23bd88d4ac58018c889ff820aa62dc3,156cc18dd8034b21185f43c8caa9a1c25fd35103,Simpler wiki home page table,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index e5ffc75b..ab6ec7e5 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -11,8 +11,8 @@ LOGGER = logging.getLogger(__name__)
 
 def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
     TABLE_BEGINNING = """"""\
-| Month | File |
-| - | - |
+| Month |
+| - |
 """"""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index e5ffc75b..ab6ec7e5 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -11,8 +11,8 @@ LOGGER = logging.getLogger(__name__)
 
 def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
     TABLE_BEGINNING = """"""\
-| Month | File |
-| - | - |
+| Month |
+| - |
 """"""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()",Yes
tagging/update_wiki.py,tagging/update_wiki.py,5f31a1fdba722b72d2c6f0b24cb884eab523d0dd,8521680eb23bd88d4ac58018c889ff820aa62dc3,Simpler month_line,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index ab6ec7e5..2796b7e2 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -16,7 +16,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
 """"""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
-    month_line = f""| `{month}` | [`link`](./{month}) |\n""
+    month_line = f""| [`{month}`](./{month}) |\n""
     if month_line not in wiki_home_content:
         wiki_home_content = wiki_home_content.replace(
             TABLE_BEGINNING, TABLE_BEGINNING + month_line","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index ab6ec7e5..2796b7e2 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -16,7 +16,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
 """"""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
-    month_line = f""| `{month}` | [`link`](./{month}) |\n""
+    month_line = f""| [`{month}`](./{month}) |\n""
     if month_line not in wiki_home_content:
         wiki_home_content = wiki_home_content.replace(
             TABLE_BEGINNING, TABLE_BEGINNING + month_line",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,6e880b01328be2110fff76cdbcd324582d0ff8ec,5f31a1fdba722b72d2c6f0b24cb884eab523d0dd,Add missing julia manifests download,"diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index dd5855f1..a6f4a91f 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -192,6 +192,18 @@ runs:
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: julia-notebook-aarch64-manifest
+        path: ${{ inputs.manifest-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: julia-notebook-x86_64-manifest
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index dd5855f1..a6f4a91f 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -192,6 +192,18 @@ runs:
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifest-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: julia-notebook-aarch64-manifest
+        path: ${{ inputs.manifest-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: julia-notebook-x86_64-manifest
+        path: ${{ inputs.manifest-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'",Yes
tagging/update_wiki.py,tagging/update_wiki.py,74dfec85fb35ea8a0f9037ed4f70eecf76a45854,6e880b01328be2110fff76cdbcd324582d0ff8ec,Remove old manifests and put everything in folders (#2026),"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 2796b7e2..d9202792 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -45,12 +45,36 @@ def update_monthly_wiki_page(
     monthly_page.write_text(monthly_page_content)
 
 
+def get_manifest_timestamp(manifest_file: Path) -> str:
+    file_content = manifest_file.read_text()
+    pos = file_content.find(""Build datetime: "")
+    return file_content[pos + 16 : pos + 36]
+
+
+def get_manifest_month(manifest_file: Path) -> str:
+    return get_manifest_timestamp(manifest_file)[:10]
+
+
+def remove_old_manifests(wiki_dir: Path) -> None:
+    MAX_NUMBER_OF_MANIFESTS = 4500
+
+    manifest_files = []
+    for file in (wiki_dir / ""manifests"").rglob(""*.md""):
+        manifest_files.append((get_manifest_timestamp(file), file))
+
+    manifest_files.sort(reverse=True)
+    for _, file in manifest_files[MAX_NUMBER_OF_MANIFESTS:]:
+        LOGGER.info(f""Removing manifest: {file.name}"")
+        file.unlink()
+
+
 def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
     LOGGER.info(""Updating wiki"")
 
     LOGGER.info(""Copying manifest files"")
     for manifest_file in manifest_dir.glob(""*.md""):
-        shutil.copy(manifest_file, wiki_dir / ""manifests"" / manifest_file.name)
+        month = get_manifest_month(manifest_file)
+        shutil.copy(manifest_file, wiki_dir / ""manifests"" / month / manifest_file.name)
         LOGGER.info(f""Manifest file added: {manifest_file.name}"")
 
     for build_history_line_file in sorted(hist_line_dir.glob(""*.txt"")):
@@ -60,6 +84,8 @@ def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None
         update_home_wiki_page(wiki_dir, month)
         update_monthly_wiki_page(wiki_dir, month, build_history_line)
 
+    remove_old_manifests(wiki_dir)
+
 
 if __name__ == ""__main__"":
     logging.basicConfig(level=logging.INFO)","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 2796b7e2..d9202792 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -45,12 +45,36 @@ def update_monthly_wiki_page(
     monthly_page.write_text(monthly_page_content)
 
 
+def get_manifest_timestamp(manifest_file: Path) -> str:
+    file_content = manifest_file.read_text()
+    pos = file_content.find(""Build datetime: "")
+    return file_content[pos + 16 : pos + 36]
+
+
+def get_manifest_month(manifest_file: Path) -> str:
+    return get_manifest_timestamp(manifest_file)[:10]
+
+
+def remove_old_manifests(wiki_dir: Path) -> None:
+    MAX_NUMBER_OF_MANIFESTS = 4500
+
+    manifest_files = []
+    for file in (wiki_dir / ""manifests"").rglob(""*.md""):
+        manifest_files.append((get_manifest_timestamp(file), file))
+
+    manifest_files.sort(reverse=True)
+    for _, file in manifest_files[MAX_NUMBER_OF_MANIFESTS:]:
+        LOGGER.info(f""Removing manifest: {file.name}"")
+        file.unlink()
+
+
 def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
     LOGGER.info(""Updating wiki"")
 
     LOGGER.info(""Copying manifest files"")
     for manifest_file in manifest_dir.glob(""*.md""):
-        shutil.copy(manifest_file, wiki_dir / ""manifests"" / manifest_file.name)
+        month = get_manifest_month(manifest_file)
+        shutil.copy(manifest_file, wiki_dir / ""manifests"" / month / manifest_file.name)
         LOGGER.info(f""Manifest file added: {manifest_file.name}"")
 
     for build_history_line_file in sorted(hist_line_dir.glob(""*.txt"")):
@@ -60,6 +84,8 @@ def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None
         update_home_wiki_page(wiki_dir, month)
         update_monthly_wiki_page(wiki_dir, month, build_history_line)
 
+    remove_old_manifests(wiki_dir)
+
 
 if __name__ == ""__main__"":
     logging.basicConfig(level=logging.INFO)",Yes
tagging/update_wiki.py,tagging/update_wiki.py,5a2225e126d2cf2171a5d579eec5a1249d492f5d,74dfec85fb35ea8a0f9037ed4f70eecf76a45854,Improve logs during manifests handle,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index d9202792..0277f390 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -22,7 +22,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
             TABLE_BEGINNING, TABLE_BEGINNING + month_line
         )
         wiki_home_file.write_text(wiki_home_content)
-        LOGGER.info(f""Wiki home file updated with month: {month}"")
+        LOGGER.info(f""Update wiki home page with month: {month}"")
 
 
 def update_monthly_wiki_page(
@@ -43,6 +43,7 @@ def update_monthly_wiki_page(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""
     )
     monthly_page.write_text(monthly_page_content)
+    LOGGER.info(f""Updated monthly page: {month}"")
 
 
 def get_manifest_timestamp(manifest_file: Path) -> str:
@@ -58,24 +59,24 @@ def get_manifest_month(manifest_file: Path) -> str:
 def remove_old_manifests(wiki_dir: Path) -> None:
     MAX_NUMBER_OF_MANIFESTS = 4500
 
-    manifest_files = []
+    manifest_files: list[tuple[str, Path]] = []
     for file in (wiki_dir / ""manifests"").rglob(""*.md""):
         manifest_files.append((get_manifest_timestamp(file), file))
 
     manifest_files.sort(reverse=True)
     for _, file in manifest_files[MAX_NUMBER_OF_MANIFESTS:]:
-        LOGGER.info(f""Removing manifest: {file.name}"")
         file.unlink()
+        LOGGER.info(f""Removed manifest: {file.relative_to(wiki_dir)}"")
 
 
 def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
     LOGGER.info(""Updating wiki"")
 
-    LOGGER.info(""Copying manifest files"")
     for manifest_file in manifest_dir.glob(""*.md""):
         month = get_manifest_month(manifest_file)
-        shutil.copy(manifest_file, wiki_dir / ""manifests"" / month / manifest_file.name)
-        LOGGER.info(f""Manifest file added: {manifest_file.name}"")
+        copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
+        shutil.copy(manifest_file, copy_to)
+        LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
 
     for build_history_line_file in sorted(hist_line_dir.glob(""*.txt"")):
         build_history_line = build_history_line_file.read_text()","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index d9202792..0277f390 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -22,7 +22,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
             TABLE_BEGINNING, TABLE_BEGINNING + month_line
         )
         wiki_home_file.write_text(wiki_home_content)
-        LOGGER.info(f""Wiki home file updated with month: {month}"")
+        LOGGER.info(f""Update wiki home page with month: {month}"")
 
 
 def update_monthly_wiki_page(
@@ -43,6 +43,7 @@ def update_monthly_wiki_page(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""
     )
     monthly_page.write_text(monthly_page_content)
+    LOGGER.info(f""Updated monthly page: {month}"")
 
 
 def get_manifest_timestamp(manifest_file: Path) -> str:
@@ -58,24 +59,24 @@ def get_manifest_month(manifest_file: Path) -> str:
 def remove_old_manifests(wiki_dir: Path) -> None:
     MAX_NUMBER_OF_MANIFESTS = 4500
 
-    manifest_files = []
+    manifest_files: list[tuple[str, Path]] = []
     for file in (wiki_dir / ""manifests"").rglob(""*.md""):
         manifest_files.append((get_manifest_timestamp(file), file))
 
     manifest_files.sort(reverse=True)
     for _, file in manifest_files[MAX_NUMBER_OF_MANIFESTS:]:
-        LOGGER.info(f""Removing manifest: {file.name}"")
         file.unlink()
+        LOGGER.info(f""Removed manifest: {file.relative_to(wiki_dir)}"")
 
 
 def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
     LOGGER.info(""Updating wiki"")
 
-    LOGGER.info(""Copying manifest files"")
     for manifest_file in manifest_dir.glob(""*.md""):
         month = get_manifest_month(manifest_file)
-        shutil.copy(manifest_file, wiki_dir / ""manifests"" / month / manifest_file.name)
-        LOGGER.info(f""Manifest file added: {manifest_file.name}"")
+        copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
+        shutil.copy(manifest_file, copy_to)
+        LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
 
     for build_history_line_file in sorted(hist_line_dir.glob(""*.txt"")):
         build_history_line = build_history_line_file.read_text()",Yes
tagging/update_wiki.py,tagging/update_wiki.py,b97d0d6d91e4701668a74dc3d1a124349646e91a,5a2225e126d2cf2171a5d579eec5a1249d492f5d,"Actually put manifests in monthly folders, not daily","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 0277f390..6e1cb36d 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -53,7 +53,7 @@ def get_manifest_timestamp(manifest_file: Path) -> str:
 
 
 def get_manifest_month(manifest_file: Path) -> str:
-    return get_manifest_timestamp(manifest_file)[:10]
+    return get_manifest_timestamp(manifest_file)[:7]
 
 
 def remove_old_manifests(wiki_dir: Path) -> None:","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 0277f390..6e1cb36d 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -53,7 +53,7 @@ def get_manifest_timestamp(manifest_file: Path) -> str:
 
 
 def get_manifest_month(manifest_file: Path) -> str:
-    return get_manifest_timestamp(manifest_file)[:10]
+    return get_manifest_timestamp(manifest_file)[:7]
 
 
 def remove_old_manifests(wiki_dir: Path) -> None:",Yes
tagging/update_wiki.py,tagging/update_wiki.py,3d87ce2006ad30eb174da69df454941fbbe03b81,b97d0d6d91e4701668a74dc3d1a124349646e91a,Create missing dir for manifest month,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 6e1cb36d..5529a97f 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -75,6 +75,7 @@ def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None
     for manifest_file in manifest_dir.glob(""*.md""):
         month = get_manifest_month(manifest_file)
         copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
+        copy_to.parent.mkdir(exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 6e1cb36d..5529a97f 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -75,6 +75,7 @@ def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None
     for manifest_file in manifest_dir.glob(""*.md""):
         month = get_manifest_month(manifest_file)
         copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
+        copy_to.parent.mkdir(exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")",Yes
tagging/update_wiki.py,tagging/update_wiki.py,9ab127bccb3b4059366bad3b310459753a1ff44d,3d87ce2006ad30eb174da69df454941fbbe03b81,Put monthly-files in its own folder in docs,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 5529a97f..75ff0f04 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -34,10 +34,10 @@ def update_monthly_wiki_page(
 | Date | Image | Links |
 | - | - | - |
 """"""
-    monthly_page = wiki_dir / (month + "".md"")
+    monthly_page = wiki_dir / ""monthly-files"" / (month + "".md"")
     if not monthly_page.exists():
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
-        LOGGER.info(f""Created monthly page: {month}"")
+        LOGGER.info(f""Created monthly page: {monthly_page.relative_to(wiki_dir)}"")
 
     monthly_page_content = monthly_page.read_text().replace(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 5529a97f..75ff0f04 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -34,10 +34,10 @@ def update_monthly_wiki_page(
 | Date | Image | Links |
 | - | - | - |
 """"""
-    monthly_page = wiki_dir / (month + "".md"")
+    monthly_page = wiki_dir / ""monthly-files"" / (month + "".md"")
     if not monthly_page.exists():
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
-        LOGGER.info(f""Created monthly page: {month}"")
+        LOGGER.info(f""Created monthly page: {monthly_page.relative_to(wiki_dir)}"")
 
     monthly_page_content = monthly_page.read_text().replace(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""",Yes
tagging/update_wiki.py,tagging/update_wiki.py,e0c2997d6ef1f58fd0efa704eefa7cdb73ee626e,9ab127bccb3b4059366bad3b310459753a1ff44d,Better logs,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 75ff0f04..4d08c052 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -43,7 +43,7 @@ def update_monthly_wiki_page(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""
     )
     monthly_page.write_text(monthly_page_content)
-    LOGGER.info(f""Updated monthly page: {month}"")
+    LOGGER.info(f""Updated monthly page: {monthly_page.relative_to(wiki_dir)}"")
 
 
 def get_manifest_timestamp(manifest_file: Path) -> str:","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 75ff0f04..4d08c052 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -43,7 +43,7 @@ def update_monthly_wiki_page(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""
     )
     monthly_page.write_text(monthly_page_content)
-    LOGGER.info(f""Updated monthly page: {month}"")
+    LOGGER.info(f""Updated monthly page: {monthly_page.relative_to(wiki_dir)}"")
 
 
 def get_manifest_timestamp(manifest_file: Path) -> str:",Yes
tagging/update_wiki.py,tagging/update_wiki.py,87afdf96890b7d98d385a723f96d3682a7e9b055,e0c2997d6ef1f58fd0efa704eefa7cdb73ee626e,Better logs,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 4d08c052..b55ae1fd 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -22,7 +22,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
             TABLE_BEGINNING, TABLE_BEGINNING + month_line
         )
         wiki_home_file.write_text(wiki_home_content)
-        LOGGER.info(f""Update wiki home page with month: {month}"")
+        LOGGER.info(f""Updated wiki home page with month: {month}"")
 
 
 def update_monthly_wiki_page(","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 4d08c052..b55ae1fd 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -22,7 +22,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
             TABLE_BEGINNING, TABLE_BEGINNING + month_line
         )
         wiki_home_file.write_text(wiki_home_content)
-        LOGGER.info(f""Update wiki home page with month: {month}"")
+        LOGGER.info(f""Updated wiki home page with month: {month}"")
 
 
 def update_monthly_wiki_page(",Yes
README.md,README.md,110503092feed6f8699afd141f87ebc87ac7d5b7,87afdf96890b7d98d385a723f96d3682a7e9b055,"Mention 2i2c as sponsoring aarch64 self-hosted runners (#2019)

* Mention 2i2c as sponsoring aarch64 builds

* Update README.md

* Update README.md","diff --git a/README.md b/README.md
index 1fd05eb2..78db6a67 100644
--- a/README.md
+++ b/README.md
@@ -84,6 +84,10 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - [Jupyter Website](https://jupyter.org)
 - [Images on Quay.io](https://quay.io/organization/jupyter)
 
+## Acknowledgments
+
+- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by amazing [`2i2c project`](https://2i2c.org)
+
 ## CPU Architectures
 
 - We publish containers for both `x86_64` and `aarch64` platforms","diff --git a/README.md b/README.md
index 1fd05eb2..78db6a67 100644
--- a/README.md
+++ b/README.md
@@ -84,6 +84,10 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - [Jupyter Website](https://jupyter.org)
 - [Images on Quay.io](https://quay.io/organization/jupyter)
 
+## Acknowledgments
+
+- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by amazing [`2i2c project`](https://2i2c.org)
+
 ## CPU Architectures
 
 - We publish containers for both `x86_64` and `aarch64` platforms",Yes
docs/conf.py,docs/conf.py,364b81a73b30edf26a1c014eb34d2c379b3e9225,110503092feed6f8699afd141f87ebc87ac7d5b7,"Revert ""[TMP] Disable mybinder linkcheck""

This reverts commit 154343498e5cf03f697d6214ee3c514015055051.","diff --git a/docs/conf.py b/docs/conf.py
index dd46367c..cacfe3d0 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -66,7 +66,6 @@ linkcheck_ignore = [
     r""https://github\.com/jupyter/docker-stacks/settings/actions/runners/new\?arch=arm64\&amp;os=linux"",  # only works for users with permissions to change runners
     r""http://127\.0\.0\.1:.*"",  # various examples
     r""https://mybinder\.org/v2/gh/.*"",  # lots of 500 errors
-    r""https://mybinder.org"",  # mybinder is down
 ]
 
 linkcheck_allowed_redirects = {","diff --git a/docs/conf.py b/docs/conf.py
index dd46367c..cacfe3d0 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -66,7 +66,6 @@ linkcheck_ignore = [
     r""https://github\.com/jupyter/docker-stacks/settings/actions/runners/new\?arch=arm64\&amp;os=linux"",  # only works for users with permissions to change runners
     r""http://127\.0\.0\.1:.*"",  # various examples
     r""https://mybinder\.org/v2/gh/.*"",  # lots of 500 errors
-    r""https://mybinder.org"",  # mybinder is down
 ]
 
 linkcheck_allowed_redirects = {",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,78fe45a776a794f7369c32505c48a3a7489ada0e,364b81a73b30edf26a1c014eb34d2c379b3e9225,"[pre-commit.ci] pre-commit autoupdate (#2027)

updates:
- [github.com/asottile/pyupgrade: v3.14.0 → v3.15.0](https://github.com/asottile/pyupgrade/compare/v3.14.0...v3.15.0)
- [github.com/psf/black: 23.9.1 → 23.10.1](https://github.com/psf/black/compare/23.9.1...23.10.1)
- [github.com/pre-commit/mirrors-mypy: v1.5.1 → v1.6.1](https://github.com/pre-commit/mirrors-mypy/compare/v1.5.1...v1.6.1)
- [github.com/pre-commit/pre-commit-hooks: v4.4.0 → v4.5.0](https://github.com/pre-commit/pre-commit-hooks/compare/v4.4.0...v4.5.0)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index b0023a0d..a413a429 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.14.0
+    rev: v3.15.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.9.1
+    rev: 23.10.1
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.5.1
+    rev: v1.6.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -66,7 +66,7 @@ repos:
 
   # `pre-commit sample-config` default hooks
   - repo: https://github.com/pre-commit/pre-commit-hooks
-    rev: v4.4.0
+    rev: v4.5.0
     hooks:
       - id: check-added-large-files
       - id: end-of-file-fixer","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index b0023a0d..a413a429 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.14.0
+    rev: v3.15.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.9.1
+    rev: 23.10.1
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.5.1
+    rev: v1.6.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -66,7 +66,7 @@ repos:
 
   # `pre-commit sample-config` default hooks
   - repo: https://github.com/pre-commit/pre-commit-hooks
-    rev: v4.4.0
+    rev: v4.5.0
     hooks:
       - id: check-added-large-files
       - id: end-of-file-fixer",Yes
,.github/workflows/aarch64-setup.yml,5f8f5b6433a4e8bb9d5517d9835538898105a49d,78fe45a776a794f7369c32505c48a3a7489ada0e,"Add workflow to check aarch64 setup script (#2028)

* Add workflow to check aarch64 setup script

* Add sudo

* Fix step name

* Do not copy authorized keys if GITHUB_ACTIONS env var exists

* Fix

* Fix typo

* Fix

* Final fix

* Fix","diff --git a/.github/workflows/aarch64-setup.yml b/.github/workflows/aarch64-setup.yml
new file mode 100644
index 00000000..02e01696
--- /dev/null
+++ b/.github/workflows/aarch64-setup.yml
@@ -0,0 +1,30 @@
+name: Test aarch64-runner setup script
+
+on:
+  schedule:
+    # Weekly, at 03:00 on Monday UTC time
+    - cron: ""0 3 * * 1""
+  pull_request:
+    paths:
+      - "".github/workflows/aarch64-setup.yml""
+      - ""aarch64-runner/setup.sh""
+  push:
+    branches:
+      - main
+    paths:
+      - "".github/workflows/aarch64-setup.yml""
+      - ""aarch64-runner/setup.sh""
+  workflow_dispatch:
+
+jobs:
+  test-script:
+    # The script itself is not aarch64 specific
+    # It is easier to test on ubuntu-latest
+    runs-on: ubuntu-latest
+
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v4
+
+      - name: Run setup script ✅
+        run: sudo ./aarch64-runner/setup.sh","diff --git a/.github/workflows/aarch64-setup.yml b/.github/workflows/aarch64-setup.yml
new file mode 100644
index 00000000..02e01696
--- /dev/null
+++ b/.github/workflows/aarch64-setup.yml
@@ -0,0 +1,30 @@
+name: Test aarch64-runner setup script
+
+on:
+  schedule:
+    # Weekly, at 03:00 on Monday UTC time
+    - cron: ""0 3 * * 1""
+  pull_request:
+    paths:
+      - "".github/workflows/aarch64-setup.yml""
+      - ""aarch64-runner/setup.sh""
+  push:
+    branches:
+      - main
+    paths:
+      - "".github/workflows/aarch64-setup.yml""
+      - ""aarch64-runner/setup.sh""
+  workflow_dispatch:
+
+jobs:
+  test-script:
+    # The script itself is not aarch64 specific
+    # It is easier to test on ubuntu-latest
+    runs-on: ubuntu-latest
+
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v4
+
+      - name: Run setup script ✅
+        run: sudo ./aarch64-runner/setup.sh",Yes
aarch64-runner/setup.sh,aarch64-runner/setup.sh,5f8f5b6433a4e8bb9d5517d9835538898105a49d,78fe45a776a794f7369c32505c48a3a7489ada0e,"Add workflow to check aarch64 setup script (#2028)

* Add workflow to check aarch64 setup script

* Add sudo

* Fix step name

* Do not copy authorized keys if GITHUB_ACTIONS env var exists

* Fix

* Fix typo

* Fix

* Final fix

* Fix","diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index 2d3956be..9a84bf71 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -14,7 +14,9 @@ apt-get upgrade --yes
 echo ""Setting up runner-user, who will run GitHub Actions runner""
 adduser --disabled-password --gecos """" ${GITHUB_RUNNER_USER}
 mkdir /home/${GITHUB_RUNNER_USER}/.ssh/
+set +e
 cp ""/home/${SUDO_USER}/.ssh/authorized_keys"" ""/home/${GITHUB_RUNNER_USER}/.ssh/authorized_keys""
+set -e
 chown --recursive ${GITHUB_RUNNER_USER}:${GITHUB_RUNNER_USER} /home/${GITHUB_RUNNER_USER}/.ssh
 
 echo ""Setting up python3""","diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index 2d3956be..9a84bf71 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -14,7 +14,9 @@ apt-get upgrade --yes
 echo ""Setting up runner-user, who will run GitHub Actions runner""
 adduser --disabled-password --gecos """" ${GITHUB_RUNNER_USER}
 mkdir /home/${GITHUB_RUNNER_USER}/.ssh/
+set +e
 cp ""/home/${SUDO_USER}/.ssh/authorized_keys"" ""/home/${GITHUB_RUNNER_USER}/.ssh/authorized_keys""
+set -e
 chown --recursive ${GITHUB_RUNNER_USER}:${GITHUB_RUNNER_USER} /home/${GITHUB_RUNNER_USER}/.ssh
 
 echo ""Setting up python3""",Yes
tagging/apply_tags.py,tagging/apply_tags.py,3badd8f21c611b7722fb751a5063931d0173a4c6,5f8f5b6433a4e8bb9d5517d9835538898105a49d,Improve text in tagging files,"diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index e8129167..784cd778 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -22,8 +22,8 @@ def apply_tags(
     platform: str,
 ) -> None:
     """"""
-    Tags <owner>/<short_image_name>:latest with the tags
-    reported by all taggers for the given image.
+    Tags <registry>/<owner>/<short_image_name>:latest with the tags reported by all taggers for this image
+    Then removes latest tag
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")","diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index e8129167..784cd778 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -22,8 +22,8 @@ def apply_tags(
     platform: str,
 ) -> None:
     """"""
-    Tags <owner>/<short_image_name>:latest with the tags
-    reported by all taggers for the given image.
+    Tags <registry>/<owner>/<short_image_name>:latest with the tags reported by all taggers for this image
+    Then removes latest tag
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")",Yes
tagging/update_wiki.py,tagging/update_wiki.py,3badd8f21c611b7722fb751a5063931d0173a4c6,5f8f5b6433a4e8bb9d5517d9835538898105a49d,Improve text in tagging files,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index b55ae1fd..03c6468c 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -97,19 +97,19 @@ if __name__ == ""__main__"":
         ""--wiki-dir"",
         required=True,
         type=Path,
-        help=""Directory for wiki repo"",
+        help=""Directory of the wiki repo"",
     )
     arg_parser.add_argument(
         ""--hist-line-dir"",
         required=True,
         type=Path,
-        help=""Directory to save history line"",
+        help=""Directory with history lines"",
     )
     arg_parser.add_argument(
         ""--manifest-dir"",
         required=True,
         type=Path,
-        help=""Directory to save manifest file"",
+        help=""Directory with manifest files"",
     )
     args = arg_parser.parse_args()","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index b55ae1fd..03c6468c 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -97,19 +97,19 @@ if __name__ == ""__main__"":
         ""--wiki-dir"",
         required=True,
         type=Path,
-        help=""Directory for wiki repo"",
+        help=""Directory of the wiki repo"",
     )
     arg_parser.add_argument(
         ""--hist-line-dir"",
         required=True,
         type=Path,
-        help=""Directory to save history line"",
+        help=""Directory with history lines"",
     )
     arg_parser.add_argument(
         ""--manifest-dir"",
         required=True,
         type=Path,
-        help=""Directory to save manifest file"",
+        help=""Directory with manifest files"",
     )
     args = arg_parser.parse_args()",Yes
tagging/write_tags_file.py,tagging/write_tags_file.py,3badd8f21c611b7722fb751a5063931d0173a4c6,5f8f5b6433a4e8bb9d5517d9835538898105a49d,Improve text in tagging files,"diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index cfdea2ac..5f063aa6 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -19,7 +19,7 @@ def write_tags_file(
     tags_dir: Path,
 ) -> None:
     """"""
-    Writes tags file for the image <owner>/<short_image_name>:latest
+    Writes tags file for the image <registry>/<owner>/<short_image_name>:latest
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")
     taggers, _ = get_taggers_and_manifests(short_image_name)","diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index cfdea2ac..5f063aa6 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -19,7 +19,7 @@ def write_tags_file(
     tags_dir: Path,
 ) -> None:
     """"""
-    Writes tags file for the image <owner>/<short_image_name>:latest
+    Writes tags file for the image <registry>/<owner>/<short_image_name>:latest
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")
     taggers, _ = get_taggers_and_manifests(short_image_name)",Yes
tagging/update_wiki.py,tagging/update_wiki.py,716683512e025a58b9e0b08330fad0b13e2d1442,3badd8f21c611b7722fb751a5063931d0173a4c6,Fix table style on the home page,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 03c6468c..70b39338 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -11,8 +11,8 @@ LOGGER = logging.getLogger(__name__)
 
 def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
     TABLE_BEGINNING = """"""\
-| Month |
-| - |
+| Month                  |
+| ---------------------- |
 """"""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 03c6468c..70b39338 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -11,8 +11,8 @@ LOGGER = logging.getLogger(__name__)
 
 def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
     TABLE_BEGINNING = """"""\
-| Month |
-| - |
+| Month                  |
+| ---------------------- |
 """"""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()",Yes
tagging/update_wiki.py,tagging/update_wiki.py,49150068fc885a2040398d17f1a5ad87c69ea5fb,716683512e025a58b9e0b08330fad0b13e2d1442,Add asserts to make sure wiki is always updated,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 70b39338..193558c8 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -18,6 +18,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
     wiki_home_content = wiki_home_file.read_text()
     month_line = f""| [`{month}`](./{month}) |\n""
     if month_line not in wiki_home_content:
+        assert TABLE_BEGINNING in wiki_home_content
         wiki_home_content = wiki_home_content.replace(
             TABLE_BEGINNING, TABLE_BEGINNING + month_line
         )
@@ -39,7 +40,9 @@ def update_monthly_wiki_page(
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
         LOGGER.info(f""Created monthly page: {monthly_page.relative_to(wiki_dir)}"")
 
-    monthly_page_content = monthly_page.read_text().replace(
+    monthly_page_content = monthly_page.read_text()
+    assert MONTHLY_PAGE_HEADER in monthly_page_content
+    monthly_page_content = monthly_page_content.replace(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""
     )
     monthly_page.write_text(monthly_page_content)","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 70b39338..193558c8 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -18,6 +18,7 @@ def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
     wiki_home_content = wiki_home_file.read_text()
     month_line = f""| [`{month}`](./{month}) |\n""
     if month_line not in wiki_home_content:
+        assert TABLE_BEGINNING in wiki_home_content
         wiki_home_content = wiki_home_content.replace(
             TABLE_BEGINNING, TABLE_BEGINNING + month_line
         )
@@ -39,7 +40,9 @@ def update_monthly_wiki_page(
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
         LOGGER.info(f""Created monthly page: {monthly_page.relative_to(wiki_dir)}"")
 
-    monthly_page_content = monthly_page.read_text().replace(
+    monthly_page_content = monthly_page.read_text()
+    assert MONTHLY_PAGE_HEADER in monthly_page_content
+    monthly_page_content = monthly_page_content.replace(
         MONTHLY_PAGE_HEADER, MONTHLY_PAGE_HEADER + build_history_line + ""\n""
     )
     monthly_page.write_text(monthly_page_content)",Yes
README.md,README.md,51f6a5ac3ea0f2932afbcca7b6f23c742561c020,49150068fc885a2040398d17f1a5ad87c69ea5fb,Mention that 2i2c is a non-profit (#2029),"diff --git a/README.md b/README.md
index 78db6a67..03354f36 100644
--- a/README.md
+++ b/README.md
@@ -86,7 +86,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 
 ## Acknowledgments
 
-- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by amazing [`2i2c project`](https://2i2c.org)
+- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by amazing [`2i2c non-profit organization`](https://2i2c.org)
 
 ## CPU Architectures","diff --git a/README.md b/README.md
index 78db6a67..03354f36 100644
--- a/README.md
+++ b/README.md
@@ -86,7 +86,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 
 ## Acknowledgments
 
-- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by amazing [`2i2c project`](https://2i2c.org)
+- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by amazing [`2i2c non-profit organization`](https://2i2c.org)
 
 ## CPU Architectures",Yes
,.github/workflows/registry-move.yml,9c07045ea6cf2bbb30df05f6f431721f62ed8470,51f6a5ac3ea0f2932afbcca7b6f23c742561c020,"Add workflow to move some images from Docker Hub to Quay.io (#2032)

* Add workflow to move some images from Docker Hub to Quay.io

* Add tag

* Add fail-fast","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
new file mode 100644
index 00000000..680f5789
--- /dev/null
+++ b/.github/workflows/registry-move.yml
@@ -0,0 +1,70 @@
+name: Move some images from Docker Hub to Quay.io
+
+env:
+  OWNER: ${{ github.repository_owner }}
+  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main')
+
+on:
+  pull_request:
+    paths:
+      - "".github/workflows/registry-move.yml""
+  push:
+    branches:
+      - main
+    paths:
+      - "".github/workflows/registry-move.yml""
+  workflow_dispatch:
+
+jobs:
+  update-overview:
+    runs-on: ubuntu-latest
+    if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
+
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v4
+
+      - name: Pull image from Docker Hub 📥
+        run: docker pull ${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+
+      - name: Login to Quay.io 🔐
+        if: env.PUSH_TO_REGISTRY == 'true'
+        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
+        with:
+          registry: quay.io
+          username: ${{ secrets.QUAY_USERNAME }}
+          password: ${{ secrets.QUAY_ROBOT_TOKEN }}
+
+      - name: Push image to Quay.io 🐳
+        if: env.PUSH_TO_REGISTRY == 'true'
+        run: |
+          docker tag ${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }} quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+          docker push quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+
+    strategy:
+      fail-fast: false
+      matrix:
+        image:
+          [
+            docker-stacks-foundation,
+            base-notebook,
+            minimal-notebook,
+            scipy-notebook,
+            r-notebook,
+            julia-notebook,
+            tensorflow-notebook,
+            datascience-notebook,
+            pyspark-notebook,
+            all-spark-notebook,
+          ]
+        tag:
+          [
+            1aac87eb7fa5,
+            a374cab4fcb6,
+            5ae537728c69,
+            f3079808ca8c,
+            b86753318aa1,
+            7285848c0a11,
+            ed2908bbb62e,
+            4d70cf8da953,
+          ]","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
new file mode 100644
index 00000000..680f5789
--- /dev/null
+++ b/.github/workflows/registry-move.yml
@@ -0,0 +1,70 @@
+name: Move some images from Docker Hub to Quay.io
+
+env:
+  OWNER: ${{ github.repository_owner }}
+  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main')
+
+on:
+  pull_request:
+    paths:
+      - "".github/workflows/registry-move.yml""
+  push:
+    branches:
+      - main
+    paths:
+      - "".github/workflows/registry-move.yml""
+  workflow_dispatch:
+
+jobs:
+  update-overview:
+    runs-on: ubuntu-latest
+    if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
+
+    steps:
+      - name: Checkout Repo ⚡️
+        uses: actions/checkout@v4
+
+      - name: Pull image from Docker Hub 📥
+        run: docker pull ${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+
+      - name: Login to Quay.io 🔐
+        if: env.PUSH_TO_REGISTRY == 'true'
+        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
+        with:
+          registry: quay.io
+          username: ${{ secrets.QUAY_USERNAME }}
+          password: ${{ secrets.QUAY_ROBOT_TOKEN }}
+
+      - name: Push image to Quay.io 🐳
+        if: env.PUSH_TO_REGISTRY == 'true'
+        run: |
+          docker tag ${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }} quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+          docker push quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+
+    strategy:
+      fail-fast: false
+      matrix:
+        image:
+          [
+            docker-stacks-foundation,
+            base-notebook,
+            minimal-notebook,
+            scipy-notebook,
+            r-notebook,
+            julia-notebook,
+            tensorflow-notebook,
+            datascience-notebook,
+            pyspark-notebook,
+            all-spark-notebook,
+          ]
+        tag:
+          [
+            1aac87eb7fa5,
+            a374cab4fcb6,
+            5ae537728c69,
+            f3079808ca8c,
+            b86753318aa1,
+            7285848c0a11,
+            ed2908bbb62e,
+            4d70cf8da953,
+          ]",Yes
.github/workflows/registry-move.yml,.github/workflows/registry-move.yml,534bcda50adc424a550e2989a1ea3dd5b4e9a50a,9c07045ea6cf2bbb30df05f6f431721f62ed8470,Fix using contexts for env vars,"diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 680f5789..dc9dead3 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -2,7 +2,7 @@ name: Move some images from Docker Hub to Quay.io
 
 env:
   OWNER: ${{ github.repository_owner }}
-  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main')
+  PUSH_TO_REGISTRY: ${{ (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main') }}
 
 on:
   pull_request:","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 680f5789..dc9dead3 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -2,7 +2,7 @@ name: Move some images from Docker Hub to Quay.io
 
 env:
   OWNER: ${{ github.repository_owner }}
-  PUSH_TO_REGISTRY: (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main')
+  PUSH_TO_REGISTRY: ${{ (github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru') && (github.ref == 'refs/heads/main') }}
 
 on:
   pull_request:",Yes
README.md,README.md,31f4c98405c9dea535f017344014061d510cb53c,534bcda50adc424a550e2989a1ea3dd5b4e9a50a,Update info about old images,"diff --git a/README.md b/README.md
index 03354f36..c3b92935 100644
--- a/README.md
+++ b/README.md
@@ -25,6 +25,11 @@ and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.
 
+```{note}
+Since `2023-10-20` our images are only pushed to `Quay.io` registry.
+Older images are available on Docker Hub, but they will no longer be updated.
+```
+
 ### Example 1
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
@@ -100,17 +105,17 @@ more information is available in the [documentation](https://jupyter-docker-stac
 This project only builds one set of images at a time.
 If you want to use older `Ubuntu` and/or `python` version, you can use following images:
 
-| Build Date   | Ubuntu | Python | Registry  | Tag            |
-| ------------ | ------ | ------ | --------- | -------------- |
-| 2022-10-09   | 20.04  | 3.7    | docker.io | `1aac87eb7fa5` |
-| 2022-10-09   | 20.04  | 3.8    | docker.io | `a374cab4fcb6` |
-| 2022-10-09   | 20.04  | 3.9    | docker.io | `5ae537728c69` |
-| 2022-10-09   | 20.04  | 3.10   | docker.io | `f3079808ca8c` |
-| 2022-10-09   | 22.04  | 3.7    | docker.io | `b86753318aa1` |
-| 2022-10-09   | 22.04  | 3.8    | docker.io | `7285848c0a11` |
-| 2022-10-09   | 22.04  | 3.9    | docker.io | `ed2908bbb62e` |
-| 2023-05-30   | 22.04  | 3.10   | docker.io | `4d70cf8da953` |
-| weekly build | 22.04  | 3.11   | quay.io   | `latest`       |
+| Build Date   | Ubuntu | Python | Tag            |
+| ------------ | ------ | ------ | -------------- |
+| 2022-10-09   | 20.04  | 3.7    | `1aac87eb7fa5` |
+| 2022-10-09   | 20.04  | 3.8    | `a374cab4fcb6` |
+| 2022-10-09   | 20.04  | 3.9    | `5ae537728c69` |
+| 2022-10-09   | 20.04  | 3.10   | `f3079808ca8c` |
+| 2022-10-09   | 22.04  | 3.7    | `b86753318aa1` |
+| 2022-10-09   | 22.04  | 3.8    | `7285848c0a11` |
+| 2022-10-09   | 22.04  | 3.9    | `ed2908bbb62e` |
+| 2023-05-30   | 22.04  | 3.10   | `4d70cf8da953` |
+| weekly build | 22.04  | 3.11   | `latest`       |
 
 ## Contributing","diff --git a/README.md b/README.md
index 03354f36..c3b92935 100644
--- a/README.md
+++ b/README.md
@@ -25,6 +25,11 @@ and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.
 
+```{note}
+Since `2023-10-20` our images are only pushed to `Quay.io` registry.
+Older images are available on Docker Hub, but they will no longer be updated.
+```
+
 ### Example 1
 
 This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
@@ -100,17 +105,17 @@ more information is available in the [documentation](https://jupyter-docker-stac
 This project only builds one set of images at a time.
 If you want to use older `Ubuntu` and/or `python` version, you can use following images:
 
-| Build Date   | Ubuntu | Python | Registry  | Tag            |
-| ------------ | ------ | ------ | --------- | -------------- |
-| 2022-10-09   | 20.04  | 3.7    | docker.io | `1aac87eb7fa5` |
-| 2022-10-09   | 20.04  | 3.8    | docker.io | `a374cab4fcb6` |
-| 2022-10-09   | 20.04  | 3.9    | docker.io | `5ae537728c69` |
-| 2022-10-09   | 20.04  | 3.10   | docker.io | `f3079808ca8c` |
-| 2022-10-09   | 22.04  | 3.7    | docker.io | `b86753318aa1` |
-| 2022-10-09   | 22.04  | 3.8    | docker.io | `7285848c0a11` |
-| 2022-10-09   | 22.04  | 3.9    | docker.io | `ed2908bbb62e` |
-| 2023-05-30   | 22.04  | 3.10   | docker.io | `4d70cf8da953` |
-| weekly build | 22.04  | 3.11   | quay.io   | `latest`       |
+| Build Date   | Ubuntu | Python | Tag            |
+| ------------ | ------ | ------ | -------------- |
+| 2022-10-09   | 20.04  | 3.7    | `1aac87eb7fa5` |
+| 2022-10-09   | 20.04  | 3.8    | `a374cab4fcb6` |
+| 2022-10-09   | 20.04  | 3.9    | `5ae537728c69` |
+| 2022-10-09   | 20.04  | 3.10   | `f3079808ca8c` |
+| 2022-10-09   | 22.04  | 3.7    | `b86753318aa1` |
+| 2022-10-09   | 22.04  | 3.8    | `7285848c0a11` |
+| 2022-10-09   | 22.04  | 3.9    | `ed2908bbb62e` |
+| 2023-05-30   | 22.04  | 3.10   | `4d70cf8da953` |
+| weekly build | 22.04  | 3.11   | `latest`       |
 
 ## Contributing",Yes
.github/workflows/registry-move.yml,.github/workflows/registry-move.yml,ec949a77173a97c11a5b8678f78642e555b85361,31f4c98405c9dea535f017344014061d510cb53c,Remove tags from registry-move workflow,"diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index dc9dead3..710aa54e 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -57,14 +57,4 @@ jobs:
             pyspark-notebook,
             all-spark-notebook,
           ]
-        tag:
-          [
-            1aac87eb7fa5,
-            a374cab4fcb6,
-            5ae537728c69,
-            f3079808ca8c,
-            b86753318aa1,
-            7285848c0a11,
-            ed2908bbb62e,
-            4d70cf8da953,
-          ]
+        tag: []","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index dc9dead3..710aa54e 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -57,14 +57,4 @@ jobs:
             pyspark-notebook,
             all-spark-notebook,
           ]
-        tag:
-          [
-            1aac87eb7fa5,
-            a374cab4fcb6,
-            5ae537728c69,
-            f3079808ca8c,
-            b86753318aa1,
-            7285848c0a11,
-            ed2908bbb62e,
-            4d70cf8da953,
-          ]
+        tag: []",Yes
.github/workflows/registry-move.yml,.github/workflows/registry-move.yml,0c800adc51f409f557a0723b344da46343fef528,ec949a77173a97c11a5b8678f78642e555b85361,Add one tag so GitHub doesn't complain,"diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 710aa54e..9750adfe 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -57,4 +57,4 @@ jobs:
             pyspark-notebook,
             all-spark-notebook,
           ]
-        tag: []
+        tag: [4d70cf8da953]","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 710aa54e..9750adfe 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -57,4 +57,4 @@ jobs:
             pyspark-notebook,
             all-spark-notebook,
           ]
-        tag: []
+        tag: [4d70cf8da953]",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,cd2875a0da7983e2eda808ea15ff3471354b803a,0c800adc51f409f557a0723b344da46343fef528,"[FAST_BUILD] Remove latest tag in workflow to make local development easier (#2034)

* Remove latest tag in workflow to make local development easier

* Fix style

* Update docker-tag-push.yml

* Update docker-tag-push.yml","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 450dee0a..38ea9f3a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -52,6 +52,9 @@ jobs:
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+      # This step is needed to prevent pushing non-multiarch ""latest"" tag
+      - name: Remove ""latest"" tag from the image 🗑️
+        run: docker image rmi ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}:latest
 
       - name: Push Images to Registry 📤
         if: env.PUSH_TO_REGISTRY == 'true'","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 450dee0a..38ea9f3a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -52,6 +52,9 @@ jobs:
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+      # This step is needed to prevent pushing non-multiarch ""latest"" tag
+      - name: Remove ""latest"" tag from the image 🗑️
+        run: docker image rmi ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}:latest
 
       - name: Push Images to Registry 📤
         if: env.PUSH_TO_REGISTRY == 'true'",Yes
tagging/apply_tags.py,tagging/apply_tags.py,cd2875a0da7983e2eda808ea15ff3471354b803a,0c800adc51f409f557a0723b344da46343fef528,"[FAST_BUILD] Remove latest tag in workflow to make local development easier (#2034)

* Remove latest tag in workflow to make local development easier

* Fix style

* Update docker-tag-push.yml

* Update docker-tag-push.yml","diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 784cd778..72634227 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -23,7 +23,6 @@ def apply_tags(
 ) -> None:
     """"""
     Tags <registry>/<owner>/<short_image_name>:latest with the tags reported by all taggers for this image
-    Then removes latest tag
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")
 
@@ -35,9 +34,6 @@ def apply_tags(
         LOGGER.info(f""Applying tag: {tag}"")
         docker[""tag"", image, tag] & plumbum.FG
 
-    LOGGER.info(""Removing latest tag from the image"")
-    docker[""image"", ""rmi"", image] & plumbum.FG
-
 
 if __name__ == ""__main__"":
     logging.basicConfig(level=logging.INFO)","diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 784cd778..72634227 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -23,7 +23,6 @@ def apply_tags(
 ) -> None:
     """"""
     Tags <registry>/<owner>/<short_image_name>:latest with the tags reported by all taggers for this image
-    Then removes latest tag
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")
 
@@ -35,9 +34,6 @@ def apply_tags(
         LOGGER.info(f""Applying tag: {tag}"")
         docker[""tag"", image, tag] & plumbum.FG
 
-    LOGGER.info(""Removing latest tag from the image"")
-    docker[""image"", ""rmi"", image] & plumbum.FG
-
 
 if __name__ == ""__main__"":
     logging.basicConfig(level=logging.INFO)",Yes
.github/workflows/registry-move.yml,.github/workflows/registry-move.yml,793bbd0c5777e9c441789b288e566b5c041007ec,cd2875a0da7983e2eda808ea15ff3471354b803a,"Correctly move multi-arch images from Docker Hub to Quay.io (#2035)

* Correctly move multi-arch images from Docker Hub to Quay.io

* Use skopeo

* Better workflow

* Only move multi-arch image

* Use macos

* Install docker

* Fix

* Switch back to ubuntu

* Revert ""Switch back to ubuntu""

This reverts commit 0ab19889d3d7f40f0e3c667f480506765b16274f.","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 9750adfe..34a50cd3 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -17,29 +17,27 @@ on:
 
 jobs:
   update-overview:
-    runs-on: ubuntu-latest
+    # To be able to use latest skopeo
+    runs-on: macos-latest
     if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
 
     steps:
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v4
 
-      - name: Pull image from Docker Hub 📥
-        run: docker pull ${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+      - name: Install skopeo and Docker 📦
+        run: |
+          brew install skopeo
+          brew install --cask docker
 
       - name: Login to Quay.io 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
-        with:
-          registry: quay.io
-          username: ${{ secrets.QUAY_USERNAME }}
-          password: ${{ secrets.QUAY_ROBOT_TOKEN }}
+        run: skopeo login quay.io --username ${{ secrets.QUAY_USERNAME }} --password ${{ secrets.QUAY_ROBOT_TOKEN }}
 
-      - name: Push image to Quay.io 🐳
+      - name: Move image from Docker Hub to Quay.io 🐳
         if: env.PUSH_TO_REGISTRY == 'true'
         run: |
-          docker tag ${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }} quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
-          docker push quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+          skopeo copy --multi-arch all docker://${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }} docker://quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
 
     strategy:
       fail-fast: false
@@ -57,4 +55,14 @@ jobs:
             pyspark-notebook,
             all-spark-notebook,
           ]
-        tag: [4d70cf8da953]
+        tag:
+          [
+            1aac87eb7fa5,
+            a374cab4fcb6,
+            5ae537728c69,
+            f3079808ca8c,
+            b86753318aa1,
+            7285848c0a11,
+            ed2908bbb62e,
+            4d70cf8da953,
+          ]","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 9750adfe..34a50cd3 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -17,29 +17,27 @@ on:
 
 jobs:
   update-overview:
-    runs-on: ubuntu-latest
+    # To be able to use latest skopeo
+    runs-on: macos-latest
     if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
 
     steps:
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v4
 
-      - name: Pull image from Docker Hub 📥
-        run: docker pull ${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+      - name: Install skopeo and Docker 📦
+        run: |
+          brew install skopeo
+          brew install --cask docker
 
       - name: Login to Quay.io 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
-        with:
-          registry: quay.io
-          username: ${{ secrets.QUAY_USERNAME }}
-          password: ${{ secrets.QUAY_ROBOT_TOKEN }}
+        run: skopeo login quay.io --username ${{ secrets.QUAY_USERNAME }} --password ${{ secrets.QUAY_ROBOT_TOKEN }}
 
-      - name: Push image to Quay.io 🐳
+      - name: Move image from Docker Hub to Quay.io 🐳
         if: env.PUSH_TO_REGISTRY == 'true'
         run: |
-          docker tag ${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }} quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
-          docker push quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
+          skopeo copy --multi-arch all docker://${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }} docker://quay.io/${{ env.OWNER }}/${{ matrix.image }}:${{ matrix.tag }}
 
     strategy:
       fail-fast: false
@@ -57,4 +55,14 @@ jobs:
             pyspark-notebook,
             all-spark-notebook,
           ]
-        tag: [4d70cf8da953]
+        tag:
+          [
+            1aac87eb7fa5,
+            a374cab4fcb6,
+            5ae537728c69,
+            f3079808ca8c,
+            b86753318aa1,
+            7285848c0a11,
+            ed2908bbb62e,
+            4d70cf8da953,
+          ]",Yes
.github/workflows/registry-move.yml,.github/workflows/registry-move.yml,5cd1f13797151e8d90743c2f224cd65542c55825,793bbd0c5777e9c441789b288e566b5c041007ec,Use tag which doesn't exist in registry-move,"diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 34a50cd3..83392898 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -55,14 +55,4 @@ jobs:
             pyspark-notebook,
             all-spark-notebook,
           ]
-        tag:
-          [
-            1aac87eb7fa5,
-            a374cab4fcb6,
-            5ae537728c69,
-            f3079808ca8c,
-            b86753318aa1,
-            7285848c0a11,
-            ed2908bbb62e,
-            4d70cf8da953,
-          ]
+        tag: [missing-tag-expected-to-fail]","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 34a50cd3..83392898 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -55,14 +55,4 @@ jobs:
             pyspark-notebook,
             all-spark-notebook,
           ]
-        tag:
-          [
-            1aac87eb7fa5,
-            a374cab4fcb6,
-            5ae537728c69,
-            f3079808ca8c,
-            b86753318aa1,
-            7285848c0a11,
-            ed2908bbb62e,
-            4d70cf8da953,
-          ]
+        tag: [missing-tag-expected-to-fail]",Yes
README.md,README.md,dbaa43f898de112b6b52e3ac8d7f321234bf451f,5cd1f13797151e8d90743c2f224cd65542c55825,Update tag example,"diff --git a/README.md b/README.md
index c3b92935..c3faa871 100644
--- a/README.md
+++ b/README.md
@@ -32,11 +32,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-10-31
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-11-17
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -51,11 +51,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-10-31
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-11-17
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index c3b92935..c3faa871 100644
--- a/README.md
+++ b/README.md
@@ -32,11 +32,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-10-31
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-11-17
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -51,11 +51,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-10-31
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-11-17
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,dbaa43f898de112b6b52e3ac8d7f321234bf451f,5cd1f13797151e8d90743c2f224cd65542c55825,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index a183da42..94b7663d 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-10-31
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-11-17
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-10-31""
+ENV TAG=""2023-11-17""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index a183da42..94b7663d 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-10-31
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-11-17
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-10-31""
+ENV TAG=""2023-11-17""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,dbaa43f898de112b6b52e3ac8d7f321234bf451f,5cd1f13797151e8d90743c2f224cd65542c55825,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index b00d4932..89c5034b 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-31
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-11-17
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2023-10-31   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2023-11-17   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-10-31
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-11-17
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2023-10-31
+    quay.io/jupyter/r-notebook:2023-11-17
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index b00d4932..89c5034b 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-10-31
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-11-17
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2023-10-31   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2023-11-17   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-10-31
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-11-17
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-10-31` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2023-10-31
+    quay.io/jupyter/r-notebook:2023-11-17
 ```
 
 ```{warning}",Yes
README.md,README.md,07fdeaa6787609de4be81d2fdacf7b5e230402f8,dbaa43f898de112b6b52e3ac8d7f321234bf451f,Update README.md,"diff --git a/README.md b/README.md
index c3faa871..59082c1c 100644
--- a/README.md
+++ b/README.md
@@ -71,7 +71,7 @@ system when the container exits, but any changes made to the `~/work` directory
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
 So, new notebooks will be saved there, unless you change the directory in the file browser.
 
-To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
+To change the default directory, you must specify `ServerApp.root_dir` by adding this line to the previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
 ## Choosing Jupyter frontend
@@ -98,12 +98,12 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-06-01`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
 
 ## Using old images
 
 This project only builds one set of images at a time.
-If you want to use older `Ubuntu` and/or `python` version, you can use following images:
+If you want to use the older `Ubuntu` and/or `python` version, you can use the following images:
 
 | Build Date   | Ubuntu | Python | Tag            |
 | ------------ | ------ | ------ | -------------- |
@@ -120,7 +120,7 @@ If you want to use older `Ubuntu` and/or `python` version, you can use following
 ## Contributing
 
 Please see the [Contributor Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)
-for information about how to contribute recipes, features, tests, and community maintained stacks.
+for information about how to contribute recipes, features, tests, and community-maintained stacks.
 
 ## Alternatives","diff --git a/README.md b/README.md
index c3faa871..59082c1c 100644
--- a/README.md
+++ b/README.md
@@ -71,7 +71,7 @@ system when the container exits, but any changes made to the `~/work` directory
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
 So, new notebooks will be saved there, unless you change the directory in the file browser.
 
-To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
+To change the default directory, you must specify `ServerApp.root_dir` by adding this line to the previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
 ## Choosing Jupyter frontend
@@ -98,12 +98,12 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - We publish containers for both `x86_64` and `aarch64` platforms
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.10.5`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
-- Starting from `2023-06-01`, we create multi-platform `tensorflow-notebook` image as well
+- Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
 
 ## Using old images
 
 This project only builds one set of images at a time.
-If you want to use older `Ubuntu` and/or `python` version, you can use following images:
+If you want to use the older `Ubuntu` and/or `python` version, you can use the following images:
 
 | Build Date   | Ubuntu | Python | Tag            |
 | ------------ | ------ | ------ | -------------- |
@@ -120,7 +120,7 @@ If you want to use older `Ubuntu` and/or `python` version, you can use following
 ## Contributing
 
 Please see the [Contributor Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/)
-for information about how to contribute recipes, features, tests, and community maintained stacks.
+for information about how to contribute recipes, features, tests, and community-maintained stacks.
 
 ## Alternatives",Yes
docs/contributing/packages.md,docs/contributing/packages.md,7378b61ac70bfa463586b9f7fdcb5c3eeacf5baf,07fdeaa6787609de4be81d2fdacf7b5e230402f8,Update packages.md,"diff --git a/docs/contributing/packages.md b/docs/contributing/packages.md
index 29f499d6..d6b77060 100644
--- a/docs/contributing/packages.md
+++ b/docs/contributing/packages.md
@@ -6,12 +6,12 @@ All this means that packages might have old versions.
 Images are rebuilt weekly, so usually, packages receive updates quite frequently.
 
 ```{note}
-We pin major.minor version of python, so this will stay the same even after invoking the `mamba update` command.
+We pin major.minor version of Python, so this will stay the same even after invoking the `mamba update` command.
 ```
 
 ## Outdated packages
 
-To help to identify packages that can be updated, you can use the following helper tool.
+To help identify packages that can be updated, you can use the following helper tool.
 It will list all the outdated packages installed in the `Dockerfile` --
 dependencies are filtered to focus only on requested packages.","diff --git a/docs/contributing/packages.md b/docs/contributing/packages.md
index 29f499d6..d6b77060 100644
--- a/docs/contributing/packages.md
+++ b/docs/contributing/packages.md
@@ -6,12 +6,12 @@ All this means that packages might have old versions.
 Images are rebuilt weekly, so usually, packages receive updates quite frequently.
 
 ```{note}
-We pin major.minor version of python, so this will stay the same even after invoking the `mamba update` command.
+We pin major.minor version of Python, so this will stay the same even after invoking the `mamba update` command.
 ```
 
 ## Outdated packages
 
-To help to identify packages that can be updated, you can use the following helper tool.
+To help identify packages that can be updated, you can use the following helper tool.
 It will list all the outdated packages installed in the `Dockerfile` --
 dependencies are filtered to focus only on requested packages.",Yes
docs/contributing/recipes.md,docs/contributing/recipes.md,bbd52113431b570a244f338491e40c291a60ac4e,7378b61ac70bfa463586b9f7fdcb5c3eeacf5baf,Update recipes.md,"diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index d44ac242..45afb60c 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -1,6 +1,6 @@
 # New Recipes
 
-We welcome contributions of [recipes](../using/recipes.md), short examples of using, configuring, or extending the Docker Stacks for inclusion in the documentation site.
+We welcome contributions of [recipes](../using/recipes.md), and short examples of using, configuring, or extending the Docker Stacks for inclusion in the documentation site.
 Follow the process below to add a new recipe:
 
 1. Open the `docs/using/recipes.md` source file.","diff --git a/docs/contributing/recipes.md b/docs/contributing/recipes.md
index d44ac242..45afb60c 100644
--- a/docs/contributing/recipes.md
+++ b/docs/contributing/recipes.md
@@ -1,6 +1,6 @@
 # New Recipes
 
-We welcome contributions of [recipes](../using/recipes.md), short examples of using, configuring, or extending the Docker Stacks for inclusion in the documentation site.
+We welcome contributions of [recipes](../using/recipes.md), and short examples of using, configuring, or extending the Docker Stacks for inclusion in the documentation site.
 Follow the process below to add a new recipe:
 
 1. Open the `docs/using/recipes.md` source file.",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,fd364af70f9e0fbf01c004e99077749f69663a71,bbd52113431b570a244f338491e40c291a60ac4e,Update stacks.md,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index f2570bfb..cfc52d0e 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -79,7 +79,7 @@ git push -u origin main
    ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
 
    ```{note}
-   First run is expected to fail, because we haven't yet added Docker credentials to push the image
+   The first run is expected to fail because we haven't yet added Docker credentials to push the image
    ```
 
 3. In the next screen, you will see information about the workflow run and duration.
@@ -103,7 +103,7 @@ you merge a GitHub pull request to the main branch of your project.
    ![Docker Hub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
 
 3. Enter a description for your image.
-4. Click on your avatar in the top-right corner and select Account settings.
+4. Click on your avatar in the top-right corner and select Account Settings.
 
    ![Docker Hub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-user-dropdown.png)
 
@@ -149,6 +149,6 @@ Finally, if you'd like to add a link to your project to this documentation site,
 
 1. Fork the [jupyter/docker-stacks](https://github.com/jupyter/docker-stacks) GitHub repository.
 2. Open the `docs/using/selecting.md` source file and locate the **Community Stacks** section in your fork.
-3. Add a table entry with a link to your project, a binder link and a short description of what your Docker image contains.
+3. Add a table entry with a link to your project, a binder link, and a short description of what your Docker image contains.
 4. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)(PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index f2570bfb..cfc52d0e 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -79,7 +79,7 @@ git push -u origin main
    ![GitHub page for jupyter/docker-stacks with the Actions tab active and a rectangle around the ""Build Docker Images"" workflow in the UI](../_static/contributing/stacks/github-actions-tab.png)
 
    ```{note}
-   First run is expected to fail, because we haven't yet added Docker credentials to push the image
+   The first run is expected to fail because we haven't yet added Docker credentials to push the image
    ```
 
 3. In the next screen, you will see information about the workflow run and duration.
@@ -103,7 +103,7 @@ you merge a GitHub pull request to the main branch of your project.
    ![Docker Hub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
 
 3. Enter a description for your image.
-4. Click on your avatar in the top-right corner and select Account settings.
+4. Click on your avatar in the top-right corner and select Account Settings.
 
    ![Docker Hub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-user-dropdown.png)
 
@@ -149,6 +149,6 @@ Finally, if you'd like to add a link to your project to this documentation site,
 
 1. Fork the [jupyter/docker-stacks](https://github.com/jupyter/docker-stacks) GitHub repository.
 2. Open the `docs/using/selecting.md` source file and locate the **Community Stacks** section in your fork.
-3. Add a table entry with a link to your project, a binder link and a short description of what your Docker image contains.
+3. Add a table entry with a link to your project, a binder link, and a short description of what your Docker image contains.
 4. [Submit a pull request](https://github.com/PointCloudLibrary/pcl/wiki/A-step-by-step-guide-on-preparing-and-submitting-a-pull-request)(PR) with your changes.
    Maintainers will respond and work with you to address any formatting or content issues.",Yes
docs/contributing/lint.md,docs/contributing/lint.md,f15ec03aa3ba0b50577b65a1515e354a7a27e021,fd364af70f9e0fbf01c004e99077749f69663a71,Update lint.md,"diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index ae9d91aa..17918912 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -44,7 +44,7 @@ More information can be found in [`.pre-commit-config.yaml` file](https://github
 
 ## Image Lint
 
-To comply with [Docker best practices][dbp], we are using the [Hadolint][hadolint] tool to analyse each `Dockerfile`.
+To comply with [Docker best practices][dbp], we are using the [Hadolint][hadolint] tool to analyze each `Dockerfile`.
 
 ### Ignoring Rules
 
@@ -52,10 +52,10 @@ Sometimes it is necessary to ignore [some rules][rules].
 The following rules are ignored by default for all images in the `.hadolint.yaml` file.
 
 - [`DL3006`][dl3006]: We use a specific policy to manage image tags.
-  - `base-notebook` `FROM` clause is fixed but based on an argument (`ARG`).
+  - The `docker-stacks-foundation` `FROM` clause is fixed but based on an argument (`ARG`).
   - Building downstream images from (`FROM`) the latest is done on purpose.
 - [`DL3008`][dl3008]: System packages are always updated (`apt-get`) to the latest version.
-- [`DL3013`][dl3013]: We always install latest packages using `pip`
+- [`DL3013`][dl3013]: We always install the latest packages using `pip`
 
 The preferred way to do it for other rules is to flag ignored ones in the `Dockerfile`.","diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index ae9d91aa..17918912 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -44,7 +44,7 @@ More information can be found in [`.pre-commit-config.yaml` file](https://github
 
 ## Image Lint
 
-To comply with [Docker best practices][dbp], we are using the [Hadolint][hadolint] tool to analyse each `Dockerfile`.
+To comply with [Docker best practices][dbp], we are using the [Hadolint][hadolint] tool to analyze each `Dockerfile`.
 
 ### Ignoring Rules
 
@@ -52,10 +52,10 @@ Sometimes it is necessary to ignore [some rules][rules].
 The following rules are ignored by default for all images in the `.hadolint.yaml` file.
 
 - [`DL3006`][dl3006]: We use a specific policy to manage image tags.
-  - `base-notebook` `FROM` clause is fixed but based on an argument (`ARG`).
+  - The `docker-stacks-foundation` `FROM` clause is fixed but based on an argument (`ARG`).
   - Building downstream images from (`FROM`) the latest is done on purpose.
 - [`DL3008`][dl3008]: System packages are always updated (`apt-get`) to the latest version.
-- [`DL3013`][dl3013]: We always install latest packages using `pip`
+- [`DL3013`][dl3013]: We always install the latest packages using `pip`
 
 The preferred way to do it for other rules is to flag ignored ones in the `Dockerfile`.",Yes
docs/contributing/tests.md,docs/contributing/tests.md,094078c1c9dd11ddd79035b3a2a407294f16dbb8,f15ec03aa3ba0b50577b65a1515e354a7a27e021,Update tests.md,"diff --git a/docs/contributing/tests.md b/docs/contributing/tests.md
index b27a3046..f7fa5c6f 100644
--- a/docs/contributing/tests.md
+++ b/docs/contributing/tests.md
@@ -1,6 +1,6 @@
 # Image Tests
 
-We greatly appreciate pull requests that extend the automated tests that vet the basic functionality of the Docker images.
+We greatly appreciate Pull Requests that extend the automated tests that vet the basic functionality of the Docker images.
 
 ## How the Tests Work
 
@@ -14,7 +14,7 @@ More info on `pytest` can be found [here](https://docs.pytest.org/en/latest/cont
 The actual image-specific test files are located in folders like `tests/<somestack>/` (e.g., `tests/docker-stacks-foundation/`, `tests/minimal-notebook/`, etc.).
 
 ```{note}
-If your test is located in `tests/<somestack>/`, it will be run against `jupyter/<somestack>` image and against all the [images inherited from this image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#image-relationships.
+If your test is located in `tests/<somestack>/`, it will be run against the `jupyter/<somestack>` image and against all the [images inherited from this image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#image-relationships.
 ```
 
 Many tests make use of global [pytest fixtures](https://docs.pytest.org/en/latest/reference/fixtures.html)
@@ -23,7 +23,7 @@ defined in the [conftest.py](https://github.com/jupyter/docker-stacks/blob/main/
 ## Unit tests
 
 You can add a unit test if you want to run a python script in one of our images.
-You should create a `tests/<somestack>/units/` directory, if it doesn't already exist and put your file there.
+You should create a `tests/<somestack>/units/` directory, if it doesn't already exist, and put your file there.
 Files in this folder will be executed in the container when tests are run.
 You can see an [example for the TensorFlow package here](https://github.com/jupyter/docker-stacks/blob/HEAD/tests/tensorflow-notebook/units/unit_tensorflow.py).
 
@@ -31,7 +31,7 @@ You can see an [example for the TensorFlow package here](https://github.com/jupy
 
 Please follow the process below to add new tests:
 
-1. Add your test code to one of the modules in `tests/<somestack>/` directory or create a new module.
+1. Add your test code to one of the modules in the `tests/<somestack>/` directory or create a new module.
 2. Build one or more images you intend to test and run the tests locally.
    If you use `make`, call:","diff --git a/docs/contributing/tests.md b/docs/contributing/tests.md
index b27a3046..f7fa5c6f 100644
--- a/docs/contributing/tests.md
+++ b/docs/contributing/tests.md
@@ -1,6 +1,6 @@
 # Image Tests
 
-We greatly appreciate pull requests that extend the automated tests that vet the basic functionality of the Docker images.
+We greatly appreciate Pull Requests that extend the automated tests that vet the basic functionality of the Docker images.
 
 ## How the Tests Work
 
@@ -14,7 +14,7 @@ More info on `pytest` can be found [here](https://docs.pytest.org/en/latest/cont
 The actual image-specific test files are located in folders like `tests/<somestack>/` (e.g., `tests/docker-stacks-foundation/`, `tests/minimal-notebook/`, etc.).
 
 ```{note}
-If your test is located in `tests/<somestack>/`, it will be run against `jupyter/<somestack>` image and against all the [images inherited from this image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#image-relationships.
+If your test is located in `tests/<somestack>/`, it will be run against the `jupyter/<somestack>` image and against all the [images inherited from this image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#image-relationships.
 ```
 
 Many tests make use of global [pytest fixtures](https://docs.pytest.org/en/latest/reference/fixtures.html)
@@ -23,7 +23,7 @@ defined in the [conftest.py](https://github.com/jupyter/docker-stacks/blob/main/
 ## Unit tests
 
 You can add a unit test if you want to run a python script in one of our images.
-You should create a `tests/<somestack>/units/` directory, if it doesn't already exist and put your file there.
+You should create a `tests/<somestack>/units/` directory, if it doesn't already exist, and put your file there.
 Files in this folder will be executed in the container when tests are run.
 You can see an [example for the TensorFlow package here](https://github.com/jupyter/docker-stacks/blob/HEAD/tests/tensorflow-notebook/units/unit_tensorflow.py).
 
@@ -31,7 +31,7 @@ You can see an [example for the TensorFlow package here](https://github.com/jupy
 
 Please follow the process below to add new tests:
 
-1. Add your test code to one of the modules in `tests/<somestack>/` directory or create a new module.
+1. Add your test code to one of the modules in the `tests/<somestack>/` directory or create a new module.
 2. Build one or more images you intend to test and run the tests locally.
    If you use `make`, call:",Yes
docs/maintaining/new-images-and-packages-policy.md,docs/maintaining/new-images-and-packages-policy.md,f1b04258b696e3ebb622b18c6bab5c0daf9d87c2,094078c1c9dd11ddd79035b3a2a407294f16dbb8,Update new-images-and-packages-policy.md,"diff --git a/docs/maintaining/new-images-and-packages-policy.md b/docs/maintaining/new-images-and-packages-policy.md
index b6e75314..637cf01e 100644
--- a/docs/maintaining/new-images-and-packages-policy.md
+++ b/docs/maintaining/new-images-and-packages-policy.md
@@ -1,8 +1,8 @@
 # Policy on adding new images and packages
 
-There are many things we consider, while adding new images and packages.
+There are many things we consider while adding new images and packages.
 
-Here is a non exhaustive list of things we do care about:
+Here is a non-exhaustive list of things we do care about:
 
 1. **Software health**, details, and maintenance status
    - reasonable versioning is adopted, and the version is considered to be stable
@@ -25,7 +25,7 @@ Here is a non exhaustive list of things we do care about:
 6. Impact on **security**
    - Does the package open additional ports, or add new web endpoints, that could be exploited?
 
-With all this in mind, we have a voting group, which consists of
+With all this in mind, we have a voting group, that consists of
 [mathbunnyru](https://github.com/mathbunnyru),
 [consideRatio](https://github.com/consideRatio),
 [yuvipanda](https://github.com/yuvipanda) and","diff --git a/docs/maintaining/new-images-and-packages-policy.md b/docs/maintaining/new-images-and-packages-policy.md
index b6e75314..637cf01e 100644
--- a/docs/maintaining/new-images-and-packages-policy.md
+++ b/docs/maintaining/new-images-and-packages-policy.md
@@ -1,8 +1,8 @@
 # Policy on adding new images and packages
 
-There are many things we consider, while adding new images and packages.
+There are many things we consider while adding new images and packages.
 
-Here is a non exhaustive list of things we do care about:
+Here is a non-exhaustive list of things we do care about:
 
 1. **Software health**, details, and maintenance status
    - reasonable versioning is adopted, and the version is considered to be stable
@@ -25,7 +25,7 @@ Here is a non exhaustive list of things we do care about:
 6. Impact on **security**
    - Does the package open additional ports, or add new web endpoints, that could be exploited?
 
-With all this in mind, we have a voting group, which consists of
+With all this in mind, we have a voting group, that consists of
 [mathbunnyru](https://github.com/mathbunnyru),
 [consideRatio](https://github.com/consideRatio),
 [yuvipanda](https://github.com/yuvipanda) and",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,b0ef5b950dda8caecbd5cb52fcaabdbd5aafc659,f1b04258b696e3ebb622b18c6bab5c0daf9d87c2,Update tasks.md,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index c6a577ae..d6a4236f 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -10,7 +10,7 @@ To build new images and publish them to the Registry, do the following:
 
    ```{note}
    GitHub Actions are pretty reliable, so please investigate if some error occurs.
-   Building Docker images in PRs is the same as building them in default branch,
+   Building Docker images in PRs is the same as building them in the default branch,
    except single-platform images are pushed to Registry and then tags are merged for `x86_64` and `aarch64`.
    ```
 
@@ -29,7 +29,7 @@ When a new `Python` version is released, we wait for:
 ## Updating the Ubuntu Base Image
 
 `jupyter/docker-stacks-foundation` is based on the LTS Ubuntu docker image.
-We wait for the first point release of the new LTS Ubuntu before updating the version.
+We are waiting for the first point release of the new LTS Ubuntu before updating the version.
 Other images are directly or indirectly inherited from `docker-stacks-foundation`.
 We rebuild our images automatically each week, which means they frequently receive updates.","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index c6a577ae..d6a4236f 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -10,7 +10,7 @@ To build new images and publish them to the Registry, do the following:
 
    ```{note}
    GitHub Actions are pretty reliable, so please investigate if some error occurs.
-   Building Docker images in PRs is the same as building them in default branch,
+   Building Docker images in PRs is the same as building them in the default branch,
    except single-platform images are pushed to Registry and then tags are merged for `x86_64` and `aarch64`.
    ```
 
@@ -29,7 +29,7 @@ When a new `Python` version is released, we wait for:
 ## Updating the Ubuntu Base Image
 
 `jupyter/docker-stacks-foundation` is based on the LTS Ubuntu docker image.
-We wait for the first point release of the new LTS Ubuntu before updating the version.
+We are waiting for the first point release of the new LTS Ubuntu before updating the version.
 Other images are directly or indirectly inherited from `docker-stacks-foundation`.
 We rebuild our images automatically each week, which means they frequently receive updates.",Yes
docs/using/common.md,docs/using/common.md,011a724ba5a7b33756f8a7721209f3b1edf07a49,b0ef5b950dda8caecbd5cb52fcaabdbd5aafc659,Update common.md,"diff --git a/docs/using/common.md b/docs/using/common.md
index e0097dac..ae51a116 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -242,7 +242,7 @@ The `/opt/conda/bin` directory is part of the default `jovyan` user's `${PATH}`.
 That directory is also searched for binaries when run using `sudo` (`sudo my_binary` will search for `my_binary` in `/opt/conda/bin/`
 
 The `jovyan` user has full read/write access to the `/opt/conda` directory.
-You can use either `mamba`, `pip` or `conda` (`mamba` is recommended) to install new packages without any additional permissions.
+You can use either `mamba`, `pip`, or `conda` (`mamba` is recommended) to install new packages without any additional permissions.
 
 ```bash
 # install a package into the default (python 3.x) environment and cleanup it after","diff --git a/docs/using/common.md b/docs/using/common.md
index e0097dac..ae51a116 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -242,7 +242,7 @@ The `/opt/conda/bin` directory is part of the default `jovyan` user's `${PATH}`.
 That directory is also searched for binaries when run using `sudo` (`sudo my_binary` will search for `my_binary` in `/opt/conda/bin/`
 
 The `jovyan` user has full read/write access to the `/opt/conda` directory.
-You can use either `mamba`, `pip` or `conda` (`mamba` is recommended) to install new packages without any additional permissions.
+You can use either `mamba`, `pip`, or `conda` (`mamba` is recommended) to install new packages without any additional permissions.
 
 ```bash
 # install a package into the default (python 3.x) environment and cleanup it after",Yes
docs/using/faq.md,docs/using/faq.md,a49920aac9c4d0a7db2242b0019a6d014a1d4cd7,011a724ba5a7b33756f8a7721209f3b1edf07a49,Update faq.md,"diff --git a/docs/using/faq.md b/docs/using/faq.md
index a072d58f..12056fe5 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -4,9 +4,9 @@
 
 There are 2 types of data, which you might want to persist.
 
-1. If you want to persist your environment (i.e. packages installed by `mamba`, `conda`, `pip`, `apt-get` and so on),
-   then you should create an inherited image and install them only once while building your Dockerfile.
-   An example for using `mamba` and `pip` in a child image is available
+1. If you want to persist your environment (i.e. packages installed by `mamba`, `conda`, `pip`, `apt-get`, and so on),
+   then you should create an inherited image and install packages only once while building your Dockerfile.
+   An example of using `mamba` and `pip` in a child image is available
    [here](./recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
 
    ```{note}
@@ -15,7 +15,7 @@ There are 2 types of data, which you might want to persist.
    To make it work, install this package in your inherited image and rerun `docker build` command.
    ```
 
-2. If you want to persist user-data (files created by you, like `python` scripts, notebooks, text files and so on),
+2. If you want to persist user data (files created by you, like `python` scripts, notebooks, text files, and so on),
    then you should use a
    [Docker bind mount](https://docs.docker.com/storage/bind-mounts/) or
    [Docker Volume](https://docs.docker.com/storage/volumes/).
@@ -26,7 +26,7 @@ There are 2 types of data, which you might want to persist.
 
 We have lots of users with different packages they want to use.
 Adding them all is impossible, so we have several images to choose from.
-[Choose the image](selecting.md), that is closest to your needs and feel free to [add your package on top of our images](recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
+[Choose the image](selecting.md), that is closest to your needs, and feel free to [add your package on top of our images](recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
 
 ## Who is `jovyan`","diff --git a/docs/using/faq.md b/docs/using/faq.md
index a072d58f..12056fe5 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -4,9 +4,9 @@
 
 There are 2 types of data, which you might want to persist.
 
-1. If you want to persist your environment (i.e. packages installed by `mamba`, `conda`, `pip`, `apt-get` and so on),
-   then you should create an inherited image and install them only once while building your Dockerfile.
-   An example for using `mamba` and `pip` in a child image is available
+1. If you want to persist your environment (i.e. packages installed by `mamba`, `conda`, `pip`, `apt-get`, and so on),
+   then you should create an inherited image and install packages only once while building your Dockerfile.
+   An example of using `mamba` and `pip` in a child image is available
    [here](./recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
 
    ```{note}
@@ -15,7 +15,7 @@ There are 2 types of data, which you might want to persist.
    To make it work, install this package in your inherited image and rerun `docker build` command.
    ```
 
-2. If you want to persist user-data (files created by you, like `python` scripts, notebooks, text files and so on),
+2. If you want to persist user data (files created by you, like `python` scripts, notebooks, text files, and so on),
    then you should use a
    [Docker bind mount](https://docs.docker.com/storage/bind-mounts/) or
    [Docker Volume](https://docs.docker.com/storage/volumes/).
@@ -26,7 +26,7 @@ There are 2 types of data, which you might want to persist.
 
 We have lots of users with different packages they want to use.
 Adding them all is impossible, so we have several images to choose from.
-[Choose the image](selecting.md), that is closest to your needs and feel free to [add your package on top of our images](recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
+[Choose the image](selecting.md), that is closest to your needs, and feel free to [add your package on top of our images](recipes.md#using-mamba-install-recommended-or-pip-install-in-a-child-docker-image).
 
 ## Who is `jovyan`",Yes
docs/using/recipes.md,docs/using/recipes.md,4df689f2f4b1b083263d4d7fa9eac7594d85a9bc,a49920aac9c4d0a7db2242b0019a6d014a1d4cd7,Update recipes.md,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 5df119d8..52eb60b1 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -56,8 +56,8 @@ docker run -it --rm \
 
 The default version of `Python` that ships with the image may not be the version you want.
 The instructions below permit adding a conda environment with a different `Python` version and making it accessible to Jupyter.
-You may also use older image like `jupyter/base-notebook:python-3.10`.
-List of all tags can be found [here](https://github.com/jupyter/docker-stacks/wiki)
+You may also use older images like `jupyter/base-notebook:python-3.10`.
+A list of all tags can be found [here](https://github.com/jupyter/docker-stacks/wiki)
 
 ```{literalinclude} recipe_code/custom_environment.dockerfile
 :language: docker
@@ -93,7 +93,7 @@ docker run -it --rm \
 This recipe is not tested and might be broken.
 ```
 
-See the README for a basic automation here
+See the README for basic automation here
 <https://github.com/jupyter/docker-stacks/tree/main/examples/make-deploy>
 which includes steps for requesting and renewing a Let's Encrypt certificate.
 
@@ -104,8 +104,8 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/78>
 [RISE](https://github.com/jupyterlab-contrib/rise): ""Live"" Reveal.js JupyterLab Slideshow Extension.
 
 ```{note}
-We're providing the recipe to install JupyterLab extension.
-You can find the original Jupyter Notebook extenstion [here](https://github.com/damianavila/RISE)
+We're providing the recipe to install the JupyterLab extension.
+You can find the original Jupyter Notebook extension [here](https://github.com/damianavila/RISE)
 ```
 
 ```{literalinclude} recipe_code/rise_jupyterlab.dockerfile
@@ -178,7 +178,7 @@ You can find an example of using DockerSpawner [here](https://github.com/jupyter
 ### Containers with a specific version of JupyterHub
 
 The version of `jupyterhub` in your image should match the
-version in the JupyterHub itself.
+version in JupyterHub itself.
 To use a specific version of JupyterHub, do the following:
 
 ```{literalinclude} recipe_code/jupyterhub_version.dockerfile
@@ -187,7 +187,7 @@ To use a specific version of JupyterHub, do the following:
 
 ## Spark
 
-A few suggestions have been made regarding using Docker Stacks with spark.
+A few suggestions have been made regarding using Docker Stacks with Spark.
 
 ### Using PySpark with AWS S3
 
@@ -514,7 +514,7 @@ Pre-built images are hosted in the [realiserad/jupyter-docker-mssql](https://git
 This recipe only works for x86_64 architecture.
 ```
 
-The following recipe demonstrates how to add functionality to connect to a Oracle Database using [Oracle Instant Client](https://www.oracle.com/database/technologies/instant-client.html)
+The following recipe demonstrates how to add functionality to connect to an Oracle Database using [Oracle Instant Client](https://www.oracle.com/database/technologies/instant-client.html)
 in your notebook.
 This recipe installs version `21.11.0.0.0`.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 5df119d8..52eb60b1 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -56,8 +56,8 @@ docker run -it --rm \
 
 The default version of `Python` that ships with the image may not be the version you want.
 The instructions below permit adding a conda environment with a different `Python` version and making it accessible to Jupyter.
-You may also use older image like `jupyter/base-notebook:python-3.10`.
-List of all tags can be found [here](https://github.com/jupyter/docker-stacks/wiki)
+You may also use older images like `jupyter/base-notebook:python-3.10`.
+A list of all tags can be found [here](https://github.com/jupyter/docker-stacks/wiki)
 
 ```{literalinclude} recipe_code/custom_environment.dockerfile
 :language: docker
@@ -93,7 +93,7 @@ docker run -it --rm \
 This recipe is not tested and might be broken.
 ```
 
-See the README for a basic automation here
+See the README for basic automation here
 <https://github.com/jupyter/docker-stacks/tree/main/examples/make-deploy>
 which includes steps for requesting and renewing a Let's Encrypt certificate.
 
@@ -104,8 +104,8 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/78>
 [RISE](https://github.com/jupyterlab-contrib/rise): ""Live"" Reveal.js JupyterLab Slideshow Extension.
 
 ```{note}
-We're providing the recipe to install JupyterLab extension.
-You can find the original Jupyter Notebook extenstion [here](https://github.com/damianavila/RISE)
+We're providing the recipe to install the JupyterLab extension.
+You can find the original Jupyter Notebook extension [here](https://github.com/damianavila/RISE)
 ```
 
 ```{literalinclude} recipe_code/rise_jupyterlab.dockerfile
@@ -178,7 +178,7 @@ You can find an example of using DockerSpawner [here](https://github.com/jupyter
 ### Containers with a specific version of JupyterHub
 
 The version of `jupyterhub` in your image should match the
-version in the JupyterHub itself.
+version in JupyterHub itself.
 To use a specific version of JupyterHub, do the following:
 
 ```{literalinclude} recipe_code/jupyterhub_version.dockerfile
@@ -187,7 +187,7 @@ To use a specific version of JupyterHub, do the following:
 
 ## Spark
 
-A few suggestions have been made regarding using Docker Stacks with spark.
+A few suggestions have been made regarding using Docker Stacks with Spark.
 
 ### Using PySpark with AWS S3
 
@@ -514,7 +514,7 @@ Pre-built images are hosted in the [realiserad/jupyter-docker-mssql](https://git
 This recipe only works for x86_64 architecture.
 ```
 
-The following recipe demonstrates how to add functionality to connect to a Oracle Database using [Oracle Instant Client](https://www.oracle.com/database/technologies/instant-client.html)
+The following recipe demonstrates how to add functionality to connect to an Oracle Database using [Oracle Instant Client](https://www.oracle.com/database/technologies/instant-client.html)
 in your notebook.
 This recipe installs version `21.11.0.0.0`.",Yes
docs/using/running.md,docs/using/running.md,1ed3bb0093c7b11d47be8c98d88430d48d6f44c8,4df689f2f4b1b083263d4d7fa9eac7594d85a9bc,Update running.md,"diff --git a/docs/using/running.md b/docs/using/running.md
index 89c5034b..7c0d7cd9 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -10,7 +10,7 @@ This section provides details about the second.
 ## Using the Docker CLI
 
 You can launch a local Docker container from the Jupyter Docker Stacks using the [Docker command-line interface](https://docs.docker.com/engine/reference/commandline/cli/).
-There are numerous ways to configure containers using the CLI.
+There are numerous ways to configure containers using CLI.
 The following are some common patterns.
 
 ### Example 1
@@ -55,7 +55,7 @@ docker rm eca4aa01751c
 
 This command pulls the `jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
-The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
+The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
 docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-11-17
@@ -69,7 +69,7 @@ Any other changes made in the container will be lost.
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
 So, new notebooks will be saved there, unless you change the directory in the file browser.
 
-To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to the previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
 ### Example 3","diff --git a/docs/using/running.md b/docs/using/running.md
index 89c5034b..7c0d7cd9 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -10,7 +10,7 @@ This section provides details about the second.
 ## Using the Docker CLI
 
 You can launch a local Docker container from the Jupyter Docker Stacks using the [Docker command-line interface](https://docs.docker.com/engine/reference/commandline/cli/).
-There are numerous ways to configure containers using the CLI.
+There are numerous ways to configure containers using CLI.
 The following are some common patterns.
 
 ### Example 1
@@ -55,7 +55,7 @@ docker rm eca4aa01751c
 
 This command pulls the `jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
-The server logs appear in the terminal and include a URL to the Server, but with the internal container port (8888) instead of the correct host port (10000).
+The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
 docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-11-17
@@ -69,7 +69,7 @@ Any other changes made in the container will be lost.
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.
 So, new notebooks will be saved there, unless you change the directory in the file browser.
 
-To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
+To change the default directory, you will need to specify `ServerApp.root_dir` by adding this line to the previous command: `start-notebook.py --ServerApp.root_dir=/home/jovyan/work`.
 ```
 
 ### Example 3",Yes
docs/using/selecting.md,docs/using/selecting.md,e79a501d7f7c934b69e1c9aff6dee1fd2c08acea,1ed3bb0093c7b11d47be8c98d88430d48d6f44c8,Update selecting.md,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index f86d576a..9184a724 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -25,7 +25,7 @@ The following sections describe these images, including their contents, relation
 `jupyter/docker-stacks-foundation` is a small image supporting a majority of [options common across all core stacks](common.md).
 It is the basis for all other stacks on which Jupyter-related applications can be built
 (e.g., kernel-based containers, [nbclient](https://github.com/jupyter/nbclient) applications, etc.).
-As such, it does not contain application-level software like JupyterLab, Jupyter Notebook or JupyterHub.
+As such, it does not contain application-level software like JupyterLab, Jupyter Notebook, or JupyterHub.
 
 It contains:
 
@@ -55,13 +55,13 @@ It contains:
 
 - Everything in `jupyter/docker-stacks-foundation`
 - Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
-- `notebook`, `jupyterhub` and `jupyterlab` packages
+- `notebook`, `jupyterhub`, and `jupyterlab` packages
 - A `start-notebook.py` script as the default command
 - A `start-singleuser.py` script useful for launching containers in JupyterHub
 - Options for a self-signed HTTPS certificate
 
 ```{warning}
-`jupyter/base-notebook` also contains `start-notebook.sh` and `start-singleuser.sh` files to maintain backwards compatibility.
+`jupyter/base-notebook` also contains `start-notebook.sh` and `start-singleuser.sh` files to maintain backward compatibility.
 External config that explicitly refers to those files should instead
 update to refer to `start-notebook.py` and `start-singleuser.py`.
 The shim `.sh` files will be removed at some future date.
@@ -307,12 +307,12 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 [almond]: https://almond.sh
 [almond_b]: https://mybinder.org/v2/gh/almond-sh/examples/master?urlpath=lab%2Ftree%2Fnotebooks%2Findex.ipynb
 
-### GPU accelerated notebooks
+### GPU-accelerated notebooks
 
 | Flavor             | Description                                                                                                                                                                                                                                                                                                                                                 |
 | ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
-| [GPU-Jupyter][gpu] | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
-| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                        |
+| [GPU-Jupyter][gpu] | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule, and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
+| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                        |
 | [b-data][b-data]   | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].        |
 
 [gpu]: https://github.com/iot-salzburg/gpu-jupyter","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index f86d576a..9184a724 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -25,7 +25,7 @@ The following sections describe these images, including their contents, relation
 `jupyter/docker-stacks-foundation` is a small image supporting a majority of [options common across all core stacks](common.md).
 It is the basis for all other stacks on which Jupyter-related applications can be built
 (e.g., kernel-based containers, [nbclient](https://github.com/jupyter/nbclient) applications, etc.).
-As such, it does not contain application-level software like JupyterLab, Jupyter Notebook or JupyterHub.
+As such, it does not contain application-level software like JupyterLab, Jupyter Notebook, or JupyterHub.
 
 It contains:
 
@@ -55,13 +55,13 @@ It contains:
 
 - Everything in `jupyter/docker-stacks-foundation`
 - Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
-- `notebook`, `jupyterhub` and `jupyterlab` packages
+- `notebook`, `jupyterhub`, and `jupyterlab` packages
 - A `start-notebook.py` script as the default command
 - A `start-singleuser.py` script useful for launching containers in JupyterHub
 - Options for a self-signed HTTPS certificate
 
 ```{warning}
-`jupyter/base-notebook` also contains `start-notebook.sh` and `start-singleuser.sh` files to maintain backwards compatibility.
+`jupyter/base-notebook` also contains `start-notebook.sh` and `start-singleuser.sh` files to maintain backward compatibility.
 External config that explicitly refers to those files should instead
 update to refer to `start-notebook.py` and `start-singleuser.py`.
 The shim `.sh` files will be removed at some future date.
@@ -307,12 +307,12 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 [almond]: https://almond.sh
 [almond_b]: https://mybinder.org/v2/gh/almond-sh/examples/master?urlpath=lab%2Ftree%2Fnotebooks%2Findex.ipynb
 
-### GPU accelerated notebooks
+### GPU-accelerated notebooks
 
 | Flavor             | Description                                                                                                                                                                                                                                                                                                                                                 |
 | ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
-| [GPU-Jupyter][gpu] | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
-| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                        |
+| [GPU-Jupyter][gpu] | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule, and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
+| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                        |
 | [b-data][b-data]   | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].        |
 
 [gpu]: https://github.com/iot-salzburg/gpu-jupyter",Yes
docs/using/selecting.md,docs/using/selecting.md,52e4cb96f29cd3432c26e951f7c4495e4998ef40,e79a501d7f7c934b69e1c9aff6dee1fd2c08acea,Fix codestyle,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 9184a724..82305b9e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -309,11 +309,11 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 
 ### GPU-accelerated notebooks
 
-| Flavor             | Description                                                                                                                                                                                                                                                                                                                                                 |
-| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
+| Flavor             | Description                                                                                                                                                                                                                                                                                                                                                  |
+| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
 | [GPU-Jupyter][gpu] | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule, and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
-| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                        |
-| [b-data][b-data]   | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].        |
+| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                         |
+| [b-data][b-data]   | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].         |
 
 [gpu]: https://github.com/iot-salzburg/gpu-jupyter
 [prp_gpu]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/-/tree/prp","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 9184a724..82305b9e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -309,11 +309,11 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 
 ### GPU-accelerated notebooks
 
-| Flavor             | Description                                                                                                                                                                                                                                                                                                                                                 |
-| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
+| Flavor             | Description                                                                                                                                                                                                                                                                                                                                                  |
+| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
 | [GPU-Jupyter][gpu] | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule, and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
-| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                        |
-| [b-data][b-data]   | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].        |
+| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                         |
+| [b-data][b-data]   | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].         |
 
 [gpu]: https://github.com/iot-salzburg/gpu-jupyter
 [prp_gpu]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/-/tree/prp",Yes
docs/using/specifics.md,docs/using/specifics.md,db01bfbd237480227295b2130fd7bcd9a6bf98bf,52e4cb96f29cd3432c26e951f7c4495e4998ef40,Update specifics.md,"diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 39776551..3510674d 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -42,7 +42,7 @@ ipython profile create
 You can build a `pyspark-notebook` image with a different `Spark` version by overriding the default value of the following arguments at build time.
 `all-spark-notebook` is inherited from `pyspark-notebook`, so you have to first build `pyspark-notebook` and then `all-spark-notebook` to get the same version in `all-spark-notebook`.
 
-- Spark distribution is defined by the combination of Spark, Hadoop and Scala versions and verified by the package checksum,
+- Spark distribution is defined by the combination of Spark, Hadoop, and Scala versions and verified by the package checksum,
   see [Download Apache Spark](https://spark.apache.org/downloads.html) and the [archive repo](https://archive.apache.org/dist/spark/) for more information.
 
   - `spark_version`: The Spark version to install (`3.3.0`).
@@ -55,7 +55,7 @@ You can build a `pyspark-notebook` image with a different `Spark` version by ove
 
 - Starting with _Spark >= 3.2_, the distribution file might contain Scala version.
 
-For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2` and OpenJDK `11`.
+For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2`, and OpenJDK `11`.
 
 ```{warning}
 This recipe is not tested and might be broken.","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 39776551..3510674d 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -42,7 +42,7 @@ ipython profile create
 You can build a `pyspark-notebook` image with a different `Spark` version by overriding the default value of the following arguments at build time.
 `all-spark-notebook` is inherited from `pyspark-notebook`, so you have to first build `pyspark-notebook` and then `all-spark-notebook` to get the same version in `all-spark-notebook`.
 
-- Spark distribution is defined by the combination of Spark, Hadoop and Scala versions and verified by the package checksum,
+- Spark distribution is defined by the combination of Spark, Hadoop, and Scala versions and verified by the package checksum,
   see [Download Apache Spark](https://spark.apache.org/downloads.html) and the [archive repo](https://archive.apache.org/dist/spark/) for more information.
 
   - `spark_version`: The Spark version to install (`3.3.0`).
@@ -55,7 +55,7 @@ You can build a `pyspark-notebook` image with a different `Spark` version by ove
 
 - Starting with _Spark >= 3.2_, the distribution file might contain Scala version.
 
-For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2` and OpenJDK `11`.
+For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2`, and OpenJDK `11`.
 
 ```{warning}
 This recipe is not tested and might be broken.",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,cc00341fccb796a0c1c21689a88dfaa3c0bece3e,db01bfbd237480227295b2130fd7bcd9a6bf98bf,Update troubleshooting.md,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 89ef2298..74e8e088 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -77,7 +77,7 @@ The following sections cover a few of these scenarios and how to fix them.
       - If you are mounting your volume inside the `/home/` directory, you can use the `-e CHOWN_HOME=yes` and `CHOWN_HOME_OPTS=""-R""` flags
       instead of the `-e CHOWN_EXTRA` and `-e CHOWN_EXTRA_OPTS` in the example above.
       - This solution should work in most cases where you have created a docker volume
-      (i.e. using the [`docker volume create --name <my-volume>`command](https://docs.docker.com/storage/volumes/#create-and-manage-volumes)) and mounted it using the`-v` flag in `docker run`.
+      (i.e. using the [`docker volume create --name <my-volume>`command](https://docs.docker.com/storage/volumes/#create-and-manage-volumes)) and mounted it using the `-v` flag in `docker run`.
    ```
 
 2. **Matching the container's UID/GID with the host's**
@@ -270,7 +270,7 @@ conda config --show default_channels
 
 **Installing packages from alternative channels:**
 
-You can install packages from other conda channels (e.g. bioconda) by disabling the `channel_priority` setting:
+You can install packages from other conda channels (e.g. `bioconda`) by disabling the `channel_priority` setting:
 
 ```bash
 # install by disabling channel priority at еру command level","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 89ef2298..74e8e088 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -77,7 +77,7 @@ The following sections cover a few of these scenarios and how to fix them.
       - If you are mounting your volume inside the `/home/` directory, you can use the `-e CHOWN_HOME=yes` and `CHOWN_HOME_OPTS=""-R""` flags
       instead of the `-e CHOWN_EXTRA` and `-e CHOWN_EXTRA_OPTS` in the example above.
       - This solution should work in most cases where you have created a docker volume
-      (i.e. using the [`docker volume create --name <my-volume>`command](https://docs.docker.com/storage/volumes/#create-and-manage-volumes)) and mounted it using the`-v` flag in `docker run`.
+      (i.e. using the [`docker volume create --name <my-volume>`command](https://docs.docker.com/storage/volumes/#create-and-manage-volumes)) and mounted it using the `-v` flag in `docker run`.
    ```
 
 2. **Matching the container's UID/GID with the host's**
@@ -270,7 +270,7 @@ conda config --show default_channels
 
 **Installing packages from alternative channels:**
 
-You can install packages from other conda channels (e.g. bioconda) by disabling the `channel_priority` setting:
+You can install packages from other conda channels (e.g. `bioconda`) by disabling the `channel_priority` setting:
 
 ```bash
 # install by disabling channel priority at еру command level",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,132dfd1f592a604c09276303417341c01f7cb601,cc00341fccb796a0c1c21689a88dfaa3c0bece3e,Docker build doesn't depend on tests/README.md,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index a65280d8..956542b0 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -30,6 +30,7 @@ on:
       - ""tagging/**""
       - ""!tagging/README.md""
       - ""tests/**""
+      - ""!tests/README.md""
       - ""requirements-dev.txt""
   push:
     branches:
@@ -50,6 +51,7 @@ on:
       - ""tagging/**""
       - ""!tagging/README.md""
       - ""tests/**""
+      - ""!tests/README.md""
       - ""requirements-dev.txt""
   workflow_dispatch:","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index a65280d8..956542b0 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -30,6 +30,7 @@ on:
       - ""tagging/**""
       - ""!tagging/README.md""
       - ""tests/**""
+      - ""!tests/README.md""
       - ""requirements-dev.txt""
   push:
     branches:
@@ -50,6 +51,7 @@ on:
       - ""tagging/**""
       - ""!tagging/README.md""
       - ""tests/**""
+      - ""!tests/README.md""
       - ""requirements-dev.txt""
   workflow_dispatch:",Yes
tagging/README.md,tagging/README.md,188ff1eb1b3aea791dbc87a5efe519e54b6ef8a3,132dfd1f592a604c09276303417341c01f7cb601,Update README.md,"diff --git a/tagging/README.md b/tagging/README.md
index 5d62917a..34c34af6 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -50,7 +50,7 @@ The prefix of commit hash (namely, 12 letters) is used as an image tag to make i
 
 ### Tagger
 
-`Tagger` is a class which can be run inside a docker container to calculate some tag for an image.
+`Tagger` is a class that can be run inside a docker container to calculate some tag for an image.
 
 All the taggers are inherited from `TaggerInterface`:
 
@@ -79,12 +79,12 @@ class SHATagger(TaggerInterface):
 ```
 
 - `taggers.py` contains all the taggers.
-- `tag_image.py` is a python executable which is used to tag the image.
+- `tag_image.py` is a Python executable that is used to tag the image.
 
 ### Manifest
 
 `ManifestHeader` is a build manifest header.
-It contains information about `Build datetime`, `Docker image size` and `Git commit` info.
+It contains information about `Build datetime`, `Docker image size`, and `Git commit` info.
 
 All the other manifest classes are inherited from `ManifestInterface`:
 
@@ -97,7 +97,7 @@ class ManifestInterface:
         raise NotImplementedError
 ```
 
-- `markdown_piece(container)` method returns a piece of markdown file to be used as a part of the build manifest.
+- The `markdown_piece(container)` method returns a piece of markdown file to be used as a part of the build manifest.
 
 `AptPackagesManifest` example:
 
@@ -117,7 +117,7 @@ class AptPackagesManifest(ManifestInterface):
 - `quoted_output` simply runs the command inside a container using `DockerRunner.run_simple_command` and wraps it to triple quotes to create a valid markdown piece.
   It also adds the command which was run to the markdown piece.
 - `manifests.py` contains all the manifests.
-- `write_manifest.py` is a python executable which is used to create the build manifest and history line for an image.
+- `write_manifest.py` is a Python executable that is used to create the build manifest and history line for an image.
 
 ### Images Hierarchy","diff --git a/tagging/README.md b/tagging/README.md
index 5d62917a..34c34af6 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -50,7 +50,7 @@ The prefix of commit hash (namely, 12 letters) is used as an image tag to make i
 
 ### Tagger
 
-`Tagger` is a class which can be run inside a docker container to calculate some tag for an image.
+`Tagger` is a class that can be run inside a docker container to calculate some tag for an image.
 
 All the taggers are inherited from `TaggerInterface`:
 
@@ -79,12 +79,12 @@ class SHATagger(TaggerInterface):
 ```
 
 - `taggers.py` contains all the taggers.
-- `tag_image.py` is a python executable which is used to tag the image.
+- `tag_image.py` is a Python executable that is used to tag the image.
 
 ### Manifest
 
 `ManifestHeader` is a build manifest header.
-It contains information about `Build datetime`, `Docker image size` and `Git commit` info.
+It contains information about `Build datetime`, `Docker image size`, and `Git commit` info.
 
 All the other manifest classes are inherited from `ManifestInterface`:
 
@@ -97,7 +97,7 @@ class ManifestInterface:
         raise NotImplementedError
 ```
 
-- `markdown_piece(container)` method returns a piece of markdown file to be used as a part of the build manifest.
+- The `markdown_piece(container)` method returns a piece of markdown file to be used as a part of the build manifest.
 
 `AptPackagesManifest` example:
 
@@ -117,7 +117,7 @@ class AptPackagesManifest(ManifestInterface):
 - `quoted_output` simply runs the command inside a container using `DockerRunner.run_simple_command` and wraps it to triple quotes to create a valid markdown piece.
   It also adds the command which was run to the markdown piece.
 - `manifests.py` contains all the manifests.
-- `write_manifest.py` is a python executable which is used to create the build manifest and history line for an image.
+- `write_manifest.py` is a Python executable that is used to create the build manifest and history line for an image.
 
 ### Images Hierarchy",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,bb56acf0d97d47ca727962b18733dc769fcb609b,188ff1eb1b3aea791dbc87a5efe519e54b6ef8a3,Fix typo,"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 25f04838..6bfc5e6f 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -36,7 +36,7 @@ jobs:
 
       # Self-hosted runners share a state (whole VM) between runs
       # Also, they might have running or stopped containers,
-      # which are not cleaned up by `docker system prun`
+      # which are not cleaned up by `docker system prune`
       - name: Reset docker state and cleanup artifacts 🗑️
         if: inputs.platform != 'x86_64'
         run: |","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 25f04838..6bfc5e6f 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -36,7 +36,7 @@ jobs:
 
       # Self-hosted runners share a state (whole VM) between runs
       # Also, they might have running or stopped containers,
-      # which are not cleaned up by `docker system prun`
+      # which are not cleaned up by `docker system prune`
       - name: Reset docker state and cleanup artifacts 🗑️
         if: inputs.platform != 'x86_64'
         run: |",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,8517280b6e46f8741f7ad7b27e2ccbb3fa79a627,bb56acf0d97d47ca727962b18733dc769fcb609b,Unify style,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 2f8eeb44..78821c0b 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -52,4 +52,4 @@ jobs:
         shell: bash
 
     strategy:
-      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}
+      matrix: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 2f8eeb44..78821c0b 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -52,4 +52,4 @@ jobs:
         shell: bash
 
     strategy:
-      matrix: ${{fromJson(needs.generate-matrix.outputs.matrix)}}
+      matrix: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}",Yes
.github/workflows/sphinx.yml,.github/workflows/sphinx.yml,71e66b2d57ae660f4c2259c5424192d3dbd99108,8517280b6e46f8741f7ad7b27e2ccbb3fa79a627,Sphinx workflow doesn't depend on .readthedocs.yaml,"diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index fde0d4ea..d3f56119 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -10,7 +10,6 @@ on:
 
       - ""docs/**""
       - ""README.md""
-      - "".readthedocs.yaml""
   push:
     branches:
       - main
@@ -19,7 +18,6 @@ on:
 
       - ""docs/**""
       - ""README.md""
-      - "".readthedocs.yaml""
   workflow_dispatch:
 
 jobs:","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index fde0d4ea..d3f56119 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -10,7 +10,6 @@ on:
 
       - ""docs/**""
       - ""README.md""
-      - "".readthedocs.yaml""
   push:
     branches:
       - main
@@ -19,7 +18,6 @@ on:
 
       - ""docs/**""
       - ""README.md""
-      - "".readthedocs.yaml""
   workflow_dispatch:
 
 jobs:",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index af7aa187..2efad71b 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -124,5 +124,5 @@ body:
       label: Latest Docker version
       description: You should try to use the latest Docker version
       options:
-        - label: I've updated my Docker version to the latest available, and the issue still persists
+        - label: I've updated my Docker version to the latest available, and the issue persists
           required: true","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index af7aa187..2efad71b 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -124,5 +124,5 @@ body:
       label: Latest Docker version
       description: You should try to use the latest Docker version
       options:
-        - label: I've updated my Docker version to the latest available, and the issue still persists
+        - label: I've updated my Docker version to the latest available, and the issue persists
           required: true",Yes
.github/actions/create-dev-env/action.yml,.github/actions/create-dev-env/action.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/actions/create-dev-env/action.yml b/.github/actions/create-dev-env/action.yml
index 5686b6d1..2a507f1c 100644
--- a/.github/actions/create-dev-env/action.yml
+++ b/.github/actions/create-dev-env/action.yml
@@ -1,5 +1,5 @@
 name: Build environment
-description: Create build environment
+description: Create a build environment
 
 runs:
   using: composite","diff --git a/.github/actions/create-dev-env/action.yml b/.github/actions/create-dev-env/action.yml
index 5686b6d1..2a507f1c 100644
--- a/.github/actions/create-dev-env/action.yml
+++ b/.github/actions/create-dev-env/action.yml
@@ -1,5 +1,5 @@
 name: Build environment
-description: Create build environment
+description: Create a build environment
 
 runs:
   using: composite",Yes
.github/actions/load-image/action.yml,.github/actions/load-image/action.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index 23195a01..c32f3479 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -1,5 +1,5 @@
 name: Load Docker image
-description: Download image tar and load it to docker
+description: Download the image tar and load it to Docker
 
 inputs:
   image:","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index 23195a01..c32f3479 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -1,5 +1,5 @@
 name: Load Docker image
-description: Download image tar and load it to docker
+description: Download the image tar and load it to Docker
 
 inputs:
   image:",Yes
.github/workflows/aarch64-setup.yml,.github/workflows/aarch64-setup.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/workflows/aarch64-setup.yml b/.github/workflows/aarch64-setup.yml
index 02e01696..441a9aa2 100644
--- a/.github/workflows/aarch64-setup.yml
+++ b/.github/workflows/aarch64-setup.yml
@@ -2,7 +2,7 @@ name: Test aarch64-runner setup script
 
 on:
   schedule:
-    # Weekly, at 03:00 on Monday UTC time
+    # Weekly, at 03:00 on Monday UTC
     - cron: ""0 3 * * 1""
   pull_request:
     paths:
@@ -18,7 +18,7 @@ on:
 
 jobs:
   test-script:
-    # The script itself is not aarch64 specific
+    # The script itself is not aarch64-specific
     # It is easier to test on ubuntu-latest
     runs-on: ubuntu-latest","diff --git a/.github/workflows/aarch64-setup.yml b/.github/workflows/aarch64-setup.yml
index 02e01696..441a9aa2 100644
--- a/.github/workflows/aarch64-setup.yml
+++ b/.github/workflows/aarch64-setup.yml
@@ -2,7 +2,7 @@ name: Test aarch64-runner setup script
 
 on:
   schedule:
-    # Weekly, at 03:00 on Monday UTC time
+    # Weekly, at 03:00 on Monday UTC
     - cron: ""0 3 * * 1""
   pull_request:
     paths:
@@ -18,7 +18,7 @@ on:
 
 jobs:
   test-script:
-    # The script itself is not aarch64 specific
+    # The script itself is not aarch64-specific
     # It is easier to test on ubuntu-latest
     runs-on: ubuntu-latest",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 78821c0b..77d84e04 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -1,4 +1,4 @@
-name: Test contributed recipes
+name: Test the contributed recipes
 
 on:
   schedule:
@@ -33,7 +33,7 @@ jobs:
         run: docs/using/recipe_code/generate_matrix.py >> $GITHUB_OUTPUT
 
   test-recipes:
-    runs-on: ${{ matrix.runsOn }}
+    runs-on: ${{ matrix.runs-on }}
     needs: generate-matrix
     if: github.repository_owner == 'jupyter'
 
@@ -42,7 +42,7 @@ jobs:
         uses: actions/checkout@v4
 
       - name: Build recipe 🛠
-        # We're pulling here to avoid accidentally using image which migt be present on aarch64 self-hosted runner
+        # We're pulling here to avoid accidentally using an image that might be present on aarch64 self-hosted runner
         run: docker build --pull --rm --force-rm --tag my-custom-image -f ./${{ matrix.dockerfile }} ./
         env:
           DOCKER_BUILDKIT: 1","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 78821c0b..77d84e04 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -1,4 +1,4 @@
-name: Test contributed recipes
+name: Test the contributed recipes
 
 on:
   schedule:
@@ -33,7 +33,7 @@ jobs:
         run: docs/using/recipe_code/generate_matrix.py >> $GITHUB_OUTPUT
 
   test-recipes:
-    runs-on: ${{ matrix.runsOn }}
+    runs-on: ${{ matrix.runs-on }}
     needs: generate-matrix
     if: github.repository_owner == 'jupyter'
 
@@ -42,7 +42,7 @@ jobs:
         uses: actions/checkout@v4
 
       - name: Build recipe 🛠
-        # We're pulling here to avoid accidentally using image which migt be present on aarch64 self-hosted runner
+        # We're pulling here to avoid accidentally using an image that might be present on aarch64 self-hosted runner
         run: docker build --pull --rm --force-rm --tag my-custom-image -f ./${{ matrix.dockerfile }} ./
         env:
           DOCKER_BUILDKIT: 1",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 6bfc5e6f..2ebad196 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -1,4 +1,4 @@
-name: Download parent image, build a new one and test it; then upload the image, tags and manifests to GitHub artifacts
+name: Download a parent image, build a new one, and test it; then upload the image, tags, and manifests to GitHub artifacts
 
 env:
   REGISTRY: quay.io
@@ -7,7 +7,7 @@ env:
 on:
   workflow_call:
     inputs:
-      parentImage:
+      parent-image:
         description: Parent image name
         required: true
         type: string
@@ -19,14 +19,14 @@ on:
         description: Image platform
         required: true
         type: string
-      runsOn:
+      runs-on:
         description: GitHub Actions Runner image
         required: true
         type: string
 
 jobs:
   build-test-upload:
-    runs-on: ${{ inputs.runsOn }}
+    runs-on: ${{ inputs.runs-on }}
 
     steps:
       - name: Checkout Repo ⚡️
@@ -47,14 +47,14 @@ jobs:
         shell: bash
 
       - name: Load parent built image to Docker 📥
-        if: inputs.parentImage != ''
+        if: inputs.parent-image != ''
         uses: ./.github/actions/load-image
         with:
-          image: ${{ inputs.parentImage }}
+          image: ${{ inputs.parent-image }}
           platform: ${{ inputs.platform }}
 
       - name: Pull ubuntu:22.04 image 📥
-        if: inputs.parentImage == ''
+        if: inputs.parent-image == ''
         run: docker pull ubuntu:22.04
         shell: bash","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 6bfc5e6f..2ebad196 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -1,4 +1,4 @@
-name: Download parent image, build a new one and test it; then upload the image, tags and manifests to GitHub artifacts
+name: Download a parent image, build a new one, and test it; then upload the image, tags, and manifests to GitHub artifacts
 
 env:
   REGISTRY: quay.io
@@ -7,7 +7,7 @@ env:
 on:
   workflow_call:
     inputs:
-      parentImage:
+      parent-image:
         description: Parent image name
         required: true
         type: string
@@ -19,14 +19,14 @@ on:
         description: Image platform
         required: true
         type: string
-      runsOn:
+      runs-on:
         description: GitHub Actions Runner image
         required: true
         type: string
 
 jobs:
   build-test-upload:
-    runs-on: ${{ inputs.runsOn }}
+    runs-on: ${{ inputs.runs-on }}
 
     steps:
       - name: Checkout Repo ⚡️
@@ -47,14 +47,14 @@ jobs:
         shell: bash
 
       - name: Load parent built image to Docker 📥
-        if: inputs.parentImage != ''
+        if: inputs.parent-image != ''
         uses: ./.github/actions/load-image
         with:
-          image: ${{ inputs.parentImage }}
+          image: ${{ inputs.parent-image }}
           platform: ${{ inputs.platform }}
 
       - name: Pull ubuntu:22.04 image 📥
-        if: inputs.parentImage == ''
+        if: inputs.parent-image == ''
         run: docker pull ubuntu:22.04
         shell: bash",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index d1ad9a44..bd90b8b2 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -1,4 +1,4 @@
-name: Download images tags from GitHub artifacts and create multi-platform manifests
+name: Download all tags from GitHub artifacts and create multi-platform manifests
 
 env:
   OWNER: ${{ github.repository_owner }}","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index d1ad9a44..bd90b8b2 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -1,4 +1,4 @@
-name: Download images tags from GitHub artifacts and create multi-platform manifests
+name: Download all tags from GitHub artifacts and create multi-platform manifests
 
 env:
   OWNER: ${{ github.repository_owner }}",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 38ea9f3a..36f56b21 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,4 +1,4 @@
-name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
+name: Download a Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
 
 env:
   REGISTRY: quay.io
@@ -52,8 +52,8 @@ jobs:
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
-      # This step is needed to prevent pushing non-multiarch ""latest"" tag
-      - name: Remove ""latest"" tag from the image 🗑️
+      # This step is needed to prevent pushing non-multi-arch ""latest"" tag
+      - name: Remove the ""latest"" tag from the image 🗑️
         run: docker image rmi ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}:latest
 
       - name: Push Images to Registry 📤","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 38ea9f3a..36f56b21 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,4 +1,4 @@
-name: Download Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
+name: Download a Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
 
 env:
   REGISTRY: quay.io
@@ -52,8 +52,8 @@ jobs:
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
         run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
-      # This step is needed to prevent pushing non-multiarch ""latest"" tag
-      - name: Remove ""latest"" tag from the image 🗑️
+      # This step is needed to prevent pushing non-multi-arch ""latest"" tag
+      - name: Remove the ""latest"" tag from the image 🗑️
         run: docker image rmi ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}:latest
 
       - name: Push Images to Registry 📤",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 956542b0..4046c19b 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -1,18 +1,18 @@
-name: Build, test and push Docker Images
+name: Build, test, and push Docker Images
 
 # [FAST_BUILD] in the PR title makes this workflow only build
-# `jupyter/docker-stacks-foundation` and `jupyter/base-notebook`
-# This allows to run CI faster if full build is not required
-# This only works for `pull_request` event and has no effect on `push` to the `main` branch
+# the `jupyter/docker-stacks-foundation` and `jupyter/base-notebook` images
+# This allows to run CI faster if a full build is not required
+# This only works for a `pull_request` event and does not affect `push` to the `main` branch
 
 on:
   schedule:
-    # Weekly, at 03:00 on Monday UTC time
+    # Weekly, at 03:00 on Monday UTC
     - cron: ""0 3 * * 1""
   pull_request:
     paths:
       - "".github/workflows/docker.yml""
-      # We use local reusable workflows to make architecture clean an simple
+      # We use local reusable workflows to make architecture clean and simple
       # https://docs.github.com/en/actions/using-workflows/reusing-workflows
       - "".github/workflows/docker-build-test-upload.yml""
       - "".github/workflows/docker-merge-tags.yml""
@@ -57,7 +57,7 @@ on:
 
 # https://docs.github.com/en/actions/using-jobs/using-concurrency
 concurrency:
-  # only cancel in-progress jobs or runs for the current workflow - matches against branch & tags
+  # Only cancel in-progress jobs or runs for the current workflow - matches against branch & tags
   group: ${{ github.workflow }}-${{ github.ref }}
   cancel-in-progress: true
 
@@ -65,196 +65,196 @@ jobs:
   aarch64-foundation:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: """"
+      parent-image: """"
       image: docker-stacks-foundation
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     if: github.repository_owner == 'jupyter'
 
   x86_64-foundation:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: """"
+      parent-image: """"
       image: docker-stacks-foundation
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
 
   aarch64-base:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: docker-stacks-foundation
+      parent-image: docker-stacks-foundation
       image: base-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-foundation]
     if: github.repository_owner == 'jupyter'
 
   x86_64-base:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: docker-stacks-foundation
+      parent-image: docker-stacks-foundation
       image: base-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-foundation]
 
   aarch64-minimal:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: base-notebook
+      parent-image: base-notebook
       image: minimal-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-base]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-minimal:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: base-notebook
+      parent-image: base-notebook
       image: minimal-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-base]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: scipy-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: scipy-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-minimal]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: r-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: r-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-minimal]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: julia-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: julia-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-minimal]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: tensorflow-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: tensorflow-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: datascience-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: datascience-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: pyspark-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: pyspark-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: pyspark-notebook
+      parent-image: pyspark-notebook
       image: all-spark-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-pyspark]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: pyspark-notebook
+      parent-image: pyspark-notebook
       image: all-spark-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-pyspark]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 956542b0..4046c19b 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -1,18 +1,18 @@
-name: Build, test and push Docker Images
+name: Build, test, and push Docker Images
 
 # [FAST_BUILD] in the PR title makes this workflow only build
-# `jupyter/docker-stacks-foundation` and `jupyter/base-notebook`
-# This allows to run CI faster if full build is not required
-# This only works for `pull_request` event and has no effect on `push` to the `main` branch
+# the `jupyter/docker-stacks-foundation` and `jupyter/base-notebook` images
+# This allows to run CI faster if a full build is not required
+# This only works for a `pull_request` event and does not affect `push` to the `main` branch
 
 on:
   schedule:
-    # Weekly, at 03:00 on Monday UTC time
+    # Weekly, at 03:00 on Monday UTC
     - cron: ""0 3 * * 1""
   pull_request:
     paths:
       - "".github/workflows/docker.yml""
-      # We use local reusable workflows to make architecture clean an simple
+      # We use local reusable workflows to make architecture clean and simple
       # https://docs.github.com/en/actions/using-workflows/reusing-workflows
       - "".github/workflows/docker-build-test-upload.yml""
       - "".github/workflows/docker-merge-tags.yml""
@@ -57,7 +57,7 @@ on:
 
 # https://docs.github.com/en/actions/using-jobs/using-concurrency
 concurrency:
-  # only cancel in-progress jobs or runs for the current workflow - matches against branch & tags
+  # Only cancel in-progress jobs or runs for the current workflow - matches against branch & tags
   group: ${{ github.workflow }}-${{ github.ref }}
   cancel-in-progress: true
 
@@ -65,196 +65,196 @@ jobs:
   aarch64-foundation:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: """"
+      parent-image: """"
       image: docker-stacks-foundation
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     if: github.repository_owner == 'jupyter'
 
   x86_64-foundation:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: """"
+      parent-image: """"
       image: docker-stacks-foundation
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
 
   aarch64-base:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: docker-stacks-foundation
+      parent-image: docker-stacks-foundation
       image: base-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-foundation]
     if: github.repository_owner == 'jupyter'
 
   x86_64-base:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: docker-stacks-foundation
+      parent-image: docker-stacks-foundation
       image: base-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-foundation]
 
   aarch64-minimal:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: base-notebook
+      parent-image: base-notebook
       image: minimal-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-base]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-minimal:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: base-notebook
+      parent-image: base-notebook
       image: minimal-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-base]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: scipy-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-scipy:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: scipy-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-minimal]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: r-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-r:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: r-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-minimal]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: julia-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-julia:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: minimal-notebook
+      parent-image: minimal-notebook
       image: julia-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-minimal]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: tensorflow-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-tensorflow:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: tensorflow-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: datascience-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: datascience-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: pyspark-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-pyspark:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: scipy-notebook
+      parent-image: scipy-notebook
       image: pyspark-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
   aarch64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: pyspark-notebook
+      parent-image: pyspark-notebook
       image: all-spark-notebook
       platform: aarch64
-      runsOn: ARM64
+      runs-on: ARM64
     needs: [aarch64-pyspark]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   x86_64-all-spark:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
-      parentImage: pyspark-notebook
+      parent-image: pyspark-notebook
       image: all-spark-notebook
       platform: x86_64
-      runsOn: ubuntu-latest
+      runs-on: ubuntu-latest
     needs: [x86_64-pyspark]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}",Yes
.github/workflows/registry-move.yml,.github/workflows/registry-move.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 83392898..e5c37c91 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -17,7 +17,7 @@ on:
 
 jobs:
   update-overview:
-    # To be able to use latest skopeo
+    # To be able to use the latest skopeo
     runs-on: macos-latest
     if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index 83392898..e5c37c91 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -17,7 +17,7 @@ on:
 
 jobs:
   update-overview:
-    # To be able to use latest skopeo
+    # To be able to use the latest skopeo
     runs-on: macos-latest
     if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'",Yes
.github/workflows/sphinx.yml,.github/workflows/sphinx.yml,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index d3f56119..a00f229a 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -2,7 +2,7 @@ name: Build Sphinx Documentation and check links
 
 on:
   schedule:
-    # Weekly, at 03:00 on Monday UTC time
+    # Weekly, at 03:00 on Monday UTC
     - cron: ""0 3 * * 1""
   pull_request:
     paths:","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index d3f56119..a00f229a 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -2,7 +2,7 @@ name: Build Sphinx Documentation and check links
 
 on:
   schedule:
-    # Weekly, at 03:00 on Monday UTC time
+    # Weekly, at 03:00 on Monday UTC
     - cron: ""0 3 * * 1""
   pull_request:
     paths:",Yes
README.md,README.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/README.md b/README.md
index 59082c1c..6103c1c9 100644
--- a/README.md
+++ b/README.md
@@ -91,7 +91,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 
 ## Acknowledgments
 
-- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by amazing [`2i2c non-profit organization`](https://2i2c.org)
+- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by an amazing [`2i2c non-profit organization`](https://2i2c.org)
 
 ## CPU Architectures
 
@@ -103,7 +103,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 ## Using old images
 
 This project only builds one set of images at a time.
-If you want to use the older `Ubuntu` and/or `python` version, you can use the following images:
+If you want to use the older `Ubuntu` and/or `Python` version, you can use the following images:
 
 | Build Date   | Ubuntu | Python | Tag            |
 | ------------ | ------ | ------ | -------------- |","diff --git a/README.md b/README.md
index 59082c1c..6103c1c9 100644
--- a/README.md
+++ b/README.md
@@ -91,7 +91,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 
 ## Acknowledgments
 
-- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by amazing [`2i2c non-profit organization`](https://2i2c.org)
+- Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by an amazing [`2i2c non-profit organization`](https://2i2c.org)
 
 ## CPU Architectures
 
@@ -103,7 +103,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 ## Using old images
 
 This project only builds one set of images at a time.
-If you want to use the older `Ubuntu` and/or `python` version, you can use the following images:
+If you want to use the older `Ubuntu` and/or `Python` version, you can use the following images:
 
 | Build Date   | Ubuntu | Python | Tag            |
 | ------------ | ------ | ------ | -------------- |",Yes
docs/contributing/features.md,docs/contributing/features.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 82d268df..b4d68197 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -24,9 +24,9 @@ Roughly speaking, we evaluate new features based on the following criteria:
   Is the feature generally applicable across domains?
   Does it work with JupyterLab, Jupyter Notebook, JupyterHub, etc.?
 - **Fit with the image purpose**:
-  Does the feature match the theme of the stack in which it will be added?
+  Does the feature match the theme of the stack to which it will be added?
   Would it fit better in a new community stack?
-- **Complexity of build/runtime configuration**:
+- **The complexity of build/runtime configuration**:
   How many lines of code does the feature require in one of the Dockerfiles or startup scripts?
   Does it require new scripts entirely?
   Do users need to adjust how they use the images?
@@ -36,7 +36,7 @@ Roughly speaking, we evaluate new features based on the following criteria:
 - **Ability to support the addition**:
   Can existing maintainers answer user questions and address future build issues?
   Are the contributors interested in helping with long-term maintenance?
-  Can we write tests to ensure the feature continues to work over time?
+  Can we write tests to ensure the feature continues to work over the years?
 
 ## Submitting a Pull Request","diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index 82d268df..b4d68197 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -24,9 +24,9 @@ Roughly speaking, we evaluate new features based on the following criteria:
   Is the feature generally applicable across domains?
   Does it work with JupyterLab, Jupyter Notebook, JupyterHub, etc.?
 - **Fit with the image purpose**:
-  Does the feature match the theme of the stack in which it will be added?
+  Does the feature match the theme of the stack to which it will be added?
   Would it fit better in a new community stack?
-- **Complexity of build/runtime configuration**:
+- **The complexity of build/runtime configuration**:
   How many lines of code does the feature require in one of the Dockerfiles or startup scripts?
   Does it require new scripts entirely?
   Do users need to adjust how they use the images?
@@ -36,7 +36,7 @@ Roughly speaking, we evaluate new features based on the following criteria:
 - **Ability to support the addition**:
   Can existing maintainers answer user questions and address future build issues?
   Are the contributors interested in helping with long-term maintenance?
-  Can we write tests to ensure the feature continues to work over time?
+  Can we write tests to ensure the feature continues to work over the years?
 
 ## Submitting a Pull Request",Yes
docs/maintaining/aarch64-runner.md,docs/maintaining/aarch64-runner.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/docs/maintaining/aarch64-runner.md b/docs/maintaining/aarch64-runner.md
index 45f9c9b3..a0beed19 100644
--- a/docs/maintaining/aarch64-runner.md
+++ b/docs/maintaining/aarch64-runner.md
@@ -6,7 +6,7 @@ Each runner is recommended to have at least _2 cores_ and _30 GB_ of disk space.
 
 Add a new runner:
 
-- To use [Oracle OCI](https://www.oracle.com/cloud/), create a compute instance `VM.Standard.A1.Flex` .
+- To use [Oracle OCI](https://www.oracle.com/cloud/), create a compute instance `VM.Standard.A1.Flex`.
 - To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-arm-vm-instance#armpublicimage).
 
 Configure your runner:
@@ -19,7 +19,7 @@ Configure your runner:
 
    This will perform the initial runner setup and create a user `runner-user` without `sudo` capabilities.
 
-2. Setup new GitHub Runner under `runner-user` using [GitHub Instructions](https://github.com/jupyter/docker-stacks/settings/actions/runners/new?arch=arm64&os=linux).
+2. Set up a new GitHub Runner under `runner-user` using [GitHub Instructions](https://github.com/jupyter/docker-stacks/settings/actions/runners/new?arch=arm64&os=linux).
    **Do not `./run.sh` yet**.
 3. Run under `root`:","diff --git a/docs/maintaining/aarch64-runner.md b/docs/maintaining/aarch64-runner.md
index 45f9c9b3..a0beed19 100644
--- a/docs/maintaining/aarch64-runner.md
+++ b/docs/maintaining/aarch64-runner.md
@@ -6,7 +6,7 @@ Each runner is recommended to have at least _2 cores_ and _30 GB_ of disk space.
 
 Add a new runner:
 
-- To use [Oracle OCI](https://www.oracle.com/cloud/), create a compute instance `VM.Standard.A1.Flex` .
+- To use [Oracle OCI](https://www.oracle.com/cloud/), create a compute instance `VM.Standard.A1.Flex`.
 - To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-arm-vm-instance#armpublicimage).
 
 Configure your runner:
@@ -19,7 +19,7 @@ Configure your runner:
 
    This will perform the initial runner setup and create a user `runner-user` without `sudo` capabilities.
 
-2. Setup new GitHub Runner under `runner-user` using [GitHub Instructions](https://github.com/jupyter/docker-stacks/settings/actions/runners/new?arch=arm64&os=linux).
+2. Set up a new GitHub Runner under `runner-user` using [GitHub Instructions](https://github.com/jupyter/docker-stacks/settings/actions/runners/new?arch=arm64&os=linux).
    **Do not `./run.sh` yet**.
 3. Run under `root`:",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index d6a4236f..e909bdf8 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -16,14 +16,14 @@ To build new images and publish them to the Registry, do the following:
 
 4. Avoid merging another PR to the main branch until all pending builds in the main branch are complete.
    This way, you will know which commit might have broken the build
-   and also have the correct tags for moving tags (like the `python` version).
+   and also have the correct tags for moving tags (like the `Python` version).
 
 ## Updating Python version
 
 When a new `Python` version is released, we wait for:
 
 - all the dependencies to be available (as wheels or in `conda-forge`).
-- the first `python` patch release for this version.
+- the first `Python` patch release for this version.
   This allows us to avoid many bugs, which can happen in a major release.
 
 ## Updating the Ubuntu Base Image","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index d6a4236f..e909bdf8 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -16,14 +16,14 @@ To build new images and publish them to the Registry, do the following:
 
 4. Avoid merging another PR to the main branch until all pending builds in the main branch are complete.
    This way, you will know which commit might have broken the build
-   and also have the correct tags for moving tags (like the `python` version).
+   and also have the correct tags for moving tags (like the `Python` version).
 
 ## Updating Python version
 
 When a new `Python` version is released, we wait for:
 
 - all the dependencies to be available (as wheels or in `conda-forge`).
-- the first `python` patch release for this version.
+- the first `Python` patch release for this version.
   This allows us to avoid many bugs, which can happen in a major release.
 
 ## Updating the Ubuntu Base Image",Yes
docs/using/common.md,docs/using/common.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/docs/using/common.md b/docs/using/common.md
index ae51a116..c51dd512 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -262,7 +262,7 @@ conda install --yes some-package && \
     fix-permissions ""/home/${NB_USER}""
 ```
 
-### Using alternative channels
+### Using Alternative Channels
 
 Conda is configured by default to use only the [`conda-forge`](https://anaconda.org/conda-forge) channel.
 However, you can use alternative channels, either one-shot by overwriting the default channel in the installation command or by configuring `mamba` to use different channels.","diff --git a/docs/using/common.md b/docs/using/common.md
index ae51a116..c51dd512 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -262,7 +262,7 @@ conda install --yes some-package && \
     fix-permissions ""/home/${NB_USER}""
 ```
 
-### Using alternative channels
+### Using Alternative Channels
 
 Conda is configured by default to use only the [`conda-forge`](https://anaconda.org/conda-forge) channel.
 However, you can use alternative channels, either one-shot by overwriting the default channel in the installation command or by configuring `mamba` to use different channels.",Yes
docs/using/faq.md,docs/using/faq.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/docs/using/faq.md b/docs/using/faq.md
index 12056fe5..a8b71688 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -15,11 +15,11 @@ There are 2 types of data, which you might want to persist.
    To make it work, install this package in your inherited image and rerun `docker build` command.
    ```
 
-2. If you want to persist user data (files created by you, like `python` scripts, notebooks, text files, and so on),
+2. If you want to persist user data (files created by you, like `Python` scripts, notebooks, text files, and so on),
    then you should use a
    [Docker bind mount](https://docs.docker.com/storage/bind-mounts/) or
    [Docker Volume](https://docs.docker.com/storage/volumes/).
-   You can find [an example of using bind mount here](./running.md#example-2).
+   You can find [an example of using a bind mount here](./running.md#example-2).
    There is also [a mount troubleshooting section](./troubleshooting.md#permission-denied-when-mounting-volumes) if you experience any issues.
 
 ## Why we do not add your favorite package","diff --git a/docs/using/faq.md b/docs/using/faq.md
index 12056fe5..a8b71688 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -15,11 +15,11 @@ There are 2 types of data, which you might want to persist.
    To make it work, install this package in your inherited image and rerun `docker build` command.
    ```
 
-2. If you want to persist user data (files created by you, like `python` scripts, notebooks, text files, and so on),
+2. If you want to persist user data (files created by you, like `Python` scripts, notebooks, text files, and so on),
    then you should use a
    [Docker bind mount](https://docs.docker.com/storage/bind-mounts/) or
    [Docker Volume](https://docs.docker.com/storage/volumes/).
-   You can find [an example of using bind mount here](./running.md#example-2).
+   You can find [an example of using a bind mount here](./running.md#example-2).
    There is also [a mount troubleshooting section](./troubleshooting.md#permission-denied-when-mounting-volumes) if you experience any issues.
 
 ## Why we do not add your favorite package",Yes
docs/using/recipe_code/generate_matrix.py,docs/using/recipe_code/generate_matrix.py,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/docs/using/recipe_code/generate_matrix.py b/docs/using/recipe_code/generate_matrix.py
index 417cdfb1..62159f30 100755
--- a/docs/using/recipe_code/generate_matrix.py
+++ b/docs/using/recipe_code/generate_matrix.py
@@ -12,8 +12,8 @@ def generate_matrix() -> dict[str, Any]:
     dockerfiles = sorted(file.name for file in THIS_DIR.glob(""*.dockerfile""))
     return {
         ""dockerfile"": dockerfiles,
-        ""runsOn"": [""ubuntu-latest"", ""ARM64""],
-        ""exclude"": [{""dockerfile"": ""oracledb.dockerfile"", ""runsOn"": ""ARM64""}],
+        ""runs-on"": [""ubuntu-latest"", ""ARM64""],
+        ""exclude"": [{""dockerfile"": ""oracledb.dockerfile"", ""runs-on"": ""ARM64""}],
     }","diff --git a/docs/using/recipe_code/generate_matrix.py b/docs/using/recipe_code/generate_matrix.py
index 417cdfb1..62159f30 100755
--- a/docs/using/recipe_code/generate_matrix.py
+++ b/docs/using/recipe_code/generate_matrix.py
@@ -12,8 +12,8 @@ def generate_matrix() -> dict[str, Any]:
     dockerfiles = sorted(file.name for file in THIS_DIR.glob(""*.dockerfile""))
     return {
         ""dockerfile"": dockerfiles,
-        ""runsOn"": [""ubuntu-latest"", ""ARM64""],
-        ""exclude"": [{""dockerfile"": ""oracledb.dockerfile"", ""runsOn"": ""ARM64""}],
+        ""runs-on"": [""ubuntu-latest"", ""ARM64""],
+        ""exclude"": [{""dockerfile"": ""oracledb.dockerfile"", ""runs-on"": ""ARM64""}],
     }",Yes
docs/using/running.md,docs/using/running.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/docs/using/running.md b/docs/using/running.md
index 7c0d7cd9..a9c354c0 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -140,7 +140,7 @@ subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Si
 
 This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
-The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
+The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
 podman run -it --rm -p 10000:8888 \
@@ -188,5 +188,5 @@ instructions for the [dockerspawner](https://github.com/jupyterhub/dockerspawner
 ## Using Other Tools and Services
 
 You can use the Jupyter Docker Stacks with any Docker-compatible technology
-(e.g., [Docker Compose](https://docs.docker.com/compose/), [docker-py](https://github.com/docker/docker-py), your favorite cloud container service).
+(e.g., [Docker Compose](https://docs.docker.com/compose/), [docker-py](https://github.com/docker/docker-py), or your favorite cloud container service).
 See the documentation of the tool, library, or service for details about how to reference, configure, and launch containers from these images.","diff --git a/docs/using/running.md b/docs/using/running.md
index 7c0d7cd9..a9c354c0 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -140,7 +140,7 @@ subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Si
 
 This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
-The server logs appear in the terminal and include a URL to the server, but with the internal container port (8888) instead of the correct host port (10000).
+The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
 podman run -it --rm -p 10000:8888 \
@@ -188,5 +188,5 @@ instructions for the [dockerspawner](https://github.com/jupyterhub/dockerspawner
 ## Using Other Tools and Services
 
 You can use the Jupyter Docker Stacks with any Docker-compatible technology
-(e.g., [Docker Compose](https://docs.docker.com/compose/), [docker-py](https://github.com/docker/docker-py), your favorite cloud container service).
+(e.g., [Docker Compose](https://docs.docker.com/compose/), [docker-py](https://github.com/docker/docker-py), or your favorite cloud container service).
 See the documentation of the tool, library, or service for details about how to reference, configure, and launch containers from these images.",Yes
docs/using/selecting.md,docs/using/selecting.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 82305b9e..861f106e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -257,7 +257,7 @@ Whenever a docker image is pushed to the container registry, it is tagged with:
 ```
 
 For stability and reproducibility, you should either reference a date formatted
-tag from a date before the current date (in UTC time) or a git commit SHA older
+tag from a date before the current date (in UTC) or a git commit SHA older
 than the latest git commit SHA in the default branch of the
 [jupyter/docker-stacks GitHub repository](https://github.com/jupyter/docker-stacks/).","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 82305b9e..861f106e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -257,7 +257,7 @@ Whenever a docker image is pushed to the container registry, it is tagged with:
 ```
 
 For stability and reproducibility, you should either reference a date formatted
-tag from a date before the current date (in UTC time) or a git commit SHA older
+tag from a date before the current date (in UTC) or a git commit SHA older
 than the latest git commit SHA in the default branch of the
 [jupyter/docker-stacks GitHub repository](https://github.com/jupyter/docker-stacks/).",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 74e8e088..70483c39 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -40,7 +40,7 @@ The following sections cover a few of these scenarios and how to fix them.
    You can change the ownership of the volume mount using the `chown` command.
    In the case of the docker-stacks images, you can set the `CHOWN_EXTRA` and `CHOWN_EXTRA_OPTS` environment variables.
 
-   For example, to change the ownership of the volume mount to the jovyan user (non-privileged default user in the Docker images):
+   For example, to change the ownership of the volume mount to the `jovyan` user (non-privileged default user in the Docker images):
 
    ```bash
    # running in detached mode - can also be run in interactive mode
@@ -128,7 +128,7 @@ The following sections cover a few of these scenarios and how to fix them.
 
 If you have also **created a new user**, you might be experiencing any of the following issues:
 
-- `root` is the owner of `/home` or a mounted volume
+- the `root` user is the owner of `/home` or a mounted volume
 - when starting the container, you get an error such as `Failed to change ownership of the home directory.`
 - getting permission denied when trying to `conda install` packages
 
@@ -277,7 +277,7 @@ You can install packages from other conda channels (e.g. `bioconda`) by disablin
 conda install --no-channel-priority -c bioconda bioconductor-geoquery
 ```
 
-Additional details are provided in the [Using alternative channels](../using/common.md#using-alternative-channels) section of the [Common features](common.md) page.
+Additional details are provided in the [Using Alternative Channels](../using/common.md#using-alternative-channels) section of the [Common Features](common.md) page.
 
 ## Tokens are being rejected
 
@@ -334,7 +334,7 @@ you might experience either of these issues when using any of the docker-stacks
    ```
 
    When the terminal provides the link to access Jupyter: <http://127.0.0.1:8888/lab?token=80d45d241a1ba4c2...>,
-   change the default port value of `8888` in the url to the port value mapped with the `docker run` command.
+   change the default port value of `8888` in the URL to the port value mapped with the `docker run` command.
 
    In this example, we use 8001, so the edited link would be: <http://127.0.0.1:8001/lab?token=80d45d241a1ba4c2...>.","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 74e8e088..70483c39 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -40,7 +40,7 @@ The following sections cover a few of these scenarios and how to fix them.
    You can change the ownership of the volume mount using the `chown` command.
    In the case of the docker-stacks images, you can set the `CHOWN_EXTRA` and `CHOWN_EXTRA_OPTS` environment variables.
 
-   For example, to change the ownership of the volume mount to the jovyan user (non-privileged default user in the Docker images):
+   For example, to change the ownership of the volume mount to the `jovyan` user (non-privileged default user in the Docker images):
 
    ```bash
    # running in detached mode - can also be run in interactive mode
@@ -128,7 +128,7 @@ The following sections cover a few of these scenarios and how to fix them.
 
 If you have also **created a new user**, you might be experiencing any of the following issues:
 
-- `root` is the owner of `/home` or a mounted volume
+- the `root` user is the owner of `/home` or a mounted volume
 - when starting the container, you get an error such as `Failed to change ownership of the home directory.`
 - getting permission denied when trying to `conda install` packages
 
@@ -277,7 +277,7 @@ You can install packages from other conda channels (e.g. `bioconda`) by disablin
 conda install --no-channel-priority -c bioconda bioconductor-geoquery
 ```
 
-Additional details are provided in the [Using alternative channels](../using/common.md#using-alternative-channels) section of the [Common features](common.md) page.
+Additional details are provided in the [Using Alternative Channels](../using/common.md#using-alternative-channels) section of the [Common Features](common.md) page.
 
 ## Tokens are being rejected
 
@@ -334,7 +334,7 @@ you might experience either of these issues when using any of the docker-stacks
    ```
 
    When the terminal provides the link to access Jupyter: <http://127.0.0.1:8888/lab?token=80d45d241a1ba4c2...>,
-   change the default port value of `8888` in the url to the port value mapped with the `docker run` command.
+   change the default port value of `8888` in the URL to the port value mapped with the `docker run` command.
 
    In this example, we use 8001, so the edited link would be: <http://127.0.0.1:8001/lab?token=80d45d241a1ba4c2...>.",Yes
tagging/README.md,tagging/README.md,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,71e66b2d57ae660f4c2259c5424192d3dbd99108,Fix some grammar issues,"diff --git a/tagging/README.md b/tagging/README.md
index 34c34af6..129f3d15 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -3,7 +3,7 @@
 The main purpose of the source code in this folder is to properly tag all the images and to update [build manifests](https://github.com/jupyter/docker-stacks/wiki).
 These two processes are closely related, so the source code is widely reused.
 
-A basic example of a tag is a `python` version tag.
+A basic example of a tag is a `Python` version tag.
 For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a full image name `quay.io/jupyter/base-notebook:python-3.10.5`.
 This tag (and all the other tags) are pushed to Quay.io.","diff --git a/tagging/README.md b/tagging/README.md
index 34c34af6..129f3d15 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -3,7 +3,7 @@
 The main purpose of the source code in this folder is to properly tag all the images and to update [build manifests](https://github.com/jupyter/docker-stacks/wiki).
 These two processes are closely related, so the source code is widely reused.
 
-A basic example of a tag is a `python` version tag.
+A basic example of a tag is a `Python` version tag.
 For example, an image `jupyter/base-notebook` with `python 3.10.5` will have a full image name `quay.io/jupyter/base-notebook:python-3.10.5`.
 This tag (and all the other tags) are pushed to Quay.io.",Yes
.flake8,.flake8,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/.flake8 b/.flake8
index 460421cf..a609f12d 100644
--- a/.flake8
+++ b/.flake8
@@ -1,4 +1,4 @@
 [flake8]
 max-line-length = 88
-select = C,E,F,W,B,B950
+select = C, E, F, W, B, B950
 extend-ignore = E203, E501, W503","diff --git a/.flake8 b/.flake8
index 460421cf..a609f12d 100644
--- a/.flake8
+++ b/.flake8
@@ -1,4 +1,4 @@
 [flake8]
 max-line-length = 88
-select = C,E,F,W,B,B950
+select = C, E, F, W, B, B950
 extend-ignore = E203, E501, W503",Yes
.github/ISSUE_TEMPLATE/feature_request.yml,.github/ISSUE_TEMPLATE/feature_request.yml,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index d0aff55d..0fd90c04 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -52,7 +52,7 @@ body:
         Example:
           - Altair is a declarative statistical visualization library for Python, based on Vega and Vega-Lite, and the source is available on GitHub.
           - With Altair, you can spend more time understanding your data and its meaning.
-          - Altair's API is simple, friendly and consistent and built on top of the powerful Vega-Lite visualization grammar.
+          - Altair's API is simple, friendly, and consistent and built on top of the powerful Vega-Lite visualization grammar.
           - This elegant simplicity produces beautiful and effective visualizations with a minimal amount of code.
     validations:
       required: true","diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index d0aff55d..0fd90c04 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -52,7 +52,7 @@ body:
         Example:
           - Altair is a declarative statistical visualization library for Python, based on Vega and Vega-Lite, and the source is available on GitHub.
           - With Altair, you can spend more time understanding your data and its meaning.
-          - Altair's API is simple, friendly and consistent and built on top of the powerful Vega-Lite visualization grammar.
+          - Altair's API is simple, friendly, and consistent and built on top of the powerful Vega-Lite visualization grammar.
           - This elegant simplicity produces beautiful and effective visualizations with a minimal amount of code.
     validations:
       required: true",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 36f56b21..ec22e7f3 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,4 +1,4 @@
-name: Download a Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
+name: Download a Docker image and its tags from GitHub artifacts, apply them, and push the image to the Registry
 
 env:
   REGISTRY: quay.io","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 36f56b21..ec22e7f3 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -1,4 +1,4 @@
-name: Download a Docker image and its tags from GitHub artifacts, apply them and push the image to the Registry
+name: Download a Docker image and its tags from GitHub artifacts, apply them, and push the image to the Registry
 
 env:
   REGISTRY: quay.io",Yes
Makefile,Makefile,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/Makefile b/Makefile
index 9d4ab710..d399ab10 100644
--- a/Makefile
+++ b/Makefile
@@ -102,7 +102,7 @@ push-all: $(foreach I, $(ALL_IMAGES), push/$(I)) ## push all tagged images
 
 run-shell/%: ## run a bash in interactive mode in a stack
 	docker run -it --rm ""$(REGISTRY)/$(OWNER)/$(notdir $@)"" $(SHELL)
-run-sudo-shell/%: ## run a bash in interactive mode as root in a stack
+run-sudo-shell/%: ## run bash in interactive mode as root in a stack
 	docker run -it --rm --user root ""$(REGISTRY)/$(OWNER)/$(notdir $@)"" $(SHELL)","diff --git a/Makefile b/Makefile
index 9d4ab710..d399ab10 100644
--- a/Makefile
+++ b/Makefile
@@ -102,7 +102,7 @@ push-all: $(foreach I, $(ALL_IMAGES), push/$(I)) ## push all tagged images
 
 run-shell/%: ## run a bash in interactive mode in a stack
 	docker run -it --rm ""$(REGISTRY)/$(OWNER)/$(notdir $@)"" $(SHELL)
-run-sudo-shell/%: ## run a bash in interactive mode as root in a stack
+run-sudo-shell/%: ## run bash in interactive mode as root in a stack
 	docker run -it --rm --user root ""$(REGISTRY)/$(OWNER)/$(notdir $@)"" $(SHELL)",Yes
README.md,README.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/README.md b/README.md
index 6103c1c9..5d4f1621 100644
--- a/README.md
+++ b/README.md
@@ -20,8 +20,7 @@ You can use a stack image to do any of the following (and more):
 You can try a [relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb)
 by simply clicking the preceding link.
 Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
-know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use
-and want to launch a single Jupyter Application in a container.
+know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use, and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.
 
@@ -44,8 +43,8 @@ You can modify the port on which the container's port is exposed by [changing th
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab,
 where:
 
-- `hostname` is the name of the computer running Docker
-- `token` is the secret token printed in the console.
+- The `hostname` is the name of the computer running Docker
+- The `token` is the secret token printed in the console.
 
 The container remains intact for restart after the Server exits.
 
@@ -127,6 +126,6 @@ for information about how to contribute recipes, features, tests, and community-
 - [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) -
   Turn git repositories into Jupyter-enabled Docker Images
 - [openshift/source-to-image](https://github.com/openshift/source-to-image) -
-  A tool for building artifacts from source and injecting them into docker images
+  A tool for building artifacts from source code and injecting them into docker images
 - [jupyter-on-openshift/jupyter-notebooks](https://github.com/jupyter-on-openshift/jupyter-notebooks) -
   OpenShift compatible S2I builder for basic notebook images","diff --git a/README.md b/README.md
index 6103c1c9..5d4f1621 100644
--- a/README.md
+++ b/README.md
@@ -20,8 +20,7 @@ You can use a stack image to do any of the following (and more):
 You can try a [relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb)
 by simply clicking the preceding link.
 Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
-know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use
-and want to launch a single Jupyter Application in a container.
+know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use, and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.
 
@@ -44,8 +43,8 @@ You can modify the port on which the container's port is exposed by [changing th
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab,
 where:
 
-- `hostname` is the name of the computer running Docker
-- `token` is the secret token printed in the console.
+- The `hostname` is the name of the computer running Docker
+- The `token` is the secret token printed in the console.
 
 The container remains intact for restart after the Server exits.
 
@@ -127,6 +126,6 @@ for information about how to contribute recipes, features, tests, and community-
 - [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) -
   Turn git repositories into Jupyter-enabled Docker Images
 - [openshift/source-to-image](https://github.com/openshift/source-to-image) -
-  A tool for building artifacts from source and injecting them into docker images
+  A tool for building artifacts from source code and injecting them into docker images
 - [jupyter-on-openshift/jupyter-notebooks](https://github.com/jupyter-on-openshift/jupyter-notebooks) -
   OpenShift compatible S2I builder for basic notebook images",Yes
docs/conf.py,docs/conf.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/conf.py b/docs/conf.py
index cacfe3d0..cb3f07f0 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -29,7 +29,7 @@ language = ""en""
 html_theme = ""alabaster""
 html_static_path = [""_static""]
 
-# File above was generated using sphinx 6.2.1 with this command:
+# The file above was generated using sphinx 6.2.1 with this command:
 # sphinx-quickstart --project ""docker-stacks"" --author ""Project Jupyter"" -v ""latest"" -r ""latest"" -l en --no-sep --no-makefile --no-batchfile
 # These are custom options for this project","diff --git a/docs/conf.py b/docs/conf.py
index cacfe3d0..cb3f07f0 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -29,7 +29,7 @@ language = ""en""
 html_theme = ""alabaster""
 html_static_path = [""_static""]
 
-# File above was generated using sphinx 6.2.1 with this command:
+# The file above was generated using sphinx 6.2.1 with this command:
 # sphinx-quickstart --project ""docker-stacks"" --author ""Project Jupyter"" -v ""latest"" -r ""latest"" -l en --no-sep --no-makefile --no-batchfile
 # These are custom options for this project",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index cfc52d0e..4f911fa2 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -100,12 +100,12 @@ you merge a GitHub pull request to the main branch of your project.
 2. Create a new repository - make sure to use the correct namespace (account or organization).
    Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
 
-   ![Docker Hub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
+   ![Docker Hub - 'Create repository' page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
 
 3. Enter a description for your image.
 4. Click on your avatar in the top-right corner and select Account Settings.
 
-   ![Docker Hub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-user-dropdown.png)
+   ![The Docker Hub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-user-dropdown.png)
 
 5. Click on **Security** and then click on the **New Access Token** button.","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index cfc52d0e..4f911fa2 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -100,12 +100,12 @@ you merge a GitHub pull request to the main branch of your project.
 2. Create a new repository - make sure to use the correct namespace (account or organization).
    Enter the name of the image matching the one you entered when prompted with `stack_name` by the cookiecutter.
 
-   ![Docker Hub - Create Repository page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
+   ![Docker Hub - 'Create repository' page with the name field set to ""My specialized jupyter stack""](../_static/contributing/stacks/docker-repo-name.png)
 
 3. Enter a description for your image.
 4. Click on your avatar in the top-right corner and select Account Settings.
 
-   ![Docker Hub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-user-dropdown.png)
+   ![The Docker Hub page zoomed into the user's settings and accounts menu](../_static/contributing/stacks/docker-user-dropdown.png)
 
 5. Click on **Security** and then click on the **New Access Token** button.",Yes
docs/contributing/tests.md,docs/contributing/tests.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/contributing/tests.md b/docs/contributing/tests.md
index f7fa5c6f..40278386 100644
--- a/docs/contributing/tests.md
+++ b/docs/contributing/tests.md
@@ -22,7 +22,7 @@ defined in the [conftest.py](https://github.com/jupyter/docker-stacks/blob/main/
 
 ## Unit tests
 
-You can add a unit test if you want to run a python script in one of our images.
+You can add a unit test if you want to run a Python script in one of our images.
 You should create a `tests/<somestack>/units/` directory, if it doesn't already exist, and put your file there.
 Files in this folder will be executed in the container when tests are run.
 You can see an [example for the TensorFlow package here](https://github.com/jupyter/docker-stacks/blob/HEAD/tests/tensorflow-notebook/units/unit_tensorflow.py).","diff --git a/docs/contributing/tests.md b/docs/contributing/tests.md
index f7fa5c6f..40278386 100644
--- a/docs/contributing/tests.md
+++ b/docs/contributing/tests.md
@@ -22,7 +22,7 @@ defined in the [conftest.py](https://github.com/jupyter/docker-stacks/blob/main/
 
 ## Unit tests
 
-You can add a unit test if you want to run a python script in one of our images.
+You can add a unit test if you want to run a Python script in one of our images.
 You should create a `tests/<somestack>/units/` directory, if it doesn't already exist, and put your file there.
 Files in this folder will be executed in the container when tests are run.
 You can see an [example for the TensorFlow package here](https://github.com/jupyter/docker-stacks/blob/HEAD/tests/tensorflow-notebook/units/unit_tensorflow.py).",Yes
docs/maintaining/new-images-and-packages-policy.md,docs/maintaining/new-images-and-packages-policy.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/maintaining/new-images-and-packages-policy.md b/docs/maintaining/new-images-and-packages-policy.md
index 637cf01e..ec297451 100644
--- a/docs/maintaining/new-images-and-packages-policy.md
+++ b/docs/maintaining/new-images-and-packages-policy.md
@@ -26,10 +26,10 @@ Here is a non-exhaustive list of things we do care about:
    - Does the package open additional ports, or add new web endpoints, that could be exploited?
 
 With all this in mind, we have a voting group, that consists of
-[mathbunnyru](https://github.com/mathbunnyru),
-[consideRatio](https://github.com/consideRatio),
-[yuvipanda](https://github.com/yuvipanda) and
-[manics](https://github.com/manics).
+[@mathbunnyru](https://github.com/mathbunnyru),
+[@consideRatio](https://github.com/consideRatio),
+[@yuvipanda](https://github.com/yuvipanda), and
+[@manics](https://github.com/manics).
 
 This voting group is responsible for accepting or declining new packages and stacks.
 The change is accepted, if there are **at least 2 positive votes**.","diff --git a/docs/maintaining/new-images-and-packages-policy.md b/docs/maintaining/new-images-and-packages-policy.md
index 637cf01e..ec297451 100644
--- a/docs/maintaining/new-images-and-packages-policy.md
+++ b/docs/maintaining/new-images-and-packages-policy.md
@@ -26,10 +26,10 @@ Here is a non-exhaustive list of things we do care about:
    - Does the package open additional ports, or add new web endpoints, that could be exploited?
 
 With all this in mind, we have a voting group, that consists of
-[mathbunnyru](https://github.com/mathbunnyru),
-[consideRatio](https://github.com/consideRatio),
-[yuvipanda](https://github.com/yuvipanda) and
-[manics](https://github.com/manics).
+[@mathbunnyru](https://github.com/mathbunnyru),
+[@consideRatio](https://github.com/consideRatio),
+[@yuvipanda](https://github.com/yuvipanda), and
+[@manics](https://github.com/manics).
 
 This voting group is responsible for accepting or declining new packages and stacks.
 The change is accepted, if there are **at least 2 positive votes**.",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index e909bdf8..ba2bca73 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -33,7 +33,7 @@ We are waiting for the first point release of the new LTS Ubuntu before updating
 Other images are directly or indirectly inherited from `docker-stacks-foundation`.
 We rebuild our images automatically each week, which means they frequently receive updates.
 
-When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger images rebuild
+When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger the rebuild of images
 [from the GitHub actions workflow UI](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml).
 Pushing the `Run Workflow` button will trigger this process.","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index e909bdf8..ba2bca73 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -33,7 +33,7 @@ We are waiting for the first point release of the new LTS Ubuntu before updating
 Other images are directly or indirectly inherited from `docker-stacks-foundation`.
 We rebuild our images automatically each week, which means they frequently receive updates.
 
-When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger images rebuild
+When there's a security fix in the Ubuntu base image, it's a good idea to manually trigger the rebuild of images
 [from the GitHub actions workflow UI](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml).
 Pushing the `Run Workflow` button will trigger this process.",Yes
docs/using/common.md,docs/using/common.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/using/common.md b/docs/using/common.md
index c51dd512..f1730553 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -233,7 +233,7 @@ This script is handy when you derive a new Dockerfile from this image and instal
 ### Others
 
 You can bypass the provided scripts and specify an arbitrary start command.
-If you do, keep in mind that features supported by the `start.sh` script and its kin will not function (e.g., `GRANT_SUDO`).
+If you do, keep in mind that features, supported by the `start.sh` script and its kin, will not function (e.g., `GRANT_SUDO`).
 
 ## Conda Environments","diff --git a/docs/using/common.md b/docs/using/common.md
index c51dd512..f1730553 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -233,7 +233,7 @@ This script is handy when you derive a new Dockerfile from this image and instal
 ### Others
 
 You can bypass the provided scripts and specify an arbitrary start command.
-If you do, keep in mind that features supported by the `start.sh` script and its kin will not function (e.g., `GRANT_SUDO`).
+If you do, keep in mind that features, supported by the `start.sh` script and its kin, will not function (e.g., `GRANT_SUDO`).
 
 ## Conda Environments",Yes
docs/using/recipe_code/custom_environment.dockerfile,docs/using/recipe_code/custom_environment.dockerfile,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 4a63cfaf..e53c9690 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,6 +1,6 @@
 FROM quay.io/jupyter/base-notebook
 
-# Name your environment and choose the python version
+# Name your environment and choose the Python version
 ARG env_name=python310
 ARG py_ver=3.10
 
@@ -40,5 +40,5 @@ RUN activate_custom_env_script=/usr/local/bin/before-notebook.d/activate_custom_
 USER ${NB_UID}
 
 # Making this environment default in Terminal
-# You can comment this line to keep the default environment in Terminal
+# You can comment this line to keep the default environment in a Terminal
 RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 4a63cfaf..e53c9690 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,6 +1,6 @@
 FROM quay.io/jupyter/base-notebook
 
-# Name your environment and choose the python version
+# Name your environment and choose the Python version
 ARG env_name=python310
 ARG py_ver=3.10
 
@@ -40,5 +40,5 @@ RUN activate_custom_env_script=/usr/local/bin/before-notebook.d/activate_custom_
 USER ${NB_UID}
 
 # Making this environment default in Terminal
-# You can comment this line to keep the default environment in Terminal
+# You can comment this line to keep the default environment in a Terminal
 RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index ff2e437d..d0daa901 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -15,7 +15,7 @@ ARG INSTANTCLIENT_MAJOR_VERSION=21
 ARG INSTANTCLIENT_VERSION=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1
 ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2111000
 
-# Then install Oracle SQL Instant client, SQL+Plus, tools and JDBC.
+# Then install Oracle SQL Instant client, SQL+Plus, tools, and JDBC.
 # Note: You may need to change the URL to a newer version.
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
 RUN mkdir ""/opt/oracle""
@@ -39,7 +39,7 @@ RUN echo ""ORACLE_HOME=/usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64"" >
     echo ""export PATH"" >> ""${HOME}/.bashrc"" && \
     echo ""export LD_LIBRARY_PATH"" >> ""${HOME}/.bashrc""
 
-# Add credentials for /redacted/ using Oracle Db.
+# Add credentials for /redacted/ using Oracle DB.
 WORKDIR /usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64/lib/network/admin/
 # Add a wildcard `[]` on the last letter of the filename to avoid throwing an error if the file does not exist.
 # See: https://stackoverflow.com/questions/31528384/conditional-copy-add-in-dockerfile","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index ff2e437d..d0daa901 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -15,7 +15,7 @@ ARG INSTANTCLIENT_MAJOR_VERSION=21
 ARG INSTANTCLIENT_VERSION=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1
 ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2111000
 
-# Then install Oracle SQL Instant client, SQL+Plus, tools and JDBC.
+# Then install Oracle SQL Instant client, SQL+Plus, tools, and JDBC.
 # Note: You may need to change the URL to a newer version.
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
 RUN mkdir ""/opt/oracle""
@@ -39,7 +39,7 @@ RUN echo ""ORACLE_HOME=/usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64"" >
     echo ""export PATH"" >> ""${HOME}/.bashrc"" && \
     echo ""export LD_LIBRARY_PATH"" >> ""${HOME}/.bashrc""
 
-# Add credentials for /redacted/ using Oracle Db.
+# Add credentials for /redacted/ using Oracle DB.
 WORKDIR /usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64/lib/network/admin/
 # Add a wildcard `[]` on the last letter of the filename to avoid throwing an error if the file does not exist.
 # See: https://stackoverflow.com/questions/31528384/conditional-copy-add-in-dockerfile",Yes
docs/using/recipes.md,docs/using/recipes.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 52eb60b1..39d2ab25 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -132,7 +132,7 @@ Sometimes it is helpful to run the Jupyter instance behind an nginx proxy, for e
   and want nginx to help improve server performance in managing the connections
 
 Here is a [quick example of NGINX configuration](https://gist.github.com/cboettig/8643341bd3c93b62b5c2) to get started.
-You'll need a server, a `.crt` and `.key` file for your server, and `docker` & `docker-compose` installed.
+You'll need a server, a `.crt`, and a `.key` file for your server, and `docker` & `docker-compose` installed.
 Then download the files at that gist and run `docker-compose up` to test it out.
 Customize the `nginx.conf` file to set the desired paths and add other services.
 
@@ -506,9 +506,9 @@ The following recipe demonstrates how to add functionality to read from and writ
 
 You can now use `pyodbc` and `sqlalchemy` to interact with the database.
 
-Pre-built images are hosted in the [realiserad/jupyter-docker-mssql](https://github.com/Realiserad/jupyter-docker-mssql) repository.
+Pre-built images are hosted in the [Realiserad/jupyter-docker-mssql](https://github.com/Realiserad/jupyter-docker-mssql) repository.
 
-## Add Oracle SQL Instant client, SQL\*Plus and other tools (Version 21.x)
+## Add Oracle SQL Instant client, SQL\*Plus, and other tools (Version 21.x)
 
 ```{note}
 This recipe only works for x86_64 architecture.
@@ -520,7 +520,7 @@ This recipe installs version `21.11.0.0.0`.
 
 Nonetheless, go to the [Oracle Instant Client Download page](https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html) for the complete list of versions available.
 You may need to perform different steps for older versions;
-the may be explained on the ""Installation instructions"" section of the Downloads page.
+they may be explained in the ""Installation instructions"" section of the Downloads page.
 
 ```{literalinclude} recipe_code/oracledb.dockerfile
 :language: docker","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 52eb60b1..39d2ab25 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -132,7 +132,7 @@ Sometimes it is helpful to run the Jupyter instance behind an nginx proxy, for e
   and want nginx to help improve server performance in managing the connections
 
 Here is a [quick example of NGINX configuration](https://gist.github.com/cboettig/8643341bd3c93b62b5c2) to get started.
-You'll need a server, a `.crt` and `.key` file for your server, and `docker` & `docker-compose` installed.
+You'll need a server, a `.crt`, and a `.key` file for your server, and `docker` & `docker-compose` installed.
 Then download the files at that gist and run `docker-compose up` to test it out.
 Customize the `nginx.conf` file to set the desired paths and add other services.
 
@@ -506,9 +506,9 @@ The following recipe demonstrates how to add functionality to read from and writ
 
 You can now use `pyodbc` and `sqlalchemy` to interact with the database.
 
-Pre-built images are hosted in the [realiserad/jupyter-docker-mssql](https://github.com/Realiserad/jupyter-docker-mssql) repository.
+Pre-built images are hosted in the [Realiserad/jupyter-docker-mssql](https://github.com/Realiserad/jupyter-docker-mssql) repository.
 
-## Add Oracle SQL Instant client, SQL\*Plus and other tools (Version 21.x)
+## Add Oracle SQL Instant client, SQL\*Plus, and other tools (Version 21.x)
 
 ```{note}
 This recipe only works for x86_64 architecture.
@@ -520,7 +520,7 @@ This recipe installs version `21.11.0.0.0`.
 
 Nonetheless, go to the [Oracle Instant Client Download page](https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html) for the complete list of versions available.
 You may need to perform different steps for older versions;
-the may be explained on the ""Installation instructions"" section of the Downloads page.
+they may be explained in the ""Installation instructions"" section of the Downloads page.
 
 ```{literalinclude} recipe_code/oracledb.dockerfile
 :language: docker",Yes
docs/using/running.md,docs/using/running.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/using/running.md b/docs/using/running.md
index a9c354c0..3b8938c2 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -170,11 +170,11 @@ Any other changes made in the container will be lost.
 
 ## Using Binder
 
-[Binder](https://mybinder.org/) is a service that allows you to create and share custom computing environments for projects in version control.
+A [Binder](https://mybinder.org/) is a service that allows you to create and share custom computing environments for projects in version control.
 You can use any of the Jupyter Docker Stacks images as a basis for a Binder-compatible Dockerfile.
 See the
 [docker-stacks example](https://mybinder.readthedocs.io/en/latest/examples/sample_repos.html#using-a-docker-image-from-the-jupyter-docker-stacks-repository) and
-[Using a Dockerfile](https://mybinder.readthedocs.io/en/latest/tutorials/dockerfile.html) sections in the
+[Using a Dockerfile](https://mybinder.readthedocs.io/en/latest/tutorials/dockerfile.html) section in the
 [Binder documentation](https://mybinder.readthedocs.io/en/latest/index.html) for instructions.
 
 ## Using JupyterHub","diff --git a/docs/using/running.md b/docs/using/running.md
index a9c354c0..3b8938c2 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -170,11 +170,11 @@ Any other changes made in the container will be lost.
 
 ## Using Binder
 
-[Binder](https://mybinder.org/) is a service that allows you to create and share custom computing environments for projects in version control.
+A [Binder](https://mybinder.org/) is a service that allows you to create and share custom computing environments for projects in version control.
 You can use any of the Jupyter Docker Stacks images as a basis for a Binder-compatible Dockerfile.
 See the
 [docker-stacks example](https://mybinder.readthedocs.io/en/latest/examples/sample_repos.html#using-a-docker-image-from-the-jupyter-docker-stacks-repository) and
-[Using a Dockerfile](https://mybinder.readthedocs.io/en/latest/tutorials/dockerfile.html) sections in the
+[Using a Dockerfile](https://mybinder.readthedocs.io/en/latest/tutorials/dockerfile.html) section in the
 [Binder documentation](https://mybinder.readthedocs.io/en/latest/index.html) for instructions.
 
 ## Using JupyterHub",Yes
docs/using/specifics.md,docs/using/specifics.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 3510674d..f0ede8f4 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -14,7 +14,7 @@ This page provides details about features specific to one or more images.
   Every new spark context that is created is put onto an incrementing port (i.e. 4040, 4041, 4042, etc.), and it might be necessary to open multiple ports.
   ```
 
-  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 quay.io/jupyter/pyspark-notebook`.
+  For example, `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 quay.io/jupyter/pyspark-notebook`.
 
 #### IPython low-level output capture and forward
 
@@ -53,7 +53,7 @@ You can build a `pyspark-notebook` image with a different `Spark` version by ove
     - This version needs to match the version supported by the Spark distribution used above.
     - See [Spark Overview](https://spark.apache.org/docs/latest/#downloading) and [Ubuntu packages](https://packages.ubuntu.com/search?keywords=openjdk).
 
-- Starting with _Spark >= 3.2_, the distribution file might contain Scala version.
+- Starting with _Spark >= 3.2_, the distribution file might contain the Scala version.
 
 For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2`, and OpenJDK `11`.
 
@@ -161,7 +161,7 @@ Connection to Spark Cluster on **[Standalone Mode](https://spark.apache.org/docs
 0. Verify that the docker image (check the Dockerfile) and the Spark Cluster, which is being
    deployed, run the same version of Spark.
 1. [Deploy Spark in Standalone Mode](https://spark.apache.org/docs/latest/spark-standalone.html).
-2. Run the Docker container with `--net=host` in a location that is network addressable by all of
+2. Run the Docker container with `--net=host` in a location that is network-addressable by all of
    your Spark workers.
    (This is a [Spark networking requirement](https://spark.apache.org/docs/latest/cluster-overview.html#components).)
 
@@ -174,7 +174,7 @@ Connection to Spark Cluster on **[Standalone Mode](https://spark.apache.org/docs
 ##### Standalone Mode in Python
 
 The **same Python version** needs to be used on the notebook (where the driver is located) and on the Spark workers.
-The python version used at the driver and worker side can be adjusted by setting the environment variables `PYSPARK_PYTHON` and/or `PYSPARK_DRIVER_PYTHON`,
+The Python version used on the driver and worker side can be adjusted by setting the environment variables `PYSPARK_PYTHON` and/or `PYSPARK_DRIVER_PYTHON`,
 see [Spark Configuration][spark-conf] for more information.
 
 ```python","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 3510674d..f0ede8f4 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -14,7 +14,7 @@ This page provides details about features specific to one or more images.
   Every new spark context that is created is put onto an incrementing port (i.e. 4040, 4041, 4042, etc.), and it might be necessary to open multiple ports.
   ```
 
-  For example: `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 quay.io/jupyter/pyspark-notebook`.
+  For example, `docker run --detach -p 8888:8888 -p 4040:4040 -p 4041:4041 quay.io/jupyter/pyspark-notebook`.
 
 #### IPython low-level output capture and forward
 
@@ -53,7 +53,7 @@ You can build a `pyspark-notebook` image with a different `Spark` version by ove
     - This version needs to match the version supported by the Spark distribution used above.
     - See [Spark Overview](https://spark.apache.org/docs/latest/#downloading) and [Ubuntu packages](https://packages.ubuntu.com/search?keywords=openjdk).
 
-- Starting with _Spark >= 3.2_, the distribution file might contain Scala version.
+- Starting with _Spark >= 3.2_, the distribution file might contain the Scala version.
 
 For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2`, and OpenJDK `11`.
 
@@ -161,7 +161,7 @@ Connection to Spark Cluster on **[Standalone Mode](https://spark.apache.org/docs
 0. Verify that the docker image (check the Dockerfile) and the Spark Cluster, which is being
    deployed, run the same version of Spark.
 1. [Deploy Spark in Standalone Mode](https://spark.apache.org/docs/latest/spark-standalone.html).
-2. Run the Docker container with `--net=host` in a location that is network addressable by all of
+2. Run the Docker container with `--net=host` in a location that is network-addressable by all of
    your Spark workers.
    (This is a [Spark networking requirement](https://spark.apache.org/docs/latest/cluster-overview.html#components).)
 
@@ -174,7 +174,7 @@ Connection to Spark Cluster on **[Standalone Mode](https://spark.apache.org/docs
 ##### Standalone Mode in Python
 
 The **same Python version** needs to be used on the notebook (where the driver is located) and on the Spark workers.
-The python version used at the driver and worker side can be adjusted by setting the environment variables `PYSPARK_PYTHON` and/or `PYSPARK_DRIVER_PYTHON`,
+The Python version used on the driver and worker side can be adjusted by setting the environment variables `PYSPARK_PYTHON` and/or `PYSPARK_DRIVER_PYTHON`,
 see [Spark Configuration][spark-conf] for more information.
 
 ```python",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 3ac6a8cd..545e2db1 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -13,17 +13,17 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for Server that starts but lacks all
+# Install all OS dependencies for the Server that starts but lacks all
 # features (e.g., download as all possible file formats)
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     fonts-liberation \
     # - pandoc is used to convert notebooks to html files
-    #   it's not present in aarch64 ubuntu image, so we install it here
+    #   it's not present in the aarch64 Ubuntu image, so we install it here
     pandoc \
     # - run-one - a wrapper script that runs no more
     #   than one unique  instance  of  some  command with a unique set of arguments,
-    #   we use `run-one-constantly` to support `RESTARTABLE` option
+    #   we use `run-one-constantly` to support the `RESTARTABLE` option
     run-one && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
@@ -64,7 +64,7 @@ USER root
 RUN fix-permissions /etc/jupyter/
 
 # HEALTHCHECK documentation: https://docs.docker.com/engine/reference/builder/#healthcheck
-# This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server` and `retro` jupyter commands
+# This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server`, and `retro` jupyter commands
 # https://github.com/jupyter/docker-stacks/issues/915#issuecomment-1068528799
 HEALTHCHECK --interval=5s --timeout=3s --start-period=5s --retries=3 \
     CMD /etc/jupyter/docker_healthcheck.py || exit 1","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 3ac6a8cd..545e2db1 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -13,17 +13,17 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for Server that starts but lacks all
+# Install all OS dependencies for the Server that starts but lacks all
 # features (e.g., download as all possible file formats)
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     fonts-liberation \
     # - pandoc is used to convert notebooks to html files
-    #   it's not present in aarch64 ubuntu image, so we install it here
+    #   it's not present in the aarch64 Ubuntu image, so we install it here
     pandoc \
     # - run-one - a wrapper script that runs no more
     #   than one unique  instance  of  some  command with a unique set of arguments,
-    #   we use `run-one-constantly` to support `RESTARTABLE` option
+    #   we use `run-one-constantly` to support the `RESTARTABLE` option
     run-one && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
@@ -64,7 +64,7 @@ USER root
 RUN fix-permissions /etc/jupyter/
 
 # HEALTHCHECK documentation: https://docs.docker.com/engine/reference/builder/#healthcheck
-# This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server` and `retro` jupyter commands
+# This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server`, and `retro` jupyter commands
 # https://github.com/jupyter/docker-stacks/issues/915#issuecomment-1068528799
 HEALTHCHECK --interval=5s --timeout=3s --start-period=5s --retries=3 \
     CMD /etc/jupyter/docker_healthcheck.py || exit 1",Yes
images/base-notebook/docker_healthcheck.py,images/base-notebook/docker_healthcheck.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/base-notebook/docker_healthcheck.py b/images/base-notebook/docker_healthcheck.py
index 41bbc785..8f3338e8 100755
--- a/images/base-notebook/docker_healthcheck.py
+++ b/images/base-notebook/docker_healthcheck.py
@@ -7,7 +7,7 @@ from pathlib import Path
 
 import requests
 
-# A number of operations below deliberately don't check for possible errors
+# Several operations below deliberately don't check for possible errors
 # As this is a healthcheck, it should succeed or raise an exception on error
 
 runtime_dir = Path(""/home/"") / os.environ[""NB_USER""] / "".local/share/jupyter/runtime/""","diff --git a/images/base-notebook/docker_healthcheck.py b/images/base-notebook/docker_healthcheck.py
index 41bbc785..8f3338e8 100755
--- a/images/base-notebook/docker_healthcheck.py
+++ b/images/base-notebook/docker_healthcheck.py
@@ -7,7 +7,7 @@ from pathlib import Path
 
 import requests
 
-# A number of operations below deliberately don't check for possible errors
+# Several operations below deliberately don't check for possible errors
 # As this is a healthcheck, it should succeed or raise an exception on error
 
 runtime_dir = Path(""/home/"") / os.environ[""NB_USER""] / "".local/share/jupyter/runtime/""",Yes
images/base-notebook/jupyter_server_config.py,images/base-notebook/jupyter_server_config.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/base-notebook/jupyter_server_config.py b/images/base-notebook/jupyter_server_config.py
index 5c13308a..c0cca3af 100644
--- a/images/base-notebook/jupyter_server_config.py
+++ b/images/base-notebook/jupyter_server_config.py
@@ -34,7 +34,7 @@ if ""GEN_CERT"" in os.environ:
     if not cnf_file.exists():
         cnf_file.write_text(OPENSSL_CONFIG)
 
-    # Generate a certificate if one doesn't exist on disk
+    # Generate a certificate if one doesn't exist on a disk
     subprocess.check_call(
         [
             ""openssl"",","diff --git a/images/base-notebook/jupyter_server_config.py b/images/base-notebook/jupyter_server_config.py
index 5c13308a..c0cca3af 100644
--- a/images/base-notebook/jupyter_server_config.py
+++ b/images/base-notebook/jupyter_server_config.py
@@ -34,7 +34,7 @@ if ""GEN_CERT"" in os.environ:
     if not cnf_file.exists():
         cnf_file.write_text(OPENSSL_CONFIG)
 
-    # Generate a certificate if one doesn't exist on disk
+    # Generate a certificate if one doesn't exist on a disk
     subprocess.check_call(
         [
             ""openssl"",",Yes
images/base-notebook/start-notebook.py,images/base-notebook/start-notebook.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
index db1efc24..b99ff315 100755
--- a/images/base-notebook/start-notebook.py
+++ b/images/base-notebook/start-notebook.py
@@ -34,7 +34,7 @@ command.append(jupyter_command)
 if ""NOTEBOOK_ARGS"" in os.environ:
     command += shlex.split(os.environ[""NOTEBOOK_ARGS""])
 
-# Pass through any other args we were passed on the commandline
+# Pass through any other args we were passed on the command line
 command += sys.argv[1:]
 
 # Execute the command!","diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
index db1efc24..b99ff315 100755
--- a/images/base-notebook/start-notebook.py
+++ b/images/base-notebook/start-notebook.py
@@ -34,7 +34,7 @@ command.append(jupyter_command)
 if ""NOTEBOOK_ARGS"" in os.environ:
     command += shlex.split(os.environ[""NOTEBOOK_ARGS""])
 
-# Pass through any other args we were passed on the commandline
+# Pass through any other args we were passed on the command line
 command += sys.argv[1:]
 
 # Execute the command!",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 5fbcd86c..2c557854 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -18,12 +18,12 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for Server that starts
+# Install all OS dependencies for the Server that starts
 # but lacks all features (e.g., download as all possible file formats)
 ENV DEBIAN_FRONTEND noninteractive
 RUN apt-get update --yes && \
-    # - apt-get upgrade is run to patch known vulnerabilities in apt-get packages as
-    #   the ubuntu base image is rebuilt too seldom sometimes (less than once a month)
+    # - `apt-get upgrade` is run to patch known vulnerabilities in apt-get packages as
+    #   the Ubuntu base image is rebuilt too seldom sometimes (less than once a month)
     apt-get upgrade --yes && \
     apt-get install --yes --no-install-recommends \
     # - bzip2 is necessary to extract the micromamba executable.
@@ -76,19 +76,19 @@ RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
 
 USER ${NB_UID}
 
-# Pin python version here, or set it to ""default""
+# Pin Python version here, or set it to ""default""
 ARG PYTHON_VERSION=3.11
 
 # Setup work directory for backward-compatibility
 RUN mkdir ""/home/${NB_USER}/work"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Download and install Micromamba, and initialize Conda prefix.
+# Download and install Micromamba, and initialize the Conda prefix.
 #   <https://github.com/mamba-org/mamba#micromamba>
 #   Similar projects using Micromamba:
 #     - Micromamba-Docker: <https://github.com/mamba-org/micromamba-docker>
 #     - repo2docker: <https://github.com/jupyterhub/repo2docker>
-# Install Python, Mamba and jupyter_core
+# Install Python, Mamba, and jupyter_core
 # Cleanup temporary files and remove Micromamba
 # Correct permissions
 # Do all this in a single RUN command to avoid duplicating all of the","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 5fbcd86c..2c557854 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -18,12 +18,12 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for Server that starts
+# Install all OS dependencies for the Server that starts
 # but lacks all features (e.g., download as all possible file formats)
 ENV DEBIAN_FRONTEND noninteractive
 RUN apt-get update --yes && \
-    # - apt-get upgrade is run to patch known vulnerabilities in apt-get packages as
-    #   the ubuntu base image is rebuilt too seldom sometimes (less than once a month)
+    # - `apt-get upgrade` is run to patch known vulnerabilities in apt-get packages as
+    #   the Ubuntu base image is rebuilt too seldom sometimes (less than once a month)
     apt-get upgrade --yes && \
     apt-get install --yes --no-install-recommends \
     # - bzip2 is necessary to extract the micromamba executable.
@@ -76,19 +76,19 @@ RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
 
 USER ${NB_UID}
 
-# Pin python version here, or set it to ""default""
+# Pin Python version here, or set it to ""default""
 ARG PYTHON_VERSION=3.11
 
 # Setup work directory for backward-compatibility
 RUN mkdir ""/home/${NB_USER}/work"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Download and install Micromamba, and initialize Conda prefix.
+# Download and install Micromamba, and initialize the Conda prefix.
 #   <https://github.com/mamba-org/mamba#micromamba>
 #   Similar projects using Micromamba:
 #     - Micromamba-Docker: <https://github.com/mamba-org/micromamba-docker>
 #     - repo2docker: <https://github.com/jupyterhub/repo2docker>
-# Install Python, Mamba and jupyter_core
+# Install Python, Mamba, and jupyter_core
 # Cleanup temporary files and remove Micromamba
 # Correct permissions
 # Do all this in a single RUN command to avoid duplicating all of the",Yes
images/docker-stacks-foundation/fix-permissions,images/docker-stacks-foundation/fix-permissions,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/docker-stacks-foundation/fix-permissions b/images/docker-stacks-foundation/fix-permissions
index d167578b..47b6d0e2 100755
--- a/images/docker-stacks-foundation/fix-permissions
+++ b/images/docker-stacks-foundation/fix-permissions
@@ -1,16 +1,14 @@
 #!/bin/bash
-# set permissions on a directory
-# after any installation, if a directory needs to be (human) user-writable,
-# run this script on it.
-# It will make everything in the directory owned by the group ${NB_GID}
-# and writable by that group.
+# Set permissions on a directory
+# After any installation, if a directory needs to be (human) user-writable, run this script on it.
+# It will make everything in the directory owned by the group ${NB_GID} and writable by that group.
 # Deployments that want to set a specific user id can preserve permissions
 # by adding the `--group-add users` line to `docker run`.
 
-# uses find to avoid touching files that already have the right permissions,
-# which would cause massive image explosion
+# Uses find to avoid touching files that already have the right permissions,
+# which would cause a massive image explosion
 
-# right permissions are:
+# Right permissions are:
 # group=${NB_GID}
 # AND permissions include group rwX (directory-execute)
 # AND directories have setuid,setgid bits set","diff --git a/images/docker-stacks-foundation/fix-permissions b/images/docker-stacks-foundation/fix-permissions
index d167578b..47b6d0e2 100755
--- a/images/docker-stacks-foundation/fix-permissions
+++ b/images/docker-stacks-foundation/fix-permissions
@@ -1,16 +1,14 @@
 #!/bin/bash
-# set permissions on a directory
-# after any installation, if a directory needs to be (human) user-writable,
-# run this script on it.
-# It will make everything in the directory owned by the group ${NB_GID}
-# and writable by that group.
+# Set permissions on a directory
+# After any installation, if a directory needs to be (human) user-writable, run this script on it.
+# It will make everything in the directory owned by the group ${NB_GID} and writable by that group.
 # Deployments that want to set a specific user id can preserve permissions
 # by adding the `--group-add users` line to `docker run`.
 
-# uses find to avoid touching files that already have the right permissions,
-# which would cause massive image explosion
+# Uses find to avoid touching files that already have the right permissions,
+# which would cause a massive image explosion
 
-# right permissions are:
+# Right permissions are:
 # group=${NB_GID}
 # AND permissions include group rwX (directory-execute)
 # AND directories have setuid,setgid bits set",Yes
images/docker-stacks-foundation/run-hooks.sh,images/docker-stacks-foundation/run-hooks.sh,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/docker-stacks-foundation/run-hooks.sh b/images/docker-stacks-foundation/run-hooks.sh
index d5dc28ea..18a801a6 100755
--- a/images/docker-stacks-foundation/run-hooks.sh
+++ b/images/docker-stacks-foundation/run-hooks.sh
@@ -10,7 +10,7 @@ if [ ""$#"" -ne 1 ]; then
     return 1
 fi
 
-if [[ ! -d ""${1}"" ]] ; then
+if [[ ! -d ""${1}"" ]]; then
     echo ""Directory ${1} doesn't exist or is not a directory""
     return 1
 fi
@@ -25,16 +25,16 @@ for f in ""${1}/""*; do
             # shellcheck disable=SC1090
             source ""${f}""
             # shellcheck disable=SC2181
-            if [ $? -ne 0 ] ; then
+            if [ $? -ne 0 ]; then
                 echo ""${f} has failed, continuing execution""
             fi
             ;;
         *)
-            if [ -x ""${f}"" ] ; then
+            if [ -x ""${f}"" ]; then
                 echo ""Running executable: ${f}""
                 ""${f}""
                 # shellcheck disable=SC2181
-                if [ $? -ne 0 ] ; then
+                if [ $? -ne 0 ]; then
                     echo ""${f} has failed, continuing execution""
                 fi
             else","diff --git a/images/docker-stacks-foundation/run-hooks.sh b/images/docker-stacks-foundation/run-hooks.sh
index d5dc28ea..18a801a6 100755
--- a/images/docker-stacks-foundation/run-hooks.sh
+++ b/images/docker-stacks-foundation/run-hooks.sh
@@ -10,7 +10,7 @@ if [ ""$#"" -ne 1 ]; then
     return 1
 fi
 
-if [[ ! -d ""${1}"" ]] ; then
+if [[ ! -d ""${1}"" ]]; then
     echo ""Directory ${1} doesn't exist or is not a directory""
     return 1
 fi
@@ -25,16 +25,16 @@ for f in ""${1}/""*; do
             # shellcheck disable=SC1090
             source ""${f}""
             # shellcheck disable=SC2181
-            if [ $? -ne 0 ] ; then
+            if [ $? -ne 0 ]; then
                 echo ""${f} has failed, continuing execution""
             fi
             ;;
         *)
-            if [ -x ""${f}"" ] ; then
+            if [ -x ""${f}"" ]; then
                 echo ""Running executable: ${f}""
                 ""${f}""
                 # shellcheck disable=SC2181
-                if [ $? -ne 0 ] ; then
+                if [ $? -ne 0 ]; then
                     echo ""${f} has failed, continuing execution""
                 fi
             else",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index ac4f02da..f35bc7d5 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -43,7 +43,7 @@ source /usr/local/bin/run-hooks.sh /usr/local/bin/start-notebook.d
 # things before we run the command passed to start.sh as the desired user
 # (NB_USER).
 #
-if [ ""$(id -u)"" == 0 ] ; then
+if [ ""$(id -u)"" == 0 ]; then
     # Environment variables:
     # - NB_USER: the desired username and associated home folder
     # - NB_UID: the desired user id
@@ -51,11 +51,11 @@ if [ ""$(id -u)"" == 0 ] ; then
     # - NB_GROUP: a group name we want for the group
     # - GRANT_SUDO: a boolean (""1"" or ""yes"") to grant the user sudo rights
     # - CHOWN_HOME: a boolean (""1"" or ""yes"") to chown the user's home folder
-    # - CHOWN_EXTRA: a comma separated list of paths to chown
+    # - CHOWN_EXTRA: a comma-separated list of paths to chown
     # - CHOWN_HOME_OPTS / CHOWN_EXTRA_OPTS: arguments to the chown commands
 
-    # Refit the jovyan user to the desired the user (NB_USER)
-    if id jovyan &> /dev/null ; then
+    # Refit the jovyan user to the desired user (NB_USER)
+    if id jovyan &> /dev/null; then
         if ! usermod --home ""/home/${NB_USER}"" --login ""${NB_USER}"" jovyan 2>&1 | grep ""no changes"" > /dev/null; then
             _log ""Updated the jovyan user:""
             _log ""- username: jovyan       -> ${NB_USER}""
@@ -78,7 +78,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         useradd --no-log-init --home ""/home/${NB_USER}"" --shell /bin/bash --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
     fi
 
-    # Move or symlink the jovyan home directory to the desired users home
+    # Move or symlink the jovyan home directory to the desired user's home
     # directory if it doesn't already exist, and update the current working
     # directory to the new location if needed.
     if [[ ""${NB_USER}"" != ""jovyan"" ]]; then
@@ -106,7 +106,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         fi
     fi
 
-    # Optionally ensure the desired user get filesystem ownership of it's home
+    # Optionally ensure the desired user gets filesystem ownership of its home
     # folder and/or additional folders
     if [[ ""${CHOWN_HOME}"" == ""1"" || ""${CHOWN_HOME}"" == ""yes"" ]]; then
         _log ""Ensuring /home/${NB_USER} is owned by ${NB_UID}:${NB_GID} ${CHOWN_HOME_OPTS:+(chown options: ${CHOWN_HOME_OPTS})}""
@@ -121,7 +121,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         done
     fi
 
-    # Update potentially outdated environment variables since image build
+    # Update potentially outdated environment variables since the image build
     export XDG_CACHE_HOME=""/home/${NB_USER}/.cache""
 
     # Prepend ${CONDA_DIR}/bin to sudo secure_path
@@ -163,7 +163,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         # - We use the `--set-home` flag to set the HOME variable appropriately.
         #
         # - To reduce the default list of variables deleted by sudo, we could have
-        #   used `env_delete` from /etc/sudoers. It has higher priority than the
+        #   used `env_delete` from /etc/sudoers. It has a higher priority than the
         #   `--preserve-env` flag and the `env_keep` configuration.
         #
         # - We preserve LD_LIBRARY_PATH, PATH and PYTHONPATH explicitly. Note however that sudo
@@ -186,7 +186,7 @@ else
     # Attempt to ensure the user uid we currently run as has a named entry in
     # the /etc/passwd file, as it avoids software crashing on hard assumptions
     # on such entry. Writing to the /etc/passwd was allowed for the root group
-    # from the Dockerfile during build.
+    # from the Dockerfile during the build.
     #
     # ref: https://github.com/jupyter/docker-stacks/issues/552
     if ! whoami &> /dev/null; then","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index ac4f02da..f35bc7d5 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -43,7 +43,7 @@ source /usr/local/bin/run-hooks.sh /usr/local/bin/start-notebook.d
 # things before we run the command passed to start.sh as the desired user
 # (NB_USER).
 #
-if [ ""$(id -u)"" == 0 ] ; then
+if [ ""$(id -u)"" == 0 ]; then
     # Environment variables:
     # - NB_USER: the desired username and associated home folder
     # - NB_UID: the desired user id
@@ -51,11 +51,11 @@ if [ ""$(id -u)"" == 0 ] ; then
     # - NB_GROUP: a group name we want for the group
     # - GRANT_SUDO: a boolean (""1"" or ""yes"") to grant the user sudo rights
     # - CHOWN_HOME: a boolean (""1"" or ""yes"") to chown the user's home folder
-    # - CHOWN_EXTRA: a comma separated list of paths to chown
+    # - CHOWN_EXTRA: a comma-separated list of paths to chown
     # - CHOWN_HOME_OPTS / CHOWN_EXTRA_OPTS: arguments to the chown commands
 
-    # Refit the jovyan user to the desired the user (NB_USER)
-    if id jovyan &> /dev/null ; then
+    # Refit the jovyan user to the desired user (NB_USER)
+    if id jovyan &> /dev/null; then
         if ! usermod --home ""/home/${NB_USER}"" --login ""${NB_USER}"" jovyan 2>&1 | grep ""no changes"" > /dev/null; then
             _log ""Updated the jovyan user:""
             _log ""- username: jovyan       -> ${NB_USER}""
@@ -78,7 +78,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         useradd --no-log-init --home ""/home/${NB_USER}"" --shell /bin/bash --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
     fi
 
-    # Move or symlink the jovyan home directory to the desired users home
+    # Move or symlink the jovyan home directory to the desired user's home
     # directory if it doesn't already exist, and update the current working
     # directory to the new location if needed.
     if [[ ""${NB_USER}"" != ""jovyan"" ]]; then
@@ -106,7 +106,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         fi
     fi
 
-    # Optionally ensure the desired user get filesystem ownership of it's home
+    # Optionally ensure the desired user gets filesystem ownership of its home
     # folder and/or additional folders
     if [[ ""${CHOWN_HOME}"" == ""1"" || ""${CHOWN_HOME}"" == ""yes"" ]]; then
         _log ""Ensuring /home/${NB_USER} is owned by ${NB_UID}:${NB_GID} ${CHOWN_HOME_OPTS:+(chown options: ${CHOWN_HOME_OPTS})}""
@@ -121,7 +121,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         done
     fi
 
-    # Update potentially outdated environment variables since image build
+    # Update potentially outdated environment variables since the image build
     export XDG_CACHE_HOME=""/home/${NB_USER}/.cache""
 
     # Prepend ${CONDA_DIR}/bin to sudo secure_path
@@ -163,7 +163,7 @@ if [ ""$(id -u)"" == 0 ] ; then
         # - We use the `--set-home` flag to set the HOME variable appropriately.
         #
         # - To reduce the default list of variables deleted by sudo, we could have
-        #   used `env_delete` from /etc/sudoers. It has higher priority than the
+        #   used `env_delete` from /etc/sudoers. It has a higher priority than the
         #   `--preserve-env` flag and the `env_keep` configuration.
         #
         # - We preserve LD_LIBRARY_PATH, PATH and PYTHONPATH explicitly. Note however that sudo
@@ -186,7 +186,7 @@ else
     # Attempt to ensure the user uid we currently run as has a named entry in
     # the /etc/passwd file, as it avoids software crashing on hard assumptions
     # on such entry. Writing to the /etc/passwd was allowed for the root group
-    # from the Dockerfile during build.
+    # from the Dockerfile during the build.
     #
     # ref: https://github.com/jupyter/docker-stacks/issues/552
     if ! whoami &> /dev/null; then",Yes
images/minimal-notebook/Dockerfile,images/minimal-notebook/Dockerfile,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index 228509aa..a0dbfc65 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -13,7 +13,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for fully functional Server
+# Install all OS dependencies for a fully functional Server
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     # Common useful utilities
@@ -43,7 +43,7 @@ RUN update-alternatives --install /usr/bin/nano nano /bin/nano-tiny 10
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}
 
-# Add R mimetype option to specify how the plot returns from R to the browser
+# Add an R mimetype option to specify how the plot returns from R to the browser
 COPY --chown=${NB_UID}:${NB_GID} Rprofile.site /opt/conda/lib/R/etc/
 
 # Add setup scripts that may be used by downstream images or inherited images","diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index 228509aa..a0dbfc65 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -13,7 +13,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for fully functional Server
+# Install all OS dependencies for a fully functional Server
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     # Common useful utilities
@@ -43,7 +43,7 @@ RUN update-alternatives --install /usr/bin/nano nano /bin/nano-tiny 10
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}
 
-# Add R mimetype option to specify how the plot returns from R to the browser
+# Add an R mimetype option to specify how the plot returns from R to the browser
 COPY --chown=${NB_UID}:${NB_GID} Rprofile.site /opt/conda/lib/R/etc/
 
 # Add setup scripts that may be used by downstream images or inherited images",Yes
images/minimal-notebook/setup-scripts/setup-julia-packages.bash,images/minimal-notebook/setup-scripts/setup-julia-packages.bash,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 7cc0a45f..16adb428 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -1,7 +1,7 @@
 #!/bin/bash
 set -exuo pipefail
 # Requirements:
-# - Run as non-root user
+# - Run as a non-root user
 # - The JULIA_PKGDIR environment variable is set
 # - Julia is already set up, with the setup-julia.bash command","diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 7cc0a45f..16adb428 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -1,7 +1,7 @@
 #!/bin/bash
 set -exuo pipefail
 # Requirements:
-# - Run as non-root user
+# - Run as a non-root user
 # - The JULIA_PKGDIR environment variable is set
 # - Julia is already set up, with the setup-julia.bash command",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 28d40dc2..9346c43c 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -15,7 +15,7 @@ USER root
 
 # Spark dependencies
 # Default values can be overridden at build time
-# (ARGS are in lower case to distinguish them from ENV)
+# (ARGS are in lowercase to distinguish them from ENV)
 ARG spark_version=""3.5.0""
 ARG hadoop_version=""3""
 ARG scala_version
@@ -35,7 +35,7 @@ RUN apt-get update --yes && \
 WORKDIR /tmp
 
 # You need to use https://archive.apache.org/dist/ website if you want to download old Spark versions
-# But it seems to be slower, that's why we use recommended site for download
+# But it seems to be slower, that's why we use the recommended site for download
 RUN if [ -z ""${scala_version}"" ]; then \
     curl --progress-bar --location --output ""spark.tgz"" \
         ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 28d40dc2..9346c43c 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -15,7 +15,7 @@ USER root
 
 # Spark dependencies
 # Default values can be overridden at build time
-# (ARGS are in lower case to distinguish them from ENV)
+# (ARGS are in lowercase to distinguish them from ENV)
 ARG spark_version=""3.5.0""
 ARG hadoop_version=""3""
 ARG scala_version
@@ -35,7 +35,7 @@ RUN apt-get update --yes && \
 WORKDIR /tmp
 
 # You need to use https://archive.apache.org/dist/ website if you want to download old Spark versions
-# But it seems to be slower, that's why we use recommended site for download
+# But it seems to be slower, that's why we use the recommended site for download
 RUN if [ -z ""${scala_version}"" ]; then \
     curl --progress-bar --location --output ""spark.tgz"" \
         ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \",Yes
images/scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index bc0f80b9..8b687eb7 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -66,7 +66,7 @@ RUN mamba install --yes \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Install facets which does not have a pip or conda package at the moment
+# Install facets package which does not have a `pip` or `conda-forge` package at the moment
 WORKDIR /tmp
 RUN git clone https://github.com/PAIR-code/facets && \
     jupyter nbclassic-extension install facets/facets-dist/ --sys-prefix && \","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index bc0f80b9..8b687eb7 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -66,7 +66,7 @@ RUN mamba install --yes \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Install facets which does not have a pip or conda package at the moment
+# Install facets package which does not have a `pip` or `conda-forge` package at the moment
 WORKDIR /tmp
 RUN git clone https://github.com/PAIR-code/facets && \
     jupyter nbclassic-extension install facets/facets-dist/ --sys-prefix && \",Yes
tagging/README.md,tagging/README.md,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tagging/README.md b/tagging/README.md
index 129f3d15..fad3e5b2 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -84,7 +84,7 @@ class SHATagger(TaggerInterface):
 ### Manifest
 
 `ManifestHeader` is a build manifest header.
-It contains information about `Build datetime`, `Docker image size`, and `Git commit` info.
+It contains the following sections: `Build timestamp`, `Docker image size`, and `Git commit` info.
 
 All the other manifest classes are inherited from `ManifestInterface`:","diff --git a/tagging/README.md b/tagging/README.md
index 129f3d15..fad3e5b2 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -84,7 +84,7 @@ class SHATagger(TaggerInterface):
 ### Manifest
 
 `ManifestHeader` is a build manifest header.
-It contains information about `Build datetime`, `Docker image size`, and `Git commit` info.
+It contains the following sections: `Build timestamp`, `Docker image size`, and `Git commit` info.
 
 All the other manifest classes are inherited from `ManifestInterface`:",Yes
tagging/manifests.py,tagging/manifests.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tagging/manifests.py b/tagging/manifests.py
index 8ed6bc19..f043de05 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -49,7 +49,7 @@ class ManifestHeader:
 
 ## Build Info
 
-- Build datetime: {build_timestamp}
+- Build timestamp: {build_timestamp}
 - Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`
 - Docker image size: {image_size}
 - Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})","diff --git a/tagging/manifests.py b/tagging/manifests.py
index 8ed6bc19..f043de05 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -49,7 +49,7 @@ class ManifestHeader:
 
 ## Build Info
 
-- Build datetime: {build_timestamp}
+- Build timestamp: {build_timestamp}
 - Docker image: `{registry}/{owner}/{short_image_name}:{commit_hash_tag}`
 - Docker image size: {image_size}
 - Git commit SHA: [{commit_hash}](https://github.com/jupyter/docker-stacks/commit/{commit_hash})",Yes
tagging/update_wiki.py,tagging/update_wiki.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 193558c8..3b2ac6f0 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -51,7 +51,7 @@ def update_monthly_wiki_page(
 
 def get_manifest_timestamp(manifest_file: Path) -> str:
     file_content = manifest_file.read_text()
-    pos = file_content.find(""Build datetime: "")
+    pos = file_content.find(""Build timestamp: "")
     return file_content[pos + 16 : pos + 36]","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 193558c8..3b2ac6f0 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -51,7 +51,7 @@ def update_monthly_wiki_page(
 
 def get_manifest_timestamp(manifest_file: Path) -> str:
     file_content = manifest_file.read_text()
-    pos = file_content.find(""Build datetime: "")
+    pos = file_content.find(""Build timestamp: "")
     return file_content[pos + 16 : pos + 36]",Yes
tagging/write_manifest.py,tagging/write_manifest.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index 589906dc..66912bee 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -16,7 +16,7 @@ from tagging.manifests import ManifestHeader, ManifestInterface
 
 LOGGER = logging.getLogger(__name__)
 
-# This would actually be manifest creation timestamp
+# We use a manifest creation timestamp, which happens right after a build
 BUILD_TIMESTAMP = datetime.datetime.utcnow().isoformat()[:-7] + ""Z""
 MARKDOWN_LINE_BREAK = ""<br />""","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index 589906dc..66912bee 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -16,7 +16,7 @@ from tagging.manifests import ManifestHeader, ManifestInterface
 
 LOGGER = logging.getLogger(__name__)
 
-# This would actually be manifest creation timestamp
+# We use a manifest creation timestamp, which happens right after a build
 BUILD_TIMESTAMP = datetime.datetime.utcnow().isoformat()[:-7] + ""Z""
 MARKDOWN_LINE_BREAK = ""<br />""",Yes
tests/base-notebook/test_container_options.py,tests/base-notebook/test_container_options.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 1ea501d8..91203501 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -42,7 +42,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
     # Use sleep, not wait, because the container sleeps forever.
     time.sleep(1)
     LOGGER.info(
-        f""Checking if home folder of {nb_user} contains the hidden '.jupyter' folder with appropriate permissions ...""
+        f""Checking if a home folder of {nb_user} contains the hidden '.jupyter' folder with appropriate permissions ...""
     )
     command = f'stat -c ""%F %U %G"" /home/{nb_user}/.jupyter'
     expected_output = f""directory {nb_user} users""","diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 1ea501d8..91203501 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -42,7 +42,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
     # Use sleep, not wait, because the container sleeps forever.
     time.sleep(1)
     LOGGER.info(
-        f""Checking if home folder of {nb_user} contains the hidden '.jupyter' folder with appropriate permissions ...""
+        f""Checking if a home folder of {nb_user} contains the hidden '.jupyter' folder with appropriate permissions ...""
     )
     command = f'stat -c ""%F %U %G"" /home/{nb_user}/.jupyter'
     expected_output = f""directory {nb_user} users""",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index a049c9c3..aa5c4bb9 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -15,8 +15,8 @@ The goal is to detect import errors that can be caused by incompatibilities betw
 This module checks dynamically, through the `CondaPackageHelper`,
 only the requested packages i.e. packages requested by `mamba install` in the `Dockerfile`s.
 This means that it does not check dependencies.
-This choice is a tradeoff to cover the main requirements while achieving reasonable test duration.
-However it could be easily changed (or completed) to cover also dependencies.
+This choice is a tradeoff to cover the main requirements while achieving a reasonable test duration.
+However, it could be easily changed (or completed) to cover dependencies as well.
 Use `package_helper.installed_packages()` instead of `package_helper.requested_packages()`.
 
 Example:
@@ -145,7 +145,7 @@ def _check_import_packages(
     """"""Test if packages can be imported
 
     Note: using a list of packages instead of a fixture for the list of packages
-    since pytest prevents use of multiple yields
+    since pytest prevents the use of multiple yields
     """"""
     failures = {}
     LOGGER.info(""Testing the import of packages ..."")","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index a049c9c3..aa5c4bb9 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -15,8 +15,8 @@ The goal is to detect import errors that can be caused by incompatibilities betw
 This module checks dynamically, through the `CondaPackageHelper`,
 only the requested packages i.e. packages requested by `mamba install` in the `Dockerfile`s.
 This means that it does not check dependencies.
-This choice is a tradeoff to cover the main requirements while achieving reasonable test duration.
-However it could be easily changed (or completed) to cover also dependencies.
+This choice is a tradeoff to cover the main requirements while achieving a reasonable test duration.
+However, it could be easily changed (or completed) to cover dependencies as well.
 Use `package_helper.installed_packages()` instead of `package_helper.requested_packages()`.
 
 Example:
@@ -145,7 +145,7 @@ def _check_import_packages(
     """"""Test if packages can be imported
 
     Note: using a list of packages instead of a fixture for the list of packages
-    since pytest prevents use of multiple yields
+    since pytest prevents the use of multiple yields
     """"""
     failures = {}
     LOGGER.info(""Testing the import of packages ..."")",Yes
tests/docker-stacks-foundation/test_run_hooks.py,tests/docker-stacks-foundation/test_run_hooks.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index 6bcbaf8c..87467f9f 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -83,7 +83,7 @@ def run_source_in_dir(
     cont_data_dir = ""/home/jovyan/data""
     # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
     # Unfortunately, Docker treats all files in mounter dir as executable files
-    # So we make a copy of mounted dir inside a container
+    # So we make a copy of the mounted dir inside a container
     command = (
         ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
         ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/"" + command_suffix","diff --git a/tests/docker-stacks-foundation/test_run_hooks.py b/tests/docker-stacks-foundation/test_run_hooks.py
index 6bcbaf8c..87467f9f 100644
--- a/tests/docker-stacks-foundation/test_run_hooks.py
+++ b/tests/docker-stacks-foundation/test_run_hooks.py
@@ -83,7 +83,7 @@ def run_source_in_dir(
     cont_data_dir = ""/home/jovyan/data""
     # https://forums.docker.com/t/all-files-appear-as-executable-in-file-paths-using-bind-mount/99921
     # Unfortunately, Docker treats all files in mounter dir as executable files
-    # So we make a copy of mounted dir inside a container
+    # So we make a copy of the mounted dir inside a container
     command = (
         ""cp -r /home/jovyan/data/ /home/jovyan/data-copy/ &&""
         ""source /usr/local/bin/run-hooks.sh /home/jovyan/data-copy/"" + command_suffix",Yes
tests/docker-stacks-foundation/test_user_options.py,tests/docker-stacks-foundation/test_user_options.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index 8702af50..cc8a1b83 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -74,7 +74,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
     ), f""Bad owner for the {nb_user} home folder {output}, expected {expected_output}""
 
     LOGGER.info(
-        f""Checking if home folder of {nb_user} contains the 'work' folder with appropriate permissions ...""
+        f""Checking if a home folder of {nb_user} contains the 'work' folder with appropriate permissions ...""
     )
     command = f'stat -c ""%F %U %G"" /home/{nb_user}/work'
     expected_output = f""directory {nb_user} users""
@@ -86,7 +86,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
 
 
 def test_chown_extra(container: TrackedContainer) -> None:
-    """"""Container should change the UID/GID of a comma separated
+    """"""Container should change the UID/GID of a comma-separated
     CHOWN_EXTRA list of folders.""""""
     logs = container.run_and_wait(
         timeout=120,  # chown is slow so give it some time
@@ -184,7 +184,7 @@ def test_group_add(container: TrackedContainer) -> None:
 def test_set_uid(container: TrackedContainer) -> None:
     """"""Container should run with the specified uid and NB_USER.
     The /home/jovyan directory will not be writable since it's owned by 1000:users.
-    Additionally verify that ""--group-add=users"" is suggested in a warning to restore
+    Additionally, verify that ""--group-add=users"" is suggested in a warning to restore
     write access.
     """"""
     logs = container.run_and_wait(
@@ -270,7 +270,7 @@ def test_jupyter_env_vars_to_unset(
 
 
 def test_secure_path(container: TrackedContainer, tmp_path: pathlib.Path) -> None:
-    """"""Make sure that the sudo command has conda's python (not system's) on path.
+    """"""Make sure that the sudo command has conda's python (not system's) on PATH.
     See <https://github.com/jupyter/docker-stacks/issues/1053>.
     """"""
     d = tmp_path / ""data""","diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index 8702af50..cc8a1b83 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -74,7 +74,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
     ), f""Bad owner for the {nb_user} home folder {output}, expected {expected_output}""
 
     LOGGER.info(
-        f""Checking if home folder of {nb_user} contains the 'work' folder with appropriate permissions ...""
+        f""Checking if a home folder of {nb_user} contains the 'work' folder with appropriate permissions ...""
     )
     command = f'stat -c ""%F %U %G"" /home/{nb_user}/work'
     expected_output = f""directory {nb_user} users""
@@ -86,7 +86,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
 
 
 def test_chown_extra(container: TrackedContainer) -> None:
-    """"""Container should change the UID/GID of a comma separated
+    """"""Container should change the UID/GID of a comma-separated
     CHOWN_EXTRA list of folders.""""""
     logs = container.run_and_wait(
         timeout=120,  # chown is slow so give it some time
@@ -184,7 +184,7 @@ def test_group_add(container: TrackedContainer) -> None:
 def test_set_uid(container: TrackedContainer) -> None:
     """"""Container should run with the specified uid and NB_USER.
     The /home/jovyan directory will not be writable since it's owned by 1000:users.
-    Additionally verify that ""--group-add=users"" is suggested in a warning to restore
+    Additionally, verify that ""--group-add=users"" is suggested in a warning to restore
     write access.
     """"""
     logs = container.run_and_wait(
@@ -270,7 +270,7 @@ def test_jupyter_env_vars_to_unset(
 
 
 def test_secure_path(container: TrackedContainer, tmp_path: pathlib.Path) -> None:
-    """"""Make sure that the sudo command has conda's python (not system's) on path.
+    """"""Make sure that the sudo command has conda's python (not system's) on PATH.
     See <https://github.com/jupyter/docker-stacks/issues/1053>.
     """"""
     d = tmp_path / ""data""",Yes
tests/scipy-notebook/test_cython.py,tests/scipy-notebook/test_cython.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tests/scipy-notebook/test_cython.py b/tests/scipy-notebook/test_cython.py
index 839d83a1..5d24e971 100644
--- a/tests/scipy-notebook/test_cython.py
+++ b/tests/scipy-notebook/test_cython.py
@@ -19,7 +19,7 @@ def test_cython(container: TrackedContainer) -> None:
             ""start.sh"",
             ""bash"",
             ""-c"",
-            # We copy our data to temporary folder to be able to modify the directory
+            # We copy our data to a temporary folder to be able to modify the directory
             f""cp -r {cont_data_dir}/ /tmp/test/ && cd /tmp/test && python3 setup.py build_ext"",
         ],
     )","diff --git a/tests/scipy-notebook/test_cython.py b/tests/scipy-notebook/test_cython.py
index 839d83a1..5d24e971 100644
--- a/tests/scipy-notebook/test_cython.py
+++ b/tests/scipy-notebook/test_cython.py
@@ -19,7 +19,7 @@ def test_cython(container: TrackedContainer) -> None:
             ""start.sh"",
             ""bash"",
             ""-c"",
-            # We copy our data to temporary folder to be able to modify the directory
+            # We copy our data to a temporary folder to be able to modify the directory
             f""cp -r {cont_data_dir}/ /tmp/test/ && cd /tmp/test && python3 setup.py build_ext"",
         ],
     )",Yes
tests/scipy-notebook/test_matplotlib.py,tests/scipy-notebook/test_matplotlib.py,d8c60bc42cad227c5a35214a43a29c157c0a345e,d03229331a5354b4c3b7ee08abf9e03bed1d8cfe,Fix more grammar issues,"diff --git a/tests/scipy-notebook/test_matplotlib.py b/tests/scipy-notebook/test_matplotlib.py
index 27c6d3c3..ac4fcdae 100644
--- a/tests/scipy-notebook/test_matplotlib.py
+++ b/tests/scipy-notebook/test_matplotlib.py
@@ -17,7 +17,7 @@ THIS_DIR = Path(__file__).parent.resolve()
         (
             ""matplotlib_1.py"",
             ""test.png"",
-            ""Test that matplotlib is able to plot a graph and write it as an image ..."",
+            ""Test that matplotlib can plot a graph and write it as an image ..."",
         ),
         (
             ""matplotlib_fonts_1.py"",","diff --git a/tests/scipy-notebook/test_matplotlib.py b/tests/scipy-notebook/test_matplotlib.py
index 27c6d3c3..ac4fcdae 100644
--- a/tests/scipy-notebook/test_matplotlib.py
+++ b/tests/scipy-notebook/test_matplotlib.py
@@ -17,7 +17,7 @@ THIS_DIR = Path(__file__).parent.resolve()
         (
             ""matplotlib_1.py"",
             ""test.png"",
-            ""Test that matplotlib is able to plot a graph and write it as an image ..."",
+            ""Test that matplotlib can plot a graph and write it as an image ..."",
         ),
         (
             ""matplotlib_fonts_1.py"",",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,69e5b1d5c2cd32e8df0dd9d95794b377d8876827,d8c60bc42cad227c5a35214a43a29c157c0a345e,Fix arg names for --hist-lines-dir and --manifests-dir,"diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index a6f4a91f..350510cf 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -6,10 +6,10 @@ description: Download all manifests and history lines
 # https://github.com/actions/download-artifact/issues/6
 
 inputs:
-  hist-line-dir:
+  hist-lines-dir:
     description: Directory to store history lines
     required: true
-  manifest-dir:
+  manifests-dir:
     description: Directory to store manifest files
     required: true
   fast-build:
@@ -23,232 +23,232 @@ runs:
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
 
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index a6f4a91f..350510cf 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -6,10 +6,10 @@ description: Download all manifests and history lines
 # https://github.com/actions/download-artifact/issues/6
 
 inputs:
-  hist-line-dir:
+  hist-lines-dir:
     description: Directory to store history lines
     required: true
-  manifest-dir:
+  manifests-dir:
     description: Directory to store manifest files
     required: true
   fast-build:
@@ -23,232 +23,232 @@ runs:
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
-        path: ${{ inputs.hist-line-dir }}
+        path: ${{ inputs.hist-lines-dir }}
 
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest
-        path: ${{ inputs.manifest-dir }}
+        path: ${{ inputs.manifests-dir }}",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,69e5b1d5c2cd32e8df0dd9d95794b377d8876827,d8c60bc42cad227c5a35214a43a29c157c0a345e,Fix arg names for --hist-lines-dir and --manifests-dir,"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 2ebad196..84ea58f3 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -82,7 +82,7 @@ jobs:
           retention-days: 3
 
       - name: Write manifest and build history file 🏷
-        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
         uses: actions/upload-artifact@v3","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 2ebad196..84ea58f3 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -82,7 +82,7 @@ jobs:
           retention-days: 3
 
       - name: Write manifest and build history file 🏷
-        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
         uses: actions/upload-artifact@v3",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,69e5b1d5c2cd32e8df0dd9d95794b377d8876827,d8c60bc42cad227c5a35214a43a29c157c0a345e,Fix arg names for --hist-lines-dir and --manifests-dir,"diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 13aa2bcf..88d794c4 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -21,8 +21,8 @@ jobs:
       - name: Download all manifests and history lines 📥
         uses: ./.github/actions/download-manifests
         with:
-          hist-line-dir: /tmp/jupyter/hist_lines/
-          manifest-dir: /tmp/jupyter/manifests/
+          hist-lines-dir: /tmp/jupyter/hist_lines/
+          manifests-dir: /tmp/jupyter/manifests/
           fast-build: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
       - name: Display structure of downloaded files 🔍️
         run: |
@@ -37,7 +37,7 @@ jobs:
           path: wiki/
 
       - name: Update wiki 🏷
-        run: python3 -m tagging.update_wiki --wiki-dir wiki/ --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/
+        run: python3 -m tagging.update_wiki --wiki-dir wiki/ --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/
         shell: bash
 
       - name: Push Wiki to GitHub 📤","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 13aa2bcf..88d794c4 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -21,8 +21,8 @@ jobs:
       - name: Download all manifests and history lines 📥
         uses: ./.github/actions/download-manifests
         with:
-          hist-line-dir: /tmp/jupyter/hist_lines/
-          manifest-dir: /tmp/jupyter/manifests/
+          hist-lines-dir: /tmp/jupyter/hist_lines/
+          manifests-dir: /tmp/jupyter/manifests/
           fast-build: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
       - name: Display structure of downloaded files 🔍️
         run: |
@@ -37,7 +37,7 @@ jobs:
           path: wiki/
 
       - name: Update wiki 🏷
-        run: python3 -m tagging.update_wiki --wiki-dir wiki/ --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/
+        run: python3 -m tagging.update_wiki --wiki-dir wiki/ --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/
         shell: bash
 
       - name: Push Wiki to GitHub 📤",Yes
Makefile,Makefile,69e5b1d5c2cd32e8df0dd9d95794b377d8876827,d8c60bc42cad227c5a35214a43a29c157c0a345e,Fix arg names for --hist-lines-dir and --manifests-dir,"diff --git a/Makefile b/Makefile
index d399ab10..e79f133f 100644
--- a/Makefile
+++ b/Makefile
@@ -70,7 +70,7 @@ linkcheck-docs: ## check broken links
 
 hook/%: ## run post-build hooks for an image
 	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
 	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images","diff --git a/Makefile b/Makefile
index d399ab10..e79f133f 100644
--- a/Makefile
+++ b/Makefile
@@ -70,7 +70,7 @@ linkcheck-docs: ## check broken links
 
 hook/%: ## run post-build hooks for an image
 	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-line-dir /tmp/jupyter/hist_lines/ --manifest-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
 	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images",Yes
tagging/update_wiki.py,tagging/update_wiki.py,69e5b1d5c2cd32e8df0dd9d95794b377d8876827,d8c60bc42cad227c5a35214a43a29c157c0a345e,Fix arg names for --hist-lines-dir and --manifests-dir,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 3b2ac6f0..ad004e67 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -103,13 +103,13 @@ if __name__ == ""__main__"":
         help=""Directory of the wiki repo"",
     )
     arg_parser.add_argument(
-        ""--hist-line-dir"",
+        ""--hist-lines-dir"",
         required=True,
         type=Path,
         help=""Directory with history lines"",
     )
     arg_parser.add_argument(
-        ""--manifest-dir"",
+        ""--manifests-dir"",
         required=True,
         type=Path,
         help=""Directory with manifest files"",","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 3b2ac6f0..ad004e67 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -103,13 +103,13 @@ if __name__ == ""__main__"":
         help=""Directory of the wiki repo"",
     )
     arg_parser.add_argument(
-        ""--hist-line-dir"",
+        ""--hist-lines-dir"",
         required=True,
         type=Path,
         help=""Directory with history lines"",
     )
     arg_parser.add_argument(
-        ""--manifest-dir"",
+        ""--manifests-dir"",
         required=True,
         type=Path,
         help=""Directory with manifest files"",",Yes
tagging/write_manifest.py,tagging/write_manifest.py,69e5b1d5c2cd32e8df0dd9d95794b377d8876827,d8c60bc42cad227c5a35214a43a29c157c0a345e,Fix arg names for --hist-lines-dir and --manifests-dir,"diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index 66912bee..eb7b66a8 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -114,13 +114,13 @@ if __name__ == ""__main__"":
         help=""Short image name to create manifests for"",
     )
     arg_parser.add_argument(
-        ""--hist-line-dir"",
+        ""--hist-lines-dir"",
         required=True,
         type=Path,
         help=""Directory to save history line"",
     )
     arg_parser.add_argument(
-        ""--manifest-dir"",
+        ""--manifests-dir"",
         required=True,
         type=Path,
         help=""Directory to save manifest file"",","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index 66912bee..eb7b66a8 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -114,13 +114,13 @@ if __name__ == ""__main__"":
         help=""Short image name to create manifests for"",
     )
     arg_parser.add_argument(
-        ""--hist-line-dir"",
+        ""--hist-lines-dir"",
         required=True,
         type=Path,
         help=""Directory to save history line"",
     )
     arg_parser.add_argument(
-        ""--manifest-dir"",
+        ""--manifests-dir"",
         required=True,
         type=Path,
         help=""Directory to save manifest file"",",Yes
tagging/update_wiki.py,tagging/update_wiki.py,809672790e5fa6253fa765fa3a1e20b3c5b84def,69e5b1d5c2cd32e8df0dd9d95794b377d8876827,Fix usages of hist_lines_dir and manifests_dir,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index ad004e67..8f80263c 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -72,17 +72,17 @@ def remove_old_manifests(wiki_dir: Path) -> None:
         LOGGER.info(f""Removed manifest: {file.relative_to(wiki_dir)}"")
 
 
-def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
+def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> None:
     LOGGER.info(""Updating wiki"")
 
-    for manifest_file in manifest_dir.glob(""*.md""):
+    for manifest_file in manifests_dir.glob(""*.md""):
         month = get_manifest_month(manifest_file)
         copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
         copy_to.parent.mkdir(exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
 
-    for build_history_line_file in sorted(hist_line_dir.glob(""*.txt"")):
+    for build_history_line_file in sorted(hist_lines_dir.glob(""*.txt"")):
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
         month = build_history_line[3:10]
@@ -116,4 +116,4 @@ if __name__ == ""__main__"":
     )
     args = arg_parser.parse_args()
 
-    update_wiki(args.wiki_dir, args.hist_line_dir, args.manifest_dir)
+    update_wiki(args.wiki_dir, args.hist_lines_dir, args.manifests_dir)","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index ad004e67..8f80263c 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -72,17 +72,17 @@ def remove_old_manifests(wiki_dir: Path) -> None:
         LOGGER.info(f""Removed manifest: {file.relative_to(wiki_dir)}"")
 
 
-def update_wiki(wiki_dir: Path, hist_line_dir: Path, manifest_dir: Path) -> None:
+def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> None:
     LOGGER.info(""Updating wiki"")
 
-    for manifest_file in manifest_dir.glob(""*.md""):
+    for manifest_file in manifests_dir.glob(""*.md""):
         month = get_manifest_month(manifest_file)
         copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
         copy_to.parent.mkdir(exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
 
-    for build_history_line_file in sorted(hist_line_dir.glob(""*.txt"")):
+    for build_history_line_file in sorted(hist_lines_dir.glob(""*.txt"")):
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
         month = build_history_line[3:10]
@@ -116,4 +116,4 @@ if __name__ == ""__main__"":
     )
     args = arg_parser.parse_args()
 
-    update_wiki(args.wiki_dir, args.hist_line_dir, args.manifest_dir)
+    update_wiki(args.wiki_dir, args.hist_lines_dir, args.manifests_dir)",Yes
tagging/write_manifest.py,tagging/write_manifest.py,809672790e5fa6253fa765fa3a1e20b3c5b84def,69e5b1d5c2cd32e8df0dd9d95794b377d8876827,Fix usages of hist_lines_dir and manifests_dir,"diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index eb7b66a8..4bfbf3f7 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -25,7 +25,7 @@ def write_build_history_line(
     short_image_name: str,
     registry: str,
     owner: str,
-    hist_line_dir: Path,
+    hist_lines_dir: Path,
     filename: str,
     all_tags: list[str],
 ) -> None:
@@ -44,15 +44,15 @@ def write_build_history_line(
         ]
     )
     build_history_line = f""| {date_column} | {image_column} | {links_column} |""
-    hist_line_dir.mkdir(parents=True, exist_ok=True)
-    (hist_line_dir / f""{filename}.txt"").write_text(build_history_line)
+    hist_lines_dir.mkdir(parents=True, exist_ok=True)
+    (hist_lines_dir / f""{filename}.txt"").write_text(build_history_line)
 
 
 def write_manifest_file(
     short_image_name: str,
     registry: str,
     owner: str,
-    manifest_dir: Path,
+    manifests_dir: Path,
     filename: str,
     manifests: list[ManifestInterface],
     container: Container,
@@ -65,16 +65,16 @@ def write_manifest_file(
     ] + [manifest.markdown_piece(container) for manifest in manifests]
     markdown_content = ""\n\n"".join(markdown_pieces) + ""\n""
 
-    manifest_dir.mkdir(parents=True, exist_ok=True)
-    (manifest_dir / f""{filename}.md"").write_text(markdown_content)
+    manifests_dir.mkdir(parents=True, exist_ok=True)
+    (manifests_dir / f""{filename}.md"").write_text(markdown_content)
 
 
 def write_manifest(
     short_image_name: str,
     registry: str,
     owner: str,
-    hist_line_dir: Path,
-    manifest_dir: Path,
+    hist_lines_dir: Path,
+    manifests_dir: Path,
 ) -> None:
     LOGGER.info(f""Creating manifests for image: {short_image_name}"")
     taggers, manifests = get_taggers_and_manifests(short_image_name)
@@ -91,13 +91,13 @@ def write_manifest(
             tags_prefix + ""-"" + tagger.tag_value(container) for tagger in taggers
         ]
         write_build_history_line(
-            short_image_name, registry, owner, hist_line_dir, filename, all_tags
+            short_image_name, registry, owner, hist_lines_dir, filename, all_tags
         )
         write_manifest_file(
             short_image_name,
             registry,
             owner,
-            manifest_dir,
+            manifests_dir,
             filename,
             manifests,
             container,
@@ -145,6 +145,6 @@ if __name__ == ""__main__"":
         args.short_image_name,
         args.registry,
         args.owner,
-        args.hist_line_dir,
-        args.manifest_dir,
+        args.hist_lines_dir,
+        args.manifests_dir,
     )","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index eb7b66a8..4bfbf3f7 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -25,7 +25,7 @@ def write_build_history_line(
     short_image_name: str,
     registry: str,
     owner: str,
-    hist_line_dir: Path,
+    hist_lines_dir: Path,
     filename: str,
     all_tags: list[str],
 ) -> None:
@@ -44,15 +44,15 @@ def write_build_history_line(
         ]
     )
     build_history_line = f""| {date_column} | {image_column} | {links_column} |""
-    hist_line_dir.mkdir(parents=True, exist_ok=True)
-    (hist_line_dir / f""{filename}.txt"").write_text(build_history_line)
+    hist_lines_dir.mkdir(parents=True, exist_ok=True)
+    (hist_lines_dir / f""{filename}.txt"").write_text(build_history_line)
 
 
 def write_manifest_file(
     short_image_name: str,
     registry: str,
     owner: str,
-    manifest_dir: Path,
+    manifests_dir: Path,
     filename: str,
     manifests: list[ManifestInterface],
     container: Container,
@@ -65,16 +65,16 @@ def write_manifest_file(
     ] + [manifest.markdown_piece(container) for manifest in manifests]
     markdown_content = ""\n\n"".join(markdown_pieces) + ""\n""
 
-    manifest_dir.mkdir(parents=True, exist_ok=True)
-    (manifest_dir / f""{filename}.md"").write_text(markdown_content)
+    manifests_dir.mkdir(parents=True, exist_ok=True)
+    (manifests_dir / f""{filename}.md"").write_text(markdown_content)
 
 
 def write_manifest(
     short_image_name: str,
     registry: str,
     owner: str,
-    hist_line_dir: Path,
-    manifest_dir: Path,
+    hist_lines_dir: Path,
+    manifests_dir: Path,
 ) -> None:
     LOGGER.info(f""Creating manifests for image: {short_image_name}"")
     taggers, manifests = get_taggers_and_manifests(short_image_name)
@@ -91,13 +91,13 @@ def write_manifest(
             tags_prefix + ""-"" + tagger.tag_value(container) for tagger in taggers
         ]
         write_build_history_line(
-            short_image_name, registry, owner, hist_line_dir, filename, all_tags
+            short_image_name, registry, owner, hist_lines_dir, filename, all_tags
         )
         write_manifest_file(
             short_image_name,
             registry,
             owner,
-            manifest_dir,
+            manifests_dir,
             filename,
             manifests,
             container,
@@ -145,6 +145,6 @@ if __name__ == ""__main__"":
         args.short_image_name,
         args.registry,
         args.owner,
-        args.hist_line_dir,
-        args.manifest_dir,
+        args.hist_lines_dir,
+        args.manifests_dir,
     )",Yes
docs/contributing/lint.md,docs/contributing/lint.md,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,809672790e5fa6253fa765fa3a1e20b3c5b84def,Minor improvements,"diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 17918912..fe838084 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -2,7 +2,7 @@
 
 To enforce some rules, **linters** are used in this project.
 Linters can be run either during the **development phase** (by the developer) or the **integration phase** (by GitHub Actions).
-To integrate and enforce this process in the project lifecycle, we are using **git hooks** through [pre-commit][pre-commit].
+To integrate and enforce this process in the project lifecycle, we are using **git hooks** through [pre-commit](https://pre-commit.com/).
 
 ## Using pre-commit hooks
 
@@ -44,11 +44,12 @@ More information can be found in [`.pre-commit-config.yaml` file](https://github
 
 ## Image Lint
 
-To comply with [Docker best practices][dbp], we are using the [Hadolint][hadolint] tool to analyze each `Dockerfile`.
+To comply with [Docker best practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices),
+we are using the [Hadolint](https://github.com/hadolint/hadolint) tool to analyze each `Dockerfile`.
 
 ### Ignoring Rules
 
-Sometimes it is necessary to ignore [some rules][rules].
+Sometimes it is necessary to ignore [some rules](https://github.com/hadolint/hadolint#rules).
 The following rules are ignored by default for all images in the `.hadolint.yaml` file.
 
 - [`DL3006`][dl3006]: We use a specific policy to manage image tags.
@@ -70,10 +71,6 @@ FROM ubuntu
 RUN cd /tmp && echo ""hello!""
 ```
 
-[hadolint]: https://github.com/hadolint/hadolint
-[dbp]: https://docs.docker.com/develop/develop-images/dockerfile_best-practices
-[rules]: https://github.com/hadolint/hadolint#rules
 [dl3006]: https://github.com/hadolint/hadolint/wiki/DL3006
 [dl3008]: https://github.com/hadolint/hadolint/wiki/DL3008
 [dl3013]: https://github.com/hadolint/hadolint/wiki/DL3013
-[pre-commit]: https://pre-commit.com/","diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 17918912..fe838084 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -2,7 +2,7 @@
 
 To enforce some rules, **linters** are used in this project.
 Linters can be run either during the **development phase** (by the developer) or the **integration phase** (by GitHub Actions).
-To integrate and enforce this process in the project lifecycle, we are using **git hooks** through [pre-commit][pre-commit].
+To integrate and enforce this process in the project lifecycle, we are using **git hooks** through [pre-commit](https://pre-commit.com/).
 
 ## Using pre-commit hooks
 
@@ -44,11 +44,12 @@ More information can be found in [`.pre-commit-config.yaml` file](https://github
 
 ## Image Lint
 
-To comply with [Docker best practices][dbp], we are using the [Hadolint][hadolint] tool to analyze each `Dockerfile`.
+To comply with [Docker best practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices),
+we are using the [Hadolint](https://github.com/hadolint/hadolint) tool to analyze each `Dockerfile`.
 
 ### Ignoring Rules
 
-Sometimes it is necessary to ignore [some rules][rules].
+Sometimes it is necessary to ignore [some rules](https://github.com/hadolint/hadolint#rules).
 The following rules are ignored by default for all images in the `.hadolint.yaml` file.
 
 - [`DL3006`][dl3006]: We use a specific policy to manage image tags.
@@ -70,10 +71,6 @@ FROM ubuntu
 RUN cd /tmp && echo ""hello!""
 ```
 
-[hadolint]: https://github.com/hadolint/hadolint
-[dbp]: https://docs.docker.com/develop/develop-images/dockerfile_best-practices
-[rules]: https://github.com/hadolint/hadolint#rules
 [dl3006]: https://github.com/hadolint/hadolint/wiki/DL3006
 [dl3008]: https://github.com/hadolint/hadolint/wiki/DL3008
 [dl3013]: https://github.com/hadolint/hadolint/wiki/DL3013
-[pre-commit]: https://pre-commit.com/",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,809672790e5fa6253fa765fa3a1e20b3c5b84def,Minor improvements,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 4f911fa2..af551991 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -12,7 +12,7 @@ Following these steps will:
 4. Update the [list of community stacks](../using/selecting.md#community-stacks) in this documentation to include your image.
 
 This approach mirrors how we build and share the core stack images.
-Feel free to follow it or pave your own path using alternative services and build tools.
+Feel free to follow it or pave your path using alternative services and build tools.
 
 ## Creating a Project","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index 4f911fa2..af551991 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -12,7 +12,7 @@ Following these steps will:
 4. Update the [list of community stacks](../using/selecting.md#community-stacks) in this documentation to include your image.
 
 This approach mirrors how we build and share the core stack images.
-Feel free to follow it or pave your own path using alternative services and build tools.
+Feel free to follow it or pave your path using alternative services and build tools.
 
 ## Creating a Project",Yes
docs/contributing/tests.md,docs/contributing/tests.md,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,809672790e5fa6253fa765fa3a1e20b3c5b84def,Minor improvements,"diff --git a/docs/contributing/tests.md b/docs/contributing/tests.md
index 40278386..3d7888bf 100644
--- a/docs/contributing/tests.md
+++ b/docs/contributing/tests.md
@@ -25,7 +25,7 @@ defined in the [conftest.py](https://github.com/jupyter/docker-stacks/blob/main/
 You can add a unit test if you want to run a Python script in one of our images.
 You should create a `tests/<somestack>/units/` directory, if it doesn't already exist, and put your file there.
 Files in this folder will be executed in the container when tests are run.
-You can see an [example for the TensorFlow package here](https://github.com/jupyter/docker-stacks/blob/HEAD/tests/tensorflow-notebook/units/unit_tensorflow.py).
+You can see an [TensorFlow package example here](https://github.com/jupyter/docker-stacks/blob/HEAD/tests/tensorflow-notebook/units/unit_tensorflow.py).
 
 ## Contributing New Tests","diff --git a/docs/contributing/tests.md b/docs/contributing/tests.md
index 40278386..3d7888bf 100644
--- a/docs/contributing/tests.md
+++ b/docs/contributing/tests.md
@@ -25,7 +25,7 @@ defined in the [conftest.py](https://github.com/jupyter/docker-stacks/blob/main/
 You can add a unit test if you want to run a Python script in one of our images.
 You should create a `tests/<somestack>/units/` directory, if it doesn't already exist, and put your file there.
 Files in this folder will be executed in the container when tests are run.
-You can see an [example for the TensorFlow package here](https://github.com/jupyter/docker-stacks/blob/HEAD/tests/tensorflow-notebook/units/unit_tensorflow.py).
+You can see an [TensorFlow package example here](https://github.com/jupyter/docker-stacks/blob/HEAD/tests/tensorflow-notebook/units/unit_tensorflow.py).
 
 ## Contributing New Tests",Yes
docs/using/recipe_code/spellcheck_notebookv6.dockerfile,docs/using/recipe_code/spellcheck_notebook_v6.dockerfile,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,809672790e5fa6253fa765fa3a1e20b3c5b84def,Minor improvements,"diff --git a/docs/using/recipe_code/spellcheck_notebook_v6.dockerfile b/docs/using/recipe_code/spellcheck_notebook_v6.dockerfile
new file mode 100644
index 00000000..1e12b562
--- /dev/null
+++ b/docs/using/recipe_code/spellcheck_notebook_v6.dockerfile
@@ -0,0 +1,9 @@
+# Using Docker Hub here, because this image is old and not pushed to Quay.io
+FROM docker.io/jupyter/base-notebook:notebook-6.5.4
+
+RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
+    jupyter contrib nbextension install --user && \
+    # can modify or enable additional extensions here
+    jupyter nbclassic-extension enable spellchecker/main --user && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/spellcheck_notebook_v6.dockerfile b/docs/using/recipe_code/spellcheck_notebook_v6.dockerfile
new file mode 100644
index 00000000..1e12b562
--- /dev/null
+++ b/docs/using/recipe_code/spellcheck_notebook_v6.dockerfile
@@ -0,0 +1,9 @@
+# Using Docker Hub here, because this image is old and not pushed to Quay.io
+FROM docker.io/jupyter/base-notebook:notebook-6.5.4
+
+RUN pip install --no-cache-dir 'jupyter_contrib_nbextensions' && \
+    jupyter contrib nbextension install --user && \
+    # can modify or enable additional extensions here
+    jupyter nbclassic-extension enable spellchecker/main --user && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
docs/using/recipes.md,docs/using/recipes.md,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,809672790e5fa6253fa765fa3a1e20b3c5b84def,Minor improvements,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 39d2ab25..bdca0803 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -401,7 +401,7 @@ This recipe only works for NBCassic with Jupyter Notebook < 7.
 It is recommended to use [jupyterlab-spellchecker](https://github.com/jupyterlab-contrib/spellchecker) in modern environments.
 ```
 
-```{literalinclude} recipe_code/spellcheck_notebookv6.dockerfile
+```{literalinclude} recipe_code/spellcheck_notebook_v6.dockerfile
 :language: docker
 ```","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 39d2ab25..bdca0803 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -401,7 +401,7 @@ This recipe only works for NBCassic with Jupyter Notebook < 7.
 It is recommended to use [jupyterlab-spellchecker](https://github.com/jupyterlab-contrib/spellchecker) in modern environments.
 ```
 
-```{literalinclude} recipe_code/spellcheck_notebookv6.dockerfile
+```{literalinclude} recipe_code/spellcheck_notebook_v6.dockerfile
 :language: docker
 ```",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index a413a429..2910837d 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -150,7 +150,7 @@ repos:
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if
-        # the python code blocks includes jupyter specific additions such as % or !
+        # the python code blocks include jupyter-specific additions such as % or !
         # See https://github.com/adamchainz/blacken-docs/issues/127 for an upstream
         # feature request about this.
         args: [--target-version=py39, --skip-errors]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index a413a429..2910837d 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -150,7 +150,7 @@ repos:
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if
-        # the python code blocks includes jupyter specific additions such as % or !
+        # the python code blocks include jupyter-specific additions such as % or !
         # See https://github.com/adamchainz/blacken-docs/issues/127 for an upstream
         # feature request about this.
         args: [--target-version=py39, --skip-errors]",Yes
CONTRIBUTING.md,CONTRIBUTING.md,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
index 0685e105..c14c6980 100644
--- a/CONTRIBUTING.md
+++ b/CONTRIBUTING.md
@@ -5,6 +5,6 @@ for information about how to contribute
 [features](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/features.html),
 [recipes](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/recipes.html),
 [tests](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/tests.html),
-[community-maintained stacks](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html).
+and [community-maintained stacks](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html).
 
 <!-- markdownlint-disable-file MD041 -->","diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
index 0685e105..c14c6980 100644
--- a/CONTRIBUTING.md
+++ b/CONTRIBUTING.md
@@ -5,6 +5,6 @@ for information about how to contribute
 [features](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/features.html),
 [recipes](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/recipes.html),
 [tests](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/tests.html),
-[community-maintained stacks](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html).
+and [community-maintained stacks](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html).
 
 <!-- markdownlint-disable-file MD041 -->",Yes
docs/using/selecting.md,docs/using/selecting.md,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 861f106e..08f84f8c 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -48,7 +48,7 @@ It contains:
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/base-notebook/Dockerfile) |
 [Quay.io image tags](https://quay.io/repository/jupyter/base-notebook?tab=tags)
 
-`jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
+`jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub, and NBClassic
 and serves as the basis for all other stacks besides `jupyter/docker-stacks-foundation`.
 
 It contains:
@@ -83,7 +83,7 @@ It contains:
   [git](https://git-scm.com/),
   [nano](https://www.nano-editor.org/) (actually `nano-tiny`),
   [tzdata](https://www.iana.org/time-zones),
-  [unzip](https://code.launchpad.net/ubuntu/+source/unzip)
+  [unzip](https://code.launchpad.net/ubuntu/+source/unzip),
   and [vi](https://www.vim.org) (actually `vim-tiny`),
 - [TeX Live](https://www.tug.org/texlive/) for notebook document conversion
 
@@ -193,7 +193,7 @@ It contains:
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/datascience-notebook/Dockerfile) |
 [Quay.io image tags](https://quay.io/repository/jupyter/datascience-notebook?tab=tags)
 
-`jupyter/datascience-notebook` includes libraries for data analysis from the Python, and R, and Julia communities.
+`jupyter/datascience-notebook` includes libraries for data analysis from the Python, R, and Julia communities.
 
 - Everything in the `jupyter/scipy-notebook`, `jupyter/r-notebook`, and `jupyter/julia-notebook` images and their ancestor
   images
@@ -244,7 +244,7 @@ Every Monday and whenever a pull request is merged, images are rebuilt and pushe
 
 Whenever a docker image is pushed to the container registry, it is tagged with:
 
-- a `latest` tag
+- the `latest` tag
 - a 12-character git commit SHA like `1ffe43816ba9`
 - a date formatted like `2023-01-30`
 - OS version like `ubuntu-22.04`","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 861f106e..08f84f8c 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -48,7 +48,7 @@ It contains:
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/base-notebook/Dockerfile) |
 [Quay.io image tags](https://quay.io/repository/jupyter/base-notebook?tab=tags)
 
-`jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
+`jupyter/base-notebook` adds base Jupyter Applications like JupyterLab, Jupyter Notebook, JupyterHub, and NBClassic
 and serves as the basis for all other stacks besides `jupyter/docker-stacks-foundation`.
 
 It contains:
@@ -83,7 +83,7 @@ It contains:
   [git](https://git-scm.com/),
   [nano](https://www.nano-editor.org/) (actually `nano-tiny`),
   [tzdata](https://www.iana.org/time-zones),
-  [unzip](https://code.launchpad.net/ubuntu/+source/unzip)
+  [unzip](https://code.launchpad.net/ubuntu/+source/unzip),
   and [vi](https://www.vim.org) (actually `vim-tiny`),
 - [TeX Live](https://www.tug.org/texlive/) for notebook document conversion
 
@@ -193,7 +193,7 @@ It contains:
 [Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/datascience-notebook/Dockerfile) |
 [Quay.io image tags](https://quay.io/repository/jupyter/datascience-notebook?tab=tags)
 
-`jupyter/datascience-notebook` includes libraries for data analysis from the Python, and R, and Julia communities.
+`jupyter/datascience-notebook` includes libraries for data analysis from the Python, R, and Julia communities.
 
 - Everything in the `jupyter/scipy-notebook`, `jupyter/r-notebook`, and `jupyter/julia-notebook` images and their ancestor
   images
@@ -244,7 +244,7 @@ Every Monday and whenever a pull request is merged, images are rebuilt and pushe
 
 Whenever a docker image is pushed to the container registry, it is tagged with:
 
-- a `latest` tag
+- the `latest` tag
 - a 12-character git commit SHA like `1ffe43816ba9`
 - a date formatted like `2023-01-30`
 - OS version like `ubuntu-22.04`",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 2c557854..3fc4ec15 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -76,7 +76,7 @@ RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
 
 USER ${NB_UID}
 
-# Pin Python version here, or set it to ""default""
+# Pin the Python version here, or set it to ""default""
 ARG PYTHON_VERSION=3.11
 
 # Setup work directory for backward-compatibility","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 2c557854..3fc4ec15 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -76,7 +76,7 @@ RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
 
 USER ${NB_UID}
 
-# Pin Python version here, or set it to ""default""
+# Pin the Python version here, or set it to ""default""
 ARG PYTHON_VERSION=3.11
 
 # Setup work directory for backward-compatibility",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index f35bc7d5..688c4586 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -4,9 +4,9 @@
 
 set -e
 
-# The _log function is used for everything this script wants to log. It will
-# always log errors and warnings, but can be silenced for other messages
-# by setting JUPYTER_DOCKER_STACKS_QUIET environment variable.
+# The _log function is used for everything this script wants to log.
+# It will always log errors and warnings but can be silenced for other messages
+# by setting the JUPYTER_DOCKER_STACKS_QUIET environment variable.
 _log () {
     if [[ ""$*"" == ""ERROR:""* ]] || [[ ""$*"" == ""WARNING:""* ]] || [[ ""${JUPYTER_DOCKER_STACKS_QUIET}"" == """" ]]; then
         echo ""$@""
@@ -62,7 +62,7 @@ if [ ""$(id -u)"" == 0 ]; then
             _log ""- home dir: /home/jovyan -> /home/${NB_USER}""
         fi
     elif ! id -u ""${NB_USER}"" &> /dev/null; then
-        _log ""ERROR: Neither the jovyan user or '${NB_USER}' exists. This could be the result of stopping and starting, the container with a different NB_USER environment variable.""
+        _log ""ERROR: Neither the jovyan user nor '${NB_USER}' exists. This could be the result of stopping and starting, the container with a different NB_USER environment variable.""
         exit 1
     fi
     # Ensure the desired user (NB_USER) gets its desired user id (NB_UID) and is","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index f35bc7d5..688c4586 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -4,9 +4,9 @@
 
 set -e
 
-# The _log function is used for everything this script wants to log. It will
-# always log errors and warnings, but can be silenced for other messages
-# by setting JUPYTER_DOCKER_STACKS_QUIET environment variable.
+# The _log function is used for everything this script wants to log.
+# It will always log errors and warnings but can be silenced for other messages
+# by setting the JUPYTER_DOCKER_STACKS_QUIET environment variable.
 _log () {
     if [[ ""$*"" == ""ERROR:""* ]] || [[ ""$*"" == ""WARNING:""* ]] || [[ ""${JUPYTER_DOCKER_STACKS_QUIET}"" == """" ]]; then
         echo ""$@""
@@ -62,7 +62,7 @@ if [ ""$(id -u)"" == 0 ]; then
             _log ""- home dir: /home/jovyan -> /home/${NB_USER}""
         fi
     elif ! id -u ""${NB_USER}"" &> /dev/null; then
-        _log ""ERROR: Neither the jovyan user or '${NB_USER}' exists. This could be the result of stopping and starting, the container with a different NB_USER environment variable.""
+        _log ""ERROR: Neither the jovyan user nor '${NB_USER}' exists. This could be the result of stopping and starting, the container with a different NB_USER environment variable.""
         exit 1
     fi
     # Ensure the desired user (NB_USER) gets its desired user id (NB_UID) and is",Yes
tagging/README.md,tagging/README.md,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/tagging/README.md b/tagging/README.md
index fad3e5b2..5d4ff4a5 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -15,8 +15,8 @@ For example, we dump all the `conda` packages, including their versions.
 - All the images are located in a hierarchical tree.
   More info on [image relationships](../docs/using/selecting.md#image-relationships).
 - We have `tagger` and `manifest` classes, which can be run inside docker containers to obtain tags and build manifest pieces.
-- These classes are inherited from the parent image to all the children images.
-- Because manifests and tags might change from parent to children, `taggers` and `manifests` are reevaluated on each image.
+- These classes are inherited from the parent image to all the child images.
+- Because manifests and tags might change from parent to child, `taggers` and `manifests` are reevaluated on each image.
   So, the values are not inherited.
 - To tag an image and create a manifest, run `make hook/base-notebook` (or another image of your choice).","diff --git a/tagging/README.md b/tagging/README.md
index fad3e5b2..5d4ff4a5 100644
--- a/tagging/README.md
+++ b/tagging/README.md
@@ -15,8 +15,8 @@ For example, we dump all the `conda` packages, including their versions.
 - All the images are located in a hierarchical tree.
   More info on [image relationships](../docs/using/selecting.md#image-relationships).
 - We have `tagger` and `manifest` classes, which can be run inside docker containers to obtain tags and build manifest pieces.
-- These classes are inherited from the parent image to all the children images.
-- Because manifests and tags might change from parent to children, `taggers` and `manifests` are reevaluated on each image.
+- These classes are inherited from the parent image to all the child images.
+- Because manifests and tags might change from parent to child, `taggers` and `manifests` are reevaluated on each image.
   So, the values are not inherited.
 - To tag an image and create a manifest, run `make hook/base-notebook` (or another image of your choice).",Yes
tagging/apply_tags.py,tagging/apply_tags.py,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 72634227..1c33a8fe 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -42,7 +42,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to apply tags for"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--tags-dir"",","diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 72634227..1c33a8fe 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -42,7 +42,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to apply tags for"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--tags-dir"",",Yes
tagging/merge_tags.py,tagging/merge_tags.py,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/tagging/merge_tags.py b/tagging/merge_tags.py
index 58247e5e..885a4821 100755
--- a/tagging/merge_tags.py
+++ b/tagging/merge_tags.py
@@ -59,7 +59,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to apply tags for"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--tags-dir"",","diff --git a/tagging/merge_tags.py b/tagging/merge_tags.py
index 58247e5e..885a4821 100755
--- a/tagging/merge_tags.py
+++ b/tagging/merge_tags.py
@@ -59,7 +59,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to apply tags for"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--tags-dir"",",Yes
tagging/write_manifest.py,tagging/write_manifest.py,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index 4bfbf3f7..c4605fd7 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -111,7 +111,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to create manifests for"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--hist-lines-dir"",","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index 4bfbf3f7..c4605fd7 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -111,7 +111,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to create manifests for"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--hist-lines-dir"",",Yes
tagging/write_tags_file.py,tagging/write_tags_file.py,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index 5f063aa6..880fec40 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -50,7 +50,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to write tags for"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--tags-dir"",","diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index 5f063aa6..880fec40 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -50,7 +50,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to write tags for"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--tags-dir"",",Yes
tests/R_mimetype_check.py,tests/R_mimetype_check.py,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/tests/R_mimetype_check.py b/tests/R_mimetype_check.py
index 4cfe7267..71a983d3 100644
--- a/tests/R_mimetype_check.py
+++ b/tests/R_mimetype_check.py
@@ -10,11 +10,11 @@ LOGGER = logging.getLogger(__name__)
 def check_r_mimetypes(container: TrackedContainer) -> None:
     """"""Check if Rscript command can be executed""""""
     LOGGER.info(""Test that R command can be executed ..."")
-    Rcommand = 'if (length(getOption(""jupyter.plot_mimetypes"")) != 5) {stop(""missing jupyter.plot_mimetypes"")}'
+    R_MIMETYPES_CHECK_CMD = 'if (length(getOption(""jupyter.plot_mimetypes"")) != 5) {stop(""missing jupyter.plot_mimetypes"")}'
     logs = container.run_and_wait(
         timeout=10,
         tty=True,
-        command=[""Rscript"", ""-e"", Rcommand],
+        command=[""Rscript"", ""-e"", R_MIMETYPES_CHECK_CMD],
     )
     LOGGER.debug(f""{logs=}"")
-    assert len(logs) == 0, f""Command {Rcommand=} failed""
+    assert len(logs) == 0, f""Command {R_MIMETYPES_CHECK_CMD=} failed""","diff --git a/tests/R_mimetype_check.py b/tests/R_mimetype_check.py
index 4cfe7267..71a983d3 100644
--- a/tests/R_mimetype_check.py
+++ b/tests/R_mimetype_check.py
@@ -10,11 +10,11 @@ LOGGER = logging.getLogger(__name__)
 def check_r_mimetypes(container: TrackedContainer) -> None:
     """"""Check if Rscript command can be executed""""""
     LOGGER.info(""Test that R command can be executed ..."")
-    Rcommand = 'if (length(getOption(""jupyter.plot_mimetypes"")) != 5) {stop(""missing jupyter.plot_mimetypes"")}'
+    R_MIMETYPES_CHECK_CMD = 'if (length(getOption(""jupyter.plot_mimetypes"")) != 5) {stop(""missing jupyter.plot_mimetypes"")}'
     logs = container.run_and_wait(
         timeout=10,
         tty=True,
-        command=[""Rscript"", ""-e"", Rcommand],
+        command=[""Rscript"", ""-e"", R_MIMETYPES_CHECK_CMD],
     )
     LOGGER.debug(f""{logs=}"")
-    assert len(logs) == 0, f""Command {Rcommand=} failed""
+    assert len(logs) == 0, f""Command {R_MIMETYPES_CHECK_CMD=} failed""",Yes
tests/conftest.py,tests/conftest.py,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/tests/conftest.py b/tests/conftest.py
index 0e592543..a151eb6b 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -78,8 +78,8 @@ class TrackedContainer:
         self.kwargs: Any = kwargs
 
     def run_detached(self, **kwargs: Any) -> Container:
-        """"""Runs a docker container using the preconfigured image name
-        and a mix of the preconfigured container options and those passed
+        """"""Runs a docker container using the pre-configured image name
+        and a mix of the pre-configured container options and those passed
         to this method.
 
         Keeps track of the docker.Container instance spawned to kill it","diff --git a/tests/conftest.py b/tests/conftest.py
index 0e592543..a151eb6b 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -78,8 +78,8 @@ class TrackedContainer:
         self.kwargs: Any = kwargs
 
     def run_detached(self, **kwargs: Any) -> Container:
-        """"""Runs a docker container using the preconfigured image name
-        and a mix of the preconfigured container options and those passed
+        """"""Runs a docker container using the pre-configured image name
+        and a mix of the pre-configured container options and those passed
         to this method.
 
         Keeps track of the docker.Container instance spawned to kill it",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index aa5c4bb9..4fee6428 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -4,7 +4,7 @@
 """"""
 test_packages
 ~~~~~~~~~~~~~~~
-This test module tests if R and Python packages installed can be imported.
+This test module tests if the R and Python packages installed can be imported.
 It's a basic test aiming to prove that the package is working properly.
 
 The goal is to detect import errors that can be caused by incompatibilities between packages, for example:","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index aa5c4bb9..4fee6428 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -4,7 +4,7 @@
 """"""
 test_packages
 ~~~~~~~~~~~~~~~
-This test module tests if R and Python packages installed can be imported.
+This test module tests if the R and Python packages installed can be imported.
 It's a basic test aiming to prove that the package is working properly.
 
 The goal is to detect import errors that can be caused by incompatibilities between packages, for example:",Yes
tests/run_tests.py,tests/run_tests.py,0a75e3d3a6f2450bf354e3014cfc071658d90884,d53e39763d5fc4b8ec97d9cbc76c783c46c8d244,Minor improvements,"diff --git a/tests/run_tests.py b/tests/run_tests.py
index 6263be6d..90529e77 100755
--- a/tests/run_tests.py
+++ b/tests/run_tests.py
@@ -39,7 +39,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to run test on"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--registry"",","diff --git a/tests/run_tests.py b/tests/run_tests.py
index 6263be6d..90529e77 100755
--- a/tests/run_tests.py
+++ b/tests/run_tests.py
@@ -39,7 +39,7 @@ if __name__ == ""__main__"":
     arg_parser.add_argument(
         ""--short-image-name"",
         required=True,
-        help=""Short image name to run test on"",
+        help=""Short image name"",
     )
     arg_parser.add_argument(
         ""--registry"",",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 2efad71b..064028d4 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -26,6 +26,7 @@ body:
         - julia-notebook
         - minimal-notebook
         - pyspark-notebook
+        - pytorch-notebook
         - r-notebook
         - scipy-notebook
         - tensorflow-notebook","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 2efad71b..064028d4 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -26,6 +26,7 @@ body:
         - julia-notebook
         - minimal-notebook
         - pyspark-notebook
+        - pytorch-notebook
         - r-notebook
         - scipy-notebook
         - tensorflow-notebook",Yes
.github/ISSUE_TEMPLATE/feature_request.yml,.github/ISSUE_TEMPLATE/feature_request.yml,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index 0fd90c04..f0da4062 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -24,6 +24,7 @@ body:
         - julia-notebook
         - minimal-notebook
         - pyspark-notebook
+        - pytorch-notebook
         - r-notebook
         - scipy-notebook
         - tensorflow-notebook","diff --git a/.github/ISSUE_TEMPLATE/feature_request.yml b/.github/ISSUE_TEMPLATE/feature_request.yml
index 0fd90c04..f0da4062 100644
--- a/.github/ISSUE_TEMPLATE/feature_request.yml
+++ b/.github/ISSUE_TEMPLATE/feature_request.yml
@@ -24,6 +24,7 @@ body:
         - julia-notebook
         - minimal-notebook
         - pyspark-notebook
+        - pytorch-notebook
         - r-notebook
         - scipy-notebook
         - tensorflow-notebook",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 350510cf..ddc26a82 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -99,6 +99,18 @@ runs:
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: pytorch-notebook-aarch64-history_line
+        path: ${{ inputs.hist-lines-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: pytorch-notebook-x86_64-history_line
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
@@ -216,6 +228,18 @@ runs:
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: pytorch-notebook-aarch64-manifest
+        path: ${{ inputs.manifests-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: pytorch-notebook-x86_64-manifest
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index 350510cf..ddc26a82 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -99,6 +99,18 @@ runs:
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: pytorch-notebook-aarch64-history_line
+        path: ${{ inputs.hist-lines-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: pytorch-notebook-x86_64-history_line
+        path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
@@ -216,6 +228,18 @@ runs:
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: pytorch-notebook-aarch64-manifest
+        path: ${{ inputs.manifests-dir }}
+    - name: Download artifact 📥
+      uses: actions/download-artifact@v3
+      if: inputs.fast-build == 'false'
+      with:
+        name: pytorch-notebook-x86_64-manifest
+        path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
       uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 4046c19b..9ab19659 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -198,6 +198,26 @@ jobs:
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
+  aarch64-pytorch:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: pytorch-notebook
+      platform: aarch64
+      runs-on: ARM64
+    needs: [aarch64-scipy]
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+
+  x86_64-pytorch:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: pytorch-notebook
+      platform: x86_64
+      runs-on: ubuntu-latest
+    needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
   aarch64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
@@ -277,6 +297,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,
@@ -290,6 +311,7 @@ jobs:
         aarch64-r,
         aarch64-julia,
         aarch64-tensorflow,
+        aarch64-pytorch,
         aarch64-datascience,
         aarch64-pyspark,
         aarch64-all-spark,
@@ -329,6 +351,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,
@@ -342,6 +365,7 @@ jobs:
         x86_64-r,
         x86_64-julia,
         x86_64-tensorflow,
+        x86_64-pytorch,
         x86_64-datascience,
         x86_64-pyspark,
         x86_64-all-spark,
@@ -380,6 +404,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 4046c19b..9ab19659 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -198,6 +198,26 @@ jobs:
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
+  aarch64-pytorch:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: pytorch-notebook
+      platform: aarch64
+      runs-on: ARM64
+    needs: [aarch64-scipy]
+    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+
+  x86_64-pytorch:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: pytorch-notebook
+      platform: x86_64
+      runs-on: ubuntu-latest
+    needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
   aarch64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
@@ -277,6 +297,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,
@@ -290,6 +311,7 @@ jobs:
         aarch64-r,
         aarch64-julia,
         aarch64-tensorflow,
+        aarch64-pytorch,
         aarch64-datascience,
         aarch64-pyspark,
         aarch64-all-spark,
@@ -329,6 +351,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,
@@ -342,6 +365,7 @@ jobs:
         x86_64-r,
         x86_64-julia,
         x86_64-tensorflow,
+        x86_64-pytorch,
         x86_64-datascience,
         x86_64-pyspark,
         x86_64-all-spark,
@@ -380,6 +404,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,",Yes
.github/workflows/registry-move.yml,.github/workflows/registry-move.yml,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index e5c37c91..09ef3d28 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -51,6 +51,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,","diff --git a/.github/workflows/registry-move.yml b/.github/workflows/registry-move.yml
index e5c37c91..09ef3d28 100644
--- a/.github/workflows/registry-move.yml
+++ b/.github/workflows/registry-move.yml
@@ -51,6 +51,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,",Yes
.github/workflows/registry-overviews.yml,.github/workflows/registry-overviews.yml,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/.github/workflows/registry-overviews.yml b/.github/workflows/registry-overviews.yml
index f4914300..91a6b1f4 100644
--- a/.github/workflows/registry-overviews.yml
+++ b/.github/workflows/registry-overviews.yml
@@ -42,6 +42,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,","diff --git a/.github/workflows/registry-overviews.yml b/.github/workflows/registry-overviews.yml
index f4914300..91a6b1f4 100644
--- a/.github/workflows/registry-overviews.yml
+++ b/.github/workflows/registry-overviews.yml
@@ -42,6 +42,7 @@ jobs:
             r-notebook,
             julia-notebook,
             tensorflow-notebook,
+            pytorch-notebook,
             datascience-notebook,
             pyspark-notebook,
             all-spark-notebook,",Yes
Makefile,Makefile,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/Makefile b/Makefile
index e79f133f..6e28f762 100644
--- a/Makefile
+++ b/Makefile
@@ -17,6 +17,7 @@ ALL_IMAGES:= \
 	julia-notebook \
 	scipy-notebook \
 	tensorflow-notebook \
+	pytorch-notebook \
 	datascience-notebook \
 	pyspark-notebook \
 	all-spark-notebook","diff --git a/Makefile b/Makefile
index e79f133f..6e28f762 100644
--- a/Makefile
+++ b/Makefile
@@ -17,6 +17,7 @@ ALL_IMAGES:= \
 	julia-notebook \
 	scipy-notebook \
 	tensorflow-notebook \
+	pytorch-notebook \
 	datascience-notebook \
 	pyspark-notebook \
 	all-spark-notebook",Yes
docs/images/inherit.svg,docs/images/inherit.svg,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/docs/images/inherit.svg b/docs/images/inherit.svg
index 0f5467a4..5324df89 100644
--- a/docs/images/inherit.svg
+++ b/docs/images/inherit.svg
@@ -1,6 +1,6 @@
 <?xml version='1.0' encoding='UTF-8'?>
 <!DOCTYPE svg PUBLIC ""-//W3C//DTD SVG 1.0//EN"" ""http://www.w3.org/TR/2001/REC-SVG-20010904/DTD/svg10.dtd"">
-<svg viewBox=""0 0 640 600"" xmlns=""http://www.w3.org/2000/svg"" xmlns:inkspace=""http://www.inkscape.org/namespaces/inkscape"" xmlns:xlink=""http://www.w3.org/1999/xlink"">
+<svg viewBox=""0 0 832 600"" xmlns=""http://www.w3.org/2000/svg"" xmlns:inkspace=""http://www.inkscape.org/namespaces/inkscape"" xmlns:xlink=""http://www.w3.org/1999/xlink"">
   <defs id=""defs_block"">
     <filter height=""1.504"" id=""filter_blur"" inkspace:collect=""always"" width=""1.1575"" x=""-0.07875"" y=""-0.252"">
       <feGaussianBlur id=""feGaussianBlur3780"" inkspace:collect=""always"" stdDeviation=""4.2"" />
@@ -18,7 +18,8 @@
   <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""67"" y=""446"" />
   <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""259"" y=""446"" />
   <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""451"" y=""446"" />
-  <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""451"" y=""526"" />
+  <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""643"" y=""446"" />
+  <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""643"" y=""526"" />
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""64"" y=""40"" />
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""30"" x=""128"" y=""59"">ubuntu</text>
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""119"" x=""128"" y=""70"">(LTS with point release)</text>
@@ -37,37 +38,43 @@
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""64"" y=""440"" />
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""95"" x=""128"" y=""465"">tensorflow-notebook</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""256"" y=""440"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""100"" x=""320"" y=""465"">datascience-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""320"" y=""465"">pytorch-notebook</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""448"" y=""440"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""512"" y=""465"">pyspark-notebook</text>
-  <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""448"" y=""520"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""90"" x=""512"" y=""545"">all-spark-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""100"" x=""512"" y=""465"">datascience-notebook</text>
+  <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""640"" y=""440"" />
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""704"" y=""465"">pyspark-notebook</text>
+  <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""640"" y=""520"" />
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""90"" x=""704"" y=""545"">all-spark-notebook</text>
   <path d=""M 128 80 L 128 112"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""128,119 124,112 132,112 128,119"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 160 L 128 192"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""128,199 124,192 132,192 128,199"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 240 L 128 272"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""128,279 124,272 132,272 128,279"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 320 L 128 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""128,359 124,352 132,352 128,359"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 320 L 128 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 340 L 320 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 320 340 L 320 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""320,359 316,352 324,352 320,359"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 320 L 128 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""128,359 124,352 132,352 128,359"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 320 L 128 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 340 L 512 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 512 340 L 512 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""512,359 508,352 516,352 512,359"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 400 L 128 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""128,439 124,432 132,432 128,439"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 420 L 704 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 704 420 L 704 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""704,439 700,432 708,432 704,439"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 420 L 512 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 512 420 L 512 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""512,439 508,432 516,432 512,439"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 400 L 128 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""128,439 124,432 132,432 128,439"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 420 L 320 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 320 420 L 320 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""320,439 316,432 324,432 320,439"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 512 480 L 512 512"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""512,519 508,512 516,512 512,519"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 704 480 L 704 512"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""704,519 700,512 708,512 704,519"" stroke=""rgb(0,0,0)"" />
 </svg>","diff --git a/docs/images/inherit.svg b/docs/images/inherit.svg
index 0f5467a4..5324df89 100644
--- a/docs/images/inherit.svg
+++ b/docs/images/inherit.svg
@@ -1,6 +1,6 @@
 <?xml version='1.0' encoding='UTF-8'?>
 <!DOCTYPE svg PUBLIC ""-//W3C//DTD SVG 1.0//EN"" ""http://www.w3.org/TR/2001/REC-SVG-20010904/DTD/svg10.dtd"">
-<svg viewBox=""0 0 640 600"" xmlns=""http://www.w3.org/2000/svg"" xmlns:inkspace=""http://www.inkscape.org/namespaces/inkscape"" xmlns:xlink=""http://www.w3.org/1999/xlink"">
+<svg viewBox=""0 0 832 600"" xmlns=""http://www.w3.org/2000/svg"" xmlns:inkspace=""http://www.inkscape.org/namespaces/inkscape"" xmlns:xlink=""http://www.w3.org/1999/xlink"">
   <defs id=""defs_block"">
     <filter height=""1.504"" id=""filter_blur"" inkspace:collect=""always"" width=""1.1575"" x=""-0.07875"" y=""-0.252"">
       <feGaussianBlur id=""feGaussianBlur3780"" inkspace:collect=""always"" stdDeviation=""4.2"" />
@@ -18,7 +18,8 @@
   <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""67"" y=""446"" />
   <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""259"" y=""446"" />
   <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""451"" y=""446"" />
-  <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""451"" y=""526"" />
+  <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""643"" y=""446"" />
+  <rect fill=""rgb(0,0,0)"" height=""40"" stroke=""rgb(0,0,0)"" style=""filter:url(#filter_blur);opacity:0.7;fill-opacity:1"" width=""128"" x=""643"" y=""526"" />
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""64"" y=""40"" />
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""30"" x=""128"" y=""59"">ubuntu</text>
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""119"" x=""128"" y=""70"">(LTS with point release)</text>
@@ -37,37 +38,43 @@
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""64"" y=""440"" />
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""95"" x=""128"" y=""465"">tensorflow-notebook</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""256"" y=""440"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""100"" x=""320"" y=""465"">datascience-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""320"" y=""465"">pytorch-notebook</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""448"" y=""440"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""512"" y=""465"">pyspark-notebook</text>
-  <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""448"" y=""520"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""90"" x=""512"" y=""545"">all-spark-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""100"" x=""512"" y=""465"">datascience-notebook</text>
+  <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""640"" y=""440"" />
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""704"" y=""465"">pyspark-notebook</text>
+  <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""640"" y=""520"" />
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""90"" x=""704"" y=""545"">all-spark-notebook</text>
   <path d=""M 128 80 L 128 112"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""128,119 124,112 132,112 128,119"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 160 L 128 192"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""128,199 124,192 132,192 128,199"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 240 L 128 272"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""128,279 124,272 132,272 128,279"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 320 L 128 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""128,359 124,352 132,352 128,359"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 320 L 128 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 340 L 320 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 320 340 L 320 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""320,359 316,352 324,352 320,359"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 320 L 128 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""128,359 124,352 132,352 128,359"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 320 L 128 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 340 L 512 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 512 340 L 512 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""512,359 508,352 516,352 512,359"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 400 L 128 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""128,439 124,432 132,432 128,439"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 420 L 704 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 704 420 L 704 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""704,439 700,432 708,432 704,439"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 420 L 512 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 512 420 L 512 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""512,439 508,432 516,432 512,439"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 400 L 128 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""128,439 124,432 132,432 128,439"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 420 L 320 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 320 420 L 320 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""320,439 316,432 324,432 320,439"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 512 480 L 512 512"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""512,519 508,512 516,512 512,519"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 704 480 L 704 512"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""704,519 700,512 708,512 704,519"" stroke=""rgb(0,0,0)"" />
 </svg>",Yes
docs/using/selecting.md,docs/using/selecting.md,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 08f84f8c..27399303 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -187,6 +187,17 @@ It contains:
 - Everything in `jupyter/scipy-notebook` and its ancestor images
 - [tensorflow](https://www.tensorflow.org/) machine learning library
 
+### jupyter/pytorch-notebook
+
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/pytorch-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/pytorch-notebook/Dockerfile) |
+[Quay.io image tags](https://quay.io/repository/jupyter/pytorch-notebook?tab=tags)
+
+`jupyter/pytorch-notebook` includes popular Python deep learning libraries.
+
+- Everything in `jupyter/scipy-notebook` and its ancestor images
+- [pytorch](https://pytorch.org/) machine learning library
+
 ### jupyter/datascience-notebook
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |
@@ -234,7 +245,7 @@ The following diagram depicts the build dependency tree of the core images. (i.e
 Any given image inherits the complete content of all ancestor images pointing to it.
 
 [![Image inheritance
-diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=deflate&src=eJyFjkFuwkAMRfecwsqKLuYACMEJuqPLSshJHDAZ7GjGIwSIuzPTRaWJWmX7_vP_br12Y894gucKoKcBk7fjoGKRHwQ72Gwz18AkhsYqGU0aLCDbdpWjJrVJLH3L-vPrADe2c85ZDAJ5wkgfDbg99HmFgouG3RjdoEn6n7ZS_l9W7trc4ESNWtWxyBUoxpWFr-grac6KFzue7pVVk-I0RhI1DF5vv7z5W80vYqYkHS1Oh0XjkjzjwnPTPU4Yxsqas-Kh925uvt4imKoO)
+diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=deflate&src=eJyFz8FOwzAMgOH7nsLqCQ55ADTBE3CDIxJyU5eZZnaUOJoK2rsv4YCUSlOvv784yRjULxPjF_weACaasQT7nFUs8w_BMzwda9fEJIbGKjVFTZaQ7Xioo6GMRax8yMPr-xtc2E51zmKQKBBmehzAvcBUb6HksqFfspu1yPS3rS2_N2vnxrrBiRqNqkvDXWjizMJnDB3atuay57h2qi_NDEaSNc1BL_99uEPjapr8ac_Vr2CtJJ52n5h2xXcJjDufiGuOmJZObVtzGILbyusNkda3zw)
 
 ### Builds","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 08f84f8c..27399303 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -187,6 +187,17 @@ It contains:
 - Everything in `jupyter/scipy-notebook` and its ancestor images
 - [tensorflow](https://www.tensorflow.org/) machine learning library
 
+### jupyter/pytorch-notebook
+
+[Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/pytorch-notebook) |
+[Dockerfile commit history](https://github.com/jupyter/docker-stacks/commits/main/images/pytorch-notebook/Dockerfile) |
+[Quay.io image tags](https://quay.io/repository/jupyter/pytorch-notebook?tab=tags)
+
+`jupyter/pytorch-notebook` includes popular Python deep learning libraries.
+
+- Everything in `jupyter/scipy-notebook` and its ancestor images
+- [pytorch](https://pytorch.org/) machine learning library
+
 ### jupyter/datascience-notebook
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |
@@ -234,7 +245,7 @@ The following diagram depicts the build dependency tree of the core images. (i.e
 Any given image inherits the complete content of all ancestor images pointing to it.
 
 [![Image inheritance
-diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=deflate&src=eJyFjkFuwkAMRfecwsqKLuYACMEJuqPLSshJHDAZ7GjGIwSIuzPTRaWJWmX7_vP_br12Y894gucKoKcBk7fjoGKRHwQ72Gwz18AkhsYqGU0aLCDbdpWjJrVJLH3L-vPrADe2c85ZDAJ5wkgfDbg99HmFgouG3RjdoEn6n7ZS_l9W7trc4ESNWtWxyBUoxpWFr-grac6KFzue7pVVk-I0RhI1DF5vv7z5W80vYqYkHS1Oh0XjkjzjwnPTPU4Yxsqas-Kh925uvt4imKoO)
+diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=deflate&src=eJyFz8FOwzAMgOH7nsLqCQ55ADTBE3CDIxJyU5eZZnaUOJoK2rsv4YCUSlOvv784yRjULxPjF_weACaasQT7nFUs8w_BMzwda9fEJIbGKjVFTZaQ7Xioo6GMRax8yMPr-xtc2E51zmKQKBBmehzAvcBUb6HksqFfspu1yPS3rS2_N2vnxrrBiRqNqkvDXWjizMJnDB3atuay57h2qi_NDEaSNc1BL_99uEPjapr8ac_Vr2CtJJ52n5h2xXcJjDufiGuOmJZObVtzGILbyusNkda3zw)
 
 ### Builds",Yes
,images/pytorch-notebook/.dockerignore,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/images/pytorch-notebook/.dockerignore b/images/pytorch-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/pytorch-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md","diff --git a/images/pytorch-notebook/.dockerignore b/images/pytorch-notebook/.dockerignore
new file mode 100644
index 00000000..9dea340f
--- /dev/null
+++ b/images/pytorch-notebook/.dockerignore
@@ -0,0 +1,2 @@
+# Documentation
+README.md",Yes
,images/pytorch-notebook/Dockerfile,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/images/pytorch-notebook/Dockerfile b/images/pytorch-notebook/Dockerfile
new file mode 100644
index 00000000..f1a5c540
--- /dev/null
+++ b/images/pytorch-notebook/Dockerfile
@@ -0,0 +1,21 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=quay.io
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install PyTorch with pip
+# hadolint ignore=DL3013
+RUN pip install --no-cache-dir --index-url 'https://download.pytorch.org/whl/cpu' \
+    'torch' \
+    'torchvision' \
+    'torchaudio'  && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""","diff --git a/images/pytorch-notebook/Dockerfile b/images/pytorch-notebook/Dockerfile
new file mode 100644
index 00000000..f1a5c540
--- /dev/null
+++ b/images/pytorch-notebook/Dockerfile
@@ -0,0 +1,21 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=quay.io
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install PyTorch with pip
+# hadolint ignore=DL3013
+RUN pip install --no-cache-dir --index-url 'https://download.pytorch.org/whl/cpu' \
+    'torch' \
+    'torchvision' \
+    'torchaudio'  && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""",Yes
,images/pytorch-notebook/README.md,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/images/pytorch-notebook/README.md b/images/pytorch-notebook/README.md
new file mode 100644
index 00000000..72cc65c1
--- /dev/null
+++ b/images/pytorch-notebook/README.md
@@ -0,0 +1,8 @@
+# Jupyter Notebook Deep Learning Stack
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/pytorch-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-pytorch-notebook)","diff --git a/images/pytorch-notebook/README.md b/images/pytorch-notebook/README.md
new file mode 100644
index 00000000..72cc65c1
--- /dev/null
+++ b/images/pytorch-notebook/README.md
@@ -0,0 +1,8 @@
+# Jupyter Notebook Deep Learning Stack
+
+GitHub Actions in the <https://github.com/jupyter/docker-stacks> project builds and pushes this image to the Registry.
+
+Please visit the project documentation site for help to use and contribute to this image and others.
+
+- [Jupyter Docker Stacks on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/index.html)
+- [Selecting an Image :: Core Stacks :: jupyter/pytorch-notebook](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-pytorch-notebook)",Yes
mypy.ini,mypy.ini,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/mypy.ini b/mypy.ini
index decc686c..3e20bf5b 100644
--- a/mypy.ini
+++ b/mypy.ini
@@ -41,3 +41,6 @@ ignore_missing_imports = True
 
 [mypy-tensorflow.*]
 ignore_missing_imports = True
+
+[mypy-torch.*]
+ignore_missing_imports = True","diff --git a/mypy.ini b/mypy.ini
index decc686c..3e20bf5b 100644
--- a/mypy.ini
+++ b/mypy.ini
@@ -41,3 +41,6 @@ ignore_missing_imports = True
 
 [mypy-tensorflow.*]
 ignore_missing_imports = True
+
+[mypy-torch.*]
+ignore_missing_imports = True",Yes
tagging/images_hierarchy.py,tagging/images_hierarchy.py,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/tagging/images_hierarchy.py b/tagging/images_hierarchy.py
index 7a083198..f4145876 100644
--- a/tagging/images_hierarchy.py
+++ b/tagging/images_hierarchy.py
@@ -21,6 +21,7 @@ from tagging.taggers import (
     JupyterNotebookVersionTagger,
     PythonMajorMinorVersionTagger,
     PythonVersionTagger,
+    PytorchVersionTagger,
     RVersionTagger,
     SHATagger,
     SparkVersionTagger,
@@ -72,6 +73,9 @@ ALL_IMAGES = {
     ""tensorflow-notebook"": ImageDescription(
         parent_image=""scipy-notebook"", taggers=[TensorflowVersionTagger()]
     ),
+    ""pytorch-notebook"": ImageDescription(
+        parent_image=""scipy-notebook"", taggers=[PytorchVersionTagger()]
+    ),
     ""datascience-notebook"": ImageDescription(
         parent_image=""scipy-notebook"",
         taggers=[RVersionTagger(), JuliaVersionTagger()],","diff --git a/tagging/images_hierarchy.py b/tagging/images_hierarchy.py
index 7a083198..f4145876 100644
--- a/tagging/images_hierarchy.py
+++ b/tagging/images_hierarchy.py
@@ -21,6 +21,7 @@ from tagging.taggers import (
     JupyterNotebookVersionTagger,
     PythonMajorMinorVersionTagger,
     PythonVersionTagger,
+    PytorchVersionTagger,
     RVersionTagger,
     SHATagger,
     SparkVersionTagger,
@@ -72,6 +73,9 @@ ALL_IMAGES = {
     ""tensorflow-notebook"": ImageDescription(
         parent_image=""scipy-notebook"", taggers=[TensorflowVersionTagger()]
     ),
+    ""pytorch-notebook"": ImageDescription(
+        parent_image=""scipy-notebook"", taggers=[PytorchVersionTagger()]
+    ),
     ""datascience-notebook"": ImageDescription(
         parent_image=""scipy-notebook"",
         taggers=[RVersionTagger(), JuliaVersionTagger()],",Yes
tagging/taggers.py,tagging/taggers.py,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/tagging/taggers.py b/tagging/taggers.py
index 85537117..0aee5188 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -113,6 +113,12 @@ class TensorflowVersionTagger(TaggerInterface):
         return ""tensorflow-"" + _get_pip_package_version(container, ""tensorflow"")
 
 
+class PytorchVersionTagger(TaggerInterface):
+    @staticmethod
+    def tag_value(container: Container) -> str:
+        return ""pytorch-"" + _get_pip_package_version(container, ""torch"").split(""+"")[0]
+
+
 class JuliaVersionTagger(TaggerInterface):
     @staticmethod
     def tag_value(container: Container) -> str:","diff --git a/tagging/taggers.py b/tagging/taggers.py
index 85537117..0aee5188 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -113,6 +113,12 @@ class TensorflowVersionTagger(TaggerInterface):
         return ""tensorflow-"" + _get_pip_package_version(container, ""tensorflow"")
 
 
+class PytorchVersionTagger(TaggerInterface):
+    @staticmethod
+    def tag_value(container: Container) -> str:
+        return ""pytorch-"" + _get_pip_package_version(container, ""torch"").split(""+"")[0]
+
+
 class JuliaVersionTagger(TaggerInterface):
     @staticmethod
     def tag_value(container: Container) -> str:",Yes
tests/images_hierarchy.py,tests/images_hierarchy.py,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/tests/images_hierarchy.py b/tests/images_hierarchy.py
index fc0240cd..193ec270 100644
--- a/tests/images_hierarchy.py
+++ b/tests/images_hierarchy.py
@@ -15,6 +15,7 @@ ALL_IMAGES = {
     ""r-notebook"": ""minimal-notebook"",
     ""julia-notebook"": ""minimal-notebook"",
     ""tensorflow-notebook"": ""scipy-notebook"",
+    ""pytorch-notebook"": ""scipy-notebook"",
     ""datascience-notebook"": ""scipy-notebook"",
     ""pyspark-notebook"": ""scipy-notebook"",
     ""all-spark-notebook"": ""pyspark-notebook"",","diff --git a/tests/images_hierarchy.py b/tests/images_hierarchy.py
index fc0240cd..193ec270 100644
--- a/tests/images_hierarchy.py
+++ b/tests/images_hierarchy.py
@@ -15,6 +15,7 @@ ALL_IMAGES = {
     ""r-notebook"": ""minimal-notebook"",
     ""julia-notebook"": ""minimal-notebook"",
     ""tensorflow-notebook"": ""scipy-notebook"",
+    ""pytorch-notebook"": ""scipy-notebook"",
     ""datascience-notebook"": ""scipy-notebook"",
     ""pyspark-notebook"": ""scipy-notebook"",
     ""all-spark-notebook"": ""pyspark-notebook"",",Yes
,tests/pytorch-notebook/units/unit_pytorch.py,278dd768377fb5c3001404f7f8c3cde3c0960b0f,0a75e3d3a6f2450bf354e3014cfc071658d90884,"Add jupyter/pytorch-notebook (#1936)

* Add PyTorch image

* Fix linting errors

* Fix link to pytorch website

* Address review comments

* Fix PytorchVersionTagger

* Remove ""+cpu"" suffix from pytorch version tag

* Update selecting.md

* Rename pytorch-notebook/.dockerignore to images/pytorch-notebook/.dockerignore

* Rename pytorch-notebook/Dockerfile to images/pytorch-notebook/Dockerfile

* Rename pytorch-notebook/README.md to images/pytorch-notebook/README.md

* Add pytorch-notebook to registry-overviews

* Add registry to pytorch image

* Use Quay.io

* Remove incorrect link

* Update action.yml

* Update docker.yml

* Remove information about Docker Hub, because this image won't be uploaded to Docker Hub

* Update docker.yml

* Update action.yml

* Add pytorch-notebook to registry-move.yml

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@gmail.com>","diff --git a/tests/pytorch-notebook/units/unit_pytorch.py b/tests/pytorch-notebook/units/unit_pytorch.py
new file mode 100644
index 00000000..1b739a59
--- /dev/null
+++ b/tests/pytorch-notebook/units/unit_pytorch.py
@@ -0,0 +1,5 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import torch
+
+print(torch.tensor([[1.0, 4.0, 7.0], [4.0, 9.0, 11.0]]))","diff --git a/tests/pytorch-notebook/units/unit_pytorch.py b/tests/pytorch-notebook/units/unit_pytorch.py
new file mode 100644
index 00000000..1b739a59
--- /dev/null
+++ b/tests/pytorch-notebook/units/unit_pytorch.py
@@ -0,0 +1,5 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import torch
+
+print(torch.tensor([[1.0, 4.0, 7.0], [4.0, 9.0, 11.0]]))",Yes
docs/maintaining/tasks.md,docs/maintaining/tasks.md,406e397d43c6b29ec8e8702de5ad8238cf9a2e97,278dd768377fb5c3001404f7f8c3cde3c0960b0f,Add info about robot permission when adding a new image,"diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index ba2bca73..274bded7 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -58,6 +58,7 @@ When there's a new stack definition, check before merging the PR:
    in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
 4. A new repository is created in the `jupyter` organization in the Registry,
    and it's named after the stack folder in the git repo.
+5. Robot `Write` permission is added in the `Repository Settings`.
 
 ## Adding a New Registry Owner Account","diff --git a/docs/maintaining/tasks.md b/docs/maintaining/tasks.md
index ba2bca73..274bded7 100644
--- a/docs/maintaining/tasks.md
+++ b/docs/maintaining/tasks.md
@@ -58,6 +58,7 @@ When there's a new stack definition, check before merging the PR:
    in the [tagging](https://github.com/jupyter/docker-stacks/tree/main/tagging) folder.
 4. A new repository is created in the `jupyter` organization in the Registry,
    and it's named after the stack folder in the git repo.
+5. Robot `Write` permission is added in the `Repository Settings`.
 
 ## Adding a New Registry Owner Account",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,baa110d3f9855f18d8e5db317f48a9591c06cc6b,406e397d43c6b29ec8e8702de5ad8238cf9a2e97,"Remove environment variable XDG_CACHE_HOME (#2038)

- Fixes https://github.com/jupyter/docker-stacks/issues/2037","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 688c4586..76419b60 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -121,9 +121,6 @@ if [ ""$(id -u)"" == 0 ]; then
         done
     fi
 
-    # Update potentially outdated environment variables since the image build
-    export XDG_CACHE_HOME=""/home/${NB_USER}/.cache""
-
     # Prepend ${CONDA_DIR}/bin to sudo secure_path
     sed -r ""s#Defaults\s+secure_path\s*=\s*\""?([^\""]+)\""?#Defaults secure_path=\""${CONDA_DIR}/bin:\1\""#"" /etc/sudoers | grep secure_path > /etc/sudoers.d/path","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 688c4586..76419b60 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -121,9 +121,6 @@ if [ ""$(id -u)"" == 0 ]; then
         done
     fi
 
-    # Update potentially outdated environment variables since the image build
-    export XDG_CACHE_HOME=""/home/${NB_USER}/.cache""
-
     # Prepend ${CONDA_DIR}/bin to sudo secure_path
     sed -r ""s#Defaults\s+secure_path\s*=\s*\""?([^\""]+)\""?#Defaults secure_path=\""${CONDA_DIR}/bin:\1\""#"" /etc/sudoers | grep secure_path > /etc/sudoers.d/path",Yes
images/scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,baa110d3f9855f18d8e5db317f48a9591c06cc6b,406e397d43c6b29ec8e8702de5ad8238cf9a2e97,"Remove environment variable XDG_CACHE_HOME (#2038)

- Fixes https://github.com/jupyter/docker-stacks/issues/2037","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 8b687eb7..55bf7eb5 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -74,9 +74,6 @@ RUN git clone https://github.com/PAIR-code/facets && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Import matplotlib the first time to build the font cache.
-ENV XDG_CACHE_HOME=""/home/${NB_USER}/.cache/""
-
 RUN MPLBACKEND=Agg python -c ""import matplotlib.pyplot"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 8b687eb7..55bf7eb5 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -74,9 +74,6 @@ RUN git clone https://github.com/PAIR-code/facets && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Import matplotlib the first time to build the font cache.
-ENV XDG_CACHE_HOME=""/home/${NB_USER}/.cache/""
-
 RUN MPLBACKEND=Agg python -c ""import matplotlib.pyplot"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
images/scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,d91bb62be0cb525529e6028d9dfcb53d20775fe5,baa110d3f9855f18d8e5db317f48a9591c06cc6b,Add comment about building font cache back,"diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 55bf7eb5..6f14a27a 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -74,6 +74,7 @@ RUN git clone https://github.com/PAIR-code/facets && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
+# Import matplotlib the first time to build the font cache
 RUN MPLBACKEND=Agg python -c ""import matplotlib.pyplot"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 55bf7eb5..6f14a27a 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -74,6 +74,7 @@ RUN git clone https://github.com/PAIR-code/facets && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
+# Import matplotlib the first time to build the font cache
 RUN MPLBACKEND=Agg python -c ""import matplotlib.pyplot"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
images/minimal-notebook/setup-scripts/setup-julia-packages.bash,images/minimal-notebook/setup-scripts/setup-julia-packages.bash,99d306450edf23e0d2dba4c26d361d2d8127912c,d91bb62be0cb525529e6028d9dfcb53d20775fe5,"Specify multiple architectures for Julia to precompile to (#2044)

* Specify multiple architectures for Julia to precompile to

For amd64 (x86_64), we should specify what specific targets the
precompilation should be done for.  If we don't specify it,
it's *only* done for the target of the host doing the compilation.
When the container runs on a host that's still x86_64, but
a *different* generation of CPU than what the build host was, the
precompilation is useless and Julia takes a long long time to start
up. This specific multitarget comes from
https://docs.julialang.org/en/v1/devdocs/sysimg/#Specifying-multiple-system-image-targets,
and is the same set of options that the official Julia x86_64 build is
compiled with.  If the architecture the container runs on is
different, precompilation may still have to be re-done on first
startup - but this *should* catch most of the issues.

h/t to
https://discourse.julialang.org/t/is-it-possible-to-make-precompilation-portable-for-docker-images-built-with-a-different-cpu/95913
which helped point me towards `JULIA_CPU_TARGET`.

Fixes https://github.com/jupyter/docker-stacks/issues/2015 for more information

* Fix bash syntax issue

* Add JULIA_CPU_TARGET for aarch64 as well

- Don't need `export` as this is only used within this
  script
- Steal from upstream what should be setup for aarch64

* Re-add export for JULIA_CPU_TARGET

Quietens pre-commit","diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 16adb428..fa1421e9 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -5,6 +5,28 @@ set -exuo pipefail
 # - The JULIA_PKGDIR environment variable is set
 # - Julia is already set up, with the setup-julia.bash command
 
+
+# If we don't specify what CPUs the precompilation should be done for, it's
+# *only* done for the target of the host doing the compilation.  When the
+# container runs on a host that's the same architecture, but a *different*
+# generation of CPU than what the build host was, the precompilation is useless
+# and Julia takes a long long time to start up. This specific multitarget comes
+# from https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L20-L76,
+# and may need to be updated as new CPU generations come out.
+# If the architecture the container runs on is different,
+# precompilation may still have to be re-done on first startup - but this
+# *should* catch most of the issues.  See
+# https://github.com/jupyter/docker-stacks/issues/2015 for more information
+if [ ""$(uname -m)"" == ""x86_64"" ]; then
+    # See https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L24
+    # for an explanation of these options
+    export JULIA_CPU_TARGET=""generic;sandybridge,-xsaveopt,clone_all;haswell,-rdrnd,base(1)""
+elif [ ""$(uname -m)"" == ""aarch64"" ]; then
+    # See https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L54
+    # for an explanation of these options
+    export JULIA_CPU_TARGET=""generic;cortex-a57;thunderx2t99;carmel""
+fi
+
 # Install base Julia packages
 julia -e '
 import Pkg;","diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 16adb428..fa1421e9 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -5,6 +5,28 @@ set -exuo pipefail
 # - The JULIA_PKGDIR environment variable is set
 # - Julia is already set up, with the setup-julia.bash command
 
+
+# If we don't specify what CPUs the precompilation should be done for, it's
+# *only* done for the target of the host doing the compilation.  When the
+# container runs on a host that's the same architecture, but a *different*
+# generation of CPU than what the build host was, the precompilation is useless
+# and Julia takes a long long time to start up. This specific multitarget comes
+# from https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L20-L76,
+# and may need to be updated as new CPU generations come out.
+# If the architecture the container runs on is different,
+# precompilation may still have to be re-done on first startup - but this
+# *should* catch most of the issues.  See
+# https://github.com/jupyter/docker-stacks/issues/2015 for more information
+if [ ""$(uname -m)"" == ""x86_64"" ]; then
+    # See https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L24
+    # for an explanation of these options
+    export JULIA_CPU_TARGET=""generic;sandybridge,-xsaveopt,clone_all;haswell,-rdrnd,base(1)""
+elif [ ""$(uname -m)"" == ""aarch64"" ]; then
+    # See https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L54
+    # for an explanation of these options
+    export JULIA_CPU_TARGET=""generic;cortex-a57;thunderx2t99;carmel""
+fi
+
 # Install base Julia packages
 julia -e '
 import Pkg;",Yes
README.md,README.md,72601cbd689869181dd5636b9efbf20f70639a70,99d306450edf23e0d2dba4c26d361d2d8127912c,"Add acknowledgement of me :) (#2033)

* Add acknowledgement of me :)

* Fix link

* Update README.md","diff --git a/README.md b/README.md
index 5d4f1621..43dac093 100644
--- a/README.md
+++ b/README.md
@@ -90,6 +90,8 @@ more information is available in the [documentation](https://jupyter-docker-stac
 
 ## Acknowledgments
 
+- Starting from `2022-07-05`, `aarch64` self-hosted runners were sponsored by [`@mathbunnyru`](https://github.com/mathbunnyru/).
+  Please, consider [sponsoring his work](https://github.com/sponsors/mathbunnyru) on GitHub
 - Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by an amazing [`2i2c non-profit organization`](https://2i2c.org)
 
 ## CPU Architectures","diff --git a/README.md b/README.md
index 5d4f1621..43dac093 100644
--- a/README.md
+++ b/README.md
@@ -90,6 +90,8 @@ more information is available in the [documentation](https://jupyter-docker-stac
 
 ## Acknowledgments
 
+- Starting from `2022-07-05`, `aarch64` self-hosted runners were sponsored by [`@mathbunnyru`](https://github.com/mathbunnyru/).
+  Please, consider [sponsoring his work](https://github.com/sponsors/mathbunnyru) on GitHub
 - Starting from `2023-10-31`, `aarch64` self-hosted runners are sponsored by an amazing [`2i2c non-profit organization`](https://2i2c.org)
 
 ## CPU Architectures",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,2927745fb23de0a14ae3442884d5160f26b0bf9d,72601cbd689869181dd5636b9efbf20f70639a70,Add order of precedence for spark-config script,"diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 9346c43c..87b03048 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -58,7 +58,7 @@ RUN if [ -z ""${scala_version}"" ]; then \
     ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}"" ""${SPARK_HOME}""; \
   fi && \
   # Add a link in the before_notebook hook in order to source automatically PYTHONPATH && \
-  ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/spark-config.sh
+  ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/10spark-config.sh
 
 # Configure IPython system-wide
 COPY ipython_kernel_config.py ""/etc/ipython/""","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 9346c43c..87b03048 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -58,7 +58,7 @@ RUN if [ -z ""${scala_version}"" ]; then \
     ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}"" ""${SPARK_HOME}""; \
   fi && \
   # Add a link in the before_notebook hook in order to source automatically PYTHONPATH && \
-  ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/spark-config.sh
+  ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/10spark-config.sh
 
 # Configure IPython system-wide
 COPY ipython_kernel_config.py ""/etc/ipython/""",Yes
docs/using/recipe_code/custom_environment.dockerfile,docs/using/recipe_code/custom_environment.dockerfile,3253fc39b56fcfc08baf1a2aa59161e2cf8fa994,2927745fb23de0a14ae3442884d5160f26b0bf9d,"Fix conda hook to work in both terminal and Jupyter Notebook (#2047)

* Fix conda hook to work in both terminal and Jupyter Notebook

* Fix hook for Jupyter Terminals

* Rename startup hook to have order of precedence

* Try to increase sleep

* Comment making env_name default in custom_environment","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index e53c9690..9fd94b01 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -28,17 +28,16 @@ RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --nam
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
     'flake8'
 
-# Creating a startup hook, which will activate our custom environment by default in Jupyter Notebook
-# More info about startup hooks: https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#startup-hooks
-# You can comment this section to keep the default environment in Jupyter Notebook
-USER root
-RUN activate_custom_env_script=/usr/local/bin/before-notebook.d/activate_custom_env.sh && \
-    echo ""#!/bin/bash"" > ${activate_custom_env_script} && \
-    echo ""eval \""$(conda shell.bash activate ""${env_name}"")\"""" >> ${activate_custom_env_script} && \
-    chmod +x ${activate_custom_env_script}
+# Uncomment this section to activate custom environment by default
+# Note: uncommenting this section makes ""${env_name}"" default both for Jupyter Notebook and Terminals
+# More information here: https://github.com/jupyter/docker-stacks/pull/2047
+# USER root
+# RUN \
+#     # This changes a startup hook, which will activate our custom environment for the process
+#     echo conda activate ""${env_name}"" >> /usr/local/bin/before-notebook.d/10activate-conda-env.sh && \
+#     # This makes the custom environment default in Jupyter Terminals for all users which might be created later
+#     echo conda activate ""${env_name}"" >> /etc/skel/.bashrc && \
+#     # This makes the custom environment default in Jupyter Terminals for already existing NB_USER
+#     echo conda activate ""${env_name}"" >> ""/home/${NB_USER}/.bashrc""
 
 USER ${NB_UID}
-
-# Making this environment default in Terminal
-# You can comment this line to keep the default environment in a Terminal
-RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index e53c9690..9fd94b01 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -28,17 +28,16 @@ RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --nam
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
     'flake8'
 
-# Creating a startup hook, which will activate our custom environment by default in Jupyter Notebook
-# More info about startup hooks: https://jupyter-docker-stacks.readthedocs.io/en/latest/using/common.html#startup-hooks
-# You can comment this section to keep the default environment in Jupyter Notebook
-USER root
-RUN activate_custom_env_script=/usr/local/bin/before-notebook.d/activate_custom_env.sh && \
-    echo ""#!/bin/bash"" > ${activate_custom_env_script} && \
-    echo ""eval \""$(conda shell.bash activate ""${env_name}"")\"""" >> ${activate_custom_env_script} && \
-    chmod +x ${activate_custom_env_script}
+# Uncomment this section to activate custom environment by default
+# Note: uncommenting this section makes ""${env_name}"" default both for Jupyter Notebook and Terminals
+# More information here: https://github.com/jupyter/docker-stacks/pull/2047
+# USER root
+# RUN \
+#     # This changes a startup hook, which will activate our custom environment for the process
+#     echo conda activate ""${env_name}"" >> /usr/local/bin/before-notebook.d/10activate-conda-env.sh && \
+#     # This makes the custom environment default in Jupyter Terminals for all users which might be created later
+#     echo conda activate ""${env_name}"" >> /etc/skel/.bashrc && \
+#     # This makes the custom environment default in Jupyter Terminals for already existing NB_USER
+#     echo conda activate ""${env_name}"" >> ""/home/${NB_USER}/.bashrc""
 
 USER ${NB_UID}
-
-# Making this environment default in Terminal
-# You can comment this line to keep the default environment in a Terminal
-RUN echo ""conda activate ${env_name}"" >> ""${HOME}/.bashrc""",Yes
,images/docker-stacks-foundation/10activate-conda-env.sh,3253fc39b56fcfc08baf1a2aa59161e2cf8fa994,2927745fb23de0a14ae3442884d5160f26b0bf9d,"Fix conda hook to work in both terminal and Jupyter Notebook (#2047)

* Fix conda hook to work in both terminal and Jupyter Notebook

* Fix hook for Jupyter Terminals

* Rename startup hook to have order of precedence

* Try to increase sleep

* Comment making env_name default in custom_environment","diff --git a/images/docker-stacks-foundation/10activate-conda-env.sh b/images/docker-stacks-foundation/10activate-conda-env.sh
new file mode 100755
index 00000000..ed7347f3
--- /dev/null
+++ b/images/docker-stacks-foundation/10activate-conda-env.sh
@@ -0,0 +1,8 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# This registers the initialization code for the conda shell code
+# It also activates default environment in the end, so we don't need to activate it manually
+# Documentation: https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html
+eval ""$(conda shell.bash hook)""","diff --git a/images/docker-stacks-foundation/10activate-conda-env.sh b/images/docker-stacks-foundation/10activate-conda-env.sh
new file mode 100755
index 00000000..ed7347f3
--- /dev/null
+++ b/images/docker-stacks-foundation/10activate-conda-env.sh
@@ -0,0 +1,8 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# This registers the initialization code for the conda shell code
+# It also activates default environment in the end, so we don't need to activate it manually
+# Documentation: https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html
+eval ""$(conda shell.bash hook)""",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,3253fc39b56fcfc08baf1a2aa59161e2cf8fa994,2927745fb23de0a14ae3442884d5160f26b0bf9d,"Fix conda hook to work in both terminal and Jupyter Notebook (#2047)

* Fix conda hook to work in both terminal and Jupyter Notebook

* Fix hook for Jupyter Terminals

* Rename startup hook to have order of precedence

* Try to increase sleep

* Comment making env_name default in custom_environment","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 3fc4ec15..34a3077e 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -59,8 +59,9 @@ RUN chmod a+rx /usr/local/bin/fix-permissions
 # Enable prompt color in the skeleton .bashrc before creating the default NB_USER
 # hadolint ignore=SC2016
 RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashrc && \
-   # Add call to conda init script see https://stackoverflow.com/a/58081608/4413446
-   echo 'eval ""$(command conda shell.bash hook 2> /dev/null)""' >> /etc/skel/.bashrc
+    # More information in: https://github.com/jupyter/docker-stacks/pull/2047
+    # and docs: https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html
+    echo 'eval ""$(conda shell.bash hook)""' >> /etc/skel/.bashrc
 
 # Create NB_USER with name jovyan user with UID=1000 and in the 'users' group
 # and make sure these dirs are writable by the `users` group.
@@ -135,6 +136,8 @@ USER root
 RUN mkdir /usr/local/bin/start-notebook.d && \
     mkdir /usr/local/bin/before-notebook.d
 
+COPY 10activate-conda-env.sh /usr/local/bin/before-notebook.d/
+
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 3fc4ec15..34a3077e 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -59,8 +59,9 @@ RUN chmod a+rx /usr/local/bin/fix-permissions
 # Enable prompt color in the skeleton .bashrc before creating the default NB_USER
 # hadolint ignore=SC2016
 RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashrc && \
-   # Add call to conda init script see https://stackoverflow.com/a/58081608/4413446
-   echo 'eval ""$(command conda shell.bash hook 2> /dev/null)""' >> /etc/skel/.bashrc
+    # More information in: https://github.com/jupyter/docker-stacks/pull/2047
+    # and docs: https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html
+    echo 'eval ""$(conda shell.bash hook)""' >> /etc/skel/.bashrc
 
 # Create NB_USER with name jovyan user with UID=1000 and in the 'users' group
 # and make sure these dirs are writable by the `users` group.
@@ -135,6 +136,8 @@ USER root
 RUN mkdir /usr/local/bin/start-notebook.d && \
     mkdir /usr/local/bin/before-notebook.d
 
+COPY 10activate-conda-env.sh /usr/local/bin/before-notebook.d/
+
 # Switch back to jovyan to avoid accidental container runs as root
 USER ${NB_UID}",Yes
tests/base-notebook/test_start_container.py,tests/base-notebook/test_start_container.py,3253fc39b56fcfc08baf1a2aa59161e2cf8fa994,2927745fb23de0a14ae3442884d5160f26b0bf9d,"Fix conda hook to work in both terminal and Jupyter Notebook (#2047)

* Fix conda hook to work in both terminal and Jupyter Notebook

* Fix hook for Jupyter Terminals

* Rename startup hook to have order of precedence

* Try to increase sleep

* Comment making env_name default in custom_environment","diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index 830b36c7..3fbf08aa 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -48,7 +48,7 @@ def test_start_notebook(
         ports={""8888/tcp"": host_port},
     )
     # sleeping some time to let the server start
-    time.sleep(1)
+    time.sleep(2)
     logs = running_container.logs().decode(""utf-8"")
     LOGGER.debug(logs)
     # checking that the expected command is launched","diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index 830b36c7..3fbf08aa 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -48,7 +48,7 @@ def test_start_notebook(
         ports={""8888/tcp"": host_port},
     )
     # sleeping some time to let the server start
-    time.sleep(1)
+    time.sleep(2)
     logs = running_container.logs().decode(""utf-8"")
     LOGGER.debug(logs)
     # checking that the expected command is launched",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,9f12db6067eb74aa61a554918d9fcbdc33e272ff,3253fc39b56fcfc08baf1a2aa59161e2cf8fa994,"[pre-commit.ci] pre-commit autoupdate (#2048)

* [pre-commit.ci] pre-commit autoupdate

updates:
- [github.com/psf/black: 23.10.1 → 23.11.0](https://github.com/psf/black/compare/23.10.1...23.11.0)
- [github.com/pre-commit/mirrors-mypy: v1.6.1 → v1.7.1](https://github.com/pre-commit/mirrors-mypy/compare/v1.6.1...v1.7.1)
- [github.com/pre-commit/mirrors-prettier: v3.0.3 → v4.0.0-alpha.3](https://github.com/pre-commit/mirrors-prettier/compare/v3.0.3...v4.0.0-alpha.3)
- [github.com/adrienverge/yamllint: v1.32.0 → v1.33.0](https://github.com/adrienverge/yamllint/compare/v1.32.0...v1.33.0)
- [github.com/nbQA-dev/nbQA: 1.7.0 → 1.7.1](https://github.com/nbQA-dev/nbQA/compare/1.7.0...1.7.1)

* Update .pre-commit-config.yaml

* Update .pre-commit-config.yaml

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 2910837d..fe8f0ef3 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.10.1
+    rev: 23.11.0
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.6.1
+    rev: v1.7.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -60,7 +60,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.0.3
+    rev: v3.1.0
     hooks:
       - id: prettier
 
@@ -93,7 +93,7 @@ repos:
 
   # Lint: YAML
   - repo: https://github.com/adrienverge/yamllint
-    rev: v1.32.0
+    rev: v1.33.0
     hooks:
       - id: yamllint
         args: [""-d {extends: relaxed, rules: {line-length: disable}}"", ""-s""]
@@ -135,7 +135,7 @@ repos:
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.7.0
+    rev: 1.7.1
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 2910837d..fe8f0ef3 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.10.1
+    rev: 23.11.0
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.6.1
+    rev: v1.7.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -60,7 +60,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.0.3
+    rev: v3.1.0
     hooks:
       - id: prettier
 
@@ -93,7 +93,7 @@ repos:
 
   # Lint: YAML
   - repo: https://github.com/adrienverge/yamllint
-    rev: v1.32.0
+    rev: v1.33.0
     hooks:
       - id: yamllint
         args: [""-d {extends: relaxed, rules: {line-length: disable}}"", ""-s""]
@@ -135,7 +135,7 @@ repos:
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.7.0
+    rev: 1.7.1
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]",Yes
images/datascience-notebook/Dockerfile,images/datascience-notebook/Dockerfile,b6104850fa83d19555884a1443e38dababe7df7b,9f12db6067eb74aa61a554918d9fcbdc33e272ff,"Automatically install latest julia version (#2046)

* Automatically install latest julia version

* Better text

* Fix

* Fix

* Update setup-julia.bash

* Install plumbum

* Better docs

* Better docs

* Use subprocess.check_call instead of plumbum

* Do not use dash in python filename

* Remove plumbum from the image

* Remove jq from the image

* Remove setup-julia.bash file

* Fix file name

* Fix docstring","diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
index 2d49e559..1d5f13ad 100644
--- a/images/datascience-notebook/Dockerfile
+++ b/images/datascience-notebook/Dockerfile
@@ -27,7 +27,7 @@ ENV JULIA_DEPOT_PATH=/opt/julia \
     JULIA_PKGDIR=/opt/julia
 
 # Setup Julia
-RUN /opt/setup-scripts/setup-julia.bash
+RUN /opt/setup-scripts/setup_julia.py
 
 USER ${NB_UID}","diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
index 2d49e559..1d5f13ad 100644
--- a/images/datascience-notebook/Dockerfile
+++ b/images/datascience-notebook/Dockerfile
@@ -27,7 +27,7 @@ ENV JULIA_DEPOT_PATH=/opt/julia \
     JULIA_PKGDIR=/opt/julia
 
 # Setup Julia
-RUN /opt/setup-scripts/setup-julia.bash
+RUN /opt/setup-scripts/setup_julia.py
 
 USER ${NB_UID}",Yes
images/julia-notebook/Dockerfile,images/julia-notebook/Dockerfile,b6104850fa83d19555884a1443e38dababe7df7b,9f12db6067eb74aa61a554918d9fcbdc33e272ff,"Automatically install latest julia version (#2046)

* Automatically install latest julia version

* Better text

* Fix

* Fix

* Update setup-julia.bash

* Install plumbum

* Better docs

* Better docs

* Use subprocess.check_call instead of plumbum

* Do not use dash in python filename

* Remove plumbum from the image

* Remove jq from the image

* Remove setup-julia.bash file

* Fix file name

* Fix docstring","diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
index 2c982a8b..9dbfd7fc 100644
--- a/images/julia-notebook/Dockerfile
+++ b/images/julia-notebook/Dockerfile
@@ -19,7 +19,7 @@ ENV JULIA_DEPOT_PATH=/opt/julia \
     JULIA_PKGDIR=/opt/julia
 
 # Setup Julia
-RUN /opt/setup-scripts/setup-julia.bash
+RUN /opt/setup-scripts/setup_julia.py
 
 USER ${NB_UID}","diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
index 2c982a8b..9dbfd7fc 100644
--- a/images/julia-notebook/Dockerfile
+++ b/images/julia-notebook/Dockerfile
@@ -19,7 +19,7 @@ ENV JULIA_DEPOT_PATH=/opt/julia \
     JULIA_PKGDIR=/opt/julia
 
 # Setup Julia
-RUN /opt/setup-scripts/setup-julia.bash
+RUN /opt/setup-scripts/setup_julia.py
 
 USER ${NB_UID}",Yes
images/minimal-notebook/setup-scripts/setup-julia.bash,images/minimal-notebook/setup-scripts/setup-julia.bash,b6104850fa83d19555884a1443e38dababe7df7b,9f12db6067eb74aa61a554918d9fcbdc33e272ff,"Automatically install latest julia version (#2046)

* Automatically install latest julia version

* Better text

* Fix

* Fix

* Update setup-julia.bash

* Install plumbum

* Better docs

* Better docs

* Use subprocess.check_call instead of plumbum

* Do not use dash in python filename

* Remove plumbum from the image

* Remove jq from the image

* Remove setup-julia.bash file

* Fix file name

* Fix docstring","diff --git a/images/minimal-notebook/setup-scripts/setup-julia.bash b/images/minimal-notebook/setup-scripts/setup-julia.bash
deleted file mode 100755
index 137b225f..00000000
--- a/images/minimal-notebook/setup-scripts/setup-julia.bash
+++ /dev/null
@@ -1,40 +0,0 @@
-#!/bin/bash
-set -exuo pipefail
-# Requirements:
-# - Run as the root user
-# - The JULIA_PKGDIR environment variable is set
-
-# Default julia version to install if env var is not set
-# Check https://julialang.org/downloads/
-JULIA_VERSION=""${JULIA_VERSION:-1.9.3}""
-
-# Figure out what architecture we are installing in
-JULIA_ARCH=$(uname -m)
-JULIA_SHORT_ARCH=""${JULIA_ARCH}""
-if [ ""${JULIA_SHORT_ARCH}"" == ""x86_64"" ]; then
-    JULIA_SHORT_ARCH=""x64""
-fi
-
-# Figure out Julia Installer URL
-JULIA_INSTALLER=""julia-${JULIA_VERSION}-linux-${JULIA_ARCH}.tar.gz""
-JULIA_MAJOR_MINOR=$(echo ""${JULIA_VERSION}"" | cut -d. -f 1,2)
-
-# Download and install Julia
-cd /tmp
-mkdir ""/opt/julia-${JULIA_VERSION}""
-curl --progress-bar --location --output ""${JULIA_INSTALLER}"" \
-    ""https://julialang-s3.julialang.org/bin/linux/${JULIA_SHORT_ARCH}/${JULIA_MAJOR_MINOR}/${JULIA_INSTALLER}""
-tar xzf ""${JULIA_INSTALLER}"" -C ""/opt/julia-${JULIA_VERSION}"" --strip-components=1
-rm ""${JULIA_INSTALLER}""
-
-# Link Julia installed version to /usr/local/bin, so julia launches it
-ln -fs /opt/julia-*/bin/julia /usr/local/bin/julia
-
-# Tell Julia where conda libraries are
-mkdir -p /etc/julia
-echo ""push!(Libdl.DL_LOAD_PATH, \""${CONDA_DIR}/lib\"")"" >> /etc/julia/juliarc.jl
-
-# Create JULIA_PKGDIR, where user libraries are installed
-mkdir ""${JULIA_PKGDIR}""
-chown ""${NB_USER}"" ""${JULIA_PKGDIR}""
-fix-permissions ""${JULIA_PKGDIR}""","diff --git a/images/minimal-notebook/setup-scripts/setup-julia.bash b/images/minimal-notebook/setup-scripts/setup-julia.bash
deleted file mode 100755
index 137b225f..00000000
--- a/images/minimal-notebook/setup-scripts/setup-julia.bash
+++ /dev/null
@@ -1,40 +0,0 @@
-#!/bin/bash
-set -exuo pipefail
-# Requirements:
-# - Run as the root user
-# - The JULIA_PKGDIR environment variable is set
-
-# Default julia version to install if env var is not set
-# Check https://julialang.org/downloads/
-JULIA_VERSION=""${JULIA_VERSION:-1.9.3}""
-
-# Figure out what architecture we are installing in
-JULIA_ARCH=$(uname -m)
-JULIA_SHORT_ARCH=""${JULIA_ARCH}""
-if [ ""${JULIA_SHORT_ARCH}"" == ""x86_64"" ]; then
-    JULIA_SHORT_ARCH=""x64""
-fi
-
-# Figure out Julia Installer URL
-JULIA_INSTALLER=""julia-${JULIA_VERSION}-linux-${JULIA_ARCH}.tar.gz""
-JULIA_MAJOR_MINOR=$(echo ""${JULIA_VERSION}"" | cut -d. -f 1,2)
-
-# Download and install Julia
-cd /tmp
-mkdir ""/opt/julia-${JULIA_VERSION}""
-curl --progress-bar --location --output ""${JULIA_INSTALLER}"" \
-    ""https://julialang-s3.julialang.org/bin/linux/${JULIA_SHORT_ARCH}/${JULIA_MAJOR_MINOR}/${JULIA_INSTALLER}""
-tar xzf ""${JULIA_INSTALLER}"" -C ""/opt/julia-${JULIA_VERSION}"" --strip-components=1
-rm ""${JULIA_INSTALLER}""
-
-# Link Julia installed version to /usr/local/bin, so julia launches it
-ln -fs /opt/julia-*/bin/julia /usr/local/bin/julia
-
-# Tell Julia where conda libraries are
-mkdir -p /etc/julia
-echo ""push!(Libdl.DL_LOAD_PATH, \""${CONDA_DIR}/lib\"")"" >> /etc/julia/juliarc.jl
-
-# Create JULIA_PKGDIR, where user libraries are installed
-mkdir ""${JULIA_PKGDIR}""
-chown ""${NB_USER}"" ""${JULIA_PKGDIR}""
-fix-permissions ""${JULIA_PKGDIR}""",Yes
,images/minimal-notebook/setup-scripts/setup_julia.py,b6104850fa83d19555884a1443e38dababe7df7b,9f12db6067eb74aa61a554918d9fcbdc33e272ff,"Automatically install latest julia version (#2046)

* Automatically install latest julia version

* Better text

* Fix

* Fix

* Update setup-julia.bash

* Install plumbum

* Better docs

* Better docs

* Use subprocess.check_call instead of plumbum

* Do not use dash in python filename

* Remove plumbum from the image

* Remove jq from the image

* Remove setup-julia.bash file

* Fix file name

* Fix docstring","diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
new file mode 100755
index 00000000..0cdbe0cf
--- /dev/null
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -0,0 +1,85 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# Requirements:
+# - Run as the root user
+# - The JULIA_PKGDIR environment variable is set
+
+import os
+import platform
+import shutil
+import subprocess
+from pathlib import Path
+
+import requests
+
+
+def unify_aarch64(platform: str) -> str:
+    """"""
+    Renames arm64->aarch64 to support local builds on on aarch64 Macs
+    """"""
+    return {
+        ""aarch64"": ""aarch64"",
+        ""arm64"": ""aarch64"",
+        ""x86_64"": ""x86_64"",
+    }[platform]
+
+
+def get_latest_julia_url() -> tuple[str, str]:
+    """"""
+    Get the last stable version of Julia
+    Based on: https://github.com/JuliaLang/www.julialang.org/issues/878#issuecomment-749234813
+    """"""
+
+    versions = requests.get(
+        ""https://julialang-s3.julialang.org/bin/versions.json""
+    ).json()
+    stable_versions = {k: v for k, v in versions.items() if v[""stable""]}
+    latest_version_files = stable_versions[max(stable_versions)][""files""]
+    triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
+    file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
+    return file_info[""url""], file_info[""version""]
+
+
+def download_julia(julia_url: str) -> None:
+    """"""
+    Downloads and unpacks julia
+    The resulting julia directory is ""/opt/julia-VERSION/""
+    """"""
+    tmp_file = Path(""/tmp/julia.tar.gz"")
+    subprocess.check_call(
+        [""curl"", ""--progress-bar"", ""--location"", ""--output"", tmp_file, julia_url]
+    )
+    shutil.unpack_archive(tmp_file, ""/opt/"")
+    tmp_file.unlink()
+
+
+def prepare_julia(julia_version: str) -> None:
+    """"""
+    Creates /usr/local/bin/julia symlink
+    Make Julia aware of conda libraries
+    Creates a directory for Julia user libraries
+    """"""
+    # Link Julia installed version to /usr/local/bin, so julia launches it
+    subprocess.check_call(
+        [""ln"", ""-fs"", f""/opt/julia-{julia_version}/bin/julia"", ""/usr/local/bin/julia""]
+    )
+
+    # Tell Julia where conda libraries are
+    Path(""/etc/julia"").mkdir()
+    Path(""/etc/julia/juliarc.jl"").write_text(
+        f'push!(Libdl.DL_LOAD_PATH, ""{os.environ[""CONDA_DIR""]}/lib"")\n'
+    )
+
+    # Create JULIA_PKGDIR, where user libraries are installed
+    JULIA_PKGDIR = Path(os.environ[""JULIA_PKGDIR""])
+    JULIA_PKGDIR.mkdir()
+    subprocess.check_call([""chown"", os.environ[""NB_USER""], JULIA_PKGDIR])
+    subprocess.check_call([""fix-permissions"", JULIA_PKGDIR])
+
+
+if __name__ == ""__main__"":
+    julia_url, julia_version = get_latest_julia_url()
+    download_julia(julia_url=julia_url)
+    prepare_julia(julia_version=julia_version)","diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
new file mode 100755
index 00000000..0cdbe0cf
--- /dev/null
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -0,0 +1,85 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# Requirements:
+# - Run as the root user
+# - The JULIA_PKGDIR environment variable is set
+
+import os
+import platform
+import shutil
+import subprocess
+from pathlib import Path
+
+import requests
+
+
+def unify_aarch64(platform: str) -> str:
+    """"""
+    Renames arm64->aarch64 to support local builds on on aarch64 Macs
+    """"""
+    return {
+        ""aarch64"": ""aarch64"",
+        ""arm64"": ""aarch64"",
+        ""x86_64"": ""x86_64"",
+    }[platform]
+
+
+def get_latest_julia_url() -> tuple[str, str]:
+    """"""
+    Get the last stable version of Julia
+    Based on: https://github.com/JuliaLang/www.julialang.org/issues/878#issuecomment-749234813
+    """"""
+
+    versions = requests.get(
+        ""https://julialang-s3.julialang.org/bin/versions.json""
+    ).json()
+    stable_versions = {k: v for k, v in versions.items() if v[""stable""]}
+    latest_version_files = stable_versions[max(stable_versions)][""files""]
+    triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
+    file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
+    return file_info[""url""], file_info[""version""]
+
+
+def download_julia(julia_url: str) -> None:
+    """"""
+    Downloads and unpacks julia
+    The resulting julia directory is ""/opt/julia-VERSION/""
+    """"""
+    tmp_file = Path(""/tmp/julia.tar.gz"")
+    subprocess.check_call(
+        [""curl"", ""--progress-bar"", ""--location"", ""--output"", tmp_file, julia_url]
+    )
+    shutil.unpack_archive(tmp_file, ""/opt/"")
+    tmp_file.unlink()
+
+
+def prepare_julia(julia_version: str) -> None:
+    """"""
+    Creates /usr/local/bin/julia symlink
+    Make Julia aware of conda libraries
+    Creates a directory for Julia user libraries
+    """"""
+    # Link Julia installed version to /usr/local/bin, so julia launches it
+    subprocess.check_call(
+        [""ln"", ""-fs"", f""/opt/julia-{julia_version}/bin/julia"", ""/usr/local/bin/julia""]
+    )
+
+    # Tell Julia where conda libraries are
+    Path(""/etc/julia"").mkdir()
+    Path(""/etc/julia/juliarc.jl"").write_text(
+        f'push!(Libdl.DL_LOAD_PATH, ""{os.environ[""CONDA_DIR""]}/lib"")\n'
+    )
+
+    # Create JULIA_PKGDIR, where user libraries are installed
+    JULIA_PKGDIR = Path(os.environ[""JULIA_PKGDIR""])
+    JULIA_PKGDIR.mkdir()
+    subprocess.check_call([""chown"", os.environ[""NB_USER""], JULIA_PKGDIR])
+    subprocess.check_call([""fix-permissions"", JULIA_PKGDIR])
+
+
+if __name__ == ""__main__"":
+    julia_url, julia_version = get_latest_julia_url()
+    download_julia(julia_url=julia_url)
+    prepare_julia(julia_version=julia_version)",Yes
tagging/get_platform.py,tagging/get_platform.py,b6104850fa83d19555884a1443e38dababe7df7b,9f12db6067eb74aa61a554918d9fcbdc33e272ff,"Automatically install latest julia version (#2046)

* Automatically install latest julia version

* Better text

* Fix

* Fix

* Update setup-julia.bash

* Install plumbum

* Better docs

* Better docs

* Use subprocess.check_call instead of plumbum

* Do not use dash in python filename

* Remove plumbum from the image

* Remove jq from the image

* Remove setup-julia.bash file

* Fix file name

* Fix docstring","diff --git a/tagging/get_platform.py b/tagging/get_platform.py
index 187a2592..cda791ab 100644
--- a/tagging/get_platform.py
+++ b/tagging/get_platform.py
@@ -6,9 +6,12 @@ ALL_PLATFORMS = {""x86_64"", ""aarch64""}
 
 
 def unify_aarch64(platform: str) -> str:
+    """"""
+    Renames arm64->aarch64 to support local builds on on aarch64 Macs
+    """"""
     return {
         ""aarch64"": ""aarch64"",
-        ""arm64"": ""aarch64"",  # To support local building on aarch64 Macs
+        ""arm64"": ""aarch64"",
         ""x86_64"": ""x86_64"",
     }[platform]","diff --git a/tagging/get_platform.py b/tagging/get_platform.py
index 187a2592..cda791ab 100644
--- a/tagging/get_platform.py
+++ b/tagging/get_platform.py
@@ -6,9 +6,12 @@ ALL_PLATFORMS = {""x86_64"", ""aarch64""}
 
 
 def unify_aarch64(platform: str) -> str:
+    """"""
+    Renames arm64->aarch64 to support local builds on on aarch64 Macs
+    """"""
     return {
         ""aarch64"": ""aarch64"",
-        ""arm64"": ""aarch64"",  # To support local building on aarch64 Macs
+        ""arm64"": ""aarch64"",
         ""x86_64"": ""x86_64"",
     }[platform]",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,01e2a4e0a9122604021b6f0a70de35060adfacfe,b6104850fa83d19555884a1443e38dababe7df7b,"[FAST_BUILD] [TMP] Fix mamba clean by downloading updated file (#2052)

* [TMP] Fix mamba clean by downloading updated file

* Fix wget option","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 34a3077e..d85a4a14 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -117,6 +117,10 @@ RUN set -x && \
         'mamba' \
         'jupyter_core' && \
     rm micromamba && \
+    # Temporary fix till mamba 1.5.5 is released
+    # Download mamba.py after merged fix for `mamba clean`: https://github.com/mamba-org/mamba/pull/3040
+    wget --progress=dot:giga https://raw.githubusercontent.com/mamba-org/mamba/cf9c063479c7bd32f1e6e8adfd04a1e15ba12981/mamba/mamba/mamba.py \
+        -O /opt/conda/lib/python3.11/site-packages/mamba/mamba.py && \
     # Pin major.minor version of python
     mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 34a3077e..d85a4a14 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -117,6 +117,10 @@ RUN set -x && \
         'mamba' \
         'jupyter_core' && \
     rm micromamba && \
+    # Temporary fix till mamba 1.5.5 is released
+    # Download mamba.py after merged fix for `mamba clean`: https://github.com/mamba-org/mamba/pull/3040
+    wget --progress=dot:giga https://raw.githubusercontent.com/mamba-org/mamba/cf9c063479c7bd32f1e6e8adfd04a1e15ba12981/mamba/mamba/mamba.py \
+        -O /opt/conda/lib/python3.11/site-packages/mamba/mamba.py && \
     # Pin major.minor version of python
     mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \",Yes
docs/using/recipe_code/custom_environment.dockerfile,docs/using/recipe_code/custom_environment.dockerfile,c1d212784394ada89acb70cc8390d8cefaf1bef2,01e2a4e0a9122604021b6f0a70de35060adfacfe,"Use custom conda environment in Jupyter Notebook when user wants to use it (#2050)

* Modify the custom Python kernel

- to activate the custom environment
- for the respective Jupyter Notebook and Jupyter Console

Signed-off-by: Ayaz Salikhov <mathbunnyru@gmail.com>

* Add DL3059 to hadolint ignore list

Signed-off-by: Ayaz Salikhov <mathbunnyru@gmail.com>

* Move hadolint ignore to a single line

* Use python heredoc

* Remove unused print

* Fix style

* Do not hardcode CONDA_DIR

* Update custom_environment.dockerfile

* Use indent=1

* Implement activate_notebook_custom_env.py as a separate script

* Do not call Python manually

---------

Signed-off-by: Ayaz Salikhov <mathbunnyru@gmail.com>
Co-authored-by: Olivier Benz <olivier.benz@b-data.ch>","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 9fd94b01..e204395b 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -28,12 +28,17 @@ RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --nam
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
     'flake8'
 
-# Uncomment this section to activate custom environment by default
+# This changes the custom Python kernel so that the custom environment will
+# be activated for the respective Jupyter Notebook and Jupyter Console
+# hadolint ignore=DL3059
+RUN /opt/setup-scripts/activate_notebook_custom_env.py ""{env_name}""
+
+# Comment the line above and uncomment the section below instead to activate the custom environment by default
 # Note: uncommenting this section makes ""${env_name}"" default both for Jupyter Notebook and Terminals
 # More information here: https://github.com/jupyter/docker-stacks/pull/2047
 # USER root
 # RUN \
-#     # This changes a startup hook, which will activate our custom environment for the process
+#     # This changes a startup hook, which will activate the custom environment for the process
 #     echo conda activate ""${env_name}"" >> /usr/local/bin/before-notebook.d/10activate-conda-env.sh && \
 #     # This makes the custom environment default in Jupyter Terminals for all users which might be created later
 #     echo conda activate ""${env_name}"" >> /etc/skel/.bashrc && \","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index 9fd94b01..e204395b 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -28,12 +28,17 @@ RUN ""${CONDA_DIR}/envs/${env_name}/bin/python"" -m ipykernel install --user --nam
 RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
     'flake8'
 
-# Uncomment this section to activate custom environment by default
+# This changes the custom Python kernel so that the custom environment will
+# be activated for the respective Jupyter Notebook and Jupyter Console
+# hadolint ignore=DL3059
+RUN /opt/setup-scripts/activate_notebook_custom_env.py ""{env_name}""
+
+# Comment the line above and uncomment the section below instead to activate the custom environment by default
 # Note: uncommenting this section makes ""${env_name}"" default both for Jupyter Notebook and Terminals
 # More information here: https://github.com/jupyter/docker-stacks/pull/2047
 # USER root
 # RUN \
-#     # This changes a startup hook, which will activate our custom environment for the process
+#     # This changes a startup hook, which will activate the custom environment for the process
 #     echo conda activate ""${env_name}"" >> /usr/local/bin/before-notebook.d/10activate-conda-env.sh && \
 #     # This makes the custom environment default in Jupyter Terminals for all users which might be created later
 #     echo conda activate ""${env_name}"" >> /etc/skel/.bashrc && \",Yes
,images/minimal-notebook/setup-scripts/activate_notebook_custom_env.py,c1d212784394ada89acb70cc8390d8cefaf1bef2,01e2a4e0a9122604021b6f0a70de35060adfacfe,"Use custom conda environment in Jupyter Notebook when user wants to use it (#2050)

* Modify the custom Python kernel

- to activate the custom environment
- for the respective Jupyter Notebook and Jupyter Console

Signed-off-by: Ayaz Salikhov <mathbunnyru@gmail.com>

* Add DL3059 to hadolint ignore list

Signed-off-by: Ayaz Salikhov <mathbunnyru@gmail.com>

* Move hadolint ignore to a single line

* Use python heredoc

* Remove unused print

* Fix style

* Do not hardcode CONDA_DIR

* Update custom_environment.dockerfile

* Use indent=1

* Implement activate_notebook_custom_env.py as a separate script

* Do not call Python manually

---------

Signed-off-by: Ayaz Salikhov <mathbunnyru@gmail.com>
Co-authored-by: Olivier Benz <olivier.benz@b-data.ch>","diff --git a/images/minimal-notebook/setup-scripts/activate_notebook_custom_env.py b/images/minimal-notebook/setup-scripts/activate_notebook_custom_env.py
new file mode 100755
index 00000000..4d5da9bc
--- /dev/null
+++ b/images/minimal-notebook/setup-scripts/activate_notebook_custom_env.py
@@ -0,0 +1,24 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import json
+import os
+import sys
+from pathlib import Path
+
+env_name = sys.argv[1]
+CONDA_DIR = os.environ[""CONDA_DIR""]
+
+file = Path.home() / f"".local/share/jupyter/kernels/{env_name}/kernel.json""
+content = json.loads(file.read_text())
+content[""env""] = {
+    ""XML_CATALOG_FILES"": """",
+    ""PATH"": f""{CONDA_DIR}/envs/{env_name}/bin:$PATH"",
+    ""CONDA_PREFIX"": f""{CONDA_DIR}/envs/{env_name}"",
+    ""CONDA_PROMPT_MODIFIER"": f""({env_name}) "",
+    ""CONDA_SHLVL"": ""2"",
+    ""CONDA_DEFAULT_ENV"": env_name,
+    ""CONDA_PREFIX_1"": CONDA_DIR,
+}
+
+file.write_text(json.dumps(content, indent=1))","diff --git a/images/minimal-notebook/setup-scripts/activate_notebook_custom_env.py b/images/minimal-notebook/setup-scripts/activate_notebook_custom_env.py
new file mode 100755
index 00000000..4d5da9bc
--- /dev/null
+++ b/images/minimal-notebook/setup-scripts/activate_notebook_custom_env.py
@@ -0,0 +1,24 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import json
+import os
+import sys
+from pathlib import Path
+
+env_name = sys.argv[1]
+CONDA_DIR = os.environ[""CONDA_DIR""]
+
+file = Path.home() / f"".local/share/jupyter/kernels/{env_name}/kernel.json""
+content = json.loads(file.read_text())
+content[""env""] = {
+    ""XML_CATALOG_FILES"": """",
+    ""PATH"": f""{CONDA_DIR}/envs/{env_name}/bin:$PATH"",
+    ""CONDA_PREFIX"": f""{CONDA_DIR}/envs/{env_name}"",
+    ""CONDA_PROMPT_MODIFIER"": f""({env_name}) "",
+    ""CONDA_SHLVL"": ""2"",
+    ""CONDA_DEFAULT_ENV"": env_name,
+    ""CONDA_PREFIX_1"": CONDA_DIR,
+}
+
+file.write_text(json.dumps(content, indent=1))",Yes
docs/using/recipe_code/custom_environment.dockerfile,docs/using/recipe_code/custom_environment.dockerfile,2760b2e07576611cb14987878fc9c39faeb34189,c1d212784394ada89acb70cc8390d8cefaf1bef2,Use jupyter/minimal-notebook for custom env example,"diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index e204395b..b5d4c47e 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook
+FROM quay.io/jupyter/minimal-notebook
 
 # Name your environment and choose the Python version
 ARG env_name=python310","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index e204395b..b5d4c47e 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook
+FROM quay.io/jupyter/minimal-notebook
 
 # Name your environment and choose the Python version
 ARG env_name=python310",Yes
docs/using/recipe_code/custom_environment.dockerfile,docs/using/recipe_code/custom_environment.dockerfile,027d3a10265b2998e89671e2e2c2dfd0bc227448,2760b2e07576611cb14987878fc9c39faeb34189,Fix cusotm env recipe,"diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index b5d4c47e..547245c0 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -31,7 +31,7 @@ RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
 # This changes the custom Python kernel so that the custom environment will
 # be activated for the respective Jupyter Notebook and Jupyter Console
 # hadolint ignore=DL3059
-RUN /opt/setup-scripts/activate_notebook_custom_env.py ""{env_name}""
+RUN /opt/setup-scripts/activate_notebook_custom_env.py ""${env_name}""
 
 # Comment the line above and uncomment the section below instead to activate the custom environment by default
 # Note: uncommenting this section makes ""${env_name}"" default both for Jupyter Notebook and Terminals","diff --git a/docs/using/recipe_code/custom_environment.dockerfile b/docs/using/recipe_code/custom_environment.dockerfile
index b5d4c47e..547245c0 100644
--- a/docs/using/recipe_code/custom_environment.dockerfile
+++ b/docs/using/recipe_code/custom_environment.dockerfile
@@ -31,7 +31,7 @@ RUN ""${CONDA_DIR}/envs/${env_name}/bin/pip"" install --no-cache-dir \
 # This changes the custom Python kernel so that the custom environment will
 # be activated for the respective Jupyter Notebook and Jupyter Console
 # hadolint ignore=DL3059
-RUN /opt/setup-scripts/activate_notebook_custom_env.py ""{env_name}""
+RUN /opt/setup-scripts/activate_notebook_custom_env.py ""${env_name}""
 
 # Comment the line above and uncomment the section below instead to activate the custom environment by default
 # Note: uncommenting this section makes ""${env_name}"" default both for Jupyter Notebook and Terminals",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,42ff5aa6383de09733c172eb3b66dc45c8df7199,027d3a10265b2998e89671e2e2c2dfd0bc227448,Do not hardcode python3.11 in temporary fix,"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index d85a4a14..fbcb323b 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -120,7 +120,7 @@ RUN set -x && \
     # Temporary fix till mamba 1.5.5 is released
     # Download mamba.py after merged fix for `mamba clean`: https://github.com/mamba-org/mamba/pull/3040
     wget --progress=dot:giga https://raw.githubusercontent.com/mamba-org/mamba/cf9c063479c7bd32f1e6e8adfd04a1e15ba12981/mamba/mamba/mamba.py \
-        -O /opt/conda/lib/python3.11/site-packages/mamba/mamba.py && \
+        -O ""/opt/conda/lib/python${PYTHON_VERSION}/site-packages/mamba/mamba.py"" && \
     # Pin major.minor version of python
     mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index d85a4a14..fbcb323b 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -120,7 +120,7 @@ RUN set -x && \
     # Temporary fix till mamba 1.5.5 is released
     # Download mamba.py after merged fix for `mamba clean`: https://github.com/mamba-org/mamba/pull/3040
     wget --progress=dot:giga https://raw.githubusercontent.com/mamba-org/mamba/cf9c063479c7bd32f1e6e8adfd04a1e15ba12981/mamba/mamba/mamba.py \
-        -O /opt/conda/lib/python3.11/site-packages/mamba/mamba.py && \
+        -O ""/opt/conda/lib/python${PYTHON_VERSION}/site-packages/mamba/mamba.py"" && \
     # Pin major.minor version of python
     mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \",Yes
.github/workflows/pre-commit.yml,.github/workflows/pre-commit.yml,bf82b82d92a401f8967a9feee22064c840127728,42ff5aa6383de09733c172eb3b66dc45c8df7199,"Bump actions/setup-python from 4 to 5 (#2057)

Bumps [actions/setup-python](https://github.com/actions/setup-python) from 4 to 5.
- [Release notes](https://github.com/actions/setup-python/releases)
- [Commits](https://github.com/actions/setup-python/compare/v4...v5)

---
updated-dependencies:
- dependency-name: actions/setup-python
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/pre-commit.yml b/.github/workflows/pre-commit.yml
index e0ed9f54..5c2e74d6 100644
--- a/.github/workflows/pre-commit.yml
+++ b/.github/workflows/pre-commit.yml
@@ -19,7 +19,7 @@ jobs:
         uses: actions/checkout@v4
 
       - name: Set Up Python 🐍
-        uses: actions/setup-python@v4
+        uses: actions/setup-python@v5
         with:
           python-version: 3.x","diff --git a/.github/workflows/pre-commit.yml b/.github/workflows/pre-commit.yml
index e0ed9f54..5c2e74d6 100644
--- a/.github/workflows/pre-commit.yml
+++ b/.github/workflows/pre-commit.yml
@@ -19,7 +19,7 @@ jobs:
         uses: actions/checkout@v4
 
       - name: Set Up Python 🐍
-        uses: actions/setup-python@v4
+        uses: actions/setup-python@v5
         with:
           python-version: 3.x",Yes
.github/workflows/sphinx.yml,.github/workflows/sphinx.yml,bf82b82d92a401f8967a9feee22064c840127728,42ff5aa6383de09733c172eb3b66dc45c8df7199,"Bump actions/setup-python from 4 to 5 (#2057)

Bumps [actions/setup-python](https://github.com/actions/setup-python) from 4 to 5.
- [Release notes](https://github.com/actions/setup-python/releases)
- [Commits](https://github.com/actions/setup-python/compare/v4...v5)

---
updated-dependencies:
- dependency-name: actions/setup-python
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index a00f229a..9856b3ec 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -34,7 +34,7 @@ jobs:
           fetch-depth: 0
 
       - name: Set Up Python 🐍
-        uses: actions/setup-python@v4
+        uses: actions/setup-python@v5
         with:
           python-version: 3.9","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index a00f229a..9856b3ec 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -34,7 +34,7 @@ jobs:
           fetch-depth: 0
 
       - name: Set Up Python 🐍
-        uses: actions/setup-python@v4
+        uses: actions/setup-python@v5
         with:
           python-version: 3.9",Yes
.github/dependabot.yml,.github/dependabot.yml,6402f3dbfea34b29b62f5dd64113c0bf2f06d946,bf82b82d92a401f8967a9feee22064c840127728,Configure dependabot to update actions inside composite actions,"diff --git a/.github/dependabot.yml b/.github/dependabot.yml
index 5296f1a4..5ed4a1e0 100644
--- a/.github/dependabot.yml
+++ b/.github/dependabot.yml
@@ -9,3 +9,15 @@ updates:
     directory: /
     schedule:
       interval: weekly
+  - package-ecosystem: github-actions
+    directory: .github/actions/create-dev-env/
+    schedule:
+      interval: weekly
+  - package-ecosystem: github-actions
+    directory: .github/actions/download-manifests/
+    schedule:
+      interval: weekly
+  - package-ecosystem: github-actions
+    directory: .github/actions/load-image/
+    schedule:
+      interval: weekly","diff --git a/.github/dependabot.yml b/.github/dependabot.yml
index 5296f1a4..5ed4a1e0 100644
--- a/.github/dependabot.yml
+++ b/.github/dependabot.yml
@@ -9,3 +9,15 @@ updates:
     directory: /
     schedule:
       interval: weekly
+  - package-ecosystem: github-actions
+    directory: .github/actions/create-dev-env/
+    schedule:
+      interval: weekly
+  - package-ecosystem: github-actions
+    directory: .github/actions/download-manifests/
+    schedule:
+      interval: weekly
+  - package-ecosystem: github-actions
+    directory: .github/actions/load-image/
+    schedule:
+      interval: weekly",Yes
.github/actions/create-dev-env/action.yml,.github/actions/create-dev-env/action.yml,5e20409c1efd286c2a01bda7826043bc6cb3686f,6402f3dbfea34b29b62f5dd64113c0bf2f06d946,"Bump actions/setup-python from 4 to 5 in /.github/actions/create-dev-env (#2058)

Bumps [actions/setup-python](https://github.com/actions/setup-python) from 4 to 5.
- [Release notes](https://github.com/actions/setup-python/releases)
- [Commits](https://github.com/actions/setup-python/compare/v4...v5)

---
updated-dependencies:
- dependency-name: actions/setup-python
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/actions/create-dev-env/action.yml b/.github/actions/create-dev-env/action.yml
index 2a507f1c..7323494f 100644
--- a/.github/actions/create-dev-env/action.yml
+++ b/.github/actions/create-dev-env/action.yml
@@ -8,7 +8,7 @@ runs:
     # See: https://github.com/actions/setup-python/issues/108
     # python3 is manually preinstalled in the aarch64 VM self-hosted runner
     - name: Set Up Python 🐍
-      uses: actions/setup-python@v4
+      uses: actions/setup-python@v5
       with:
         python-version: 3.x
       if: runner.arch == 'X64'","diff --git a/.github/actions/create-dev-env/action.yml b/.github/actions/create-dev-env/action.yml
index 2a507f1c..7323494f 100644
--- a/.github/actions/create-dev-env/action.yml
+++ b/.github/actions/create-dev-env/action.yml
@@ -8,7 +8,7 @@ runs:
     # See: https://github.com/actions/setup-python/issues/108
     # python3 is manually preinstalled in the aarch64 VM self-hosted runner
     - name: Set Up Python 🐍
-      uses: actions/setup-python@v4
+      uses: actions/setup-python@v5
       with:
         python-version: 3.x
       if: runner.arch == 'X64'",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,781a0f4d27739e53f02ad771333262da84d085d4,5e20409c1efd286c2a01bda7826043bc6cb3686f,"Mamba 1.5.5 is released, so remove fix for mamba clean","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index fbcb323b..34a3077e 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -117,10 +117,6 @@ RUN set -x && \
         'mamba' \
         'jupyter_core' && \
     rm micromamba && \
-    # Temporary fix till mamba 1.5.5 is released
-    # Download mamba.py after merged fix for `mamba clean`: https://github.com/mamba-org/mamba/pull/3040
-    wget --progress=dot:giga https://raw.githubusercontent.com/mamba-org/mamba/cf9c063479c7bd32f1e6e8adfd04a1e15ba12981/mamba/mamba/mamba.py \
-        -O ""/opt/conda/lib/python${PYTHON_VERSION}/site-packages/mamba/mamba.py"" && \
     # Pin major.minor version of python
     mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index fbcb323b..34a3077e 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -117,10 +117,6 @@ RUN set -x && \
         'mamba' \
         'jupyter_core' && \
     rm micromamba && \
-    # Temporary fix till mamba 1.5.5 is released
-    # Download mamba.py after merged fix for `mamba clean`: https://github.com/mamba-org/mamba/pull/3040
-    wget --progress=dot:giga https://raw.githubusercontent.com/mamba-org/mamba/cf9c063479c7bd32f1e6e8adfd04a1e15ba12981/mamba/mamba/mamba.py \
-        -O ""/opt/conda/lib/python${PYTHON_VERSION}/site-packages/mamba/mamba.py"" && \
     # Pin major.minor version of python
     mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \",Yes
images/scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,55541bdc664c46a5f292dcec9c03e082f58bb757,781a0f4d27739e53f02ad771333262da84d085d4,Remove jupyterlab and notebook pins in scipy-notebook (#2060),"diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 6f14a27a..1c8003d4 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -26,10 +26,6 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
-# mamba downgrades these packages to previous major versions, which causes issues
-RUN echo 'jupyterlab >=4.0.4' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
-    echo 'notebook >=7.0.2' >> ""${CONDA_DIR}/conda-meta/pinned""
-
 # Install Python 3 packages
 RUN mamba install --yes \
     'altair' \","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 6f14a27a..1c8003d4 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -26,10 +26,6 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
-# mamba downgrades these packages to previous major versions, which causes issues
-RUN echo 'jupyterlab >=4.0.4' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
-    echo 'notebook >=7.0.2' >> ""${CONDA_DIR}/conda-meta/pinned""
-
 # Install Python 3 packages
 RUN mamba install --yes \
     'altair' \",Yes
images/docker-stacks-foundation/run-hooks.sh,images/docker-stacks-foundation/run-hooks.sh,ccbe6781543b6c4e44b8deedd39dc6bc0813431c,55541bdc664c46a5f292dcec9c03e082f58bb757,Fix typo,"diff --git a/images/docker-stacks-foundation/run-hooks.sh b/images/docker-stacks-foundation/run-hooks.sh
index 18a801a6..15df23c3 100755
--- a/images/docker-stacks-foundation/run-hooks.sh
+++ b/images/docker-stacks-foundation/run-hooks.sh
@@ -17,7 +17,7 @@ fi
 
 echo ""Running hooks in: ${1} as uid: $(id -u) gid: $(id -g)""
 for f in ""${1}/""*; do
-    # Hadling a case when the directory is empty
+    # Handling a case when the directory is empty
     [ -e ""${f}"" ] || continue
     case ""${f}"" in
         *.sh)","diff --git a/images/docker-stacks-foundation/run-hooks.sh b/images/docker-stacks-foundation/run-hooks.sh
index 18a801a6..15df23c3 100755
--- a/images/docker-stacks-foundation/run-hooks.sh
+++ b/images/docker-stacks-foundation/run-hooks.sh
@@ -17,7 +17,7 @@ fi
 
 echo ""Running hooks in: ${1} as uid: $(id -u) gid: $(id -g)""
 for f in ""${1}/""*; do
-    # Hadling a case when the directory is empty
+    # Handling a case when the directory is empty
     [ -e ""${f}"" ] || continue
     case ""${f}"" in
         *.sh)",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,07366286497c853b81d139fc170f35d113403620,ccbe6781543b6c4e44b8deedd39dc6bc0813431c,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index ddc26a82..b26c2bc3 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -20,258 +20,258 @@ runs:
   using: composite
   steps:
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
 
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index ddc26a82..b26c2bc3 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -20,258 +20,258 @@ runs:
   using: composite
   steps:
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
 
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest",Yes
.github/actions/load-image/action.yml,.github/actions/load-image/action.yml,07366286497c853b81d139fc170f35d113403620,ccbe6781543b6c4e44b8deedd39dc6bc0813431c,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index c32f3479..cbf5a8a5 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -13,7 +13,7 @@ runs:
   using: composite
   steps:
     - name: Download built image 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: ${{ inputs.image }}-${{ inputs.platform }}
         path: /tmp/jupyter/images/","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index c32f3479..cbf5a8a5 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -13,7 +13,7 @@ runs:
   using: composite
   steps:
     - name: Download built image 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: ${{ inputs.image }}-${{ inputs.platform }}
         path: /tmp/jupyter/images/",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,07366286497c853b81d139fc170f35d113403620,ccbe6781543b6c4e44b8deedd39dc6bc0813431c,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 84ea58f3..01520d34 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -75,7 +75,7 @@ jobs:
           python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
@@ -85,13 +85,13 @@ jobs:
         run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
           path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
           path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
@@ -103,7 +103,7 @@ jobs:
           docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
           path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 84ea58f3..01520d34 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -75,7 +75,7 @@ jobs:
           python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
@@ -85,13 +85,13 @@ jobs:
         run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
           path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
           path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
@@ -103,7 +103,7 @@ jobs:
           docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
           path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,07366286497c853b81d139fc170f35d113403620,ccbe6781543b6c4e44b8deedd39dc6bc0813431c,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index bd90b8b2..038dbff1 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -28,12 +28,12 @@ jobs:
         uses: ./.github/actions/create-dev-env
 
       - name: Download x86_64 tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-x86_64-tags
           path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-aarch64-tags
           path: /tmp/jupyter/tags/","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index bd90b8b2..038dbff1 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -28,12 +28,12 @@ jobs:
         uses: ./.github/actions/create-dev-env
 
       - name: Download x86_64 tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-x86_64-tags
           path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-aarch64-tags
           path: /tmp/jupyter/tags/",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,07366286497c853b81d139fc170f35d113403620,ccbe6781543b6c4e44b8deedd39dc6bc0813431c,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index ec22e7f3..b68a8d1a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -46,7 +46,7 @@ jobs:
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Download tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index ec22e7f3..b68a8d1a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -46,7 +46,7 @@ jobs:
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Download tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,dc009c260cff51015ae4df845e1409b9a5f0cc0b,07366286497c853b81d139fc170f35d113403620,"Revert ""Update actions/download-artifact and actions/upload-artifact to v4 (#2061)""

This reverts commit 07366286497c853b81d139fc170f35d113403620.","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index b26c2bc3..ddc26a82 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -20,258 +20,258 @@ runs:
   using: composite
   steps:
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
 
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index b26c2bc3..ddc26a82 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -20,258 +20,258 @@ runs:
   using: composite
   steps:
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
 
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: docker-stacks-foundation-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: base-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: base-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest",Yes
.github/actions/load-image/action.yml,.github/actions/load-image/action.yml,dc009c260cff51015ae4df845e1409b9a5f0cc0b,07366286497c853b81d139fc170f35d113403620,"Revert ""Update actions/download-artifact and actions/upload-artifact to v4 (#2061)""

This reverts commit 07366286497c853b81d139fc170f35d113403620.","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index cbf5a8a5..c32f3479 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -13,7 +13,7 @@ runs:
   using: composite
   steps:
     - name: Download built image 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: ${{ inputs.image }}-${{ inputs.platform }}
         path: /tmp/jupyter/images/","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index cbf5a8a5..c32f3479 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -13,7 +13,7 @@ runs:
   using: composite
   steps:
     - name: Download built image 📥
-      uses: actions/download-artifact@v4
+      uses: actions/download-artifact@v3
       with:
         name: ${{ inputs.image }}-${{ inputs.platform }}
         path: /tmp/jupyter/images/",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,dc009c260cff51015ae4df845e1409b9a5f0cc0b,07366286497c853b81d139fc170f35d113403620,"Revert ""Update actions/download-artifact and actions/upload-artifact to v4 (#2061)""

This reverts commit 07366286497c853b81d139fc170f35d113403620.","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 01520d34..84ea58f3 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -75,7 +75,7 @@ jobs:
           python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
-        uses: actions/upload-artifact@v4
+        uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
@@ -85,13 +85,13 @@ jobs:
         run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
-        uses: actions/upload-artifact@v4
+        uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
           path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
-        uses: actions/upload-artifact@v4
+        uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
           path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
@@ -103,7 +103,7 @@ jobs:
           docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
-        uses: actions/upload-artifact@v4
+        uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
           path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 01520d34..84ea58f3 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -75,7 +75,7 @@ jobs:
           python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
-        uses: actions/upload-artifact@v4
+        uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
@@ -85,13 +85,13 @@ jobs:
         run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
-        uses: actions/upload-artifact@v4
+        uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
           path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
-        uses: actions/upload-artifact@v4
+        uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
           path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
@@ -103,7 +103,7 @@ jobs:
           docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
-        uses: actions/upload-artifact@v4
+        uses: actions/upload-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
           path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,dc009c260cff51015ae4df845e1409b9a5f0cc0b,07366286497c853b81d139fc170f35d113403620,"Revert ""Update actions/download-artifact and actions/upload-artifact to v4 (#2061)""

This reverts commit 07366286497c853b81d139fc170f35d113403620.","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 038dbff1..bd90b8b2 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -28,12 +28,12 @@ jobs:
         uses: ./.github/actions/create-dev-env
 
       - name: Download x86_64 tags file 📥
-        uses: actions/download-artifact@v4
+        uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-x86_64-tags
           path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
-        uses: actions/download-artifact@v4
+        uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-aarch64-tags
           path: /tmp/jupyter/tags/","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 038dbff1..bd90b8b2 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -28,12 +28,12 @@ jobs:
         uses: ./.github/actions/create-dev-env
 
       - name: Download x86_64 tags file 📥
-        uses: actions/download-artifact@v4
+        uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-x86_64-tags
           path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
-        uses: actions/download-artifact@v4
+        uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-aarch64-tags
           path: /tmp/jupyter/tags/",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,dc009c260cff51015ae4df845e1409b9a5f0cc0b,07366286497c853b81d139fc170f35d113403620,"Revert ""Update actions/download-artifact and actions/upload-artifact to v4 (#2061)""

This reverts commit 07366286497c853b81d139fc170f35d113403620.","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index b68a8d1a..ec22e7f3 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -46,7 +46,7 @@ jobs:
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Download tags file 📥
-        uses: actions/download-artifact@v4
+        uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index b68a8d1a..ec22e7f3 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -46,7 +46,7 @@ jobs:
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Download tags file 📥
-        uses: actions/download-artifact@v4
+        uses: actions/download-artifact@v3
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/",Yes
docs/conf.py,docs/conf.py,474312ac7999eb36cb3682066bdadae25e4f351e,dc009c260cff51015ae4df845e1409b9a5f0cc0b,Update conf.py for new sphinx version,"diff --git a/docs/conf.py b/docs/conf.py
index cb3f07f0..ed89a61f 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -29,7 +29,7 @@ language = ""en""
 html_theme = ""alabaster""
 html_static_path = [""_static""]
 
-# The file above was generated using sphinx 6.2.1 with this command:
+# The file above was generated using sphinx 7.2.6 with this command:
 # sphinx-quickstart --project ""docker-stacks"" --author ""Project Jupyter"" -v ""latest"" -r ""latest"" -l en --no-sep --no-makefile --no-batchfile
 # These are custom options for this project","diff --git a/docs/conf.py b/docs/conf.py
index cb3f07f0..ed89a61f 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -29,7 +29,7 @@ language = ""en""
 html_theme = ""alabaster""
 html_static_path = [""_static""]
 
-# The file above was generated using sphinx 6.2.1 with this command:
+# The file above was generated using sphinx 7.2.6 with this command:
 # sphinx-quickstart --project ""docker-stacks"" --author ""Project Jupyter"" -v ""latest"" -r ""latest"" -l en --no-sep --no-makefile --no-batchfile
 # These are custom options for this project",Yes
README.md,README.md,1494233e27cdc70e3766ea2518e7153ee425fc4f,474312ac7999eb36cb3682066bdadae25e4f351e,"Link to the rocker/binder image as an alternative (#2065)

* Link to the rocker/binder image as an alternative

* Unify style in README.md

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/README.md b/README.md
index 43dac093..fd13f1f9 100644
--- a/README.md
+++ b/README.md
@@ -125,6 +125,9 @@ for information about how to contribute recipes, features, tests, and community-
 
 ## Alternatives
 
+- [rocker/binder](https://rocker-project.org/images/versioned/binder.html) -
+  From the R focused [rocker-project](https://rocker-project.org),
+  lets you run both RStudio and Jupyter either standalone or in a JupyterHub
 - [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) -
   Turn git repositories into Jupyter-enabled Docker Images
 - [openshift/source-to-image](https://github.com/openshift/source-to-image) -","diff --git a/README.md b/README.md
index 43dac093..fd13f1f9 100644
--- a/README.md
+++ b/README.md
@@ -125,6 +125,9 @@ for information about how to contribute recipes, features, tests, and community-
 
 ## Alternatives
 
+- [rocker/binder](https://rocker-project.org/images/versioned/binder.html) -
+  From the R focused [rocker-project](https://rocker-project.org),
+  lets you run both RStudio and Jupyter either standalone or in a JupyterHub
 - [jupyter/repo2docker](https://github.com/jupyterhub/repo2docker) -
   Turn git repositories into Jupyter-enabled Docker Images
 - [openshift/source-to-image](https://github.com/openshift/source-to-image) -",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,fcb20a914ed20e44a96053caf43eef6e12fb4c04,1494233e27cdc70e3766ea2518e7153ee425fc4f,"[pre-commit.ci] pre-commit autoupdate (#2071)

updates:
- [github.com/PyCQA/isort: 5.12.0 → 5.13.2](https://github.com/PyCQA/isort/compare/5.12.0...5.13.2)
- [github.com/psf/black: 23.11.0 → 23.12.1](https://github.com/psf/black/compare/23.11.0...23.12.1)
- [github.com/pre-commit/mirrors-mypy: v1.7.1 → v1.8.0](https://github.com/pre-commit/mirrors-mypy/compare/v1.7.1...v1.8.0)
- [github.com/pre-commit/mirrors-prettier: v3.1.0 → v4.0.0-alpha.8](https://github.com/pre-commit/mirrors-prettier/compare/v3.1.0...v4.0.0-alpha.8)
- [github.com/igorshubovych/markdownlint-cli: v0.37.0 → v0.38.0](https://github.com/igorshubovych/markdownlint-cli/compare/v0.37.0...v0.38.0)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index fe8f0ef3..369d60ef 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -21,21 +21,21 @@ repos:
 
   # Automatically sort python imports
   - repo: https://github.com/PyCQA/isort
-    rev: 5.12.0
+    rev: 5.13.2
     hooks:
       - id: isort
         args: [--profile, black]
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.11.0
+    rev: 23.12.1
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.7.1
+    rev: v1.8.0
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -60,7 +60,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.1.0
+    rev: v4.0.0-alpha.8
     hooks:
       - id: prettier
 
@@ -121,7 +121,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.37.0
+    rev: v0.38.0
     hooks:
       - id: markdownlint
         args: [""--fix""]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index fe8f0ef3..369d60ef 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -21,21 +21,21 @@ repos:
 
   # Automatically sort python imports
   - repo: https://github.com/PyCQA/isort
-    rev: 5.12.0
+    rev: 5.13.2
     hooks:
       - id: isort
         args: [--profile, black]
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.11.0
+    rev: 23.12.1
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.7.1
+    rev: v1.8.0
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -60,7 +60,7 @@ repos:
 
   # Autoformat: YAML, JSON, Markdown, etc.
   - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v3.1.0
+    rev: v4.0.0-alpha.8
     hooks:
       - id: prettier
 
@@ -121,7 +121,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.37.0
+    rev: v0.38.0
     hooks:
       - id: markdownlint
         args: [""--fix""]",Yes
.readthedocs.yaml,.readthedocs.yaml,dc6432a4eba17c21a3a90cf0c0560b9d24052644,fcb20a914ed20e44a96053caf43eef6e12fb4c04,Update .readthedocs.yaml,"diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index 7cc5786e..31dbf0d7 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -8,7 +8,7 @@ version: 2
 build:
   os: ubuntu-22.04
   tools:
-    python: ""3.11""
+    python: ""3.12""
     # You can also specify other tool versions:
     # nodejs: ""20""
     # rust: ""1.70""","diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index 7cc5786e..31dbf0d7 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -8,7 +8,7 @@ version: 2
 build:
   os: ubuntu-22.04
   tools:
-    python: ""3.11""
+    python: ""3.12""
     # You can also specify other tool versions:
     # nodejs: ""20""
     # rust: ""1.70""",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,06cdadd0bfcadd803b9bef578641a3b947077625,dc6432a4eba17c21a3a90cf0c0560b9d24052644,Improve spark pandas version information,"diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 87b03048..334181c3 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -71,8 +71,8 @@ USER ${NB_UID}
 # The pandas version in this Dockerfile should match the version
 # on which the Pandas API for Spark is built.
 # To find the right version:
-# 1. Check out the Spark branch you are on.
-# 2. Find the pandas version in the file spark/dev/infra/Dockerfile.
+# 1. Check out the Spark branch you are on: <https://github.com/apache/spark>
+# 2. Find the pandas version in the file `dev/infra/Dockerfile`.
 RUN mamba install --yes \
     'grpcio-status' \
     'grpcio' \","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 87b03048..334181c3 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -71,8 +71,8 @@ USER ${NB_UID}
 # The pandas version in this Dockerfile should match the version
 # on which the Pandas API for Spark is built.
 # To find the right version:
-# 1. Check out the Spark branch you are on.
-# 2. Find the pandas version in the file spark/dev/infra/Dockerfile.
+# 1. Check out the Spark branch you are on: <https://github.com/apache/spark>
+# 2. Find the pandas version in the file `dev/infra/Dockerfile`.
 RUN mamba install --yes \
     'grpcio-status' \
     'grpcio' \",Yes
images/minimal-notebook/setup-scripts/setup_julia.py,images/minimal-notebook/setup-scripts/setup_julia.py,c515e883ea2f08aeacbf59a414340dfbdf4da229,06cdadd0bfcadd803b9bef578641a3b947077625,"Fix `max(stable_versions)` on Julia version finding (#2076)

* Fix `max(stable_versions)`

Since the keys are semantic version strings, that means that `""1.9.4"" > ""1.10.0"", which we know isn't true. 🙂

I just added some code to convert the string to tuples, find the max, then convert back to a string.

I first noticed this on the `2024-01-05` build of the `datascience-notebook`, since Julia 1.10.0 was released ~2 weeks ago: https://github.com/JuliaLang/julia/releases/tag/v1.10.0.

* Migrate to comparator on `max(stable_versions)`

* Update setup_julia.py

* Update setup_julia.py

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>
Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index 0cdbe0cf..890b253a 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -36,7 +36,10 @@ def get_latest_julia_url() -> tuple[str, str]:
         ""https://julialang-s3.julialang.org/bin/versions.json""
     ).json()
     stable_versions = {k: v for k, v in versions.items() if v[""stable""]}
-    latest_version_files = stable_versions[max(stable_versions)][""files""]
+    latest_stable_version = max(
+        stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
+    )
+    latest_version_files = stable_versions[latest_stable_version][""files""]
     triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
     file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
     return file_info[""url""], file_info[""version""]","diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index 0cdbe0cf..890b253a 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -36,7 +36,10 @@ def get_latest_julia_url() -> tuple[str, str]:
         ""https://julialang-s3.julialang.org/bin/versions.json""
     ).json()
     stable_versions = {k: v for k, v in versions.items() if v[""stable""]}
-    latest_version_files = stable_versions[max(stable_versions)][""files""]
+    latest_stable_version = max(
+        stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
+    )
+    latest_version_files = stable_versions[latest_stable_version][""files""]
     triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
     file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
     return file_info[""url""], file_info[""version""]",Yes
images/minimal-notebook/setup-scripts/setup_julia.py,images/minimal-notebook/setup-scripts/setup_julia.py,48b189e585c87d48d02962afe91b2b42be62e70f,c515e883ea2f08aeacbf59a414340dfbdf4da229,Add a comment for choosing latest_stable_version for Julia,"diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index 890b253a..7f2478d1 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -36,6 +36,7 @@ def get_latest_julia_url() -> tuple[str, str]:
         ""https://julialang-s3.julialang.org/bin/versions.json""
     ).json()
     stable_versions = {k: v for k, v in versions.items() if v[""stable""]}
+    # Compare versions semantically
     latest_stable_version = max(
         stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
     )","diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index 890b253a..7f2478d1 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -36,6 +36,7 @@ def get_latest_julia_url() -> tuple[str, str]:
         ""https://julialang-s3.julialang.org/bin/versions.json""
     ).json()
     stable_versions = {k: v for k, v in versions.items() if v[""stable""]}
+    # Compare versions semantically
     latest_stable_version = max(
         stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
     )",Yes
images/base-notebook/docker_healthcheck.py,images/base-notebook/docker_healthcheck.py,2a6a115a7ce793a3a036dc6fbc2d704df766cead,48b189e585c87d48d02962afe91b2b42be62e70f,"[FAST_BUILD] Fix Docker healthcheck when using custom runtime dirs (#2074)

* Fix Docker healthcheck when using custom runtime dirs

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Use a writable directory for healthcheck test

* Allow missing import for `jupyter_core` in mypy

* Set HOME according to NB_USER in healthcheck script

* Add custom runtime dir an NB_USER case to healthcheck test

* Call `jupyter --runtime-dir` directly in healthcheck script

* Update docker_healthcheck.py

* Update docker_healthcheck.py

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/base-notebook/docker_healthcheck.py b/images/base-notebook/docker_healthcheck.py
index 8f3338e8..7dd3de02 100755
--- a/images/base-notebook/docker_healthcheck.py
+++ b/images/base-notebook/docker_healthcheck.py
@@ -3,6 +3,7 @@
 # Distributed under the terms of the Modified BSD License.
 import json
 import os
+import subprocess
 from pathlib import Path
 
 import requests
@@ -10,7 +11,19 @@ import requests
 # Several operations below deliberately don't check for possible errors
 # As this is a healthcheck, it should succeed or raise an exception on error
 
-runtime_dir = Path(""/home/"") / os.environ[""NB_USER""] / "".local/share/jupyter/runtime/""
+# Docker runs healtchecks using an exec
+# It uses the default user configured when running the image: root for the case of a custom NB_USER or jovyan for the case of the default image user.
+# We manually change HOME to make `jupyter --runtime-dir` report a correct path
+# More information: <https://github.com/jupyter/docker-stacks/pull/2074#issuecomment-1879778409>
+result = subprocess.run(
+    [""jupyter"", ""--runtime-dir""],
+    check=True,
+    capture_output=True,
+    text=True,
+    env=dict(os.environ) | {""HOME"": ""/home/"" + os.environ[""NB_USER""]},
+)
+runtime_dir = Path(result.stdout.rstrip())
+
 json_file = next(runtime_dir.glob(""*server-*.json""))
 
 url = json.loads(json_file.read_bytes())[""url""]","diff --git a/images/base-notebook/docker_healthcheck.py b/images/base-notebook/docker_healthcheck.py
index 8f3338e8..7dd3de02 100755
--- a/images/base-notebook/docker_healthcheck.py
+++ b/images/base-notebook/docker_healthcheck.py
@@ -3,6 +3,7 @@
 # Distributed under the terms of the Modified BSD License.
 import json
 import os
+import subprocess
 from pathlib import Path
 
 import requests
@@ -10,7 +11,19 @@ import requests
 # Several operations below deliberately don't check for possible errors
 # As this is a healthcheck, it should succeed or raise an exception on error
 
-runtime_dir = Path(""/home/"") / os.environ[""NB_USER""] / "".local/share/jupyter/runtime/""
+# Docker runs healtchecks using an exec
+# It uses the default user configured when running the image: root for the case of a custom NB_USER or jovyan for the case of the default image user.
+# We manually change HOME to make `jupyter --runtime-dir` report a correct path
+# More information: <https://github.com/jupyter/docker-stacks/pull/2074#issuecomment-1879778409>
+result = subprocess.run(
+    [""jupyter"", ""--runtime-dir""],
+    check=True,
+    capture_output=True,
+    text=True,
+    env=dict(os.environ) | {""HOME"": ""/home/"" + os.environ[""NB_USER""]},
+)
+runtime_dir = Path(result.stdout.rstrip())
+
 json_file = next(runtime_dir.glob(""*server-*.json""))
 
 url = json.loads(json_file.read_bytes())[""url""]",Yes
tests/base-notebook/test_healthcheck.py,tests/base-notebook/test_healthcheck.py,2a6a115a7ce793a3a036dc6fbc2d704df766cead,48b189e585c87d48d02962afe91b2b42be62e70f,"[FAST_BUILD] Fix Docker healthcheck when using custom runtime dirs (#2074)

* Fix Docker healthcheck when using custom runtime dirs

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Use a writable directory for healthcheck test

* Allow missing import for `jupyter_core` in mypy

* Set HOME according to NB_USER in healthcheck script

* Add custom runtime dir an NB_USER case to healthcheck test

* Call `jupyter --runtime-dir` directly in healthcheck script

* Update docker_healthcheck.py

* Update docker_healthcheck.py

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 50d83c27..450a0111 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -42,6 +42,16 @@ LOGGER = logging.getLogger(__name__)
             [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
+        ([""JUPYTER_RUNTIME_DIR=/tmp/jupyter-runtime""], [""start-notebook.sh""], None),
+        (
+            [
+                ""NB_USER=testuser"",
+                ""CHOWN_HOME=1"",
+                ""JUPYTER_RUNTIME_DIR=/tmp/jupyter-runtime"",
+            ],
+            [""start-notebook.sh""],
+            ""root"",
+        ),
     ],
 )
 def test_health(","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 50d83c27..450a0111 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -42,6 +42,16 @@ LOGGER = logging.getLogger(__name__)
             [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",
         ),
+        ([""JUPYTER_RUNTIME_DIR=/tmp/jupyter-runtime""], [""start-notebook.sh""], None),
+        (
+            [
+                ""NB_USER=testuser"",
+                ""CHOWN_HOME=1"",
+                ""JUPYTER_RUNTIME_DIR=/tmp/jupyter-runtime"",
+            ],
+            [""start-notebook.sh""],
+            ""root"",
+        ),
     ],
 )
 def test_health(",Yes
tests/base-notebook/test_healthcheck.py,tests/base-notebook/test_healthcheck.py,c1229303d069fe76aa6a498068b68d0360554e14,2a6a115a7ce793a3a036dc6fbc2d704df766cead,Rename some tests in test_healthcheck.py,"diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 450a0111..7aca3ac6 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -54,7 +54,7 @@ LOGGER = logging.getLogger(__name__)
         ),
     ],
 )
-def test_health(
+def test_healthy(
     container: TrackedContainer,
     env: Optional[list[str]],
     cmd: Optional[list[str]],
@@ -101,7 +101,7 @@ def test_health(
         ),
     ],
 )
-def test_health_proxy(
+def test_healthy_with_proxy(
     container: TrackedContainer,
     env: Optional[list[str]],
     cmd: Optional[list[str]],","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 450a0111..7aca3ac6 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -54,7 +54,7 @@ LOGGER = logging.getLogger(__name__)
         ),
     ],
 )
-def test_health(
+def test_healthy(
     container: TrackedContainer,
     env: Optional[list[str]],
     cmd: Optional[list[str]],
@@ -101,7 +101,7 @@ def test_health(
         ),
     ],
 )
-def test_health_proxy(
+def test_healthy_with_proxy(
     container: TrackedContainer,
     env: Optional[list[str]],
     cmd: Optional[list[str]],",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,c294e9e2d95266e50cde9aabf97ddea0a496a7fc,c1229303d069fe76aa6a498068b68d0360554e14,"Automatically install latest spark version (#2075)

* Automatically install latest pyspark version

* Better text

* Do not use shutil to keep behaviour

* Make setup_script cwd independent

* Use _get_program_version to calculate spark version

* Update setup_spark.py reqs

* Update setup_spark.py

* Add info about HADOOP_VERSION

* Add customization back

* Better text

* Specify build args when they are actually needed

* Better text

* Better code

* Better code

* Better text

* Get rid of warning

* Improve code

* Remove information about checksum

* Better text","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 369d60ef..14391a79 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -41,10 +41,12 @@ repos:
         args: [--config, ./mypy.ini]
         additional_dependencies:
           [
+            ""beautifulsoup4"",
             ""numpy"",
             ""pytest"",
             ""requests"",
             ""urllib3"",
+            ""types-beautifulsoup4"",
             ""types-requests"",
             ""types-tabulate"",
             ""types-urllib3"",","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 369d60ef..14391a79 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -41,10 +41,12 @@ repos:
         args: [--config, ./mypy.ini]
         additional_dependencies:
           [
+            ""beautifulsoup4"",
             ""numpy"",
             ""pytest"",
             ""requests"",
             ""urllib3"",
+            ""types-beautifulsoup4"",
             ""types-requests"",
             ""types-tabulate"",
             ""types-urllib3"",",Yes
docs/using/specifics.md,docs/using/specifics.md,c294e9e2d95266e50cde9aabf97ddea0a496a7fc,c1229303d069fe76aa6a498068b68d0360554e14,"Automatically install latest spark version (#2075)

* Automatically install latest pyspark version

* Better text

* Do not use shutil to keep behaviour

* Make setup_script cwd independent

* Use _get_program_version to calculate spark version

* Update setup_spark.py reqs

* Update setup_spark.py

* Add info about HADOOP_VERSION

* Add customization back

* Better text

* Specify build args when they are actually needed

* Better text

* Better code

* Better code

* Better text

* Get rid of warning

* Improve code

* Remove information about checksum

* Better text","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index f0ede8f4..c578e378 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -42,18 +42,20 @@ ipython profile create
 You can build a `pyspark-notebook` image with a different `Spark` version by overriding the default value of the following arguments at build time.
 `all-spark-notebook` is inherited from `pyspark-notebook`, so you have to first build `pyspark-notebook` and then `all-spark-notebook` to get the same version in `all-spark-notebook`.
 
-- Spark distribution is defined by the combination of Spark, Hadoop, and Scala versions and verified by the package checksum,
+- Spark distribution is defined by the combination of Spark, Hadoop, and Scala versions,
   see [Download Apache Spark](https://spark.apache.org/downloads.html) and the [archive repo](https://archive.apache.org/dist/spark/) for more information.
 
-  - `spark_version`: The Spark version to install (`3.3.0`).
-  - `hadoop_version`: The Hadoop version (`3.2`).
-  - `scala_version`: The Scala version (`2.13`, optional).
-  - `spark_checksum`: The package checksum (`BFE4540...`).
-  - `openjdk_version`: The version of the OpenJDK (JRE headless) distribution (`17`).
+  - `openjdk_version`: The version of the OpenJDK (JRE headless) distribution (`17` by default).
     - This version needs to match the version supported by the Spark distribution used above.
     - See [Spark Overview](https://spark.apache.org/docs/latest/#downloading) and [Ubuntu packages](https://packages.ubuntu.com/search?keywords=openjdk).
-
-- Starting with _Spark >= 3.2_, the distribution file might contain the Scala version.
+  - `spark_version` (optional): The Spark version to install, for example `3.5.0`.
+    If not specified (this is the default), latest stable Spark will be installed.
+  - `hadoop_version`: The Hadoop version (`3` by default).
+    Note, that _Spark < 3.3_ require to specify `major.minor` Hadoop version (i.e. `3.2`).
+  - `scala_version` (optional): The Scala version, for example `2.13` (not specified by default).
+    Starting with _Spark >= 3.2_, the distribution file might contain the Scala version.
+  - `spark_download_url`: URL to use for Spark downloads.
+    You may need to use <https://archive.apache.org/dist/spark/> url if you want to download old Spark versions.
 
 For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2`, and OpenJDK `11`.
 
@@ -65,14 +67,14 @@ This recipe is not tested and might be broken.
 # From the root of the project
 # Build the image with different arguments
 docker build --rm --force-rm \
-    -t jupyter/pyspark-notebook:spark-3.2.0 ./images/pyspark-notebook \
+    -t my-pyspark-notebook ./images/pyspark-notebook \
+    --build-arg openjdk_version=11 \
     --build-arg spark_version=3.2.0 \
     --build-arg hadoop_version=3.2 \
-    --build-arg spark_checksum=707DDE035926A50B75E53FCA72CADA519F3239B14A96546911CB4916A58DCF69A1D2BFDD2C7DD5899324DBD82B6EEAB9797A7B4ABF86736FFCA4C26D0E0BF0EE \
-    --build-arg openjdk_version=11
+    --build-arg spark_download_url=""https://archive.apache.org/dist/spark/""
 
 # Check the newly built image
-docker run -it --rm quay.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
+docker run -it --rm my-pyspark-notebook pyspark --version
 
 # Welcome to
 #       ____              __
@@ -81,7 +83,12 @@ docker run -it --rm quay.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --versi
 #    /___/ .__/\_,_/_/ /_/\_\   version 3.2.0
 #       /_/
 
-# Using Scala version 2.13.5, OpenJDK 64-Bit Server VM, 11.0.15
+# Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21
+# Branch HEAD
+# Compiled by user ubuntu on 2021-10-06T12:46:30Z
+# Revision 5d45a415f3a29898d92380380cfd82bfc7f579ea
+# Url https://github.com/apache/spark
+# Type --help for more information.
 ```
 
 ### Usage Examples","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index f0ede8f4..c578e378 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -42,18 +42,20 @@ ipython profile create
 You can build a `pyspark-notebook` image with a different `Spark` version by overriding the default value of the following arguments at build time.
 `all-spark-notebook` is inherited from `pyspark-notebook`, so you have to first build `pyspark-notebook` and then `all-spark-notebook` to get the same version in `all-spark-notebook`.
 
-- Spark distribution is defined by the combination of Spark, Hadoop, and Scala versions and verified by the package checksum,
+- Spark distribution is defined by the combination of Spark, Hadoop, and Scala versions,
   see [Download Apache Spark](https://spark.apache.org/downloads.html) and the [archive repo](https://archive.apache.org/dist/spark/) for more information.
 
-  - `spark_version`: The Spark version to install (`3.3.0`).
-  - `hadoop_version`: The Hadoop version (`3.2`).
-  - `scala_version`: The Scala version (`2.13`, optional).
-  - `spark_checksum`: The package checksum (`BFE4540...`).
-  - `openjdk_version`: The version of the OpenJDK (JRE headless) distribution (`17`).
+  - `openjdk_version`: The version of the OpenJDK (JRE headless) distribution (`17` by default).
     - This version needs to match the version supported by the Spark distribution used above.
     - See [Spark Overview](https://spark.apache.org/docs/latest/#downloading) and [Ubuntu packages](https://packages.ubuntu.com/search?keywords=openjdk).
-
-- Starting with _Spark >= 3.2_, the distribution file might contain the Scala version.
+  - `spark_version` (optional): The Spark version to install, for example `3.5.0`.
+    If not specified (this is the default), latest stable Spark will be installed.
+  - `hadoop_version`: The Hadoop version (`3` by default).
+    Note, that _Spark < 3.3_ require to specify `major.minor` Hadoop version (i.e. `3.2`).
+  - `scala_version` (optional): The Scala version, for example `2.13` (not specified by default).
+    Starting with _Spark >= 3.2_, the distribution file might contain the Scala version.
+  - `spark_download_url`: URL to use for Spark downloads.
+    You may need to use <https://archive.apache.org/dist/spark/> url if you want to download old Spark versions.
 
 For example, here is how to build a `pyspark-notebook` image with Spark `3.2.0`, Hadoop `3.2`, and OpenJDK `11`.
 
@@ -65,14 +67,14 @@ This recipe is not tested and might be broken.
 # From the root of the project
 # Build the image with different arguments
 docker build --rm --force-rm \
-    -t jupyter/pyspark-notebook:spark-3.2.0 ./images/pyspark-notebook \
+    -t my-pyspark-notebook ./images/pyspark-notebook \
+    --build-arg openjdk_version=11 \
     --build-arg spark_version=3.2.0 \
     --build-arg hadoop_version=3.2 \
-    --build-arg spark_checksum=707DDE035926A50B75E53FCA72CADA519F3239B14A96546911CB4916A58DCF69A1D2BFDD2C7DD5899324DBD82B6EEAB9797A7B4ABF86736FFCA4C26D0E0BF0EE \
-    --build-arg openjdk_version=11
+    --build-arg spark_download_url=""https://archive.apache.org/dist/spark/""
 
 # Check the newly built image
-docker run -it --rm quay.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --version
+docker run -it --rm my-pyspark-notebook pyspark --version
 
 # Welcome to
 #       ____              __
@@ -81,7 +83,12 @@ docker run -it --rm quay.io/jupyter/pyspark-notebook:spark-3.2.0 pyspark --versi
 #    /___/ .__/\_,_/_/ /_/\_\   version 3.2.0
 #       /_/
 
-# Using Scala version 2.13.5, OpenJDK 64-Bit Server VM, 11.0.15
+# Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 11.0.21
+# Branch HEAD
+# Compiled by user ubuntu on 2021-10-06T12:46:30Z
+# Revision 5d45a415f3a29898d92380380cfd82bfc7f579ea
+# Url https://github.com/apache/spark
+# Type --help for more information.
 ```
 
 ### Usage Examples",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,c294e9e2d95266e50cde9aabf97ddea0a496a7fc,c1229303d069fe76aa6a498068b68d0360554e14,"Automatically install latest spark version (#2075)

* Automatically install latest pyspark version

* Better text

* Do not use shutil to keep behaviour

* Make setup_script cwd independent

* Use _get_program_version to calculate spark version

* Update setup_spark.py reqs

* Update setup_spark.py

* Add info about HADOOP_VERSION

* Add customization back

* Better text

* Specify build args when they are actually needed

* Better text

* Better code

* Better code

* Better text

* Get rid of warning

* Improve code

* Remove information about checksum

* Better text","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 334181c3..212e3a55 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -16,49 +16,38 @@ USER root
 # Spark dependencies
 # Default values can be overridden at build time
 # (ARGS are in lowercase to distinguish them from ENV)
-ARG spark_version=""3.5.0""
-ARG hadoop_version=""3""
-ARG scala_version
-ARG spark_checksum=""8883c67e0a138069e597f3e7d4edbbd5c3a565d50b28644aad02856a1ec1da7cb92b8f80454ca427118f69459ea326eaa073cf7b1a860c3b796f4b07c2101319""
 ARG openjdk_version=""17""
 
-ENV APACHE_SPARK_VERSION=""${spark_version}"" \
-    HADOOP_VERSION=""${hadoop_version}""
-
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     ""openjdk-${openjdk_version}-jre-headless"" \
     ca-certificates-java && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
-# Spark installation
-WORKDIR /tmp
-
-# You need to use https://archive.apache.org/dist/ website if you want to download old Spark versions
+# If spark_version is not set, latest stable Spark will be installed
+ARG spark_version
+ARG hadoop_version=""3""
+# If scala_version is not set, Spark without Scala will be installed
+ARG scala_version
+# URL to use for Spark downloads
+# You need to use https://archive.apache.org/dist/spark/ website if you want to download old Spark versions
 # But it seems to be slower, that's why we use the recommended site for download
-RUN if [ -z ""${scala_version}"" ]; then \
-    curl --progress-bar --location --output ""spark.tgz"" \
-        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \
-  else \
-    curl --progress-bar --location --output ""spark.tgz"" \
-        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}.tgz""; \
-  fi && \
-  echo ""${spark_checksum} *spark.tgz"" | sha512sum -c - && \
-  tar xzf ""spark.tgz"" -C /usr/local --owner root --group root --no-same-owner && \
-  rm ""spark.tgz""
+ARG spark_download_url=""https://dlcdn.apache.org/spark/""
 
 # Configure Spark
+ENV SPARK_VERSION=""${spark_version}"" \
+    HADOOP_VERSION=""${hadoop_version}"" \
+    SCALA_VERSION=""${scala_version}"" \
+    SPARK_DOWNLOAD_URL=""${spark_download_url}""
+
 ENV SPARK_HOME=/usr/local/spark
-ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info"" \
-    PATH=""${PATH}:${SPARK_HOME}/bin""
+ENV PATH=""${PATH}:${SPARK_HOME}/bin""
+ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info""
+
+COPY setup_spark.py /opt/setup-scripts/
 
-RUN if [ -z ""${scala_version}"" ]; then \
-    ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}"" ""${SPARK_HOME}""; \
-  else \
-    ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}"" ""${SPARK_HOME}""; \
-  fi && \
-  # Add a link in the before_notebook hook in order to source automatically PYTHONPATH && \
-  ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/10spark-config.sh
+# Setup Spark
+RUN /opt/setup-scripts/setup_spark.py
 
 # Configure IPython system-wide
 COPY ipython_kernel_config.py ""/etc/ipython/""","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 334181c3..212e3a55 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -16,49 +16,38 @@ USER root
 # Spark dependencies
 # Default values can be overridden at build time
 # (ARGS are in lowercase to distinguish them from ENV)
-ARG spark_version=""3.5.0""
-ARG hadoop_version=""3""
-ARG scala_version
-ARG spark_checksum=""8883c67e0a138069e597f3e7d4edbbd5c3a565d50b28644aad02856a1ec1da7cb92b8f80454ca427118f69459ea326eaa073cf7b1a860c3b796f4b07c2101319""
 ARG openjdk_version=""17""
 
-ENV APACHE_SPARK_VERSION=""${spark_version}"" \
-    HADOOP_VERSION=""${hadoop_version}""
-
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
     ""openjdk-${openjdk_version}-jre-headless"" \
     ca-certificates-java && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
-# Spark installation
-WORKDIR /tmp
-
-# You need to use https://archive.apache.org/dist/ website if you want to download old Spark versions
+# If spark_version is not set, latest stable Spark will be installed
+ARG spark_version
+ARG hadoop_version=""3""
+# If scala_version is not set, Spark without Scala will be installed
+ARG scala_version
+# URL to use for Spark downloads
+# You need to use https://archive.apache.org/dist/spark/ website if you want to download old Spark versions
 # But it seems to be slower, that's why we use the recommended site for download
-RUN if [ -z ""${scala_version}"" ]; then \
-    curl --progress-bar --location --output ""spark.tgz"" \
-        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz""; \
-  else \
-    curl --progress-bar --location --output ""spark.tgz"" \
-        ""https://dlcdn.apache.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}.tgz""; \
-  fi && \
-  echo ""${spark_checksum} *spark.tgz"" | sha512sum -c - && \
-  tar xzf ""spark.tgz"" -C /usr/local --owner root --group root --no-same-owner && \
-  rm ""spark.tgz""
+ARG spark_download_url=""https://dlcdn.apache.org/spark/""
 
 # Configure Spark
-ENV SPARK_HOME=/usr/local/spark
-ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info"" \
-    PATH=""${PATH}:${SPARK_HOME}/bin""
+ENV SPARK_VERSION=""${spark_version}"" \
+    HADOOP_VERSION=""${hadoop_version}"" \
+    SCALA_VERSION=""${scala_version}"" \
+    SPARK_DOWNLOAD_URL=""${spark_download_url}""
 
-RUN if [ -z ""${scala_version}"" ]; then \
-    ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}"" ""${SPARK_HOME}""; \
-  else \
-    ln -s ""spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}-scala${scala_version}"" ""${SPARK_HOME}""; \
-  fi && \
-  # Add a link in the before_notebook hook in order to source automatically PYTHONPATH && \
-  ln -s ""${SPARK_HOME}/sbin/spark-config.sh"" /usr/local/bin/before-notebook.d/10spark-config.sh
+ENV SPARK_HOME=/usr/local/spark
+ENV PATH=""${PATH}:${SPARK_HOME}/bin""
+ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info""
+
+COPY setup_spark.py /opt/setup-scripts/
+
+# Setup Spark
+RUN /opt/setup-scripts/setup_spark.py
 
 # Configure IPython system-wide
 COPY ipython_kernel_config.py ""/etc/ipython/""",No
,images/pyspark-notebook/setup_spark.py,c294e9e2d95266e50cde9aabf97ddea0a496a7fc,c1229303d069fe76aa6a498068b68d0360554e14,"Automatically install latest spark version (#2075)

* Automatically install latest pyspark version

* Better text

* Do not use shutil to keep behaviour

* Make setup_script cwd independent

* Use _get_program_version to calculate spark version

* Update setup_spark.py reqs

* Update setup_spark.py

* Add info about HADOOP_VERSION

* Add customization back

* Better text

* Specify build args when they are actually needed

* Better text

* Better code

* Better code

* Better text

* Get rid of warning

* Improve code

* Remove information about checksum

* Better text","diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
new file mode 100755
index 00000000..54e59948
--- /dev/null
+++ b/images/pyspark-notebook/setup_spark.py
@@ -0,0 +1,107 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# Requirements:
+# - Run as the root user
+# - Required env variables: SPARK_HOME, HADOOP_VERSION, SPARK_DOWNLOAD_URL
+# - Optional env variables: SPARK_VERSION, SCALA_VERSION
+
+import os
+import subprocess
+from pathlib import Path
+
+import requests
+from bs4 import BeautifulSoup
+
+
+def get_all_refs(url: str) -> list[str]:
+    """"""
+    Get all the references for a given webpage
+    """"""
+    resp = requests.get(url)
+    soup = BeautifulSoup(resp.text, ""html.parser"")
+    return [a[""href""] for a in soup.find_all(""a"", href=True)]
+
+
+def get_spark_version() -> str:
+    """"""
+    If ${SPARK_VERSION} env variable is non-empty, simply returns it
+    Otherwise, returns the last stable version of Spark using spark archive
+    """"""
+    if (version := os.environ[""SPARK_VERSION""]) != """":
+        return version
+    all_refs = get_all_refs(""https://archive.apache.org/dist/spark/"")
+    stable_versions = [
+        ref.removeprefix(""spark-"").removesuffix(""/"")
+        for ref in all_refs
+        if ref.startswith(""spark-"") and ""incubating"" not in ref and ""preview"" not in ref
+    ]
+    # Compare versions semantically
+    return max(
+        stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
+    )
+
+
+def download_spark(
+    spark_version: str,
+    hadoop_version: str,
+    scala_version: str,
+    spark_download_url: Path,
+) -> str:
+    """"""
+    Downloads and unpacks spark
+    The resulting spark directory name is returned
+    """"""
+    spark_dir_name = f""spark-{spark_version}-bin-hadoop{hadoop_version}""
+    if scala_version:
+        spark_dir_name += f""-scala{scala_version}""
+    spark_url = spark_download_url / f""spark-{spark_version}"" / f""{spark_dir_name}.tgz""
+
+    tmp_file = Path(""/tmp/spark.tar.gz"")
+    subprocess.check_call(
+        [""curl"", ""--progress-bar"", ""--location"", ""--output"", tmp_file, spark_url]
+    )
+    subprocess.check_call(
+        [
+            ""tar"",
+            ""xzf"",
+            tmp_file,
+            ""-C"",
+            ""/usr/local"",
+            ""--owner"",
+            ""root"",
+            ""--group"",
+            ""root"",
+            ""--no-same-owner"",
+        ]
+    )
+    tmp_file.unlink()
+    return spark_dir_name
+
+
+def prepare_spark(spark_dir_name: str, spark_home: Path) -> None:
+    """"""
+    Creates a ${SPARK_HOME} symlink to a versioned spark directory
+    Creates a 10spark-config.sh symlink to source PYTHONPATH automatically
+    """"""
+    subprocess.check_call([""ln"", ""-s"", f""/usr/local/{spark_dir_name}"", spark_home])
+
+    # Add a link in the before_notebook hook in order to source PYTHONPATH automatically
+    CONFIG_SCRIPT = ""/usr/local/bin/before-notebook.d/10spark-config.sh""
+    subprocess.check_call(
+        [""ln"", ""-s"", spark_home / ""sbin/spark-config.sh"", CONFIG_SCRIPT]
+    )
+
+
+if __name__ == ""__main__"":
+    spark_version = get_spark_version()
+    spark_dir_name = download_spark(
+        spark_version=spark_version,
+        hadoop_version=os.environ[""HADOOP_VERSION""],
+        scala_version=os.environ[""SCALA_VERSION""],
+        spark_download_url=Path(os.environ[""SPARK_DOWNLOAD_URL""]),
+    )
+    prepare_spark(
+        spark_dir_name=spark_dir_name, spark_home=Path(os.environ[""SPARK_HOME""])
+    )","diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
new file mode 100755
index 00000000..54e59948
--- /dev/null
+++ b/images/pyspark-notebook/setup_spark.py
@@ -0,0 +1,107 @@
+#!/usr/bin/env python3
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# Requirements:
+# - Run as the root user
+# - Required env variables: SPARK_HOME, HADOOP_VERSION, SPARK_DOWNLOAD_URL
+# - Optional env variables: SPARK_VERSION, SCALA_VERSION
+
+import os
+import subprocess
+from pathlib import Path
+
+import requests
+from bs4 import BeautifulSoup
+
+
+def get_all_refs(url: str) -> list[str]:
+    """"""
+    Get all the references for a given webpage
+    """"""
+    resp = requests.get(url)
+    soup = BeautifulSoup(resp.text, ""html.parser"")
+    return [a[""href""] for a in soup.find_all(""a"", href=True)]
+
+
+def get_spark_version() -> str:
+    """"""
+    If ${SPARK_VERSION} env variable is non-empty, simply returns it
+    Otherwise, returns the last stable version of Spark using spark archive
+    """"""
+    if (version := os.environ[""SPARK_VERSION""]) != """":
+        return version
+    all_refs = get_all_refs(""https://archive.apache.org/dist/spark/"")
+    stable_versions = [
+        ref.removeprefix(""spark-"").removesuffix(""/"")
+        for ref in all_refs
+        if ref.startswith(""spark-"") and ""incubating"" not in ref and ""preview"" not in ref
+    ]
+    # Compare versions semantically
+    return max(
+        stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
+    )
+
+
+def download_spark(
+    spark_version: str,
+    hadoop_version: str,
+    scala_version: str,
+    spark_download_url: Path,
+) -> str:
+    """"""
+    Downloads and unpacks spark
+    The resulting spark directory name is returned
+    """"""
+    spark_dir_name = f""spark-{spark_version}-bin-hadoop{hadoop_version}""
+    if scala_version:
+        spark_dir_name += f""-scala{scala_version}""
+    spark_url = spark_download_url / f""spark-{spark_version}"" / f""{spark_dir_name}.tgz""
+
+    tmp_file = Path(""/tmp/spark.tar.gz"")
+    subprocess.check_call(
+        [""curl"", ""--progress-bar"", ""--location"", ""--output"", tmp_file, spark_url]
+    )
+    subprocess.check_call(
+        [
+            ""tar"",
+            ""xzf"",
+            tmp_file,
+            ""-C"",
+            ""/usr/local"",
+            ""--owner"",
+            ""root"",
+            ""--group"",
+            ""root"",
+            ""--no-same-owner"",
+        ]
+    )
+    tmp_file.unlink()
+    return spark_dir_name
+
+
+def prepare_spark(spark_dir_name: str, spark_home: Path) -> None:
+    """"""
+    Creates a ${SPARK_HOME} symlink to a versioned spark directory
+    Creates a 10spark-config.sh symlink to source PYTHONPATH automatically
+    """"""
+    subprocess.check_call([""ln"", ""-s"", f""/usr/local/{spark_dir_name}"", spark_home])
+
+    # Add a link in the before_notebook hook in order to source PYTHONPATH automatically
+    CONFIG_SCRIPT = ""/usr/local/bin/before-notebook.d/10spark-config.sh""
+    subprocess.check_call(
+        [""ln"", ""-s"", spark_home / ""sbin/spark-config.sh"", CONFIG_SCRIPT]
+    )
+
+
+if __name__ == ""__main__"":
+    spark_version = get_spark_version()
+    spark_dir_name = download_spark(
+        spark_version=spark_version,
+        hadoop_version=os.environ[""HADOOP_VERSION""],
+        scala_version=os.environ[""SCALA_VERSION""],
+        spark_download_url=Path(os.environ[""SPARK_DOWNLOAD_URL""]),
+    )
+    prepare_spark(
+        spark_dir_name=spark_dir_name, spark_home=Path(os.environ[""SPARK_HOME""])
+    )",Yes
tagging/taggers.py,tagging/taggers.py,c294e9e2d95266e50cde9aabf97ddea0a496a7fc,c1229303d069fe76aa6a498068b68d0360554e14,"Automatically install latest spark version (#2075)

* Automatically install latest pyspark version

* Better text

* Do not use shutil to keep behaviour

* Make setup_script cwd independent

* Use _get_program_version to calculate spark version

* Update setup_spark.py reqs

* Update setup_spark.py

* Add info about HADOOP_VERSION

* Add customization back

* Better text

* Specify build args when they are actually needed

* Better text

* Better code

* Better code

* Better text

* Get rid of warning

* Improve code

* Remove information about checksum

* Better text","diff --git a/tagging/taggers.py b/tagging/taggers.py
index 0aee5188..daf987b1 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -128,7 +128,12 @@ class JuliaVersionTagger(TaggerInterface):
 class SparkVersionTagger(TaggerInterface):
     @staticmethod
     def tag_value(container: Container) -> str:
-        return ""spark-"" + _get_env_variable(container, ""APACHE_SPARK_VERSION"")
+        SPARK_VERSION_LINE_PREFIX = r""   /___/ .__/\_,_/_/ /_/\_\   version""
+
+        spark_version = _get_program_version(container, ""spark-submit"")
+        version_line = spark_version.split(""\n"")[4]
+        assert version_line.startswith(SPARK_VERSION_LINE_PREFIX)
+        return ""spark-"" + version_line.split("" "")[-1]
 
 
 class HadoopVersionTagger(TaggerInterface):","diff --git a/tagging/taggers.py b/tagging/taggers.py
index 0aee5188..daf987b1 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -128,7 +128,12 @@ class JuliaVersionTagger(TaggerInterface):
 class SparkVersionTagger(TaggerInterface):
     @staticmethod
     def tag_value(container: Container) -> str:
-        return ""spark-"" + _get_env_variable(container, ""APACHE_SPARK_VERSION"")
+        SPARK_VERSION_LINE_PREFIX = r""   /___/ .__/\_,_/_/ /_/\_\   version""
+
+        spark_version = _get_program_version(container, ""spark-submit"")
+        version_line = spark_version.split(""\n"")[4]
+        assert version_line.startswith(SPARK_VERSION_LINE_PREFIX)
+        return ""spark-"" + version_line.split("" "")[-1]
 
 
 class HadoopVersionTagger(TaggerInterface):",Yes
images/minimal-notebook/setup-scripts/setup_julia.py,images/minimal-notebook/setup-scripts/setup_julia.py,e84bfdf4aece9ae68889ce1ffa400e9d585a3811,c294e9e2d95266e50cde9aabf97ddea0a496a7fc,Add logger to setup_julia and setup_spark,"diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index 7f2478d1..114e64c0 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -6,6 +6,7 @@
 # - Run as the root user
 # - The JULIA_PKGDIR environment variable is set
 
+import logging
 import os
 import platform
 import shutil
@@ -14,6 +15,8 @@ from pathlib import Path
 
 import requests
 
+LOGGER = logging.getLogger(__name__)
+
 
 def unify_aarch64(platform: str) -> str:
     """"""
@@ -31,7 +34,7 @@ def get_latest_julia_url() -> tuple[str, str]:
     Get the last stable version of Julia
     Based on: https://github.com/JuliaLang/www.julialang.org/issues/878#issuecomment-749234813
     """"""
-
+    LOGGER.info(""Downloading Julia versions information"")
     versions = requests.get(
         ""https://julialang-s3.julialang.org/bin/versions.json""
     ).json()
@@ -43,6 +46,7 @@ def get_latest_julia_url() -> tuple[str, str]:
     latest_version_files = stable_versions[latest_stable_version][""files""]
     triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
     file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
+    LOGGER.info(f""Latest version: {file_info['version']} url: {file_info['url']}"")
     return file_info[""url""], file_info[""version""]
 
 
@@ -51,6 +55,7 @@ def download_julia(julia_url: str) -> None:
     Downloads and unpacks julia
     The resulting julia directory is ""/opt/julia-VERSION/""
     """"""
+    LOGGER.info(""Downloading and unpacking Julia"")
     tmp_file = Path(""/tmp/julia.tar.gz"")
     subprocess.check_call(
         [""curl"", ""--progress-bar"", ""--location"", ""--output"", tmp_file, julia_url]
@@ -59,12 +64,13 @@ def download_julia(julia_url: str) -> None:
     tmp_file.unlink()
 
 
-def prepare_julia(julia_version: str) -> None:
+def configure_julia(julia_version: str) -> None:
     """"""
     Creates /usr/local/bin/julia symlink
     Make Julia aware of conda libraries
     Creates a directory for Julia user libraries
     """"""
+    LOGGER.info(""Configuring Julia"")
     # Link Julia installed version to /usr/local/bin, so julia launches it
     subprocess.check_call(
         [""ln"", ""-fs"", f""/opt/julia-{julia_version}/bin/julia"", ""/usr/local/bin/julia""]
@@ -84,6 +90,8 @@ def prepare_julia(julia_version: str) -> None:
 
 
 if __name__ == ""__main__"":
+    logging.basicConfig(level=logging.INFO)
+
     julia_url, julia_version = get_latest_julia_url()
     download_julia(julia_url=julia_url)
-    prepare_julia(julia_version=julia_version)
+    configure_julia(julia_version=julia_version)","diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index 7f2478d1..114e64c0 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -6,6 +6,7 @@
 # - Run as the root user
 # - The JULIA_PKGDIR environment variable is set
 
+import logging
 import os
 import platform
 import shutil
@@ -14,6 +15,8 @@ from pathlib import Path
 
 import requests
 
+LOGGER = logging.getLogger(__name__)
+
 
 def unify_aarch64(platform: str) -> str:
     """"""
@@ -31,7 +34,7 @@ def get_latest_julia_url() -> tuple[str, str]:
     Get the last stable version of Julia
     Based on: https://github.com/JuliaLang/www.julialang.org/issues/878#issuecomment-749234813
     """"""
-
+    LOGGER.info(""Downloading Julia versions information"")
     versions = requests.get(
         ""https://julialang-s3.julialang.org/bin/versions.json""
     ).json()
@@ -43,6 +46,7 @@ def get_latest_julia_url() -> tuple[str, str]:
     latest_version_files = stable_versions[latest_stable_version][""files""]
     triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
     file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
+    LOGGER.info(f""Latest version: {file_info['version']} url: {file_info['url']}"")
     return file_info[""url""], file_info[""version""]
 
 
@@ -51,6 +55,7 @@ def download_julia(julia_url: str) -> None:
     Downloads and unpacks julia
     The resulting julia directory is ""/opt/julia-VERSION/""
     """"""
+    LOGGER.info(""Downloading and unpacking Julia"")
     tmp_file = Path(""/tmp/julia.tar.gz"")
     subprocess.check_call(
         [""curl"", ""--progress-bar"", ""--location"", ""--output"", tmp_file, julia_url]
@@ -59,12 +64,13 @@ def download_julia(julia_url: str) -> None:
     tmp_file.unlink()
 
 
-def prepare_julia(julia_version: str) -> None:
+def configure_julia(julia_version: str) -> None:
     """"""
     Creates /usr/local/bin/julia symlink
     Make Julia aware of conda libraries
     Creates a directory for Julia user libraries
     """"""
+    LOGGER.info(""Configuring Julia"")
     # Link Julia installed version to /usr/local/bin, so julia launches it
     subprocess.check_call(
         [""ln"", ""-fs"", f""/opt/julia-{julia_version}/bin/julia"", ""/usr/local/bin/julia""]
@@ -84,6 +90,8 @@ def prepare_julia(julia_version: str) -> None:
 
 
 if __name__ == ""__main__"":
+    logging.basicConfig(level=logging.INFO)
+
     julia_url, julia_version = get_latest_julia_url()
     download_julia(julia_url=julia_url)
-    prepare_julia(julia_version=julia_version)
+    configure_julia(julia_version=julia_version)",Yes
images/pyspark-notebook/setup_spark.py,images/pyspark-notebook/setup_spark.py,e84bfdf4aece9ae68889ce1ffa400e9d585a3811,c294e9e2d95266e50cde9aabf97ddea0a496a7fc,Add logger to setup_julia and setup_spark,"diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index 54e59948..3481cc70 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -7,6 +7,7 @@
 # - Required env variables: SPARK_HOME, HADOOP_VERSION, SPARK_DOWNLOAD_URL
 # - Optional env variables: SPARK_VERSION, SCALA_VERSION
 
+import logging
 import os
 import subprocess
 from pathlib import Path
@@ -14,6 +15,8 @@ from pathlib import Path
 import requests
 from bs4 import BeautifulSoup
 
+LOGGER = logging.getLogger(__name__)
+
 
 def get_all_refs(url: str) -> list[str]:
     """"""
@@ -31,6 +34,7 @@ def get_spark_version() -> str:
     """"""
     if (version := os.environ[""SPARK_VERSION""]) != """":
         return version
+    LOGGER.info(""Downloading Spark versions information"")
     all_refs = get_all_refs(""https://archive.apache.org/dist/spark/"")
     stable_versions = [
         ref.removeprefix(""spark-"").removesuffix(""/"")
@@ -38,9 +42,11 @@ def get_spark_version() -> str:
         if ref.startswith(""spark-"") and ""incubating"" not in ref and ""preview"" not in ref
     ]
     # Compare versions semantically
-    return max(
+    latest_version = max(
         stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
     )
+    LOGGER.info(f""Latest version: {latest_version}"")
+    return latest_version
 
 
 def download_spark(
@@ -53,9 +59,11 @@ def download_spark(
     Downloads and unpacks spark
     The resulting spark directory name is returned
     """"""
+    LOGGER.info(""Downloading and unpacking Spark"")
     spark_dir_name = f""spark-{spark_version}-bin-hadoop{hadoop_version}""
     if scala_version:
         spark_dir_name += f""-scala{scala_version}""
+    LOGGER.info(f""Spark directory name: {spark_dir_name}"")
     spark_url = spark_download_url / f""spark-{spark_version}"" / f""{spark_dir_name}.tgz""
 
     tmp_file = Path(""/tmp/spark.tar.gz"")
@@ -80,11 +88,12 @@ def download_spark(
     return spark_dir_name
 
 
-def prepare_spark(spark_dir_name: str, spark_home: Path) -> None:
+def configure_spark(spark_dir_name: str, spark_home: Path) -> None:
     """"""
     Creates a ${SPARK_HOME} symlink to a versioned spark directory
     Creates a 10spark-config.sh symlink to source PYTHONPATH automatically
     """"""
+    LOGGER.info(""Configuring Spark"")
     subprocess.check_call([""ln"", ""-s"", f""/usr/local/{spark_dir_name}"", spark_home])
 
     # Add a link in the before_notebook hook in order to source PYTHONPATH automatically
@@ -95,6 +104,8 @@ def prepare_spark(spark_dir_name: str, spark_home: Path) -> None:
 
 
 if __name__ == ""__main__"":
+    logging.basicConfig(level=logging.INFO)
+
     spark_version = get_spark_version()
     spark_dir_name = download_spark(
         spark_version=spark_version,
@@ -102,6 +113,6 @@ if __name__ == ""__main__"":
         scala_version=os.environ[""SCALA_VERSION""],
         spark_download_url=Path(os.environ[""SPARK_DOWNLOAD_URL""]),
     )
-    prepare_spark(
+    configure_spark(
         spark_dir_name=spark_dir_name, spark_home=Path(os.environ[""SPARK_HOME""])
     )","diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index 54e59948..3481cc70 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -7,6 +7,7 @@
 # - Required env variables: SPARK_HOME, HADOOP_VERSION, SPARK_DOWNLOAD_URL
 # - Optional env variables: SPARK_VERSION, SCALA_VERSION
 
+import logging
 import os
 import subprocess
 from pathlib import Path
@@ -14,6 +15,8 @@ from pathlib import Path
 import requests
 from bs4 import BeautifulSoup
 
+LOGGER = logging.getLogger(__name__)
+
 
 def get_all_refs(url: str) -> list[str]:
     """"""
@@ -31,6 +34,7 @@ def get_spark_version() -> str:
     """"""
     if (version := os.environ[""SPARK_VERSION""]) != """":
         return version
+    LOGGER.info(""Downloading Spark versions information"")
     all_refs = get_all_refs(""https://archive.apache.org/dist/spark/"")
     stable_versions = [
         ref.removeprefix(""spark-"").removesuffix(""/"")
@@ -38,9 +42,11 @@ def get_spark_version() -> str:
         if ref.startswith(""spark-"") and ""incubating"" not in ref and ""preview"" not in ref
     ]
     # Compare versions semantically
-    return max(
+    latest_version = max(
         stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
     )
+    LOGGER.info(f""Latest version: {latest_version}"")
+    return latest_version
 
 
 def download_spark(
@@ -53,9 +59,11 @@ def download_spark(
     Downloads and unpacks spark
     The resulting spark directory name is returned
     """"""
+    LOGGER.info(""Downloading and unpacking Spark"")
     spark_dir_name = f""spark-{spark_version}-bin-hadoop{hadoop_version}""
     if scala_version:
         spark_dir_name += f""-scala{scala_version}""
+    LOGGER.info(f""Spark directory name: {spark_dir_name}"")
     spark_url = spark_download_url / f""spark-{spark_version}"" / f""{spark_dir_name}.tgz""
 
     tmp_file = Path(""/tmp/spark.tar.gz"")
@@ -80,11 +88,12 @@ def download_spark(
     return spark_dir_name
 
 
-def prepare_spark(spark_dir_name: str, spark_home: Path) -> None:
+def configure_spark(spark_dir_name: str, spark_home: Path) -> None:
     """"""
     Creates a ${SPARK_HOME} symlink to a versioned spark directory
     Creates a 10spark-config.sh symlink to source PYTHONPATH automatically
     """"""
+    LOGGER.info(""Configuring Spark"")
     subprocess.check_call([""ln"", ""-s"", f""/usr/local/{spark_dir_name}"", spark_home])
 
     # Add a link in the before_notebook hook in order to source PYTHONPATH automatically
@@ -95,6 +104,8 @@ def prepare_spark(spark_dir_name: str, spark_home: Path) -> None:
 
 
 if __name__ == ""__main__"":
+    logging.basicConfig(level=logging.INFO)
+
     spark_version = get_spark_version()
     spark_dir_name = download_spark(
         spark_version=spark_version,
@@ -102,6 +113,6 @@ if __name__ == ""__main__"":
         scala_version=os.environ[""SCALA_VERSION""],
         spark_download_url=Path(os.environ[""SPARK_DOWNLOAD_URL""]),
     )
-    prepare_spark(
+    configure_spark(
         spark_dir_name=spark_dir_name, spark_home=Path(os.environ[""SPARK_HOME""])
     )",Yes
images/minimal-notebook/setup-scripts/setup-julia-packages.bash,images/minimal-notebook/setup-scripts/setup-julia-packages.bash,6e80c1246f8a1adecbb57c303842d552562443ea,e84bfdf4aece9ae68889ce1ffa400e9d585a3811,Fix comment about setup_julia.py file,"diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
index fa1421e9..5e8f7e80 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -3,7 +3,7 @@ set -exuo pipefail
 # Requirements:
 # - Run as a non-root user
 # - The JULIA_PKGDIR environment variable is set
-# - Julia is already set up, with the setup-julia.bash command
+# - Julia is already set up, with the setup_julia.py command
 
 
 # If we don't specify what CPUs the precompilation should be done for, it's","diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
index fa1421e9..5e8f7e80 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -3,7 +3,7 @@ set -exuo pipefail
 # Requirements:
 # - Run as a non-root user
 # - The JULIA_PKGDIR environment variable is set
-# - Julia is already set up, with the setup-julia.bash command
+# - Julia is already set up, with the setup_julia.py command
 
 
 # If we don't specify what CPUs the precompilation should be done for, it's",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,2a9c7dbc268e5b85daa841c52c54a721bd1a48b0,6e80c1246f8a1adecbb57c303842d552562443ea,Update the way we install micromamba (#2077),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 34a3077e..bd06a57e 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -102,21 +102,19 @@ RUN set -x && \
         # Should be simpler, see <https://github.com/mamba-org/mamba/issues/1437>
         arch=""64""; \
     fi && \
-    wget --progress=dot:giga -O /tmp/micromamba.tar.bz2 \
-        ""https://micromamba.snakepit.net/api/micromamba/linux-${arch}/latest"" && \
-    tar -xvjf /tmp/micromamba.tar.bz2 --strip-components=1 bin/micromamba && \
-    rm /tmp/micromamba.tar.bz2 && \
+    wget --progress=dot:giga -O - \
+        ""https://micro.mamba.pm/api/micromamba/linux-${arch}/latest"" | tar -xvj bin/micromamba && \
     PYTHON_SPECIFIER=""python=${PYTHON_VERSION}"" && \
     if [[ ""${PYTHON_VERSION}"" == ""default"" ]]; then PYTHON_SPECIFIER=""python""; fi && \
     # Install the packages
-    ./micromamba install \
+    ./bin/micromamba install \
         --root-prefix=""${CONDA_DIR}"" \
         --prefix=""${CONDA_DIR}"" \
         --yes \
         ""${PYTHON_SPECIFIER}"" \
         'mamba' \
         'jupyter_core' && \
-    rm micromamba && \
+    rm -rf /tmp/bin/ && \
     # Pin major.minor version of python
     mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 34a3077e..bd06a57e 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -102,21 +102,19 @@ RUN set -x && \
         # Should be simpler, see <https://github.com/mamba-org/mamba/issues/1437>
         arch=""64""; \
     fi && \
-    wget --progress=dot:giga -O /tmp/micromamba.tar.bz2 \
-        ""https://micromamba.snakepit.net/api/micromamba/linux-${arch}/latest"" && \
-    tar -xvjf /tmp/micromamba.tar.bz2 --strip-components=1 bin/micromamba && \
-    rm /tmp/micromamba.tar.bz2 && \
+    wget --progress=dot:giga -O - \
+        ""https://micro.mamba.pm/api/micromamba/linux-${arch}/latest"" | tar -xvj bin/micromamba && \
     PYTHON_SPECIFIER=""python=${PYTHON_VERSION}"" && \
     if [[ ""${PYTHON_VERSION}"" == ""default"" ]]; then PYTHON_SPECIFIER=""python""; fi && \
     # Install the packages
-    ./micromamba install \
+    ./bin/micromamba install \
         --root-prefix=""${CONDA_DIR}"" \
         --prefix=""${CONDA_DIR}"" \
         --yes \
         ""${PYTHON_SPECIFIER}"" \
         'mamba' \
         'jupyter_core' && \
-    rm micromamba && \
+    rm -rf /tmp/bin/ && \
     # Pin major.minor version of python
     mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \",Yes
README.md,README.md,d9f41655fe6185c08e36ba6db0debf6a8d99962f,2a9c7dbc268e5b85daa841c52c54a721bd1a48b0,Simplify README.md,"diff --git a/README.md b/README.md
index fd13f1f9..46d304f7 100644
--- a/README.md
+++ b/README.md
@@ -17,8 +17,7 @@ You can use a stack image to do any of the following (and more):
 
 ## Quick Start
 
-You can try a [relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb)
-by simply clicking the preceding link.
+You can [try a relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb).
 Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
 know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use, and want to launch a single Jupyter Application in a container.","diff --git a/README.md b/README.md
index fd13f1f9..46d304f7 100644
--- a/README.md
+++ b/README.md
@@ -17,8 +17,7 @@ You can use a stack image to do any of the following (and more):
 
 ## Quick Start
 
-You can try a [relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb)
-by simply clicking the preceding link.
+You can [try a relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb).
 Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
 know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use, and want to launch a single Jupyter Application in a container.",Yes
README.md,README.md,e55bb93ff498f4b9429b70b2beaa92dfd7c363fa,d9f41655fe6185c08e36ba6db0debf6a8d99962f,Update tag example,"diff --git a/README.md b/README.md
index 46d304f7..787e6380 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-11-17
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-08
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-11-17
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-01-08
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index 46d304f7..787e6380 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2023-11-17
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-08
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2023-11-17
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-01-08
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,e55bb93ff498f4b9429b70b2beaa92dfd7c363fa,d9f41655fe6185c08e36ba6db0debf6a8d99962f,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 94b7663d..40aa975e 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-11-17
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-01-08
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-11-17""
+ENV TAG=""2024-01-08""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 94b7663d..40aa975e 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2023-11-17
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-01-08
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2023-11-17""
+ENV TAG=""2024-01-08""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,e55bb93ff498f4b9429b70b2beaa92dfd7c363fa,d9f41655fe6185c08e36ba6db0debf6a8d99962f,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index 3b8938c2..d7bd623a 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-11-17
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-01-08
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2023-11-17   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-01-08   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-11-17
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-01-08
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2023-11-17
+    quay.io/jupyter/r-notebook:2024-01-08
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 3b8938c2..d7bd623a 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2023-11-17
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-01-08
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2023-11-17   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-01-08   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2023-11-17
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-01-08
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2023-11-17` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2023-11-17
+    quay.io/jupyter/r-notebook:2024-01-08
 ```
 
 ```{warning}",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,cc3aa43c46b70ee23d4d3c1a11e7103406619e1a,e55bb93ff498f4b9429b70b2beaa92dfd7c363fa,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index ddc26a82..b26c2bc3 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -20,258 +20,258 @@ runs:
   using: composite
   steps:
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
 
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
index ddc26a82..b26c2bc3 100644
--- a/.github/actions/download-manifests/action.yml
+++ b/.github/actions/download-manifests/action.yml
@@ -20,258 +20,258 @@ runs:
   using: composite
   steps:
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-history_line
         path: ${{ inputs.hist-lines-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-history_line
         path: ${{ inputs.hist-lines-dir }}
 
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: docker-stacks-foundation-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: base-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: minimal-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: scipy-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: r-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: julia-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: tensorflow-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pytorch-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: datascience-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: pyspark-notebook-x86_64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-aarch64-manifest
         path: ${{ inputs.manifests-dir }}
     - name: Download artifact 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       if: inputs.fast-build == 'false'
       with:
         name: all-spark-notebook-x86_64-manifest",Yes
.github/actions/load-image/action.yml,.github/actions/load-image/action.yml,cc3aa43c46b70ee23d4d3c1a11e7103406619e1a,e55bb93ff498f4b9429b70b2beaa92dfd7c363fa,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index c32f3479..cbf5a8a5 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -13,7 +13,7 @@ runs:
   using: composite
   steps:
     - name: Download built image 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: ${{ inputs.image }}-${{ inputs.platform }}
         path: /tmp/jupyter/images/","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index c32f3479..cbf5a8a5 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -13,7 +13,7 @@ runs:
   using: composite
   steps:
     - name: Download built image 📥
-      uses: actions/download-artifact@v3
+      uses: actions/download-artifact@v4
       with:
         name: ${{ inputs.image }}-${{ inputs.platform }}
         path: /tmp/jupyter/images/",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,cc3aa43c46b70ee23d4d3c1a11e7103406619e1a,e55bb93ff498f4b9429b70b2beaa92dfd7c363fa,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 84ea58f3..01520d34 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -75,7 +75,7 @@ jobs:
           python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
@@ -85,13 +85,13 @@ jobs:
         run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
           path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
           path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
@@ -103,7 +103,7 @@ jobs:
           docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
           path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 84ea58f3..01520d34 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -75,7 +75,7 @@ jobs:
           python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload tags file 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
@@ -85,13 +85,13 @@ jobs:
         run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
         shell: bash
       - name: Upload manifest file 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
           path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
           path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
@@ -103,7 +103,7 @@ jobs:
           docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
-        uses: actions/upload-artifact@v3
+        uses: actions/upload-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}
           path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,cc3aa43c46b70ee23d4d3c1a11e7103406619e1a,e55bb93ff498f4b9429b70b2beaa92dfd7c363fa,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index bd90b8b2..038dbff1 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -28,12 +28,12 @@ jobs:
         uses: ./.github/actions/create-dev-env
 
       - name: Download x86_64 tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-x86_64-tags
           path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-aarch64-tags
           path: /tmp/jupyter/tags/","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index bd90b8b2..038dbff1 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -28,12 +28,12 @@ jobs:
         uses: ./.github/actions/create-dev-env
 
       - name: Download x86_64 tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-x86_64-tags
           path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-aarch64-tags
           path: /tmp/jupyter/tags/",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,cc3aa43c46b70ee23d4d3c1a11e7103406619e1a,e55bb93ff498f4b9429b70b2beaa92dfd7c363fa,Update actions/download-artifact and actions/upload-artifact to v4 (#2061),"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index ec22e7f3..b68a8d1a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -46,7 +46,7 @@ jobs:
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Download tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index ec22e7f3..b68a8d1a 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -46,7 +46,7 @@ jobs:
           password: ${{ secrets.REGISTRY_TOKEN }}
 
       - name: Download tags file 📥
-        uses: actions/download-artifact@v3
+        uses: actions/download-artifact@v4
         with:
           name: ${{ inputs.image }}-${{ inputs.platform }}-tags
           path: /tmp/jupyter/tags/",Yes
.github/actions/download-manifests/action.yml,.github/actions/download-manifests/action.yml,fccea73332a18be37d7ae09a9114ea032d862ee0,cc3aa43c46b70ee23d4d3c1a11e7103406619e1a,Get rid of separate download-manifests action,"diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
deleted file mode 100644
index b26c2bc3..00000000
--- a/.github/actions/download-manifests/action.yml
+++ /dev/null
@@ -1,278 +0,0 @@
-name: Download manifests
-description: Download all manifests and history lines
-
-# Unfortunately, `actions/download-artifact` doesn't support wildcard download
-# To make this workflow fast, we manually list all manifests and history lines downloads
-# https://github.com/actions/download-artifact/issues/6
-
-inputs:
-  hist-lines-dir:
-    description: Directory to store history lines
-    required: true
-  manifests-dir:
-    description: Directory to store manifest files
-    required: true
-  fast-build:
-    description: Only build docker-stacks-foundation and base-notebook
-    required: true
-
-runs:
-  using: composite
-  steps:
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: docker-stacks-foundation-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: docker-stacks-foundation-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: base-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: base-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: minimal-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: minimal-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: scipy-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: scipy-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: r-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: r-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: julia-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: julia-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: tensorflow-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: tensorflow-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pytorch-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pytorch-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: datascience-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: datascience-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pyspark-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pyspark-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: all-spark-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: all-spark-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: docker-stacks-foundation-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: docker-stacks-foundation-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: base-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: base-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: minimal-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: minimal-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: scipy-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: scipy-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: r-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: r-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: julia-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: julia-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: tensorflow-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: tensorflow-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pytorch-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pytorch-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: datascience-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: datascience-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pyspark-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pyspark-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: all-spark-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: all-spark-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}","diff --git a/.github/actions/download-manifests/action.yml b/.github/actions/download-manifests/action.yml
deleted file mode 100644
index b26c2bc3..00000000
--- a/.github/actions/download-manifests/action.yml
+++ /dev/null
@@ -1,278 +0,0 @@
-name: Download manifests
-description: Download all manifests and history lines
-
-# Unfortunately, `actions/download-artifact` doesn't support wildcard download
-# To make this workflow fast, we manually list all manifests and history lines downloads
-# https://github.com/actions/download-artifact/issues/6
-
-inputs:
-  hist-lines-dir:
-    description: Directory to store history lines
-    required: true
-  manifests-dir:
-    description: Directory to store manifest files
-    required: true
-  fast-build:
-    description: Only build docker-stacks-foundation and base-notebook
-    required: true
-
-runs:
-  using: composite
-  steps:
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: docker-stacks-foundation-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: docker-stacks-foundation-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: base-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: base-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: minimal-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: minimal-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: scipy-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: scipy-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: r-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: r-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: julia-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: julia-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: tensorflow-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: tensorflow-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pytorch-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pytorch-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: datascience-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: datascience-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pyspark-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pyspark-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: all-spark-notebook-aarch64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: all-spark-notebook-x86_64-history_line
-        path: ${{ inputs.hist-lines-dir }}
-
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: docker-stacks-foundation-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: docker-stacks-foundation-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: base-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      with:
-        name: base-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: minimal-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: minimal-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: scipy-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: scipy-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: r-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: r-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: julia-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: julia-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: tensorflow-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: tensorflow-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pytorch-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pytorch-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: datascience-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: datascience-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pyspark-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: pyspark-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: all-spark-notebook-aarch64-manifest
-        path: ${{ inputs.manifests-dir }}
-    - name: Download artifact 📥
-      uses: actions/download-artifact@v4
-      if: inputs.fast-build == 'false'
-      with:
-        name: all-spark-notebook-x86_64-manifest
-        path: ${{ inputs.manifests-dir }}",Yes
.github/dependabot.yml,.github/dependabot.yml,fccea73332a18be37d7ae09a9114ea032d862ee0,cc3aa43c46b70ee23d4d3c1a11e7103406619e1a,Get rid of separate download-manifests action,"diff --git a/.github/dependabot.yml b/.github/dependabot.yml
index 5ed4a1e0..8f17357f 100644
--- a/.github/dependabot.yml
+++ b/.github/dependabot.yml
@@ -13,10 +13,6 @@ updates:
     directory: .github/actions/create-dev-env/
     schedule:
       interval: weekly
-  - package-ecosystem: github-actions
-    directory: .github/actions/download-manifests/
-    schedule:
-      interval: weekly
   - package-ecosystem: github-actions
     directory: .github/actions/load-image/
     schedule:","diff --git a/.github/dependabot.yml b/.github/dependabot.yml
index 5ed4a1e0..8f17357f 100644
--- a/.github/dependabot.yml
+++ b/.github/dependabot.yml
@@ -13,10 +13,6 @@ updates:
     directory: .github/actions/create-dev-env/
     schedule:
       interval: weekly
-  - package-ecosystem: github-actions
-    directory: .github/actions/download-manifests/
-    schedule:
-      interval: weekly
   - package-ecosystem: github-actions
     directory: .github/actions/load-image/
     schedule:",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,fccea73332a18be37d7ae09a9114ea032d862ee0,cc3aa43c46b70ee23d4d3c1a11e7103406619e1a,Get rid of separate download-manifests action,"diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 88d794c4..d7867392 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -18,16 +18,24 @@ jobs:
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
 
-      - name: Download all manifests and history lines 📥
-        uses: ./.github/actions/download-manifests
+      - name: Download all history lines 📥
+        uses: actions/download-artifact@v4
         with:
-          hist-lines-dir: /tmp/jupyter/hist_lines/
-          manifests-dir: /tmp/jupyter/manifests/
-          fast-build: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
-      - name: Display structure of downloaded files 🔍️
-        run: |
-          ls -R /tmp/jupyter/hist_lines/
-          ls -R /tmp/jupyter/manifests/
+          pattern: ""*-history_line""
+          path: /tmp/jupyter/hist_lines/
+
+      - name: List the history lines directory 🔍️
+        run: ls -R /tmp/jupyter/hist_lines/
+        shell: bash
+
+      - name: Download all manifests 📥
+        uses: actions/download-artifact@v4
+        with:
+          pattern: ""*-manifest""
+          path: /tmp/jupyter/manifests/
+
+      - name: List the manifests directory 🔍️
+        run: ls -R /tmp/jupyter/manifests/
         shell: bash
 
       - name: Checkout Wiki Repo 📃","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 88d794c4..d7867392 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -18,16 +18,24 @@ jobs:
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env
 
-      - name: Download all manifests and history lines 📥
-        uses: ./.github/actions/download-manifests
+      - name: Download all history lines 📥
+        uses: actions/download-artifact@v4
         with:
-          hist-lines-dir: /tmp/jupyter/hist_lines/
-          manifests-dir: /tmp/jupyter/manifests/
-          fast-build: ${{ contains(github.event.pull_request.title, '[FAST_BUILD]') }}
-      - name: Display structure of downloaded files 🔍️
-        run: |
-          ls -R /tmp/jupyter/hist_lines/
-          ls -R /tmp/jupyter/manifests/
+          pattern: ""*-history_line""
+          path: /tmp/jupyter/hist_lines/
+
+      - name: List the history lines directory 🔍️
+        run: ls -R /tmp/jupyter/hist_lines/
+        shell: bash
+
+      - name: Download all manifests 📥
+        uses: actions/download-artifact@v4
+        with:
+          pattern: ""*-manifest""
+          path: /tmp/jupyter/manifests/
+
+      - name: List the manifests directory 🔍️
+        run: ls -R /tmp/jupyter/manifests/
         shell: bash
 
       - name: Checkout Wiki Repo 📃",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,fccea73332a18be37d7ae09a9114ea032d862ee0,cc3aa43c46b70ee23d4d3c1a11e7103406619e1a,Get rid of separate download-manifests action,"diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 9ab19659..08207492 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -22,7 +22,6 @@ on:
       # We use local composite actions to combine multiple workflow steps within one action
       # https://docs.github.com/en/actions/creating-actions/about-custom-actions#composite-actions
       - "".github/actions/create-dev-env/action.yml""
-      - "".github/actions/download-manifests/action.yml""
       - "".github/actions/load-image/action.yml""
 
       - ""images/**""
@@ -43,7 +42,6 @@ on:
       - "".github/workflows/docker-wiki-update.yml""
 
       - "".github/actions/create-dev-env/action.yml""
-      - "".github/actions/download-manifests/action.yml""
       - "".github/actions/load-image/action.yml""
 
       - ""images/**""","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 9ab19659..08207492 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -22,7 +22,6 @@ on:
       # We use local composite actions to combine multiple workflow steps within one action
       # https://docs.github.com/en/actions/creating-actions/about-custom-actions#composite-actions
       - "".github/actions/create-dev-env/action.yml""
-      - "".github/actions/download-manifests/action.yml""
       - "".github/actions/load-image/action.yml""
 
       - ""images/**""
@@ -43,7 +42,6 @@ on:
       - "".github/workflows/docker-wiki-update.yml""
 
       - "".github/actions/create-dev-env/action.yml""
-      - "".github/actions/download-manifests/action.yml""
       - "".github/actions/load-image/action.yml""
 
       - ""images/**""",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,c6c0a947edcb901568cde7dc6dccb809e343d343,fccea73332a18be37d7ae09a9114ea032d862ee0,Remove redundant step,"diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index d7867392..b5bd0cb3 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -24,20 +24,12 @@ jobs:
           pattern: ""*-history_line""
           path: /tmp/jupyter/hist_lines/
 
-      - name: List the history lines directory 🔍️
-        run: ls -R /tmp/jupyter/hist_lines/
-        shell: bash
-
       - name: Download all manifests 📥
         uses: actions/download-artifact@v4
         with:
           pattern: ""*-manifest""
           path: /tmp/jupyter/manifests/
 
-      - name: List the manifests directory 🔍️
-        run: ls -R /tmp/jupyter/manifests/
-        shell: bash
-
       - name: Checkout Wiki Repo 📃
         uses: actions/checkout@v4
         with:","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index d7867392..b5bd0cb3 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -24,20 +24,12 @@ jobs:
           pattern: ""*-history_line""
           path: /tmp/jupyter/hist_lines/
 
-      - name: List the history lines directory 🔍️
-        run: ls -R /tmp/jupyter/hist_lines/
-        shell: bash
-
       - name: Download all manifests 📥
         uses: actions/download-artifact@v4
         with:
           pattern: ""*-manifest""
           path: /tmp/jupyter/manifests/
 
-      - name: List the manifests directory 🔍️
-        run: ls -R /tmp/jupyter/manifests/
-        shell: bash
-
       - name: Checkout Wiki Repo 📃
         uses: actions/checkout@v4
         with:",Yes
tagging/update_wiki.py,tagging/update_wiki.py,4d2c81cd88d31499d54dfbbd43affa9f8798cf87,c6c0a947edcb901568cde7dc6dccb809e343d343,"Update update_wiki.py: fix for pattern download, build timestamps, additional checks","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 8f80263c..78ff107d 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -52,7 +52,11 @@ def update_monthly_wiki_page(
 def get_manifest_timestamp(manifest_file: Path) -> str:
     file_content = manifest_file.read_text()
     pos = file_content.find(""Build timestamp: "")
-    return file_content[pos + 16 : pos + 36]
+    timestamp = file_content[pos + 17 : pos + 37]
+    # Should be good enough till year 2100
+    assert timestamp.startswith(""20""), timestamp
+    assert timestamp.endswith(""Z""), timestamp
+    return timestamp
 
 
 def get_manifest_month(manifest_file: Path) -> str:
@@ -75,14 +79,18 @@ def remove_old_manifests(wiki_dir: Path) -> None:
 def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> None:
     LOGGER.info(""Updating wiki"")
 
-    for manifest_file in manifests_dir.glob(""*.md""):
+    manifest_files = list(manifests_dir.rglob(""*.md""))
+    assert manifest_files, ""expected to have some manifest files""
+    for manifest_file in manifest_files:
         month = get_manifest_month(manifest_file)
         copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
         copy_to.parent.mkdir(exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
 
-    for build_history_line_file in sorted(hist_lines_dir.glob(""*.txt"")):
+    build_history_line_files = sorted(hist_lines_dir.rglob(""*.txt""))
+    assert build_history_line_files, ""expected to have some build history line files""
+    for build_history_line_file in build_history_line_files:
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
         month = build_history_line[3:10]","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 8f80263c..78ff107d 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -52,7 +52,11 @@ def update_monthly_wiki_page(
 def get_manifest_timestamp(manifest_file: Path) -> str:
     file_content = manifest_file.read_text()
     pos = file_content.find(""Build timestamp: "")
-    return file_content[pos + 16 : pos + 36]
+    timestamp = file_content[pos + 17 : pos + 37]
+    # Should be good enough till year 2100
+    assert timestamp.startswith(""20""), timestamp
+    assert timestamp.endswith(""Z""), timestamp
+    return timestamp
 
 
 def get_manifest_month(manifest_file: Path) -> str:
@@ -75,14 +79,18 @@ def remove_old_manifests(wiki_dir: Path) -> None:
 def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> None:
     LOGGER.info(""Updating wiki"")
 
-    for manifest_file in manifests_dir.glob(""*.md""):
+    manifest_files = list(manifests_dir.rglob(""*.md""))
+    assert manifest_files, ""expected to have some manifest files""
+    for manifest_file in manifest_files:
         month = get_manifest_month(manifest_file)
         copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
         copy_to.parent.mkdir(exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
 
-    for build_history_line_file in sorted(hist_lines_dir.glob(""*.txt"")):
+    build_history_line_files = sorted(hist_lines_dir.rglob(""*.txt""))
+    assert build_history_line_files, ""expected to have some build history line files""
+    for build_history_line_file in build_history_line_files:
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
         month = build_history_line[3:10]",Yes
tagging/update_wiki.py,tagging/update_wiki.py,d599a7aeca7fcf80c07c941bcc5f385486ad37a4,4d2c81cd88d31499d54dfbbd43affa9f8798cf87,Improve get_manifest_timestamp function,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 78ff107d..292ee2d8 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -51,8 +51,11 @@ def update_monthly_wiki_page(
 
 def get_manifest_timestamp(manifest_file: Path) -> str:
     file_content = manifest_file.read_text()
-    pos = file_content.find(""Build timestamp: "")
-    timestamp = file_content[pos + 17 : pos + 37]
+    TIMESTAMP_PREFIX = ""Build timestamp: ""
+    TIMESTAMP_LENGTH = 20
+    timestamp = file_content[
+        file_content.find(TIMESTAMP_PREFIX) + len(TIMESTAMP_PREFIX) :
+    ][:TIMESTAMP_LENGTH]
     # Should be good enough till year 2100
     assert timestamp.startswith(""20""), timestamp
     assert timestamp.endswith(""Z""), timestamp","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 78ff107d..292ee2d8 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -51,8 +51,11 @@ def update_monthly_wiki_page(
 
 def get_manifest_timestamp(manifest_file: Path) -> str:
     file_content = manifest_file.read_text()
-    pos = file_content.find(""Build timestamp: "")
-    timestamp = file_content[pos + 17 : pos + 37]
+    TIMESTAMP_PREFIX = ""Build timestamp: ""
+    TIMESTAMP_LENGTH = 20
+    timestamp = file_content[
+        file_content.find(TIMESTAMP_PREFIX) + len(TIMESTAMP_PREFIX) :
+    ][:TIMESTAMP_LENGTH]
     # Should be good enough till year 2100
     assert timestamp.startswith(""20""), timestamp
     assert timestamp.endswith(""Z""), timestamp",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,eb04996c7db0f0921cabef89022dae3a8cc6bb63,d599a7aeca7fcf80c07c941bcc5f385486ad37a4,"Use 1 fast 2CPU and 3 slow 1CPU aarch64 runners (#2040)

undefined","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 08207492..a38058c7 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -66,7 +66,7 @@ jobs:
       parent-image: """"
       image: docker-stacks-foundation
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     if: github.repository_owner == 'jupyter'
 
   x86_64-foundation:
@@ -83,7 +83,7 @@ jobs:
       parent-image: docker-stacks-foundation
       image: base-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-foundation]
     if: github.repository_owner == 'jupyter'
 
@@ -102,7 +102,7 @@ jobs:
       parent-image: base-notebook
       image: minimal-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-base]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -122,7 +122,7 @@ jobs:
       parent-image: minimal-notebook
       image: scipy-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -142,7 +142,7 @@ jobs:
       parent-image: minimal-notebook
       image: r-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -162,7 +162,7 @@ jobs:
       parent-image: minimal-notebook
       image: julia-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -182,7 +182,7 @@ jobs:
       parent-image: scipy-notebook
       image: tensorflow-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -202,7 +202,7 @@ jobs:
       parent-image: scipy-notebook
       image: pytorch-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -222,7 +222,7 @@ jobs:
       parent-image: scipy-notebook
       image: datascience-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -242,7 +242,7 @@ jobs:
       parent-image: scipy-notebook
       image: pyspark-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -262,7 +262,7 @@ jobs:
       parent-image: pyspark-notebook
       image: all-spark-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-pyspark]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 08207492..a38058c7 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -66,7 +66,7 @@ jobs:
       parent-image: """"
       image: docker-stacks-foundation
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     if: github.repository_owner == 'jupyter'
 
   x86_64-foundation:
@@ -83,7 +83,7 @@ jobs:
       parent-image: docker-stacks-foundation
       image: base-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-foundation]
     if: github.repository_owner == 'jupyter'
 
@@ -102,7 +102,7 @@ jobs:
       parent-image: base-notebook
       image: minimal-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-base]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -122,7 +122,7 @@ jobs:
       parent-image: minimal-notebook
       image: scipy-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -142,7 +142,7 @@ jobs:
       parent-image: minimal-notebook
       image: r-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -162,7 +162,7 @@ jobs:
       parent-image: minimal-notebook
       image: julia-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-minimal]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -182,7 +182,7 @@ jobs:
       parent-image: scipy-notebook
       image: tensorflow-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -202,7 +202,7 @@ jobs:
       parent-image: scipy-notebook
       image: pytorch-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -222,7 +222,7 @@ jobs:
       parent-image: scipy-notebook
       image: datascience-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_SLOW
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -242,7 +242,7 @@ jobs:
       parent-image: scipy-notebook
       image: pyspark-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-scipy]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -262,7 +262,7 @@ jobs:
       parent-image: pyspark-notebook
       image: all-spark-notebook
       platform: aarch64
-      runs-on: ARM64
+      runs-on: ARM64_FAST
     needs: [aarch64-pyspark]
     if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,37018f998cedd35a28a6307545cbeb739b371077,eb04996c7db0f0921cabef89022dae3a8cc6bb63,"Add support for Docker/Podman in rootless mode (#2039)

- Fixes https://github.com/jupyter/docker-stacks/issues/2036

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 76419b60..7d354b88 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -77,6 +77,13 @@ if [ ""$(id -u)"" == 0 ]; then
         userdel ""${NB_USER}""
         useradd --no-log-init --home ""/home/${NB_USER}"" --shell /bin/bash --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
     fi
+    # Update the home directory if the desired user (NB_USER) is root and the
+    # desired user id (NB_UID) is 0 and the desired group id (NB_GID) is 0.
+    if [ ""${NB_USER}"" = ""root"" ] && [ ""${NB_UID}"" = ""$(id -u ""${NB_USER}"")"" ] && [ ""${NB_GID}"" = ""$(id -g ""${NB_USER}"")"" ]; then
+        sed -i ""s|/root|/home/root|g"" /etc/passwd
+        # Do not preserve ownership in rootless mode
+        CP_OPTS=""-a --no-preserve=ownership""
+    fi
 
     # Move or symlink the jovyan home directory to the desired user's home
     # directory if it doesn't already exist, and update the current working
@@ -85,7 +92,8 @@ if [ ""$(id -u)"" == 0 ]; then
         if [[ ! -e ""/home/${NB_USER}"" ]]; then
             _log ""Attempting to copy /home/jovyan to /home/${NB_USER}...""
             mkdir ""/home/${NB_USER}""
-            if cp -a /home/jovyan/. ""/home/${NB_USER}/""; then
+            # shellcheck disable=SC2086
+            if cp ${CP_OPTS:--a} /home/jovyan/. ""/home/${NB_USER}/""; then
                 _log ""Success!""
             else
                 _log ""Failed to copy data from /home/jovyan to /home/${NB_USER}!""","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 76419b60..7d354b88 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -77,6 +77,13 @@ if [ ""$(id -u)"" == 0 ]; then
         userdel ""${NB_USER}""
         useradd --no-log-init --home ""/home/${NB_USER}"" --shell /bin/bash --uid ""${NB_UID}"" --gid ""${NB_GID}"" --groups 100 ""${NB_USER}""
     fi
+    # Update the home directory if the desired user (NB_USER) is root and the
+    # desired user id (NB_UID) is 0 and the desired group id (NB_GID) is 0.
+    if [ ""${NB_USER}"" = ""root"" ] && [ ""${NB_UID}"" = ""$(id -u ""${NB_USER}"")"" ] && [ ""${NB_GID}"" = ""$(id -g ""${NB_USER}"")"" ]; then
+        sed -i ""s|/root|/home/root|g"" /etc/passwd
+        # Do not preserve ownership in rootless mode
+        CP_OPTS=""-a --no-preserve=ownership""
+    fi
 
     # Move or symlink the jovyan home directory to the desired user's home
     # directory if it doesn't already exist, and update the current working
@@ -85,7 +92,8 @@ if [ ""$(id -u)"" == 0 ]; then
         if [[ ! -e ""/home/${NB_USER}"" ]]; then
             _log ""Attempting to copy /home/jovyan to /home/${NB_USER}...""
             mkdir ""/home/${NB_USER}""
-            if cp -a /home/jovyan/. ""/home/${NB_USER}/""; then
+            # shellcheck disable=SC2086
+            if cp ${CP_OPTS:--a} /home/jovyan/. ""/home/${NB_USER}/""; then
                 _log ""Success!""
             else
                 _log ""Failed to copy data from /home/jovyan to /home/${NB_USER}!""",Yes
docs/using/common.md,docs/using/common.md,a63a9a6fcb4dac700de1fbc8e0da4838ce417233,37018f998cedd35a28a6307545cbeb739b371077,"Document root homedir (#2079)

* Document root homedir

* Add link to issue","diff --git a/docs/using/common.md b/docs/using/common.md
index f1730553..3754d699 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -52,6 +52,11 @@ You do so by passing arguments to the `docker run` command.
       quay.io/jupyter/base-notebook
   ```
 
+  ```{note}
+  If you set `NB_USER` to `root`, the `root` home dir will be set to `/home/root`.
+  See discussion [here](https://github.com/jupyter/docker-stacks/issues/2042).
+  ```
+
 - `-e NB_UID=<numeric uid>` - Instructs the startup script to switch the numeric user ID of `${NB_USER}` to the given value.
   The default value is `1000`.
   This feature is useful when mounting host volumes with specific owner permissions.","diff --git a/docs/using/common.md b/docs/using/common.md
index f1730553..3754d699 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -52,6 +52,11 @@ You do so by passing arguments to the `docker run` command.
       quay.io/jupyter/base-notebook
   ```
 
+  ```{note}
+  If you set `NB_USER` to `root`, the `root` home dir will be set to `/home/root`.
+  See discussion [here](https://github.com/jupyter/docker-stacks/issues/2042).
+  ```
+
 - `-e NB_UID=<numeric uid>` - Instructs the startup script to switch the numeric user ID of `${NB_USER}` to the given value.
   The default value is `1000`.
   This feature is useful when mounting host volumes with specific owner permissions.",Yes
README.md,README.md,6e01bbabeccd863aceba233b08ef1563e12841f0,a63a9a6fcb4dac700de1fbc8e0da4838ce417233,Improve wording in versioning via image tags,"diff --git a/README.md b/README.md
index 787e6380..1397c379 100644
--- a/README.md
+++ b/README.md
@@ -96,7 +96,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 ## CPU Architectures
 
 - We publish containers for both `x86_64` and `aarch64` platforms
-- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.10.5`
+- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well","diff --git a/README.md b/README.md
index 787e6380..1397c379 100644
--- a/README.md
+++ b/README.md
@@ -96,7 +96,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 ## CPU Architectures
 
 - We publish containers for both `x86_64` and `aarch64` platforms
-- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.10.5`
+- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well",Yes
docs/using/selecting.md,docs/using/selecting.md,6e01bbabeccd863aceba233b08ef1563e12841f0,a63a9a6fcb4dac700de1fbc8e0da4838ce417233,Improve wording in versioning via image tags,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 27399303..89e983e1 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -264,7 +264,7 @@ Whenever a docker image is pushed to the container registry, it is tagged with:
 ```{warning}
 - Tags before `2022-07-05` were sometimes incorrect.
   Please, do not rely on them.
-- Single-platform images have either `aarch64` or `x86_64` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
+- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 ```
 
 For stability and reproducibility, you should either reference a date formatted","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 27399303..89e983e1 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -264,7 +264,7 @@ Whenever a docker image is pushed to the container registry, it is tagged with:
 ```{warning}
 - Tags before `2022-07-05` were sometimes incorrect.
   Please, do not rely on them.
-- Single-platform images have either `aarch64` or `x86_64` tag prefixes, for example, `jupyter/base-notebook:aarch64-python-3.10.5`
+- Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 ```
 
 For stability and reproducibility, you should either reference a date formatted",Yes
README.md,README.md,9fa124053b30fde40e5d8a6d17ed88c6c6d9e2d5,6e01bbabeccd863aceba233b08ef1563e12841f0,Update tag example,"diff --git a/README.md b/README.md
index 1397c379..79483b93 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-08
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-15
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-01-08
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-01-15
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index 1397c379..79483b93 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-08
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-15
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-01-08
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-01-15
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,9fa124053b30fde40e5d8a6d17ed88c6c6d9e2d5,6e01bbabeccd863aceba233b08ef1563e12841f0,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 40aa975e..cad1fd47 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-01-08
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-01-15
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-01-08""
+ENV TAG=""2024-01-15""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 40aa975e..cad1fd47 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-01-08
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-01-15
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-01-08""
+ENV TAG=""2024-01-15""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,9fa124053b30fde40e5d8a6d17ed88c6c6d9e2d5,6e01bbabeccd863aceba233b08ef1563e12841f0,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index d7bd623a..b652b92a 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-01-08
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-01-15
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-01-08   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-01-15   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-01-08
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-01-15
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-01-08
+    quay.io/jupyter/r-notebook:2024-01-15
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index d7bd623a..b652b92a 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-01-08
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-01-15
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-01-08   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-01-15   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-01-08
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-01-15
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-01-08` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-01-08
+    quay.io/jupyter/r-notebook:2024-01-15
 ```
 
 ```{warning}",Yes
docs/using/common.md,docs/using/common.md,0386b2a630e117f3e1aa122aa468dc6e36211938,9fa124053b30fde40e5d8a6d17ed88c6c6d9e2d5,Remove some double spaces,"diff --git a/docs/using/common.md b/docs/using/common.md
index 3754d699..34f09e6a 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -22,7 +22,7 @@ You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/l
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
-   docker run  -it --rm -p 8888:8888 quay.io/jupyter/base-notebook \
+   docker run -it --rm -p 8888:8888 quay.io/jupyter/base-notebook \
        start-notebook.py --ServerApp.base_url=/customized/url/prefix/
    ```","diff --git a/docs/using/common.md b/docs/using/common.md
index 3754d699..34f09e6a 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -22,7 +22,7 @@ You can pass [Jupyter Server options](https://jupyter-server.readthedocs.io/en/l
 2. To set the [base URL](https://jupyter-server.readthedocs.io/en/latest/operators/public-server.html#running-the-notebook-with-a-customized-url-prefix) of the Jupyter Server, you can run the following:
 
    ```bash
-   docker run  -it --rm -p 8888:8888 quay.io/jupyter/base-notebook \
+   docker run -it --rm -p 8888:8888 quay.io/jupyter/base-notebook \
        start-notebook.py --ServerApp.base_url=/customized/url/prefix/
    ```",Yes
docs/using/recipes.md,docs/using/recipes.md,0386b2a630e117f3e1aa122aa468dc6e36211938,9fa124053b30fde40e5d8a6d17ed88c6c6d9e2d5,Remove some double spaces,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index bdca0803..03293c63 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -304,7 +304,7 @@ FROM quay.io/jupyter/all-spark-notebook
 ENV HADOOP_HOME /usr/local/hadoop-2.7.3
 ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
 ENV HADOOP_CONF_HOME /usr/local/hadoop-2.7.3/etc/hadoop
-ENV HADOOP_CONF_DIR  /usr/local/hadoop-2.7.3/etc/hadoop
+ENV HADOOP_CONF_DIR /usr/local/hadoop-2.7.3/etc/hadoop
 
 USER root
 # Add proper open-jdk-8 not the jre only, needed for pydoop
@@ -331,7 +331,7 @@ RUN echo 'deb https://cdn-fastly.deb.debian.org/debian jessie-backports main' >
 COPY example-hadoop-conf/ /usr/local/hadoop-2.7.3/etc/hadoop/
 
 # Spark-Submit doesn't work unless I set the following
-RUN echo ""spark.driver.extraJavaOptions -Dhdp.version=2.5.3.0-37"" >> /usr/local/spark/conf/spark-defaults.conf  && \
+RUN echo ""spark.driver.extraJavaOptions -Dhdp.version=2.5.3.0-37"" >> /usr/local/spark/conf/spark-defaults.conf && \
     echo ""spark.yarn.am.extraJavaOptions -Dhdp.version=2.5.3.0-37"" >> /usr/local/spark/conf/spark-defaults.conf && \
     echo ""spark.master=yarn"" >>  /usr/local/spark/conf/spark-defaults.conf && \
     echo ""spark.hadoop.yarn.timeline-service.enabled=false"" >> /usr/local/spark/conf/spark-defaults.conf && \","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index bdca0803..03293c63 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -304,7 +304,7 @@ FROM quay.io/jupyter/all-spark-notebook
 ENV HADOOP_HOME /usr/local/hadoop-2.7.3
 ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
 ENV HADOOP_CONF_HOME /usr/local/hadoop-2.7.3/etc/hadoop
-ENV HADOOP_CONF_DIR  /usr/local/hadoop-2.7.3/etc/hadoop
+ENV HADOOP_CONF_DIR /usr/local/hadoop-2.7.3/etc/hadoop
 
 USER root
 # Add proper open-jdk-8 not the jre only, needed for pydoop
@@ -331,7 +331,7 @@ RUN echo 'deb https://cdn-fastly.deb.debian.org/debian jessie-backports main' >
 COPY example-hadoop-conf/ /usr/local/hadoop-2.7.3/etc/hadoop/
 
 # Spark-Submit doesn't work unless I set the following
-RUN echo ""spark.driver.extraJavaOptions -Dhdp.version=2.5.3.0-37"" >> /usr/local/spark/conf/spark-defaults.conf  && \
+RUN echo ""spark.driver.extraJavaOptions -Dhdp.version=2.5.3.0-37"" >> /usr/local/spark/conf/spark-defaults.conf && \
     echo ""spark.yarn.am.extraJavaOptions -Dhdp.version=2.5.3.0-37"" >> /usr/local/spark/conf/spark-defaults.conf && \
     echo ""spark.master=yarn"" >>  /usr/local/spark/conf/spark-defaults.conf && \
     echo ""spark.hadoop.yarn.timeline-service.enabled=false"" >> /usr/local/spark/conf/spark-defaults.conf && \",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,14a29d12d836f48fc852fd01159026bd5b24b1c0,0386b2a630e117f3e1aa122aa468dc6e36211938,Improve comments in images,"diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 545e2db1..fd6a4280 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -13,16 +13,18 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for the Server that starts but lacks all
-# features (e.g., download as all possible file formats)
+# Install all OS dependencies for the Server that starts
+# but lacks all features (e.g., download as all possible file formats)
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
+    # - Add necessary fonts for matplotlib/seaborn
+    #   See https://github.com/jupyter/docker-stacks/pull/380 for details
     fonts-liberation \
-    # - pandoc is used to convert notebooks to html files
+    # - `pandoc` is used to convert notebooks to html files
     #   it's not present in the aarch64 Ubuntu image, so we install it here
     pandoc \
-    # - run-one - a wrapper script that runs no more
-    #   than one unique  instance  of  some  command with a unique set of arguments,
+    # - `run-one` - a wrapper script that runs no more
+    #   than one unique instance of some command with a unique set of arguments,
     #   we use `run-one-constantly` to support the `RESTARTABLE` option
     run-one && \
     apt-get clean && rm -rf /var/lib/apt/lists/*","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 545e2db1..fd6a4280 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -13,16 +13,18 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-# Install all OS dependencies for the Server that starts but lacks all
-# features (e.g., download as all possible file formats)
+# Install all OS dependencies for the Server that starts
+# but lacks all features (e.g., download as all possible file formats)
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends \
+    # - Add necessary fonts for matplotlib/seaborn
+    #   See https://github.com/jupyter/docker-stacks/pull/380 for details
     fonts-liberation \
-    # - pandoc is used to convert notebooks to html files
+    # - `pandoc` is used to convert notebooks to html files
     #   it's not present in the aarch64 Ubuntu image, so we install it here
     pandoc \
-    # - run-one - a wrapper script that runs no more
-    #   than one unique  instance  of  some  command with a unique set of arguments,
+    # - `run-one` - a wrapper script that runs no more
+    #   than one unique instance of some command with a unique set of arguments,
     #   we use `run-one-constantly` to support the `RESTARTABLE` option
     run-one && \
     apt-get clean && rm -rf /var/lib/apt/lists/*",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,14a29d12d836f48fc852fd01159026bd5b24b1c0,0386b2a630e117f3e1aa122aa468dc6e36211938,Improve comments in images,"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index bd06a57e..e267f5b9 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -22,8 +22,8 @@ USER root
 # but lacks all features (e.g., download as all possible file formats)
 ENV DEBIAN_FRONTEND noninteractive
 RUN apt-get update --yes && \
-    # - `apt-get upgrade` is run to patch known vulnerabilities in apt-get packages as
-    #   the Ubuntu base image is rebuilt too seldom sometimes (less than once a month)
+    # - `apt-get upgrade` is run to patch known vulnerabilities in system packages
+    #   as the Ubuntu base image is rebuilt too seldom sometimes (less than once a month)
     apt-get upgrade --yes && \
     apt-get install --yes --no-install-recommends \
     # - bzip2 is necessary to extract the micromamba executable.
@@ -31,9 +31,9 @@ RUN apt-get update --yes && \
     ca-certificates \
     locales \
     sudo \
-    # - tini is installed as a helpful container entrypoint that reaps zombie
-    #   processes and such of the actual executable we want to start, see
-    #   https://github.com/krallin/tini#why-tini for details.
+    # - `tini` is installed as a helpful container entrypoint,
+    #   that reaps zombie processes and such of the actual executable we want to start
+    #   See https://github.com/krallin/tini#why-tini for details
     tini \
     wget && \
     apt-get clean && rm -rf /var/lib/apt/lists/* && \
@@ -102,6 +102,7 @@ RUN set -x && \
         # Should be simpler, see <https://github.com/mamba-org/mamba/issues/1437>
         arch=""64""; \
     fi && \
+    # https://mamba.readthedocs.io/en/latest/installation/micromamba-installation.html#linux-and-macos
     wget --progress=dot:giga -O - \
         ""https://micro.mamba.pm/api/micromamba/linux-${arch}/latest"" | tar -xvj bin/micromamba && \
     PYTHON_SPECIFIER=""python=${PYTHON_VERSION}"" && \","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index bd06a57e..e267f5b9 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -22,8 +22,8 @@ USER root
 # but lacks all features (e.g., download as all possible file formats)
 ENV DEBIAN_FRONTEND noninteractive
 RUN apt-get update --yes && \
-    # - `apt-get upgrade` is run to patch known vulnerabilities in apt-get packages as
-    #   the Ubuntu base image is rebuilt too seldom sometimes (less than once a month)
+    # - `apt-get upgrade` is run to patch known vulnerabilities in system packages
+    #   as the Ubuntu base image is rebuilt too seldom sometimes (less than once a month)
     apt-get upgrade --yes && \
     apt-get install --yes --no-install-recommends \
     # - bzip2 is necessary to extract the micromamba executable.
@@ -31,9 +31,9 @@ RUN apt-get update --yes && \
     ca-certificates \
     locales \
     sudo \
-    # - tini is installed as a helpful container entrypoint that reaps zombie
-    #   processes and such of the actual executable we want to start, see
-    #   https://github.com/krallin/tini#why-tini for details.
+    # - `tini` is installed as a helpful container entrypoint,
+    #   that reaps zombie processes and such of the actual executable we want to start
+    #   See https://github.com/krallin/tini#why-tini for details
     tini \
     wget && \
     apt-get clean && rm -rf /var/lib/apt/lists/* && \
@@ -102,6 +102,7 @@ RUN set -x && \
         # Should be simpler, see <https://github.com/mamba-org/mamba/issues/1437>
         arch=""64""; \
     fi && \
+    # https://mamba.readthedocs.io/en/latest/installation/micromamba-installation.html#linux-and-macos
     wget --progress=dot:giga -O - \
         ""https://micro.mamba.pm/api/micromamba/linux-${arch}/latest"" | tar -xvj bin/micromamba && \
     PYTHON_SPECIFIER=""python=${PYTHON_VERSION}"" && \",Yes
images/minimal-notebook/Dockerfile,images/minimal-notebook/Dockerfile,14a29d12d836f48fc852fd01159026bd5b24b1c0,0386b2a630e117f3e1aa122aa468dc6e36211938,Improve comments in images,"diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index a0dbfc65..e77798c7 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -25,10 +25,10 @@ RUN apt-get update --yes && \
     vim-tiny \
     # git-over-ssh
     openssh-client \
-    # less is needed to run help in R
+    # `less` is needed to run help in R
     # see: https://github.com/jupyter/docker-stacks/issues/1588
     less \
-    # nbconvert dependencies
+    # `nbconvert` dependencies
     # https://nbconvert.readthedocs.io/en/latest/install.html#installing-tex
     texlive-xetex \
     texlive-fonts-recommended \","diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index a0dbfc65..e77798c7 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -25,10 +25,10 @@ RUN apt-get update --yes && \
     vim-tiny \
     # git-over-ssh
     openssh-client \
-    # less is needed to run help in R
+    # `less` is needed to run help in R
     # see: https://github.com/jupyter/docker-stacks/issues/1588
     less \
-    # nbconvert dependencies
+    # `nbconvert` dependencies
     # https://nbconvert.readthedocs.io/en/latest/install.html#installing-tex
     texlive-xetex \
     texlive-fonts-recommended \",Yes
images/pyspark-notebook/ipython_kernel_config.py,images/pyspark-notebook/ipython_kernel_config.py,14a29d12d836f48fc852fd01159026bd5b24b1c0,0386b2a630e117f3e1aa122aa468dc6e36211938,Improve comments in images,"diff --git a/images/pyspark-notebook/ipython_kernel_config.py b/images/pyspark-notebook/ipython_kernel_config.py
index f3efbe19..921e6fa8 100644
--- a/images/pyspark-notebook/ipython_kernel_config.py
+++ b/images/pyspark-notebook/ipython_kernel_config.py
@@ -7,8 +7,7 @@
 # Logs are particularly verbose with Spark, that is why we turn them off through this flag.
 # <https://github.com/jupyter/docker-stacks/issues/1423>
 
-# Attempt to capture and forward low-level output, e.g. produced by Extension
-#  libraries.
-#  Default: True
+# Attempt to capture and forward low-level output, e.g. produced by Extension libraries.
+# Default: True
 # type:ignore
 c.IPKernelApp.capture_fd_output = False  # noqa: F821","diff --git a/images/pyspark-notebook/ipython_kernel_config.py b/images/pyspark-notebook/ipython_kernel_config.py
index f3efbe19..921e6fa8 100644
--- a/images/pyspark-notebook/ipython_kernel_config.py
+++ b/images/pyspark-notebook/ipython_kernel_config.py
@@ -7,8 +7,7 @@
 # Logs are particularly verbose with Spark, that is why we turn them off through this flag.
 # <https://github.com/jupyter/docker-stacks/issues/1423>
 
-# Attempt to capture and forward low-level output, e.g. produced by Extension
-#  libraries.
-#  Default: True
+# Attempt to capture and forward low-level output, e.g. produced by Extension libraries.
+# Default: True
 # type:ignore
 c.IPKernelApp.capture_fd_output = False  # noqa: F821",Yes
tests/base-notebook/test_healthcheck.py,tests/base-notebook/test_healthcheck.py,d3e18d975cc435c1fbf79ebb652986b47d7f9620,14a29d12d836f48fc852fd01159026bd5b24b1c0,Fix some style issues in tests,"diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 7aca3ac6..2e572019 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -128,18 +128,16 @@ def test_healthy_with_proxy(
 
 
 @pytest.mark.parametrize(
-    ""env,cmd,user"",
+    ""env,cmd"",
     [
-        ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, None),
+        ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
             [""start-notebook.py"", ""--ServerApp.base_url=/test""],
-            None,
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
             [""start-notebook.py"", ""--ServerApp.base_url=/test""],
-            None,
         ),
     ],
 )
@@ -147,13 +145,11 @@ def test_not_healthy(
     container: TrackedContainer,
     env: Optional[list[str]],
     cmd: Optional[list[str]],
-    user: Optional[str],
 ) -> None:
     running_container = container.run_detached(
         tty=True,
         environment=env,
         command=cmd,
-        user=user,
     )
 
     # sleeping some time to let the server start
@@ -164,6 +160,6 @@ def test_not_healthy(
         time.sleep(wait_time)
         time_spent += wait_time
         if get_health(running_container) == ""healthy"":
-            raise RuntimeError(""Container should not be healthy for these testcases."")
+            raise RuntimeError(""Container should not be healthy for this testcase"")
 
     assert get_health(running_container) != ""healthy""","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 7aca3ac6..2e572019 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -128,18 +128,16 @@ def test_healthy_with_proxy(
 
 
 @pytest.mark.parametrize(
-    ""env,cmd,user"",
+    ""env,cmd"",
     [
-        ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None, None),
+        ([""NB_USER=testuser"", ""CHOWN_HOME=1""], None),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1""],
             [""start-notebook.py"", ""--ServerApp.base_url=/test""],
-            None,
         ),
         (
             [""NB_USER=testuser"", ""CHOWN_HOME=1"", ""JUPYTER_PORT=8123""],
             [""start-notebook.py"", ""--ServerApp.base_url=/test""],
-            None,
         ),
     ],
 )
@@ -147,13 +145,11 @@ def test_not_healthy(
     container: TrackedContainer,
     env: Optional[list[str]],
     cmd: Optional[list[str]],
-    user: Optional[str],
 ) -> None:
     running_container = container.run_detached(
         tty=True,
         environment=env,
         command=cmd,
-        user=user,
     )
 
     # sleeping some time to let the server start
@@ -164,6 +160,6 @@ def test_not_healthy(
         time.sleep(wait_time)
         time_spent += wait_time
         if get_health(running_container) == ""healthy"":
-            raise RuntimeError(""Container should not be healthy for these testcases."")
+            raise RuntimeError(""Container should not be healthy for this testcase"")
 
     assert get_health(running_container) != ""healthy""",Yes
tests/minimal-notebook/test_nbconvert.py,tests/minimal-notebook/test_nbconvert.py,d3e18d975cc435c1fbf79ebb652986b47d7f9620,14a29d12d836f48fc852fd01159026bd5b24b1c0,Fix some style issues in tests,"diff --git a/tests/minimal-notebook/test_nbconvert.py b/tests/minimal-notebook/test_nbconvert.py
index 33954cb0..115d2ff0 100644
--- a/tests/minimal-notebook/test_nbconvert.py
+++ b/tests/minimal-notebook/test_nbconvert.py
@@ -11,15 +11,8 @@ LOGGER = logging.getLogger(__name__)
 THIS_DIR = Path(__file__).parent.resolve()
 
 
-@pytest.mark.parametrize(
-    ""test_file, output_format"",
-    [
-        (""notebook_math"", ""pdf""),
-        (""notebook_math"", ""html""),
-        (""notebook_svg"", ""pdf""),
-        (""notebook_svg"", ""html""),
-    ],
-)
+@pytest.mark.parametrize(""test_file"", [""notebook_math"", ""notebook_svg""])
+@pytest.mark.parametrize(""output_format"", [""pdf"", ""html""])
 def test_nbconvert(
     container: TrackedContainer, test_file: str, output_format: str
 ) -> None:","diff --git a/tests/minimal-notebook/test_nbconvert.py b/tests/minimal-notebook/test_nbconvert.py
index 33954cb0..115d2ff0 100644
--- a/tests/minimal-notebook/test_nbconvert.py
+++ b/tests/minimal-notebook/test_nbconvert.py
@@ -11,15 +11,8 @@ LOGGER = logging.getLogger(__name__)
 THIS_DIR = Path(__file__).parent.resolve()
 
 
-@pytest.mark.parametrize(
-    ""test_file, output_format"",
-    [
-        (""notebook_math"", ""pdf""),
-        (""notebook_math"", ""html""),
-        (""notebook_svg"", ""pdf""),
-        (""notebook_svg"", ""html""),
-    ],
-)
+@pytest.mark.parametrize(""test_file"", [""notebook_math"", ""notebook_svg""])
+@pytest.mark.parametrize(""output_format"", [""pdf"", ""html""])
 def test_nbconvert(
     container: TrackedContainer, test_file: str, output_format: str
 ) -> None:",Yes
tests/package_helper.py,tests/package_helper.py,d3e18d975cc435c1fbf79ebb652986b47d7f9620,14a29d12d836f48fc852fd01159026bd5b24b1c0,Fix some style issues in tests,"diff --git a/tests/package_helper.py b/tests/package_helper.py
index 7524fe0a..1cfdd99d 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -96,7 +96,7 @@ class CondaPackageHelper:
     @staticmethod
     def _packages_from_json(env_export: str) -> dict[str, set[str]]:
         """"""Extract packages and versions from the lines returned by the list of specifications""""""
-        # dependencies = filter(lambda x:  isinstance(x, str), json.loads(env_export).get(""dependencies""))
+        # dependencies = filter(lambda x: isinstance(x, str), json.loads(env_export).get(""dependencies""))
         dependencies = json.loads(env_export).get(""dependencies"")
         # Filtering packages installed through pip in this case it's a dict {'pip': ['toree==0.3.0']}
         # Since we only manage packages installed through mamba here","diff --git a/tests/package_helper.py b/tests/package_helper.py
index 7524fe0a..1cfdd99d 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -96,7 +96,7 @@ class CondaPackageHelper:
     @staticmethod
     def _packages_from_json(env_export: str) -> dict[str, set[str]]:
         """"""Extract packages and versions from the lines returned by the list of specifications""""""
-        # dependencies = filter(lambda x:  isinstance(x, str), json.loads(env_export).get(""dependencies""))
+        # dependencies = filter(lambda x: isinstance(x, str), json.loads(env_export).get(""dependencies""))
         dependencies = json.loads(env_export).get(""dependencies"")
         # Filtering packages installed through pip in this case it's a dict {'pip': ['toree==0.3.0']}
         # Since we only manage packages installed through mamba here",Yes
images/base-notebook/start-notebook.py,images/base-notebook/start-notebook.py,86dc0f274f878ffd438f4cc1b0c900e102dcb0b6,d3e18d975cc435c1fbf79ebb652986b47d7f9620,Fix comments codestyle in python,"diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
index b99ff315..c9a899be 100755
--- a/images/base-notebook/start-notebook.py
+++ b/images/base-notebook/start-notebook.py
@@ -24,13 +24,15 @@ if os.environ.get(""RESTARTABLE"") == ""yes"":
 # We always launch a jupyter subcommand from this script
 command.append(""jupyter"")
 
-# Launch the configured subcommand. Note that this should be a single string, so we don't split it
-# We default to lab
+# Launch the configured subcommand.
+# Note that this should be a single string, so we don't split it.
+# We default to `lab`.
 jupyter_command = os.environ.get(""DOCKER_STACKS_JUPYTER_CMD"", ""lab"")
 command.append(jupyter_command)
 
-# Append any optional NOTEBOOK_ARGS we were passed in. This is supposed to be multiple args passed
-# on to the notebook command, so we split it correctly with shlex
+# Append any optional NOTEBOOK_ARGS we were passed in.
+# This is supposed to be multiple args passed on to the notebook command,
+# so we split it correctly with shlex
 if ""NOTEBOOK_ARGS"" in os.environ:
     command += shlex.split(os.environ[""NOTEBOOK_ARGS""])","diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
index b99ff315..c9a899be 100755
--- a/images/base-notebook/start-notebook.py
+++ b/images/base-notebook/start-notebook.py
@@ -24,13 +24,15 @@ if os.environ.get(""RESTARTABLE"") == ""yes"":
 # We always launch a jupyter subcommand from this script
 command.append(""jupyter"")
 
-# Launch the configured subcommand. Note that this should be a single string, so we don't split it
-# We default to lab
+# Launch the configured subcommand.
+# Note that this should be a single string, so we don't split it.
+# We default to `lab`.
 jupyter_command = os.environ.get(""DOCKER_STACKS_JUPYTER_CMD"", ""lab"")
 command.append(jupyter_command)
 
-# Append any optional NOTEBOOK_ARGS we were passed in. This is supposed to be multiple args passed
-# on to the notebook command, so we split it correctly with shlex
+# Append any optional NOTEBOOK_ARGS we were passed in.
+# This is supposed to be multiple args passed on to the notebook command,
+# so we split it correctly with shlex
 if ""NOTEBOOK_ARGS"" in os.environ:
     command += shlex.split(os.environ[""NOTEBOOK_ARGS""])",Yes
tests/base-notebook/test_container_options.py,tests/base-notebook/test_container_options.py,86dc0f274f878ffd438f4cc1b0c900e102dcb0b6,d3e18d975cc435c1fbf79ebb652986b47d7f9620,Fix comments codestyle in python,"diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 91203501..3232239b 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -65,10 +65,10 @@ def test_unsigned_ssl(
         environment=[""GEN_CERT=yes""],
         ports={""8888/tcp"": host_port},
     )
-    # NOTE: The requests.Session backing the http_client fixture does not retry
-    # properly while the server is booting up. An SSL handshake error seems to
-    # abort the retry logic. Forcing a long sleep for the moment until I have
-    # time to dig more.
+    # NOTE: The requests.Session backing the http_client fixture
+    # does not retry properly while the server is booting up.
+    # An SSL handshake error seems to abort the retry logic.
+    # Forcing a long sleep for the moment until I have time to dig more.
     time.sleep(1)
     resp = http_client.get(f""https://localhost:{host_port}"", verify=False)
     resp.raise_for_status()","diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 91203501..3232239b 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -65,10 +65,10 @@ def test_unsigned_ssl(
         environment=[""GEN_CERT=yes""],
         ports={""8888/tcp"": host_port},
     )
-    # NOTE: The requests.Session backing the http_client fixture does not retry
-    # properly while the server is booting up. An SSL handshake error seems to
-    # abort the retry logic. Forcing a long sleep for the moment until I have
-    # time to dig more.
+    # NOTE: The requests.Session backing the http_client fixture
+    # does not retry properly while the server is booting up.
+    # An SSL handshake error seems to abort the retry logic.
+    # Forcing a long sleep for the moment until I have time to dig more.
     time.sleep(1)
     resp = http_client.get(f""https://localhost:{host_port}"", verify=False)
     resp.raise_for_status()",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,d57bf9590d1407362e3b7029192d0e181fb11818,86dc0f274f878ffd438f4cc1b0c900e102dcb0b6,"Adjust sleep times (#2080)

* Adjust sleep times

* Update test_start_container.py

* Update test_healthcheck.py

* Update pluto_check.py","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index fd6a4280..07903b94 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -68,7 +68,7 @@ RUN fix-permissions /etc/jupyter/
 # HEALTHCHECK documentation: https://docs.docker.com/engine/reference/builder/#healthcheck
 # This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server`, and `retro` jupyter commands
 # https://github.com/jupyter/docker-stacks/issues/915#issuecomment-1068528799
-HEALTHCHECK --interval=5s --timeout=3s --start-period=5s --retries=3 \
+HEALTHCHECK --interval=3s --timeout=1s --start-period=3s --retries=3 \
     CMD /etc/jupyter/docker_healthcheck.py || exit 1
 
 # Switch back to jovyan to avoid accidental container runs as root","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index fd6a4280..07903b94 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -68,7 +68,7 @@ RUN fix-permissions /etc/jupyter/
 # HEALTHCHECK documentation: https://docs.docker.com/engine/reference/builder/#healthcheck
 # This healtcheck works well for `lab`, `notebook`, `nbclassic`, `server`, and `retro` jupyter commands
 # https://github.com/jupyter/docker-stacks/issues/915#issuecomment-1068528799
-HEALTHCHECK --interval=5s --timeout=3s --start-period=5s --retries=3 \
+HEALTHCHECK --interval=3s --timeout=1s --start-period=3s --retries=3 \
     CMD /etc/jupyter/docker_healthcheck.py || exit 1
 
 # Switch back to jovyan to avoid accidental container runs as root",Yes
tests/base-notebook/test_healthcheck.py,tests/base-notebook/test_healthcheck.py,d57bf9590d1407362e3b7029192d0e181fb11818,86dc0f274f878ffd438f4cc1b0c900e102dcb0b6,"Adjust sleep times (#2080)

* Adjust sleep times

* Update test_start_container.py

* Update test_healthcheck.py

* Update pluto_check.py","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 2e572019..d5874c9a 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -67,13 +67,11 @@ def test_healthy(
         user=user,
     )
 
-    # sleeping some time to let the server start
-    time_spent = 0.0
-    wait_time = 0.1
-    time_limit = 15
-    while time_spent < time_limit:
-        time.sleep(wait_time)
-        time_spent += wait_time
+    # giving some time to let the server start
+    finish_time = time.time() + 10
+    sleep_time = 0.1
+    while time.time() < finish_time:
+        time.sleep(sleep_time)
         if get_health(running_container) == ""healthy"":
             return
 
@@ -114,13 +112,11 @@ def test_healthy_with_proxy(
         user=user,
     )
 
-    # sleeping some time to let the server start
-    time_spent = 0.0
-    wait_time = 0.1
-    time_limit = 15
-    while time_spent < time_limit:
-        time.sleep(wait_time)
-        time_spent += wait_time
+    # giving some time to let the server start
+    finish_time = time.time() + 10
+    sleep_time = 0.1
+    while time.time() < finish_time:
+        time.sleep(sleep_time)
         if get_health(running_container) == ""healthy"":
             return
 
@@ -152,13 +148,11 @@ def test_not_healthy(
         command=cmd,
     )
 
-    # sleeping some time to let the server start
-    time_spent = 0.0
-    wait_time = 0.1
-    time_limit = 15
-    while time_spent < time_limit:
-        time.sleep(wait_time)
-        time_spent += wait_time
+    # giving some time to let the server start
+    finish_time = time.time() + 5
+    sleep_time = 0.1
+    while time.time() < finish_time:
+        time.sleep(sleep_time)
         if get_health(running_container) == ""healthy"":
             raise RuntimeError(""Container should not be healthy for this testcase"")","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index 2e572019..d5874c9a 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -67,13 +67,11 @@ def test_healthy(
         user=user,
     )
 
-    # sleeping some time to let the server start
-    time_spent = 0.0
-    wait_time = 0.1
-    time_limit = 15
-    while time_spent < time_limit:
-        time.sleep(wait_time)
-        time_spent += wait_time
+    # giving some time to let the server start
+    finish_time = time.time() + 10
+    sleep_time = 0.1
+    while time.time() < finish_time:
+        time.sleep(sleep_time)
         if get_health(running_container) == ""healthy"":
             return
 
@@ -114,13 +112,11 @@ def test_healthy_with_proxy(
         user=user,
     )
 
-    # sleeping some time to let the server start
-    time_spent = 0.0
-    wait_time = 0.1
-    time_limit = 15
-    while time_spent < time_limit:
-        time.sleep(wait_time)
-        time_spent += wait_time
+    # giving some time to let the server start
+    finish_time = time.time() + 10
+    sleep_time = 0.1
+    while time.time() < finish_time:
+        time.sleep(sleep_time)
         if get_health(running_container) == ""healthy"":
             return
 
@@ -152,13 +148,11 @@ def test_not_healthy(
         command=cmd,
     )
 
-    # sleeping some time to let the server start
-    time_spent = 0.0
-    wait_time = 0.1
-    time_limit = 15
-    while time_spent < time_limit:
-        time.sleep(wait_time)
-        time_spent += wait_time
+    # giving some time to let the server start
+    finish_time = time.time() + 5
+    sleep_time = 0.1
+    while time.time() < finish_time:
+        time.sleep(sleep_time)
         if get_health(running_container) == ""healthy"":
             raise RuntimeError(""Container should not be healthy for this testcase"")",Yes
tests/pluto_check.py,tests/pluto_check.py,d57bf9590d1407362e3b7029192d0e181fb11818,86dc0f274f878ffd438f4cc1b0c900e102dcb0b6,"Adjust sleep times (#2080)

* Adjust sleep times

* Update test_start_container.py

* Update test_healthcheck.py

* Update pluto_check.py","diff --git a/tests/pluto_check.py b/tests/pluto_check.py
index ebb558b4..48116db4 100644
--- a/tests/pluto_check.py
+++ b/tests/pluto_check.py
@@ -24,7 +24,7 @@ def check_pluto_proxy(
         ports={""8888/tcp"": host_port},
     )
     # Give the server a bit of time to start
-    time.sleep(3)
+    time.sleep(2)
     resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
     resp.raise_for_status()
     assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""","diff --git a/tests/pluto_check.py b/tests/pluto_check.py
index ebb558b4..48116db4 100644
--- a/tests/pluto_check.py
+++ b/tests/pluto_check.py
@@ -24,7 +24,7 @@ def check_pluto_proxy(
         ports={""8888/tcp"": host_port},
     )
     # Give the server a bit of time to start
-    time.sleep(3)
+    time.sleep(2)
     resp = http_client.get(f""http://localhost:{host_port}/pluto?token={token}"")
     resp.raise_for_status()
     assert ""Pluto.jl notebooks"" in resp.text, ""Pluto.jl text not found in /pluto page""",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,bf33945b9e4cf146f6f63fdf27774bd7b90f2ebb,d57bf9590d1407362e3b7029192d0e181fb11818,"Do not bloat spark image with ENV variables (#2081)

* Do not bloat spark image with ENV variables

* Remove HadoopVersionTagger","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 212e3a55..f64bb75d 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -34,12 +34,6 @@ ARG scala_version
 # But it seems to be slower, that's why we use the recommended site for download
 ARG spark_download_url=""https://dlcdn.apache.org/spark/""
 
-# Configure Spark
-ENV SPARK_VERSION=""${spark_version}"" \
-    HADOOP_VERSION=""${hadoop_version}"" \
-    SCALA_VERSION=""${scala_version}"" \
-    SPARK_DOWNLOAD_URL=""${spark_download_url}""
-
 ENV SPARK_HOME=/usr/local/spark
 ENV PATH=""${PATH}:${SPARK_HOME}/bin""
 ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info""
@@ -47,7 +41,11 @@ ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M
 COPY setup_spark.py /opt/setup-scripts/
 
 # Setup Spark
-RUN /opt/setup-scripts/setup_spark.py
+RUN SPARK_VERSION=""${spark_version}"" \
+    HADOOP_VERSION=""${hadoop_version}"" \
+    SCALA_VERSION=""${scala_version}"" \
+    SPARK_DOWNLOAD_URL=""${spark_download_url}"" \
+    /opt/setup-scripts/setup_spark.py
 
 # Configure IPython system-wide
 COPY ipython_kernel_config.py ""/etc/ipython/""","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 212e3a55..f64bb75d 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -34,12 +34,6 @@ ARG scala_version
 # But it seems to be slower, that's why we use the recommended site for download
 ARG spark_download_url=""https://dlcdn.apache.org/spark/""
 
-# Configure Spark
-ENV SPARK_VERSION=""${spark_version}"" \
-    HADOOP_VERSION=""${hadoop_version}"" \
-    SCALA_VERSION=""${scala_version}"" \
-    SPARK_DOWNLOAD_URL=""${spark_download_url}""
-
 ENV SPARK_HOME=/usr/local/spark
 ENV PATH=""${PATH}:${SPARK_HOME}/bin""
 ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info""
@@ -47,7 +41,11 @@ ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M
 COPY setup_spark.py /opt/setup-scripts/
 
 # Setup Spark
-RUN /opt/setup-scripts/setup_spark.py
+RUN SPARK_VERSION=""${spark_version}"" \
+    HADOOP_VERSION=""${hadoop_version}"" \
+    SCALA_VERSION=""${scala_version}"" \
+    SPARK_DOWNLOAD_URL=""${spark_download_url}"" \
+    /opt/setup-scripts/setup_spark.py
 
 # Configure IPython system-wide
 COPY ipython_kernel_config.py ""/etc/ipython/""",Yes
tagging/images_hierarchy.py,tagging/images_hierarchy.py,bf33945b9e4cf146f6f63fdf27774bd7b90f2ebb,d57bf9590d1407362e3b7029192d0e181fb11818,"Do not bloat spark image with ENV variables (#2081)

* Do not bloat spark image with ENV variables

* Remove HadoopVersionTagger","diff --git a/tagging/images_hierarchy.py b/tagging/images_hierarchy.py
index f4145876..8c3e3fd3 100644
--- a/tagging/images_hierarchy.py
+++ b/tagging/images_hierarchy.py
@@ -13,7 +13,6 @@ from tagging.manifests import (
 )
 from tagging.taggers import (
     DateTagger,
-    HadoopVersionTagger,
     JavaVersionTagger,
     JuliaVersionTagger,
     JupyterHubVersionTagger,
@@ -83,7 +82,7 @@ ALL_IMAGES = {
     ),
     ""pyspark-notebook"": ImageDescription(
         parent_image=""scipy-notebook"",
-        taggers=[SparkVersionTagger(), HadoopVersionTagger(), JavaVersionTagger()],
+        taggers=[SparkVersionTagger(), JavaVersionTagger()],
         manifests=[SparkInfoManifest()],
     ),
     ""all-spark-notebook"": ImageDescription(","diff --git a/tagging/images_hierarchy.py b/tagging/images_hierarchy.py
index f4145876..8c3e3fd3 100644
--- a/tagging/images_hierarchy.py
+++ b/tagging/images_hierarchy.py
@@ -13,7 +13,6 @@ from tagging.manifests import (
 )
 from tagging.taggers import (
     DateTagger,
-    HadoopVersionTagger,
     JavaVersionTagger,
     JuliaVersionTagger,
     JupyterHubVersionTagger,
@@ -83,7 +82,7 @@ ALL_IMAGES = {
     ),
     ""pyspark-notebook"": ImageDescription(
         parent_image=""scipy-notebook"",
-        taggers=[SparkVersionTagger(), HadoopVersionTagger(), JavaVersionTagger()],
+        taggers=[SparkVersionTagger(), JavaVersionTagger()],
         manifests=[SparkInfoManifest()],
     ),
     ""all-spark-notebook"": ImageDescription(",Yes
tagging/taggers.py,tagging/taggers.py,bf33945b9e4cf146f6f63fdf27774bd7b90f2ebb,d57bf9590d1407362e3b7029192d0e181fb11818,"Do not bloat spark image with ENV variables (#2081)

* Do not bloat spark image with ENV variables

* Remove HadoopVersionTagger","diff --git a/tagging/taggers.py b/tagging/taggers.py
index daf987b1..1aa6705d 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -12,18 +12,6 @@ def _get_program_version(container: Container, program: str) -> str:
     return DockerRunner.run_simple_command(container, cmd=f""{program} --version"")
 
 
-def _get_env_variable(container: Container, variable: str) -> str:
-    env = DockerRunner.run_simple_command(
-        container,
-        cmd=""env"",
-        print_result=False,
-    ).split()
-    for env_entry in env:
-        if env_entry.startswith(variable):
-            return env_entry[len(variable) + 1 :]
-    raise KeyError(variable)
-
-
 def _get_pip_package_version(container: Container, package: str) -> str:
     PIP_VERSION_PREFIX = ""Version: ""
 
@@ -136,12 +124,6 @@ class SparkVersionTagger(TaggerInterface):
         return ""spark-"" + version_line.split("" "")[-1]
 
 
-class HadoopVersionTagger(TaggerInterface):
-    @staticmethod
-    def tag_value(container: Container) -> str:
-        return ""hadoop-"" + _get_env_variable(container, ""HADOOP_VERSION"")
-
-
 class JavaVersionTagger(TaggerInterface):
     @staticmethod
     def tag_value(container: Container) -> str:","diff --git a/tagging/taggers.py b/tagging/taggers.py
index daf987b1..1aa6705d 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -12,18 +12,6 @@ def _get_program_version(container: Container, program: str) -> str:
     return DockerRunner.run_simple_command(container, cmd=f""{program} --version"")
 
 
-def _get_env_variable(container: Container, variable: str) -> str:
-    env = DockerRunner.run_simple_command(
-        container,
-        cmd=""env"",
-        print_result=False,
-    ).split()
-    for env_entry in env:
-        if env_entry.startswith(variable):
-            return env_entry[len(variable) + 1 :]
-    raise KeyError(variable)
-
-
 def _get_pip_package_version(container: Container, package: str) -> str:
     PIP_VERSION_PREFIX = ""Version: ""
 
@@ -136,12 +124,6 @@ class SparkVersionTagger(TaggerInterface):
         return ""spark-"" + version_line.split("" "")[-1]
 
 
-class HadoopVersionTagger(TaggerInterface):
-    @staticmethod
-    def tag_value(container: Container) -> str:
-        return ""hadoop-"" + _get_env_variable(container, ""HADOOP_VERSION"")
-
-
 class JavaVersionTagger(TaggerInterface):
     @staticmethod
     def tag_value(container: Container) -> str:",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,afe30f0c9ad88ba58a80ed5d9795adf7b7d2490c,bf33945b9e4cf146f6f63fdf27774bd7b90f2ebb,Use argparse to setup spark (#2082),"diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index f64bb75d..c9c9326b 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -41,11 +41,11 @@ ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M
 COPY setup_spark.py /opt/setup-scripts/
 
 # Setup Spark
-RUN SPARK_VERSION=""${spark_version}"" \
-    HADOOP_VERSION=""${hadoop_version}"" \
-    SCALA_VERSION=""${scala_version}"" \
-    SPARK_DOWNLOAD_URL=""${spark_download_url}"" \
-    /opt/setup-scripts/setup_spark.py
+RUN /opt/setup-scripts/setup_spark.py \
+    --spark-version=""${spark_version}"" \
+    --hadoop-version=""${hadoop_version}"" \
+    --scala-version=""${scala_version}"" \
+    --spark-download-url=""${spark_download_url}""
 
 # Configure IPython system-wide
 COPY ipython_kernel_config.py ""/etc/ipython/""","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index f64bb75d..c9c9326b 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -41,11 +41,11 @@ ENV SPARK_OPTS=""--driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M
 COPY setup_spark.py /opt/setup-scripts/
 
 # Setup Spark
-RUN SPARK_VERSION=""${spark_version}"" \
-    HADOOP_VERSION=""${hadoop_version}"" \
-    SCALA_VERSION=""${scala_version}"" \
-    SPARK_DOWNLOAD_URL=""${spark_download_url}"" \
-    /opt/setup-scripts/setup_spark.py
+RUN /opt/setup-scripts/setup_spark.py \
+    --spark-version=""${spark_version}"" \
+    --hadoop-version=""${hadoop_version}"" \
+    --scala-version=""${scala_version}"" \
+    --spark-download-url=""${spark_download_url}""
 
 # Configure IPython system-wide
 COPY ipython_kernel_config.py ""/etc/ipython/""",Yes
images/pyspark-notebook/setup_spark.py,images/pyspark-notebook/setup_spark.py,afe30f0c9ad88ba58a80ed5d9795adf7b7d2490c,bf33945b9e4cf146f6f63fdf27774bd7b90f2ebb,Use argparse to setup spark (#2082),"diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index 3481cc70..a494b832 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -4,9 +4,9 @@
 
 # Requirements:
 # - Run as the root user
-# - Required env variables: SPARK_HOME, HADOOP_VERSION, SPARK_DOWNLOAD_URL
-# - Optional env variables: SPARK_VERSION, SCALA_VERSION
+# - Required env variable: SPARK_HOME
 
+import argparse
 import logging
 import os
 import subprocess
@@ -27,13 +27,10 @@ def get_all_refs(url: str) -> list[str]:
     return [a[""href""] for a in soup.find_all(""a"", href=True)]
 
 
-def get_spark_version() -> str:
+def get_latest_spark_version() -> str:
     """"""
-    If ${SPARK_VERSION} env variable is non-empty, simply returns it
-    Otherwise, returns the last stable version of Spark using spark archive
+    Returns the last stable version of Spark using spark archive
     """"""
-    if (version := os.environ[""SPARK_VERSION""]) != """":
-        return version
     LOGGER.info(""Downloading Spark versions information"")
     all_refs = get_all_refs(""https://archive.apache.org/dist/spark/"")
     stable_versions = [
@@ -106,12 +103,20 @@ def configure_spark(spark_dir_name: str, spark_home: Path) -> None:
 if __name__ == ""__main__"":
     logging.basicConfig(level=logging.INFO)
 
-    spark_version = get_spark_version()
+    arg_parser = argparse.ArgumentParser()
+    arg_parser.add_argument(""--spark-version"", required=True)
+    arg_parser.add_argument(""--hadoop-version"", required=True)
+    arg_parser.add_argument(""--scala-version"", required=True)
+    arg_parser.add_argument(""--spark-download-url"", type=Path, required=True)
+    args = arg_parser.parse_args()
+
+    args.spark_version = args.spark_version or get_latest_spark_version()
+
     spark_dir_name = download_spark(
-        spark_version=spark_version,
-        hadoop_version=os.environ[""HADOOP_VERSION""],
-        scala_version=os.environ[""SCALA_VERSION""],
-        spark_download_url=Path(os.environ[""SPARK_DOWNLOAD_URL""]),
+        spark_version=args.spark_version,
+        hadoop_version=args.hadoop_version,
+        scala_version=args.scala_version,
+        spark_download_url=args.spark_download_url,
     )
     configure_spark(
         spark_dir_name=spark_dir_name, spark_home=Path(os.environ[""SPARK_HOME""])","diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index 3481cc70..a494b832 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -4,9 +4,9 @@
 
 # Requirements:
 # - Run as the root user
-# - Required env variables: SPARK_HOME, HADOOP_VERSION, SPARK_DOWNLOAD_URL
-# - Optional env variables: SPARK_VERSION, SCALA_VERSION
+# - Required env variable: SPARK_HOME
 
+import argparse
 import logging
 import os
 import subprocess
@@ -27,13 +27,10 @@ def get_all_refs(url: str) -> list[str]:
     return [a[""href""] for a in soup.find_all(""a"", href=True)]
 
 
-def get_spark_version() -> str:
+def get_latest_spark_version() -> str:
     """"""
-    If ${SPARK_VERSION} env variable is non-empty, simply returns it
-    Otherwise, returns the last stable version of Spark using spark archive
+    Returns the last stable version of Spark using spark archive
     """"""
-    if (version := os.environ[""SPARK_VERSION""]) != """":
-        return version
     LOGGER.info(""Downloading Spark versions information"")
     all_refs = get_all_refs(""https://archive.apache.org/dist/spark/"")
     stable_versions = [
@@ -106,12 +103,20 @@ def configure_spark(spark_dir_name: str, spark_home: Path) -> None:
 if __name__ == ""__main__"":
     logging.basicConfig(level=logging.INFO)
 
-    spark_version = get_spark_version()
+    arg_parser = argparse.ArgumentParser()
+    arg_parser.add_argument(""--spark-version"", required=True)
+    arg_parser.add_argument(""--hadoop-version"", required=True)
+    arg_parser.add_argument(""--scala-version"", required=True)
+    arg_parser.add_argument(""--spark-download-url"", type=Path, required=True)
+    args = arg_parser.parse_args()
+
+    args.spark_version = args.spark_version or get_latest_spark_version()
+
     spark_dir_name = download_spark(
-        spark_version=spark_version,
-        hadoop_version=os.environ[""HADOOP_VERSION""],
-        scala_version=os.environ[""SCALA_VERSION""],
-        spark_download_url=Path(os.environ[""SPARK_DOWNLOAD_URL""]),
+        spark_version=args.spark_version,
+        hadoop_version=args.hadoop_version,
+        scala_version=args.scala_version,
+        spark_download_url=args.spark_download_url,
     )
     configure_spark(
         spark_dir_name=spark_dir_name, spark_home=Path(os.environ[""SPARK_HOME""])",Yes
Makefile,Makefile,5d68244bb2fd8d4b7dd5552160fe8a46c9ddd7be,afe30f0c9ad88ba58a80ed5d9795adf7b7d2490c,Cleanup some commands in Makefile,"diff --git a/Makefile b/Makefile
index 6e28f762..7965b641 100644
--- a/Makefile
+++ b/Makefile
@@ -2,13 +2,14 @@
 # Distributed under the terms of the Modified BSD License.
 .PHONY: docs help test
 
-# Use bash for inline if-statements in arch_patch target
 SHELL:=bash
 REGISTRY?=quay.io
 OWNER?=jupyter
 
-# Need to list the images in build dependency order
-# All of the images
+# Enable BuildKit for Docker build
+export DOCKER_BUILDKIT:=1
+
+# All the images listed in the build dependency order
 ALL_IMAGES:= \
 	docker-stacks-foundation \
 	base-notebook \
@@ -22,9 +23,6 @@ ALL_IMAGES:= \
 	pyspark-notebook \
 	all-spark-notebook
 
-# Enable BuildKit for Docker build
-export DOCKER_BUILDKIT:=1
-
 
 
 # https://marmelab.com/blog/2016/02/29/auto-documented-makefile.html
@@ -52,13 +50,13 @@ check-outdated-all: $(foreach I, $(ALL_IMAGES), check-outdated/$(I)) ## check al
 
 
 
-cont-clean-all: cont-stop-all cont-rm-all ## clean all containers (stop + rm)
 cont-stop-all: ## stop all containers
 	@echo ""Stopping all containers ...""
 	-docker stop --time 0 $(shell docker ps --all --quiet) 2> /dev/null
 cont-rm-all: ## remove all containers
 	@echo ""Removing all containers ...""
 	-docker rm --force $(shell docker ps --all --quiet) 2> /dev/null
+cont-clean-all: cont-stop-all cont-rm-all ## clean all containers (stop + rm)
 
 
 
@@ -77,18 +75,18 @@ hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all
 
 
 
-img-clean: img-rm-dang img-rm ## clean dangling and jupyter images
 img-list: ## list jupyter images
 	@echo ""Listing $(OWNER) images ...""
 	docker images ""$(OWNER)/*""
 	docker images ""*/$(OWNER)/*""
-img-rm: ## remove jupyter images
-	@echo ""Removing $(OWNER) images ...""
-	-docker rmi --force $(shell docker images --quiet ""$(OWNER)/*"") 2> /dev/null
-	-docker rmi --force $(shell docker images --quiet ""*/$(OWNER)/*"") 2> /dev/null
 img-rm-dang: ## remove dangling images (tagged None)
 	@echo ""Removing dangling images ...""
 	-docker rmi --force $(shell docker images -f ""dangling=true"" --quiet) 2> /dev/null
+img-rm-jupyter: ## remove jupyter images
+	@echo ""Removing $(OWNER) images ...""
+	-docker rmi --force $(shell docker images --quiet ""$(OWNER)/*"") 2> /dev/null
+	-docker rmi --force $(shell docker images --quiet ""*/$(OWNER)/*"") 2> /dev/null
+img-rm: img-rm-dang img-rm-jupyter ## remove dangling and jupyter images","diff --git a/Makefile b/Makefile
index 6e28f762..7965b641 100644
--- a/Makefile
+++ b/Makefile
@@ -2,13 +2,14 @@
 # Distributed under the terms of the Modified BSD License.
 .PHONY: docs help test
 
-# Use bash for inline if-statements in arch_patch target
 SHELL:=bash
 REGISTRY?=quay.io
 OWNER?=jupyter
 
-# Need to list the images in build dependency order
-# All of the images
+# Enable BuildKit for Docker build
+export DOCKER_BUILDKIT:=1
+
+# All the images listed in the build dependency order
 ALL_IMAGES:= \
 	docker-stacks-foundation \
 	base-notebook \
@@ -22,9 +23,6 @@ ALL_IMAGES:= \
 	pyspark-notebook \
 	all-spark-notebook
 
-# Enable BuildKit for Docker build
-export DOCKER_BUILDKIT:=1
-
 
 
 # https://marmelab.com/blog/2016/02/29/auto-documented-makefile.html
@@ -52,13 +50,13 @@ check-outdated-all: $(foreach I, $(ALL_IMAGES), check-outdated/$(I)) ## check al
 
 
 
-cont-clean-all: cont-stop-all cont-rm-all ## clean all containers (stop + rm)
 cont-stop-all: ## stop all containers
 	@echo ""Stopping all containers ...""
 	-docker stop --time 0 $(shell docker ps --all --quiet) 2> /dev/null
 cont-rm-all: ## remove all containers
 	@echo ""Removing all containers ...""
 	-docker rm --force $(shell docker ps --all --quiet) 2> /dev/null
+cont-clean-all: cont-stop-all cont-rm-all ## clean all containers (stop + rm)
 
 
 
@@ -77,18 +75,18 @@ hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all
 
 
 
-img-clean: img-rm-dang img-rm ## clean dangling and jupyter images
 img-list: ## list jupyter images
 	@echo ""Listing $(OWNER) images ...""
 	docker images ""$(OWNER)/*""
 	docker images ""*/$(OWNER)/*""
-img-rm: ## remove jupyter images
-	@echo ""Removing $(OWNER) images ...""
-	-docker rmi --force $(shell docker images --quiet ""$(OWNER)/*"") 2> /dev/null
-	-docker rmi --force $(shell docker images --quiet ""*/$(OWNER)/*"") 2> /dev/null
 img-rm-dang: ## remove dangling images (tagged None)
 	@echo ""Removing dangling images ...""
 	-docker rmi --force $(shell docker images -f ""dangling=true"" --quiet) 2> /dev/null
+img-rm-jupyter: ## remove jupyter images
+	@echo ""Removing $(OWNER) images ...""
+	-docker rmi --force $(shell docker images --quiet ""$(OWNER)/*"") 2> /dev/null
+	-docker rmi --force $(shell docker images --quiet ""*/$(OWNER)/*"") 2> /dev/null
+img-rm: img-rm-dang img-rm-jupyter ## remove dangling and jupyter images",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,aadf012336aa9b3a970c2c73b729bc3bea959083,5d68244bb2fd8d4b7dd5552160fe8a46c9ddd7be,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 14391a79..6ca73edf 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -117,7 +117,7 @@ repos:
 
   # Lint: Python
   - repo: https://github.com/PyCQA/flake8
-    rev: 6.1.0
+    rev: 7.0.0
     hooks:
       - id: flake8","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 14391a79..6ca73edf 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -117,7 +117,7 @@ repos:
 
   # Lint: Python
   - repo: https://github.com/PyCQA/flake8
-    rev: 6.1.0
+    rev: 7.0.0
     hooks:
       - id: flake8",Yes
tests/docker-stacks-foundation/test_python.py,tests/docker-stacks-foundation/test_python_version.py,46d7265781bfad7b82d47c3385582ec261865e36,aadf012336aa9b3a970c2c73b729bc3bea959083,Rename test file test_python -> test_python_version,"diff --git a/tests/docker-stacks-foundation/test_python_version.py b/tests/docker-stacks-foundation/test_python_version.py
new file mode 100644
index 00000000..fe585b72
--- /dev/null
+++ b/tests/docker-stacks-foundation/test_python_version.py
@@ -0,0 +1,24 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import logging
+
+from tests.conftest import TrackedContainer
+
+LOGGER = logging.getLogger(__name__)
+EXPECTED_PYTHON_VERSION = ""3.11""
+
+
+def test_python_version(container: TrackedContainer) -> None:
+    LOGGER.info(
+        f""Checking that python major.minor version is {EXPECTED_PYTHON_VERSION}""
+    )
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        command=[""python"", ""--version""],
+    )
+    assert logs.startswith(""Python "")
+    full_version = logs.split()[1]
+    major_minor_version = full_version[: full_version.rfind(""."")]
+
+    assert major_minor_version == EXPECTED_PYTHON_VERSION","diff --git a/tests/docker-stacks-foundation/test_python_version.py b/tests/docker-stacks-foundation/test_python_version.py
new file mode 100644
index 00000000..fe585b72
--- /dev/null
+++ b/tests/docker-stacks-foundation/test_python_version.py
@@ -0,0 +1,24 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+import logging
+
+from tests.conftest import TrackedContainer
+
+LOGGER = logging.getLogger(__name__)
+EXPECTED_PYTHON_VERSION = ""3.11""
+
+
+def test_python_version(container: TrackedContainer) -> None:
+    LOGGER.info(
+        f""Checking that python major.minor version is {EXPECTED_PYTHON_VERSION}""
+    )
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        command=[""python"", ""--version""],
+    )
+    assert logs.startswith(""Python "")
+    full_version = logs.split()[1]
+    major_minor_version = full_version[: full_version.rfind(""."")]
+
+    assert major_minor_version == EXPECTED_PYTHON_VERSION",Yes
README.md,README.md,8b8d1b7dcf8694db435fa49e0bae4ff5df14a4e3,46d7265781bfad7b82d47c3385582ec261865e36,Fix Docker broken links,"diff --git a/README.md b/README.md
index 79483b93..018bdff9 100644
--- a/README.md
+++ b/README.md
@@ -37,7 +37,7 @@ It then starts a container running a Jupyter Server with the JupyterLab frontend
 docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-15
 ```
 
-You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
+You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
 
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab,
 where:
@@ -61,9 +61,11 @@ The server logs appear in the terminal.
 
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab.
 
-Due to the usage of [the flag `--rm`](https://docs.docker.com/engine/reference/run/#clean-up---rm) Docker automatically cleans up the container and removes the file
-system when the container exits, but any changes made to the `~/work` directory and its files in the container will remain intact on the host.
-[The `-it` flag](https://docs.docker.com/engine/reference/commandline/run/#name) allocates pseudo-TTY.
+Due to the usage of [the `--rm` flag](https://docs.docker.com/engine/reference/commandline/container_run/#rm)
+Docker automatically cleans up the container and removes the file system when the container exits,
+but any changes made to the `~/work` directory and its files in the container will remain intact on the host.
+[The `-i` flag](https://docs.docker.com/engine/reference/commandline/container_run/#interactive) keeps the container's `STDIN` open, and lets you send input to the container through standard input.
+[The `-t` flag](https://docs.docker.com/engine/reference/commandline/container_run/#tty) attaches a pseudo-TTY to the container.
 
 ```{note}
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.","diff --git a/README.md b/README.md
index 79483b93..018bdff9 100644
--- a/README.md
+++ b/README.md
@@ -37,7 +37,7 @@ It then starts a container running a Jupyter Server with the JupyterLab frontend
 docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-15
 ```
 
-You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#expose-incoming-ports) to `-p 8888:8888`.
+You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
 
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab,
 where:
@@ -61,9 +61,11 @@ The server logs appear in the terminal.
 
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab.
 
-Due to the usage of [the flag `--rm`](https://docs.docker.com/engine/reference/run/#clean-up---rm) Docker automatically cleans up the container and removes the file
-system when the container exits, but any changes made to the `~/work` directory and its files in the container will remain intact on the host.
-[The `-it` flag](https://docs.docker.com/engine/reference/commandline/run/#name) allocates pseudo-TTY.
+Due to the usage of [the `--rm` flag](https://docs.docker.com/engine/reference/commandline/container_run/#rm)
+Docker automatically cleans up the container and removes the file system when the container exits,
+but any changes made to the `~/work` directory and its files in the container will remain intact on the host.
+[The `-i` flag](https://docs.docker.com/engine/reference/commandline/container_run/#interactive) keeps the container's `STDIN` open, and lets you send input to the container through standard input.
+[The `-t` flag](https://docs.docker.com/engine/reference/commandline/container_run/#tty) attaches a pseudo-TTY to the container.
 
 ```{note}
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,8d0ec50095ff1a30066d08a06d568c436a6cf5a5,8b8d1b7dcf8694db435fa49e0bae4ff5df14a4e3,Improve wording,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 70483c39..d9497ed2 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -84,7 +84,7 @@ The following sections cover a few of these scenarios and how to fix them.
 
    Docker handles mounting host directories differently from mounting volumes, even though the syntax is essentially the same (i.e. `-v`).
 
-   When you initialize a Docker container using the flag `-v`, the host directories are bind-mounted directly into the container.
+   When you initialize a Docker container using the `-v`flag, the host directories are bind-mounted directly into the container.
    Therefore, the permissions and ownership are copied over and will be **the same** as the ones in your local host
    (including user ids) which may result in permissions errors when trying to access directories or create/modify files inside.","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 70483c39..d9497ed2 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -84,7 +84,7 @@ The following sections cover a few of these scenarios and how to fix them.
 
    Docker handles mounting host directories differently from mounting volumes, even though the syntax is essentially the same (i.e. `-v`).
 
-   When you initialize a Docker container using the flag `-v`, the host directories are bind-mounted directly into the container.
+   When you initialize a Docker container using the `-v`flag, the host directories are bind-mounted directly into the container.
    Therefore, the permissions and ownership are copied over and will be **the same** as the ones in your local host
    (including user ids) which may result in permissions errors when trying to access directories or create/modify files inside.",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,a4ede5de2f5f0dcc241b96f27f890eba25518a74,8d0ec50095ff1a30066d08a06d568c436a6cf5a5,Fix Python version pin (#2085),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index e267f5b9..bac0df7c 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -117,7 +117,8 @@ RUN set -x && \
         'jupyter_core' && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python
-    mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    # https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#preventing-packages-from-updating-pinning
+    mamba list --full-name 'python' | tail -1 | tr -s ' ' | cut -d ' ' -f 1,2 | sed 's/\.[^.]*$/.*/' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index e267f5b9..bac0df7c 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -117,7 +117,8 @@ RUN set -x && \
         'jupyter_core' && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python
-    mamba list python | grep '^python ' | tr -s ' ' | cut -d ' ' -f 1,2 >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    # https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#preventing-packages-from-updating-pinning
+    mamba list --full-name 'python' | tail -1 | tr -s ' ' | cut -d ' ' -f 1,2 | sed 's/\.[^.]*$/.*/' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
tests/docker-stacks-foundation/test_python_version.py,tests/docker-stacks-foundation/test_python_version.py,a4ede5de2f5f0dcc241b96f27f890eba25518a74,8d0ec50095ff1a30066d08a06d568c436a6cf5a5,Fix Python version pin (#2085),"diff --git a/tests/docker-stacks-foundation/test_python_version.py b/tests/docker-stacks-foundation/test_python_version.py
index fe585b72..810bcfc4 100644
--- a/tests/docker-stacks-foundation/test_python_version.py
+++ b/tests/docker-stacks-foundation/test_python_version.py
@@ -22,3 +22,13 @@ def test_python_version(container: TrackedContainer) -> None:
     major_minor_version = full_version[: full_version.rfind(""."")]
 
     assert major_minor_version == EXPECTED_PYTHON_VERSION
+
+
+def test_python_pinned_version(container: TrackedContainer) -> None:
+    LOGGER.info(f""Checking that pinned python version is {EXPECTED_PYTHON_VERSION}.*"")
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        command=[""cat"", ""/opt/conda/conda-meta/pinned""],
+    )
+    assert logs.startswith(f""python {EXPECTED_PYTHON_VERSION}.*"")","diff --git a/tests/docker-stacks-foundation/test_python_version.py b/tests/docker-stacks-foundation/test_python_version.py
index fe585b72..810bcfc4 100644
--- a/tests/docker-stacks-foundation/test_python_version.py
+++ b/tests/docker-stacks-foundation/test_python_version.py
@@ -22,3 +22,13 @@ def test_python_version(container: TrackedContainer) -> None:
     major_minor_version = full_version[: full_version.rfind(""."")]
 
     assert major_minor_version == EXPECTED_PYTHON_VERSION
+
+
+def test_python_pinned_version(container: TrackedContainer) -> None:
+    LOGGER.info(f""Checking that pinned python version is {EXPECTED_PYTHON_VERSION}.*"")
+    logs = container.run_and_wait(
+        timeout=5,
+        tty=True,
+        command=[""cat"", ""/opt/conda/conda-meta/pinned""],
+    )
+    assert logs.startswith(f""python {EXPECTED_PYTHON_VERSION}.*"")",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,b71f4cb5259e0ae8b658065eac90381ad578ec20,a4ede5de2f5f0dcc241b96f27f890eba25518a74,Unify access to env variables (#2086),"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 77d84e04..100ed11c 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -30,7 +30,7 @@ jobs:
 
       - name: Calculate recipes matrix 🛠
         id: set-matrix
-        run: docs/using/recipe_code/generate_matrix.py >> $GITHUB_OUTPUT
+        run: docs/using/recipe_code/generate_matrix.py >> ""${GITHUB_OUTPUT}""
 
   test-recipes:
     runs-on: ${{ matrix.runs-on }}","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 77d84e04..100ed11c 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -30,7 +30,7 @@ jobs:
 
       - name: Calculate recipes matrix 🛠
         id: set-matrix
-        run: docs/using/recipe_code/generate_matrix.py >> $GITHUB_OUTPUT
+        run: docs/using/recipe_code/generate_matrix.py >> ""${GITHUB_OUTPUT}""
 
   test-recipes:
     runs-on: ${{ matrix.runs-on }}",Yes
aarch64-runner/setup.sh,aarch64-runner/setup.sh,b71f4cb5259e0ae8b658065eac90381ad578ec20,a4ede5de2f5f0dcc241b96f27f890eba25518a74,Unify access to env variables (#2086),"diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index 9a84bf71..fb6e05b1 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -3,7 +3,7 @@ set -ex
 
 GITHUB_RUNNER_USER=""runner-user""
 
-if [ ""$EUID"" -ne 0 ]; then
+if [ ""${EUID}"" -ne 0 ]; then
     echo ""Please run as root""
     exit 1
 fi","diff --git a/aarch64-runner/setup.sh b/aarch64-runner/setup.sh
index 9a84bf71..fb6e05b1 100755
--- a/aarch64-runner/setup.sh
+++ b/aarch64-runner/setup.sh
@@ -3,7 +3,7 @@ set -ex
 
 GITHUB_RUNNER_USER=""runner-user""
 
-if [ ""$EUID"" -ne 0 ]; then
+if [ ""${EUID}"" -ne 0 ]; then
     echo ""Please run as root""
     exit 1
 fi",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,b71f4cb5259e0ae8b658065eac90381ad578ec20,a4ede5de2f5f0dcc241b96f27f890eba25518a74,Unify access to env variables (#2086),"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index d0daa901..85564d0a 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -33,7 +33,7 @@ RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclit
 
 # And configure variables
 RUN echo ""ORACLE_HOME=/usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64"" >> ""${HOME}/.bashrc"" && \
-    echo ""PATH=${ORACLE_HOME}/bin:$PATH"" >> ""${HOME}/.bashrc"" && \
+    echo ""PATH=${ORACLE_HOME}/bin:${PATH}"" >> ""${HOME}/.bashrc"" && \
     echo ""LD_LIBRARY_PATH=${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}"" >> ""${HOME}/.bashrc"" && \
     echo ""export ORACLE_HOME"" >> ""${HOME}/.bashrc"" && \
     echo ""export PATH"" >> ""${HOME}/.bashrc"" && \","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index d0daa901..85564d0a 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -33,7 +33,7 @@ RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclit
 
 # And configure variables
 RUN echo ""ORACLE_HOME=/usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64"" >> ""${HOME}/.bashrc"" && \
-    echo ""PATH=${ORACLE_HOME}/bin:$PATH"" >> ""${HOME}/.bashrc"" && \
+    echo ""PATH=${ORACLE_HOME}/bin:${PATH}"" >> ""${HOME}/.bashrc"" && \
     echo ""LD_LIBRARY_PATH=${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}"" >> ""${HOME}/.bashrc"" && \
     echo ""export ORACLE_HOME"" >> ""${HOME}/.bashrc"" && \
     echo ""export PATH"" >> ""${HOME}/.bashrc"" && \",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,b71f4cb5259e0ae8b658065eac90381ad578ec20,a4ede5de2f5f0dcc241b96f27f890eba25518a74,Unify access to env variables (#2086),"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 7d354b88..f2108258 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -133,7 +133,7 @@ if [ ""$(id -u)"" == 0 ]; then
     sed -r ""s#Defaults\s+secure_path\s*=\s*\""?([^\""]+)\""?#Defaults secure_path=\""${CONDA_DIR}/bin:\1\""#"" /etc/sudoers | grep secure_path > /etc/sudoers.d/path
 
     # Optionally grant passwordless sudo rights for the desired user
-    if [[ ""$GRANT_SUDO"" == ""1"" || ""$GRANT_SUDO"" == ""yes"" ]]; then
+    if [[ ""${GRANT_SUDO}"" == ""1"" || ""${GRANT_SUDO}"" == ""yes"" ]]; then
         _log ""Granting ${NB_USER} passwordless sudo rights!""
         echo ""${NB_USER} ALL=(ALL) NOPASSWD:ALL"" >> /etc/sudoers.d/added-by-start-script
     fi","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 7d354b88..f2108258 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -133,7 +133,7 @@ if [ ""$(id -u)"" == 0 ]; then
     sed -r ""s#Defaults\s+secure_path\s*=\s*\""?([^\""]+)\""?#Defaults secure_path=\""${CONDA_DIR}/bin:\1\""#"" /etc/sudoers | grep secure_path > /etc/sudoers.d/path
 
     # Optionally grant passwordless sudo rights for the desired user
-    if [[ ""$GRANT_SUDO"" == ""1"" || ""$GRANT_SUDO"" == ""yes"" ]]; then
+    if [[ ""${GRANT_SUDO}"" == ""1"" || ""${GRANT_SUDO}"" == ""yes"" ]]; then
         _log ""Granting ${NB_USER} passwordless sudo rights!""
         echo ""${NB_USER} ALL=(ALL) NOPASSWD:ALL"" >> /etc/sudoers.d/added-by-start-script
     fi",Yes
tests/docker-stacks-foundation/test_user_options.py,tests/docker-stacks-foundation/test_user_options.py,b71f4cb5259e0ae8b658065eac90381ad578ec20,a4ede5de2f5f0dcc241b96f27f890eba25518a74,Unify access to env variables (#2086),"diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index cc8a1b83..7463539b 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -262,7 +262,7 @@ def test_jupyter_env_vars_to_unset(
             ""start.sh"",
             ""bash"",
             ""-c"",
-            ""echo I like $FRUIT and ${SECRET_FRUIT:-stuff}, and love ${SECRET_ANIMAL:-to keep secrets}!"",
+            ""echo I like ${FRUIT} and ${SECRET_FRUIT:-stuff}, and love ${SECRET_ANIMAL:-to keep secrets}!"",
         ],
         **root_args,  # type: ignore
     )","diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index cc8a1b83..7463539b 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -262,7 +262,7 @@ def test_jupyter_env_vars_to_unset(
             ""start.sh"",
             ""bash"",
             ""-c"",
-            ""echo I like $FRUIT and ${SECRET_FRUIT:-stuff}, and love ${SECRET_ANIMAL:-to keep secrets}!"",
+            ""echo I like ${FRUIT} and ${SECRET_FRUIT:-stuff}, and love ${SECRET_ANIMAL:-to keep secrets}!"",
         ],
         **root_args,  # type: ignore
     )",Yes
docs/using/common.md,docs/using/common.md,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/docs/using/common.md b/docs/using/common.md
index 34f09e6a..b3b314c9 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -225,21 +225,17 @@ docker run -it --rm \
 
 ### `start.sh`
 
-The `start-notebook.py` script inherits most of its option handling capability from a more generic `start.sh` script.
-The `start.sh` script supports all the features described above but allows you to specify an arbitrary command to execute.
+Most of the configuration options in the `start-notebook.py` script are handled by an internal `start.sh` script that automatically runs before the command provided to the container
+(it's set as the container entrypoint).
+This allows you to specify an arbitrary command that takes advantage of all these features.
 For example, to run the text-based `ipython` console in a container, do the following:
 
 ```bash
-docker run -it --rm quay.io/jupyter/base-notebook start.sh ipython
+docker run -it --rm quay.io/jupyter/base-notebook ipython
 ```
 
 This script is handy when you derive a new Dockerfile from this image and install additional Jupyter applications with subcommands like `jupyter console`, `jupyter kernelgateway`, etc.
 
-### Others
-
-You can bypass the provided scripts and specify an arbitrary start command.
-If you do, keep in mind that features, supported by the `start.sh` script and its kin, will not function (e.g., `GRANT_SUDO`).
-
 ## Conda Environments
 
 The default Python 3.x [Conda environment](https://conda.io/projects/conda/en/latest/user-guide/concepts/environments.html) resides in `/opt/conda`.","diff --git a/docs/using/common.md b/docs/using/common.md
index 34f09e6a..b3b314c9 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -225,21 +225,17 @@ docker run -it --rm \
 
 ### `start.sh`
 
-The `start-notebook.py` script inherits most of its option handling capability from a more generic `start.sh` script.
-The `start.sh` script supports all the features described above but allows you to specify an arbitrary command to execute.
+Most of the configuration options in the `start-notebook.py` script are handled by an internal `start.sh` script that automatically runs before the command provided to the container
+(it's set as the container entrypoint).
+This allows you to specify an arbitrary command that takes advantage of all these features.
 For example, to run the text-based `ipython` console in a container, do the following:
 
 ```bash
-docker run -it --rm quay.io/jupyter/base-notebook start.sh ipython
+docker run -it --rm quay.io/jupyter/base-notebook ipython
 ```
 
 This script is handy when you derive a new Dockerfile from this image and install additional Jupyter applications with subcommands like `jupyter console`, `jupyter kernelgateway`, etc.
 
-### Others
-
-You can bypass the provided scripts and specify an arbitrary start command.
-If you do, keep in mind that features, supported by the `start.sh` script and its kin, will not function (e.g., `GRANT_SUDO`).
-
 ## Conda Environments
 
 The default Python 3.x [Conda environment](https://conda.io/projects/conda/en/latest/user-guide/concepts/environments.html) resides in `/opt/conda`.",Yes
docs/using/selecting.md,docs/using/selecting.md,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 89e983e1..d44f4562 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -34,8 +34,7 @@ It contains:
   - [mamba](https://github.com/mamba-org/mamba): ""reimplementation of the conda package manager in C++"". We use this package manager by default when installing packages.
 - Unprivileged user `jovyan` (`uid=1000`, configurable, [see options in the common features section](./common.md) of this documentation) in group `users` (`gid=100`)
   with ownership over the `/home/jovyan` and `/opt/conda` paths
-- `tini` as the container entry point
-- A `start.sh` script as the default command - useful for running alternative commands in the container as applications are added (e.g. `ipython`, `jupyter kernelgateway`, `jupyter lab`)
+- `tini` and a `start.sh` script as the container entry point - useful for running alternative commands in the container as applications are added (e.g. `ipython`, `jupyter kernelgateway`, `jupyter lab`)
 - A `run-hooks.sh` script, which can source/run files in a given directory
 - Options for a passwordless sudo
 - Common system libraries like `bzip2`, `ca-certificates`, `locales`","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 89e983e1..d44f4562 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -34,8 +34,7 @@ It contains:
   - [mamba](https://github.com/mamba-org/mamba): ""reimplementation of the conda package manager in C++"". We use this package manager by default when installing packages.
 - Unprivileged user `jovyan` (`uid=1000`, configurable, [see options in the common features section](./common.md) of this documentation) in group `users` (`gid=100`)
   with ownership over the `/home/jovyan` and `/opt/conda` paths
-- `tini` as the container entry point
-- A `start.sh` script as the default command - useful for running alternative commands in the container as applications are added (e.g. `ipython`, `jupyter kernelgateway`, `jupyter lab`)
+- `tini` and a `start.sh` script as the container entry point - useful for running alternative commands in the container as applications are added (e.g. `ipython`, `jupyter kernelgateway`, `jupyter lab`)
 - A `run-hooks.sh` script, which can source/run files in a given directory
 - Options for a passwordless sudo
 - Common system libraries like `bzip2`, `ca-certificates`, `locales`",Yes
images/base-notebook/start-notebook.py,images/base-notebook/start-notebook.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
index c9a899be..b46217e2 100755
--- a/images/base-notebook/start-notebook.py
+++ b/images/base-notebook/start-notebook.py
@@ -14,8 +14,8 @@ if ""JUPYTERHUB_API_TOKEN"" in os.environ:
     os.execvp(command[0], command)
 
 
-# Wrap everything in start.sh, no matter what
-command = [""/usr/local/bin/start.sh""]
+# Entrypoint is start.sh
+command = []
 
 # If we want to survive restarts, tell that to start.sh
 if os.environ.get(""RESTARTABLE"") == ""yes"":
@@ -40,4 +40,5 @@ if ""NOTEBOOK_ARGS"" in os.environ:
 command += sys.argv[1:]
 
 # Execute the command!
+print(""Executing: "" + "" "".join(command))
 os.execvp(command[0], command)","diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
index c9a899be..b46217e2 100755
--- a/images/base-notebook/start-notebook.py
+++ b/images/base-notebook/start-notebook.py
@@ -14,8 +14,8 @@ if ""JUPYTERHUB_API_TOKEN"" in os.environ:
     os.execvp(command[0], command)
 
 
-# Wrap everything in start.sh, no matter what
-command = [""/usr/local/bin/start.sh""]
+# Entrypoint is start.sh
+command = []
 
 # If we want to survive restarts, tell that to start.sh
 if os.environ.get(""RESTARTABLE"") == ""yes"":
@@ -40,4 +40,5 @@ if ""NOTEBOOK_ARGS"" in os.environ:
 command += sys.argv[1:]
 
 # Execute the command!
+print(""Executing: "" + "" "".join(command))
 os.execvp(command[0], command)",Yes
images/base-notebook/start-singleuser.py,images/base-notebook/start-singleuser.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/images/base-notebook/start-singleuser.py b/images/base-notebook/start-singleuser.py
index 2dcf6c09..8fe2ee02 100755
--- a/images/base-notebook/start-singleuser.py
+++ b/images/base-notebook/start-singleuser.py
@@ -5,7 +5,8 @@ import os
 import shlex
 import sys
 
-command = [""/usr/local/bin/start.sh"", ""jupyterhub-singleuser""]
+# Entrypoint is start.sh
+command = [""jupyterhub-singleuser""]
 
 # set default ip to 0.0.0.0
 if ""--ip="" not in os.environ.get(""NOTEBOOK_ARGS"", """"):
@@ -20,4 +21,5 @@ if ""NOTEBOOK_ARGS"" in os.environ:
 command += sys.argv[1:]
 
 # Execute the command!
+print(""Executing: "" + "" "".join(command))
 os.execvp(command[0], command)","diff --git a/images/base-notebook/start-singleuser.py b/images/base-notebook/start-singleuser.py
index 2dcf6c09..8fe2ee02 100755
--- a/images/base-notebook/start-singleuser.py
+++ b/images/base-notebook/start-singleuser.py
@@ -5,7 +5,8 @@ import os
 import shlex
 import sys
 
-command = [""/usr/local/bin/start.sh"", ""jupyterhub-singleuser""]
+# Entrypoint is start.sh
+command = [""jupyterhub-singleuser""]
 
 # set default ip to 0.0.0.0
 if ""--ip="" not in os.environ.get(""NOTEBOOK_ARGS"", """"):
@@ -20,4 +21,5 @@ if ""NOTEBOOK_ARGS"" in os.environ:
 command += sys.argv[1:]
 
 # Execute the command!
+print(""Executing: "" + "" "".join(command))
 os.execvp(command[0], command)",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index bac0df7c..0f21cac1 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -124,8 +124,7 @@ RUN set -x && \
     fix-permissions ""/home/${NB_USER}""
 
 # Configure container startup
-ENTRYPOINT [""tini"", ""-g"", ""--""]
-CMD [""start.sh""]
+ENTRYPOINT [""tini"", ""-g"", ""--"", ""start.sh""]
 
 # Copy local files as late as possible to avoid cache busting
 COPY run-hooks.sh start.sh /usr/local/bin/","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index bac0df7c..0f21cac1 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -124,8 +124,7 @@ RUN set -x && \
     fix-permissions ""/home/${NB_USER}""
 
 # Configure container startup
-ENTRYPOINT [""tini"", ""-g"", ""--""]
-CMD [""start.sh""]
+ENTRYPOINT [""tini"", ""-g"", ""--"", ""start.sh""]
 
 # Copy local files as late as possible to avoid cache busting
 COPY run-hooks.sh start.sh /usr/local/bin/",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index f2108258..33d12d80 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -34,6 +34,17 @@ else
     cmd=( ""$@"" )
 fi
 
+# Backwards compatibility: `start.sh` is executed by default in ENTRYPOINT
+# so it should no longer be specified in CMD
+if [ ""${_START_SH_EXECUTED}"" = ""1"" ]; then
+    _log ""WARNING: start.sh is the default ENTRYPOINT, do not include it in CMD""
+    _log ""Executing the command:"" ""${cmd[@]}""
+    exec ""${cmd[@]}""
+else
+    export _START_SH_EXECUTED=1
+fi
+
+
 # NOTE: This hook will run as the user the container was started with!
 # shellcheck disable=SC1091
 source /usr/local/bin/run-hooks.sh /usr/local/bin/start-notebook.d","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index f2108258..33d12d80 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -34,6 +34,17 @@ else
     cmd=( ""$@"" )
 fi
 
+# Backwards compatibility: `start.sh` is executed by default in ENTRYPOINT
+# so it should no longer be specified in CMD
+if [ ""${_START_SH_EXECUTED}"" = ""1"" ]; then
+    _log ""WARNING: start.sh is the default ENTRYPOINT, do not include it in CMD""
+    _log ""Executing the command:"" ""${cmd[@]}""
+    exec ""${cmd[@]}""
+else
+    export _START_SH_EXECUTED=1
+fi
+
+
 # NOTE: This hook will run as the user the container was started with!
 # shellcheck disable=SC1091
 source /usr/local/bin/run-hooks.sh /usr/local/bin/start-notebook.d",Yes
tests/R_mimetype_check.py,tests/R_mimetype_check.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/R_mimetype_check.py b/tests/R_mimetype_check.py
index 71a983d3..ba90fa51 100644
--- a/tests/R_mimetype_check.py
+++ b/tests/R_mimetype_check.py
@@ -11,10 +11,14 @@ def check_r_mimetypes(container: TrackedContainer) -> None:
     """"""Check if Rscript command can be executed""""""
     LOGGER.info(""Test that R command can be executed ..."")
     R_MIMETYPES_CHECK_CMD = 'if (length(getOption(""jupyter.plot_mimetypes"")) != 5) {stop(""missing jupyter.plot_mimetypes"")}'
+    command = [""Rscript"", ""-e"", R_MIMETYPES_CHECK_CMD]
     logs = container.run_and_wait(
         timeout=10,
         tty=True,
-        command=[""Rscript"", ""-e"", R_MIMETYPES_CHECK_CMD],
+        command=command,
     )
     LOGGER.debug(f""{logs=}"")
-    assert len(logs) == 0, f""Command {R_MIMETYPES_CHECK_CMD=} failed""
+    # If there is any output after this it means there was an error
+    assert logs.splitlines()[-1] == ""Executing the command: "" + "" "".join(
+        command
+    ), f""Command {R_MIMETYPES_CHECK_CMD=} failed""","diff --git a/tests/R_mimetype_check.py b/tests/R_mimetype_check.py
index 71a983d3..ba90fa51 100644
--- a/tests/R_mimetype_check.py
+++ b/tests/R_mimetype_check.py
@@ -11,10 +11,14 @@ def check_r_mimetypes(container: TrackedContainer) -> None:
     """"""Check if Rscript command can be executed""""""
     LOGGER.info(""Test that R command can be executed ..."")
     R_MIMETYPES_CHECK_CMD = 'if (length(getOption(""jupyter.plot_mimetypes"")) != 5) {stop(""missing jupyter.plot_mimetypes"")}'
+    command = [""Rscript"", ""-e"", R_MIMETYPES_CHECK_CMD]
     logs = container.run_and_wait(
         timeout=10,
         tty=True,
-        command=[""Rscript"", ""-e"", R_MIMETYPES_CHECK_CMD],
+        command=command,
     )
     LOGGER.debug(f""{logs=}"")
-    assert len(logs) == 0, f""Command {R_MIMETYPES_CHECK_CMD=} failed""
+    # If there is any output after this it means there was an error
+    assert logs.splitlines()[-1] == ""Executing the command: "" + "" "".join(
+        command
+    ), f""Command {R_MIMETYPES_CHECK_CMD=} failed""",Yes
tests/all-spark-notebook/test_spark_notebooks.py,tests/all-spark-notebook/test_spark_notebooks.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index 4b2559e7..7e54e5b0 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -33,7 +33,7 @@ def test_nbconvert(container: TrackedContainer, test_file: str) -> None:
         timeout=60,
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", command],
     )
 
     expected_file = f""{output_dir}/{test_file}.md""","diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index 4b2559e7..7e54e5b0 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -33,7 +33,7 @@ def test_nbconvert(container: TrackedContainer, test_file: str) -> None:
         timeout=60,
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", command],
     )
 
     expected_file = f""{output_dir}/{test_file}.md""",Yes
tests/base-notebook/test_container_options.py,tests/base-notebook/test_container_options.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 3232239b..b330c1ec 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -35,7 +35,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[f""NB_USER={nb_user}"", ""CHOWN_HOME=yes""],
-        command=[""start.sh"", ""bash"", ""-c"", ""sleep infinity""],
+        command=[""bash"", ""-c"", ""sleep infinity""],
     )
 
     # Give the chown time to complete.","diff --git a/tests/base-notebook/test_container_options.py b/tests/base-notebook/test_container_options.py
index 3232239b..b330c1ec 100644
--- a/tests/base-notebook/test_container_options.py
+++ b/tests/base-notebook/test_container_options.py
@@ -35,7 +35,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[f""NB_USER={nb_user}"", ""CHOWN_HOME=yes""],
-        command=[""start.sh"", ""bash"", ""-c"", ""sleep infinity""],
+        command=[""bash"", ""-c"", ""sleep infinity""],
     )
 
     # Give the chown time to complete.",Yes
tests/base-notebook/test_pandoc.py,tests/base-notebook/test_pandoc.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/base-notebook/test_pandoc.py b/tests/base-notebook/test_pandoc.py
index f5cce325..3c828a3f 100644
--- a/tests/base-notebook/test_pandoc.py
+++ b/tests/base-notebook/test_pandoc.py
@@ -12,6 +12,6 @@ def test_pandoc(container: TrackedContainer) -> None:
     logs = container.run_and_wait(
         timeout=10,
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", 'echo ""**BOLD**"" | pandoc'],
+        command=[""bash"", ""-c"", 'echo ""**BOLD**"" | pandoc'],
     )
     assert ""<p><strong>BOLD</strong></p>"" in logs","diff --git a/tests/base-notebook/test_pandoc.py b/tests/base-notebook/test_pandoc.py
index f5cce325..3c828a3f 100644
--- a/tests/base-notebook/test_pandoc.py
+++ b/tests/base-notebook/test_pandoc.py
@@ -12,6 +12,6 @@ def test_pandoc(container: TrackedContainer) -> None:
     logs = container.run_and_wait(
         timeout=10,
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", 'echo ""**BOLD**"" | pandoc'],
+        command=[""bash"", ""-c"", 'echo ""**BOLD**"" | pandoc'],
     )
     assert ""<p><strong>BOLD</strong></p>"" in logs",Yes
tests/base-notebook/test_start_container.py,tests/base-notebook/test_start_container.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index 3fbf08aa..729e7cac 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -53,7 +53,7 @@ def test_start_notebook(
     LOGGER.debug(logs)
     # checking that the expected command is launched
     assert (
-        f""Executing the command: {expected_command}"" in logs
+        f""Executing: {expected_command}"" in logs
     ), f""Not the expected command ({expected_command}) was launched""
     # checking errors and warnings in logs
     assert ""ERROR"" not in logs, ""ERROR(s) found in logs""
@@ -76,10 +76,7 @@ def test_tini_entrypoint(
     https://superuser.com/questions/632979/if-i-know-the-pid-number-of-a-process-how-can-i-get-its-name
     """"""
     LOGGER.info(f""Test that {command} is launched as PID {pid} ..."")
-    running_container = container.run_detached(
-        tty=True,
-        command=[""start.sh""],
-    )
+    running_container = container.run_detached(tty=True)
     # Select the PID 1 and get the corresponding command
     cmd = running_container.exec_run(f""ps -p {pid} -o comm="")
     output = cmd.output.decode(""utf-8"").strip(""\n"")","diff --git a/tests/base-notebook/test_start_container.py b/tests/base-notebook/test_start_container.py
index 3fbf08aa..729e7cac 100644
--- a/tests/base-notebook/test_start_container.py
+++ b/tests/base-notebook/test_start_container.py
@@ -53,7 +53,7 @@ def test_start_notebook(
     LOGGER.debug(logs)
     # checking that the expected command is launched
     assert (
-        f""Executing the command: {expected_command}"" in logs
+        f""Executing: {expected_command}"" in logs
     ), f""Not the expected command ({expected_command}) was launched""
     # checking errors and warnings in logs
     assert ""ERROR"" not in logs, ""ERROR(s) found in logs""
@@ -76,10 +76,7 @@ def test_tini_entrypoint(
     https://superuser.com/questions/632979/if-i-know-the-pid-number-of-a-process-how-can-i-get-its-name
     """"""
     LOGGER.info(f""Test that {command} is launched as PID {pid} ..."")
-    running_container = container.run_detached(
-        tty=True,
-        command=[""start.sh""],
-    )
+    running_container = container.run_detached(tty=True)
     # Select the PID 1 and get the corresponding command
     cmd = running_container.exec_run(f""ps -p {pid} -o comm="")
     output = cmd.output.decode(""utf-8"").strip(""\n"")",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 4fee6428..a1f7f755 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -21,17 +21,20 @@ Use `package_helper.installed_packages()` instead of `package_helper.requested_p
 
 Example:
 
-    $ make test/base-notebook
+    $ make test/docker-stacks-foundation
 
     # [...]
-    # tests/base-notebook/test_packages.py::test_python_packages
-    # ---------------------------------------------------------------------------------------------- live log setup ----------------------------------------------------------------------------------------------
-    # 2023-11-04 23:59:01 [    INFO] Starting container quay.io/jupyter/base-notebook ... (package_helper.py:55)
-    # 2023-11-04 23:59:01 [    INFO] Running quay.io/jupyter/base-notebook with args {'detach': True, 'tty': True, 'command': ['start.sh', 'bash', '-c', 'sleep infinity']} ... (conftest.py:99)
-    # 2023-11-04 23:59:01 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
-    # ---------------------------------------------------------------------------------------------- live log call -----------------------------------------------------------------------------------------------
-    # 2023-11-04 23:59:02 [    INFO] Testing the import of packages ... (test_packages.py:152)
-    # 2023-11-04 23:59:02 [    INFO] Trying to import mamba (test_packages.py:154)
+    # tests/docker-stacks-foundation/test_packages.py::test_python_packages
+    # -------------------------------- live log setup --------------------------------
+    # 2024-01-21 17:46:43 [    INFO] Starting container quay.io/jupyter/docker-stacks-foundation ... (package_helper.py:55)
+    # 2024-01-21 17:46:43 [    INFO] Running quay.io/jupyter/docker-stacks-foundation with args {'detach': True, 'tty': True, 'command': ['bash', '-c', 'sleep infinity']} ... (conftest.py:99)
+    # 2024-01-21 17:46:44 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
+    # -------------------------------- live log call ---------------------------------
+    # 2024-01-21 17:46:44 [    INFO] Testing the import of packages ... (test_packages.py:151)
+    # 2024-01-21 17:46:44 [    INFO] Trying to import mamba (test_packages.py:153)
+    # 2024-01-21 17:46:44 [    INFO] Trying to import jupyter_core (test_packages.py:153)
+    PASSED                                                                   [ 17%]
+    # ------------------------------ live log teardown -------------------------------
     # [...]
 
 """"""","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 4fee6428..a1f7f755 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -21,17 +21,20 @@ Use `package_helper.installed_packages()` instead of `package_helper.requested_p
 
 Example:
 
-    $ make test/base-notebook
+    $ make test/docker-stacks-foundation
 
     # [...]
-    # tests/base-notebook/test_packages.py::test_python_packages
-    # ---------------------------------------------------------------------------------------------- live log setup ----------------------------------------------------------------------------------------------
-    # 2023-11-04 23:59:01 [    INFO] Starting container quay.io/jupyter/base-notebook ... (package_helper.py:55)
-    # 2023-11-04 23:59:01 [    INFO] Running quay.io/jupyter/base-notebook with args {'detach': True, 'tty': True, 'command': ['start.sh', 'bash', '-c', 'sleep infinity']} ... (conftest.py:99)
-    # 2023-11-04 23:59:01 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
-    # ---------------------------------------------------------------------------------------------- live log call -----------------------------------------------------------------------------------------------
-    # 2023-11-04 23:59:02 [    INFO] Testing the import of packages ... (test_packages.py:152)
-    # 2023-11-04 23:59:02 [    INFO] Trying to import mamba (test_packages.py:154)
+    # tests/docker-stacks-foundation/test_packages.py::test_python_packages
+    # -------------------------------- live log setup --------------------------------
+    # 2024-01-21 17:46:43 [    INFO] Starting container quay.io/jupyter/docker-stacks-foundation ... (package_helper.py:55)
+    # 2024-01-21 17:46:43 [    INFO] Running quay.io/jupyter/docker-stacks-foundation with args {'detach': True, 'tty': True, 'command': ['bash', '-c', 'sleep infinity']} ... (conftest.py:99)
+    # 2024-01-21 17:46:44 [    INFO] Grabbing the list of manually requested packages ... (package_helper.py:83)
+    # -------------------------------- live log call ---------------------------------
+    # 2024-01-21 17:46:44 [    INFO] Testing the import of packages ... (test_packages.py:151)
+    # 2024-01-21 17:46:44 [    INFO] Trying to import mamba (test_packages.py:153)
+    # 2024-01-21 17:46:44 [    INFO] Trying to import jupyter_core (test_packages.py:153)
+    PASSED                                                                   [ 17%]
+    # ------------------------------ live log teardown -------------------------------
     # [...]
 
 """"""",Yes
tests/docker-stacks-foundation/test_python_version.py,tests/docker-stacks-foundation/test_python_version.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/docker-stacks-foundation/test_python_version.py b/tests/docker-stacks-foundation/test_python_version.py
index 810bcfc4..559853ab 100644
--- a/tests/docker-stacks-foundation/test_python_version.py
+++ b/tests/docker-stacks-foundation/test_python_version.py
@@ -17,8 +17,8 @@ def test_python_version(container: TrackedContainer) -> None:
         tty=True,
         command=[""python"", ""--version""],
     )
-    assert logs.startswith(""Python "")
-    full_version = logs.split()[1]
+    python = next(line for line in logs.splitlines() if line.startswith(""Python ""))
+    full_version = python.split()[1]
     major_minor_version = full_version[: full_version.rfind(""."")]
 
     assert major_minor_version == EXPECTED_PYTHON_VERSION
@@ -31,4 +31,4 @@ def test_python_pinned_version(container: TrackedContainer) -> None:
         tty=True,
         command=[""cat"", ""/opt/conda/conda-meta/pinned""],
     )
-    assert logs.startswith(f""python {EXPECTED_PYTHON_VERSION}.*"")
+    assert f""python {EXPECTED_PYTHON_VERSION}.*"" in logs","diff --git a/tests/docker-stacks-foundation/test_python_version.py b/tests/docker-stacks-foundation/test_python_version.py
index 810bcfc4..559853ab 100644
--- a/tests/docker-stacks-foundation/test_python_version.py
+++ b/tests/docker-stacks-foundation/test_python_version.py
@@ -17,8 +17,8 @@ def test_python_version(container: TrackedContainer) -> None:
         tty=True,
         command=[""python"", ""--version""],
     )
-    assert logs.startswith(""Python "")
-    full_version = logs.split()[1]
+    python = next(line for line in logs.splitlines() if line.startswith(""Python ""))
+    full_version = python.split()[1]
     major_minor_version = full_version[: full_version.rfind(""."")]
 
     assert major_minor_version == EXPECTED_PYTHON_VERSION
@@ -31,4 +31,4 @@ def test_python_pinned_version(container: TrackedContainer) -> None:
         tty=True,
         command=[""cat"", ""/opt/conda/conda-meta/pinned""],
     )
-    assert logs.startswith(f""python {EXPECTED_PYTHON_VERSION}.*"")
+    assert f""python {EXPECTED_PYTHON_VERSION}.*"" in logs",Yes
tests/docker-stacks-foundation/test_units.py,tests/docker-stacks-foundation/test_units.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/docker-stacks-foundation/test_units.py b/tests/docker-stacks-foundation/test_units.py
index 84844498..cfdbc83d 100644
--- a/tests/docker-stacks-foundation/test_units.py
+++ b/tests/docker-stacks-foundation/test_units.py
@@ -34,5 +34,5 @@ def test_units(container: TrackedContainer) -> None:
                 timeout=30,
                 volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
                 tty=True,
-                command=[""start.sh"", ""python"", f""{cont_data_dir}/{test_file_name}""],
+                command=[""python"", f""{cont_data_dir}/{test_file_name}""],
             )","diff --git a/tests/docker-stacks-foundation/test_units.py b/tests/docker-stacks-foundation/test_units.py
index 84844498..cfdbc83d 100644
--- a/tests/docker-stacks-foundation/test_units.py
+++ b/tests/docker-stacks-foundation/test_units.py
@@ -34,5 +34,5 @@ def test_units(container: TrackedContainer) -> None:
                 timeout=30,
                 volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
                 tty=True,
-                command=[""start.sh"", ""python"", f""{cont_data_dir}/{test_file_name}""],
+                command=[""python"", f""{cont_data_dir}/{test_file_name}""],
             )",Yes
tests/docker-stacks-foundation/test_user_options.py,tests/docker-stacks-foundation/test_user_options.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index 7463539b..fb2b4625 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -18,7 +18,7 @@ def test_uid_change(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[""NB_UID=1010""],
-        command=[""start.sh"", ""bash"", ""-c"", ""id && touch /opt/conda/test-file""],
+        command=[""bash"", ""-c"", ""id && touch /opt/conda/test-file""],
     )
     assert ""uid=1010(jovyan)"" in logs
 
@@ -30,7 +30,7 @@ def test_gid_change(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[""NB_GID=110""],
-        command=[""start.sh"", ""id""],
+        command=[""id""],
     )
     assert ""gid=110(jovyan)"" in logs
     assert ""groups=110(jovyan),100(users)"" in logs
@@ -43,7 +43,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[f""NB_USER={nb_user}"", ""CHOWN_HOME=yes""],
-        command=[""start.sh"", ""bash"", ""-c"", ""sleep infinity""],
+        command=[""bash"", ""-c"", ""sleep infinity""],
     )
 
     # Give the chown time to complete.
@@ -99,7 +99,6 @@ def test_chown_extra(container: TrackedContainer) -> None:
             ""CHOWN_EXTRA_OPTS=-R"",
         ],
         command=[
-            ""start.sh"",
             ""bash"",
             ""-c"",
             ""stat -c '%n:%u:%g' /home/jovyan/.bashrc /opt/conda/bin/jupyter"",
@@ -123,7 +122,7 @@ def test_chown_home(container: TrackedContainer) -> None:
             ""NB_UID=1010"",
             ""NB_GID=101"",
         ],
-        command=[""start.sh"", ""bash"", ""-c"", ""stat -c '%n:%u:%g' /home/kitten/.bashrc""],
+        command=[""bash"", ""-c"", ""stat -c '%n:%u:%g' /home/kitten/.bashrc""],
     )
     assert ""/home/kitten/.bashrc:1010:101"" in logs
 
@@ -135,7 +134,7 @@ def test_sudo(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[""GRANT_SUDO=yes""],
-        command=[""start.sh"", ""sudo"", ""id""],
+        command=[""sudo"", ""id""],
     )
     assert ""uid=0(root)"" in logs
 
@@ -147,7 +146,7 @@ def test_sudo_path(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[""GRANT_SUDO=yes""],
-        command=[""start.sh"", ""sudo"", ""which"", ""jupyter""],
+        command=[""sudo"", ""which"", ""jupyter""],
     )
     assert logs.rstrip().endswith(""/opt/conda/bin/jupyter"")
 
@@ -158,7 +157,7 @@ def test_sudo_path_without_grant(container: TrackedContainer) -> None:
         timeout=10,
         tty=True,
         user=""root"",
-        command=[""start.sh"", ""which"", ""jupyter""],
+        command=[""which"", ""jupyter""],
     )
     assert logs.rstrip().endswith(""/opt/conda/bin/jupyter"")
 
@@ -173,7 +172,7 @@ def test_group_add(container: TrackedContainer) -> None:
         no_warnings=False,
         user=""1010:1010"",
         group_add=[""users""],  # Ensures write access to /home/jovyan
-        command=[""start.sh"", ""id""],
+        command=[""id""],
     )
     warnings = TrackedContainer.get_warnings(logs)
     assert len(warnings) == 1
@@ -191,7 +190,7 @@ def test_set_uid(container: TrackedContainer) -> None:
         timeout=5,
         no_warnings=False,
         user=""1010"",
-        command=[""start.sh"", ""id""],
+        command=[""id""],
     )
     assert ""uid=1010(jovyan) gid=0(root)"" in logs
     warnings = TrackedContainer.get_warnings(logs)
@@ -207,7 +206,7 @@ def test_set_uid_and_nb_user(container: TrackedContainer) -> None:
         user=""1010"",
         environment=[""NB_USER=kitten""],
         group_add=[""users""],  # Ensures write access to /home/jovyan
-        command=[""start.sh"", ""id""],
+        command=[""id""],
     )
     assert ""uid=1010(kitten) gid=0(root)"" in logs
     warnings = TrackedContainer.get_warnings(logs)
@@ -236,7 +235,7 @@ def test_container_not_delete_bind_mount(
             ""CHOWN_HOME=yes"",
         ],
         volumes={d: {""bind"": ""/home/jovyan/data"", ""mode"": ""rw""}},
-        command=[""start.sh"", ""ls""],
+        command=[""ls""],
     )
     assert p.read_text() == ""some-content""
     assert len(list(tmp_path.iterdir())) == 1
@@ -259,7 +258,6 @@ def test_jupyter_env_vars_to_unset(
             ""SECRET_FRUIT=mango"",
         ],
         command=[
-            ""start.sh"",
             ""bash"",
             ""-c"",
             ""echo I like ${FRUIT} and ${SECRET_FRUIT:-stuff}, and love ${SECRET_ANIMAL:-to keep secrets}!"",
@@ -284,7 +282,26 @@ def test_secure_path(container: TrackedContainer, tmp_path: pathlib.Path) -> Non
         tty=True,
         user=""root"",
         volumes={p: {""bind"": ""/usr/bin/python"", ""mode"": ""ro""}},
-        command=[""start.sh"", ""python"", ""--version""],
+        command=[""python"", ""--version""],
     )
     assert ""Wrong python"" not in logs
     assert ""Python"" in logs
+
+
+def test_startsh_multiple_exec(container: TrackedContainer) -> None:
+    """"""If start.sh is executed multiple times check that configuration only occurs once.""""""
+    logs = container.run_and_wait(
+        timeout=10,
+        no_warnings=False,
+        tty=True,
+        user=""root"",
+        environment=[""GRANT_SUDO=yes""],
+        command=[""start.sh"", ""sudo"", ""id""],
+    )
+    assert ""uid=0(root)"" in logs
+    warnings = TrackedContainer.get_warnings(logs)
+    assert len(warnings) == 1
+    assert (
+        ""WARNING: start.sh is the default ENTRYPOINT, do not include it in CMD""
+        in warnings[0]
+    )","diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index 7463539b..fb2b4625 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -18,7 +18,7 @@ def test_uid_change(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[""NB_UID=1010""],
-        command=[""start.sh"", ""bash"", ""-c"", ""id && touch /opt/conda/test-file""],
+        command=[""bash"", ""-c"", ""id && touch /opt/conda/test-file""],
     )
     assert ""uid=1010(jovyan)"" in logs
 
@@ -30,7 +30,7 @@ def test_gid_change(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[""NB_GID=110""],
-        command=[""start.sh"", ""id""],
+        command=[""id""],
     )
     assert ""gid=110(jovyan)"" in logs
     assert ""groups=110(jovyan),100(users)"" in logs
@@ -43,7 +43,7 @@ def test_nb_user_change(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[f""NB_USER={nb_user}"", ""CHOWN_HOME=yes""],
-        command=[""start.sh"", ""bash"", ""-c"", ""sleep infinity""],
+        command=[""bash"", ""-c"", ""sleep infinity""],
     )
 
     # Give the chown time to complete.
@@ -99,7 +99,6 @@ def test_chown_extra(container: TrackedContainer) -> None:
             ""CHOWN_EXTRA_OPTS=-R"",
         ],
         command=[
-            ""start.sh"",
             ""bash"",
             ""-c"",
             ""stat -c '%n:%u:%g' /home/jovyan/.bashrc /opt/conda/bin/jupyter"",
@@ -123,7 +122,7 @@ def test_chown_home(container: TrackedContainer) -> None:
             ""NB_UID=1010"",
             ""NB_GID=101"",
         ],
-        command=[""start.sh"", ""bash"", ""-c"", ""stat -c '%n:%u:%g' /home/kitten/.bashrc""],
+        command=[""bash"", ""-c"", ""stat -c '%n:%u:%g' /home/kitten/.bashrc""],
     )
     assert ""/home/kitten/.bashrc:1010:101"" in logs
 
@@ -135,7 +134,7 @@ def test_sudo(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[""GRANT_SUDO=yes""],
-        command=[""start.sh"", ""sudo"", ""id""],
+        command=[""sudo"", ""id""],
     )
     assert ""uid=0(root)"" in logs
 
@@ -147,7 +146,7 @@ def test_sudo_path(container: TrackedContainer) -> None:
         tty=True,
         user=""root"",
         environment=[""GRANT_SUDO=yes""],
-        command=[""start.sh"", ""sudo"", ""which"", ""jupyter""],
+        command=[""sudo"", ""which"", ""jupyter""],
     )
     assert logs.rstrip().endswith(""/opt/conda/bin/jupyter"")
 
@@ -158,7 +157,7 @@ def test_sudo_path_without_grant(container: TrackedContainer) -> None:
         timeout=10,
         tty=True,
         user=""root"",
-        command=[""start.sh"", ""which"", ""jupyter""],
+        command=[""which"", ""jupyter""],
     )
     assert logs.rstrip().endswith(""/opt/conda/bin/jupyter"")
 
@@ -173,7 +172,7 @@ def test_group_add(container: TrackedContainer) -> None:
         no_warnings=False,
         user=""1010:1010"",
         group_add=[""users""],  # Ensures write access to /home/jovyan
-        command=[""start.sh"", ""id""],
+        command=[""id""],
     )
     warnings = TrackedContainer.get_warnings(logs)
     assert len(warnings) == 1
@@ -191,7 +190,7 @@ def test_set_uid(container: TrackedContainer) -> None:
         timeout=5,
         no_warnings=False,
         user=""1010"",
-        command=[""start.sh"", ""id""],
+        command=[""id""],
     )
     assert ""uid=1010(jovyan) gid=0(root)"" in logs
     warnings = TrackedContainer.get_warnings(logs)
@@ -207,7 +206,7 @@ def test_set_uid_and_nb_user(container: TrackedContainer) -> None:
         user=""1010"",
         environment=[""NB_USER=kitten""],
         group_add=[""users""],  # Ensures write access to /home/jovyan
-        command=[""start.sh"", ""id""],
+        command=[""id""],
     )
     assert ""uid=1010(kitten) gid=0(root)"" in logs
     warnings = TrackedContainer.get_warnings(logs)
@@ -236,7 +235,7 @@ def test_container_not_delete_bind_mount(
             ""CHOWN_HOME=yes"",
         ],
         volumes={d: {""bind"": ""/home/jovyan/data"", ""mode"": ""rw""}},
-        command=[""start.sh"", ""ls""],
+        command=[""ls""],
     )
     assert p.read_text() == ""some-content""
     assert len(list(tmp_path.iterdir())) == 1
@@ -259,7 +258,6 @@ def test_jupyter_env_vars_to_unset(
             ""SECRET_FRUIT=mango"",
         ],
         command=[
-            ""start.sh"",
             ""bash"",
             ""-c"",
             ""echo I like ${FRUIT} and ${SECRET_FRUIT:-stuff}, and love ${SECRET_ANIMAL:-to keep secrets}!"",
@@ -284,7 +282,26 @@ def test_secure_path(container: TrackedContainer, tmp_path: pathlib.Path) -> Non
         tty=True,
         user=""root"",
         volumes={p: {""bind"": ""/usr/bin/python"", ""mode"": ""ro""}},
-        command=[""start.sh"", ""python"", ""--version""],
+        command=[""python"", ""--version""],
     )
     assert ""Wrong python"" not in logs
     assert ""Python"" in logs
+
+
+def test_startsh_multiple_exec(container: TrackedContainer) -> None:
+    """"""If start.sh is executed multiple times check that configuration only occurs once.""""""
+    logs = container.run_and_wait(
+        timeout=10,
+        no_warnings=False,
+        tty=True,
+        user=""root"",
+        environment=[""GRANT_SUDO=yes""],
+        command=[""start.sh"", ""sudo"", ""id""],
+    )
+    assert ""uid=0(root)"" in logs
+    warnings = TrackedContainer.get_warnings(logs)
+    assert len(warnings) == 1
+    assert (
+        ""WARNING: start.sh is the default ENTRYPOINT, do not include it in CMD""
+        in warnings[0]
+    )",Yes
tests/minimal-notebook/test_nbconvert.py,tests/minimal-notebook/test_nbconvert.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/minimal-notebook/test_nbconvert.py b/tests/minimal-notebook/test_nbconvert.py
index 115d2ff0..9c1c017b 100644
--- a/tests/minimal-notebook/test_nbconvert.py
+++ b/tests/minimal-notebook/test_nbconvert.py
@@ -28,7 +28,7 @@ def test_nbconvert(
         timeout=30,
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", command],
     )
     expected_file = f""{output_dir}/{test_file}.{output_format}""
     assert expected_file in logs, f""Expected file {expected_file} not generated""","diff --git a/tests/minimal-notebook/test_nbconvert.py b/tests/minimal-notebook/test_nbconvert.py
index 115d2ff0..9c1c017b 100644
--- a/tests/minimal-notebook/test_nbconvert.py
+++ b/tests/minimal-notebook/test_nbconvert.py
@@ -28,7 +28,7 @@ def test_nbconvert(
         timeout=30,
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", command],
     )
     expected_file = f""{output_dir}/{test_file}.{output_format}""
     assert expected_file in logs, f""Expected file {expected_file} not generated""",Yes
tests/package_helper.py,tests/package_helper.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/package_helper.py b/tests/package_helper.py
index 1cfdd99d..2fe85f53 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -55,7 +55,7 @@ class CondaPackageHelper:
         LOGGER.info(f""Starting container {container.image_name} ..."")
         return container.run_detached(
             tty=True,
-            command=[""start.sh"", ""bash"", ""-c"", ""sleep infinity""],
+            command=[""bash"", ""-c"", ""sleep infinity""],
         )
 
     @staticmethod","diff --git a/tests/package_helper.py b/tests/package_helper.py
index 1cfdd99d..2fe85f53 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -55,7 +55,7 @@ class CondaPackageHelper:
         LOGGER.info(f""Starting container {container.image_name} ..."")
         return container.run_detached(
             tty=True,
-            command=[""start.sh"", ""bash"", ""-c"", ""sleep infinity""],
+            command=[""bash"", ""-c"", ""sleep infinity""],
         )
 
     @staticmethod",Yes
tests/run_command.py,tests/run_command.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/run_command.py b/tests/run_command.py
index 40f343d0..48e3cc07 100644
--- a/tests/run_command.py
+++ b/tests/run_command.py
@@ -18,5 +18,5 @@ def run_command(
     return container.run_and_wait(
         timeout=timeout,
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", command],
     )","diff --git a/tests/run_command.py b/tests/run_command.py
index 40f343d0..48e3cc07 100644
--- a/tests/run_command.py
+++ b/tests/run_command.py
@@ -18,5 +18,5 @@ def run_command(
     return container.run_and_wait(
         timeout=timeout,
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", command],
     )",Yes
tests/scipy-notebook/test_cython.py,tests/scipy-notebook/test_cython.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/scipy-notebook/test_cython.py b/tests/scipy-notebook/test_cython.py
index 5d24e971..092271ba 100644
--- a/tests/scipy-notebook/test_cython.py
+++ b/tests/scipy-notebook/test_cython.py
@@ -16,7 +16,6 @@ def test_cython(container: TrackedContainer) -> None:
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
         command=[
-            ""start.sh"",
             ""bash"",
             ""-c"",
             # We copy our data to a temporary folder to be able to modify the directory","diff --git a/tests/scipy-notebook/test_cython.py b/tests/scipy-notebook/test_cython.py
index 5d24e971..092271ba 100644
--- a/tests/scipy-notebook/test_cython.py
+++ b/tests/scipy-notebook/test_cython.py
@@ -16,7 +16,6 @@ def test_cython(container: TrackedContainer) -> None:
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
         command=[
-            ""start.sh"",
             ""bash"",
             ""-c"",
             # We copy our data to a temporary folder to be able to modify the directory",Yes
tests/scipy-notebook/test_extensions.py,tests/scipy-notebook/test_extensions.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/scipy-notebook/test_extensions.py b/tests/scipy-notebook/test_extensions.py
index d95f7ae5..d90cc622 100644
--- a/tests/scipy-notebook/test_extensions.py
+++ b/tests/scipy-notebook/test_extensions.py
@@ -30,5 +30,5 @@ def test_check_extension(container: TrackedContainer, extension: str) -> None:
     container.run_and_wait(
         timeout=10,
         tty=True,
-        command=[""start.sh"", ""jupyter"", ""labextension"", ""check"", extension],
+        command=[""jupyter"", ""labextension"", ""check"", extension],
     )","diff --git a/tests/scipy-notebook/test_extensions.py b/tests/scipy-notebook/test_extensions.py
index d95f7ae5..d90cc622 100644
--- a/tests/scipy-notebook/test_extensions.py
+++ b/tests/scipy-notebook/test_extensions.py
@@ -30,5 +30,5 @@ def test_check_extension(container: TrackedContainer, extension: str) -> None:
     container.run_and_wait(
         timeout=10,
         tty=True,
-        command=[""start.sh"", ""jupyter"", ""labextension"", ""check"", extension],
+        command=[""jupyter"", ""labextension"", ""check"", extension],
     )",Yes
tests/scipy-notebook/test_matplotlib.py,tests/scipy-notebook/test_matplotlib.py,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,b71f4cb5259e0ae8b658065eac90381ad578ec20,Make `start.sh` the entrypoint (#2087),"diff --git a/tests/scipy-notebook/test_matplotlib.py b/tests/scipy-notebook/test_matplotlib.py
index ac4fcdae..c67f039c 100644
--- a/tests/scipy-notebook/test_matplotlib.py
+++ b/tests/scipy-notebook/test_matplotlib.py
@@ -42,7 +42,7 @@ def test_matplotlib(
     running_container = container.run_detached(
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", command],
     )
     command = f""python {cont_data_dir}/{test_file}""
     cmd = running_container.exec_run(command)","diff --git a/tests/scipy-notebook/test_matplotlib.py b/tests/scipy-notebook/test_matplotlib.py
index ac4fcdae..c67f039c 100644
--- a/tests/scipy-notebook/test_matplotlib.py
+++ b/tests/scipy-notebook/test_matplotlib.py
@@ -42,7 +42,7 @@ def test_matplotlib(
     running_container = container.run_detached(
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
-        command=[""start.sh"", ""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", command],
     )
     command = f""python {cont_data_dir}/{test_file}""
     cmd = running_container.exec_run(command)",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,3dfe578caa15e6718ce5555c205d8dae8e413f25,6e437aa4896a7c8cd6e532d08c6d32adf8dc89a4,Configure entrypoint after copying needed files to make it work,"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 0f21cac1..68450ac1 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -123,12 +123,12 @@ RUN set -x && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Configure container startup
-ENTRYPOINT [""tini"", ""-g"", ""--"", ""start.sh""]
-
 # Copy local files as late as possible to avoid cache busting
 COPY run-hooks.sh start.sh /usr/local/bin/
 
+# Configure container entrypoint
+ENTRYPOINT [""tini"", ""-g"", ""--"", ""start.sh""]
+
 USER root
 
 # Create dirs for startup hooks","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 0f21cac1..68450ac1 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -123,12 +123,12 @@ RUN set -x && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
-# Configure container startup
-ENTRYPOINT [""tini"", ""-g"", ""--"", ""start.sh""]
-
 # Copy local files as late as possible to avoid cache busting
 COPY run-hooks.sh start.sh /usr/local/bin/
 
+# Configure container entrypoint
+ENTRYPOINT [""tini"", ""-g"", ""--"", ""start.sh""]
+
 USER root
 
 # Create dirs for startup hooks",Yes
images/base-notebook/start-singleuser.py,images/base-notebook/start-singleuser.py,7e240d59d3ef4683c4757cf90f55d89f8708418d,3dfe578caa15e6718ce5555c205d8dae8e413f25,Fix comment style in start-singleuser.py,"diff --git a/images/base-notebook/start-singleuser.py b/images/base-notebook/start-singleuser.py
index 8fe2ee02..c80339f5 100755
--- a/images/base-notebook/start-singleuser.py
+++ b/images/base-notebook/start-singleuser.py
@@ -12,8 +12,9 @@ command = [""jupyterhub-singleuser""]
 if ""--ip="" not in os.environ.get(""NOTEBOOK_ARGS"", """"):
     command.append(""--ip=0.0.0.0"")
 
-# Append any optional NOTEBOOK_ARGS we were passed in. This is supposed to be multiple args passed
-# on to the notebook command, so we split it correctly with shlex
+# Append any optional NOTEBOOK_ARGS we were passed in.
+# This is supposed to be multiple args passed on to the notebook command,
+# so we split it correctly with shlex
 if ""NOTEBOOK_ARGS"" in os.environ:
     command += shlex.split(os.environ[""NOTEBOOK_ARGS""])","diff --git a/images/base-notebook/start-singleuser.py b/images/base-notebook/start-singleuser.py
index 8fe2ee02..c80339f5 100755
--- a/images/base-notebook/start-singleuser.py
+++ b/images/base-notebook/start-singleuser.py
@@ -12,8 +12,9 @@ command = [""jupyterhub-singleuser""]
 if ""--ip="" not in os.environ.get(""NOTEBOOK_ARGS"", """"):
     command.append(""--ip=0.0.0.0"")
 
-# Append any optional NOTEBOOK_ARGS we were passed in. This is supposed to be multiple args passed
-# on to the notebook command, so we split it correctly with shlex
+# Append any optional NOTEBOOK_ARGS we were passed in.
+# This is supposed to be multiple args passed on to the notebook command,
+# so we split it correctly with shlex
 if ""NOTEBOOK_ARGS"" in os.environ:
     command += shlex.split(os.environ[""NOTEBOOK_ARGS""])",Yes
images/base-notebook/start-notebook.py,images/base-notebook/start-notebook.py,009821cdb34f49f171e159ec0e82a39e87e6e0fd,7e240d59d3ef4683c4757cf90f55d89f8708418d,Fix information about RESTARTABLE option,"diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
index b46217e2..973da5aa 100755
--- a/images/base-notebook/start-notebook.py
+++ b/images/base-notebook/start-notebook.py
@@ -17,7 +17,7 @@ if ""JUPYTERHUB_API_TOKEN"" in os.environ:
 # Entrypoint is start.sh
 command = []
 
-# If we want to survive restarts, tell that to start.sh
+# If we want to survive restarts, launch the command using `run-one-constantly`
 if os.environ.get(""RESTARTABLE"") == ""yes"":
     command.append(""run-one-constantly"")","diff --git a/images/base-notebook/start-notebook.py b/images/base-notebook/start-notebook.py
index b46217e2..973da5aa 100755
--- a/images/base-notebook/start-notebook.py
+++ b/images/base-notebook/start-notebook.py
@@ -17,7 +17,7 @@ if ""JUPYTERHUB_API_TOKEN"" in os.environ:
 # Entrypoint is start.sh
 command = []
 
-# If we want to survive restarts, tell that to start.sh
+# If we want to survive restarts, launch the command using `run-one-constantly`
 if os.environ.get(""RESTARTABLE"") == ""yes"":
     command.append(""run-one-constantly"")",Yes
tests/scipy-notebook/test_matplotlib.py,tests/scipy-notebook/test_matplotlib.py,7a5990be1f90766de2d59194bdec73327b0885c0,009821cdb34f49f171e159ec0e82a39e87e6e0fd,Do not rewrite variable with another value,"diff --git a/tests/scipy-notebook/test_matplotlib.py b/tests/scipy-notebook/test_matplotlib.py
index c67f039c..e96bc8c8 100644
--- a/tests/scipy-notebook/test_matplotlib.py
+++ b/tests/scipy-notebook/test_matplotlib.py
@@ -38,11 +38,10 @@ def test_matplotlib(
     cont_data_dir = ""/home/jovyan/data""
     output_dir = ""/tmp""
     LOGGER.info(description)
-    command = ""sleep infinity""
     running_container = container.run_detached(
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
-        command=[""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", ""sleep infinity""],
     )
     command = f""python {cont_data_dir}/{test_file}""
     cmd = running_container.exec_run(command)","diff --git a/tests/scipy-notebook/test_matplotlib.py b/tests/scipy-notebook/test_matplotlib.py
index c67f039c..e96bc8c8 100644
--- a/tests/scipy-notebook/test_matplotlib.py
+++ b/tests/scipy-notebook/test_matplotlib.py
@@ -38,11 +38,10 @@ def test_matplotlib(
     cont_data_dir = ""/home/jovyan/data""
     output_dir = ""/tmp""
     LOGGER.info(description)
-    command = ""sleep infinity""
     running_container = container.run_detached(
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
-        command=[""bash"", ""-c"", command],
+        command=[""bash"", ""-c"", ""sleep infinity""],
     )
     command = f""python {cont_data_dir}/{test_file}""
     cmd = running_container.exec_run(command)",Yes
docs/conf.py,docs/conf.py,f5a7f1af1df8484596ba399846c5c90667441514,7a5990be1f90766de2d59194bdec73327b0885c0,Update docs copyright year,"diff --git a/docs/conf.py b/docs/conf.py
index ed89a61f..efe904b8 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -7,7 +7,7 @@
 # https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information
 
 project = ""docker-stacks""
-copyright = ""2023, Project Jupyter""
+copyright = ""2024, Project Jupyter""
 author = ""Project Jupyter""
 
 version = ""latest""","diff --git a/docs/conf.py b/docs/conf.py
index ed89a61f..efe904b8 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -7,7 +7,7 @@
 # https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information
 
 project = ""docker-stacks""
-copyright = ""2023, Project Jupyter""
+copyright = ""2024, Project Jupyter""
 author = ""Project Jupyter""
 
 version = ""latest""",Yes
docs/using/recipes.md,docs/using/recipes.md,6be9ae8ce63fddb74c516b3590e77bdfdff33dcd,f5a7f1af1df8484596ba399846c5c90667441514,Fix python in docs,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 03293c63..f42696d0 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -202,9 +202,9 @@ import os
 
 # To figure out what version of Hadoop, run:
 # ls /usr/local/spark/jars/hadoop*
-os.environ[
-    ""PYSPARK_SUBMIT_ARGS""
-] = '--packages ""org.apache.hadoop:hadoop-aws:2.7.3"" pyspark-shell'
+os.environ[""PYSPARK_SUBMIT_ARGS""] = (
+    '--packages ""org.apache.hadoop:hadoop-aws:2.7.3"" pyspark-shell'
+)
 
 import pyspark
 
@@ -226,9 +226,9 @@ Using Spark context for Hadoop 2.6.0
 ```python
 import os
 
-os.environ[
-    ""PYSPARK_SUBMIT_ARGS""
-] = ""--packages com.amazonaws:aws-java-sdk:1.10.34,org.apache.hadoop:hadoop-aws:2.6.0 pyspark-shell""
+os.environ[""PYSPARK_SUBMIT_ARGS""] = (
+    ""--packages com.amazonaws:aws-java-sdk:1.10.34,org.apache.hadoop:hadoop-aws:2.6.0 pyspark-shell""
+)
 
 import pyspark
 
@@ -259,9 +259,9 @@ This recipe is not tested and might be broken.
 ```python
 import os
 
-os.environ[
-    ""PYSPARK_SUBMIT_ARGS""
-] = ""--jars /home/jovyan/spark-streaming-kafka-assembly_2.10-1.6.1.jar pyspark-shell""
+os.environ[""PYSPARK_SUBMIT_ARGS""] = (
+    ""--jars /home/jovyan/spark-streaming-kafka-assembly_2.10-1.6.1.jar pyspark-shell""
+)
 import pyspark
 from pyspark.streaming.kafka import KafkaUtils
 from pyspark.streaming import StreamingContext","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 03293c63..f42696d0 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -202,9 +202,9 @@ import os
 
 # To figure out what version of Hadoop, run:
 # ls /usr/local/spark/jars/hadoop*
-os.environ[
-    ""PYSPARK_SUBMIT_ARGS""
-] = '--packages ""org.apache.hadoop:hadoop-aws:2.7.3"" pyspark-shell'
+os.environ[""PYSPARK_SUBMIT_ARGS""] = (
+    '--packages ""org.apache.hadoop:hadoop-aws:2.7.3"" pyspark-shell'
+)
 
 import pyspark
 
@@ -226,9 +226,9 @@ Using Spark context for Hadoop 2.6.0
 ```python
 import os
 
-os.environ[
-    ""PYSPARK_SUBMIT_ARGS""
-] = ""--packages com.amazonaws:aws-java-sdk:1.10.34,org.apache.hadoop:hadoop-aws:2.6.0 pyspark-shell""
+os.environ[""PYSPARK_SUBMIT_ARGS""] = (
+    ""--packages com.amazonaws:aws-java-sdk:1.10.34,org.apache.hadoop:hadoop-aws:2.6.0 pyspark-shell""
+)
 
 import pyspark
 
@@ -259,9 +259,9 @@ This recipe is not tested and might be broken.
 ```python
 import os
 
-os.environ[
-    ""PYSPARK_SUBMIT_ARGS""
-] = ""--jars /home/jovyan/spark-streaming-kafka-assembly_2.10-1.6.1.jar pyspark-shell""
+os.environ[""PYSPARK_SUBMIT_ARGS""] = (
+    ""--jars /home/jovyan/spark-streaming-kafka-assembly_2.10-1.6.1.jar pyspark-shell""
+)
 import pyspark
 from pyspark.streaming.kafka import KafkaUtils
 from pyspark.streaming import StreamingContext",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,3692e3a84cd629f47e0a370c99743ade22ed1995,6be9ae8ce63fddb74c516b3590e77bdfdff33dcd,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 6ca73edf..4c5c3304 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.12.1
+    rev: 24.1.1
     hooks:
       - id: black
         args: [--target-version=py39]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 6ca73edf..4c5c3304 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 23.12.1
+    rev: 24.1.1
     hooks:
       - id: black
         args: [--target-version=py39]",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,ce08d9e3483fdc8bc661ef0f33ee888d0b434fcd,3692e3a84cd629f47e0a370c99743ade22ed1995,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 4c5c3304..83786366 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -123,7 +123,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.38.0
+    rev: v0.39.0
     hooks:
       - id: markdownlint
         args: [""--fix""]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 4c5c3304..83786366 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -123,7 +123,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.38.0
+    rev: v0.39.0
     hooks:
       - id: markdownlint
         args: [""--fix""]",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,949af9bbd57db732804059d3ad3ac374ef73b4e8,ce08d9e3483fdc8bc661ef0f33ee888d0b434fcd,[pre-commit.ci] pre-commit autoupdate (#2090),"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 83786366..8ed45be3 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -130,7 +130,7 @@ repos:
 
   # Strip output from Jupyter notebooks
   - repo: https://github.com/kynan/nbstripout
-    rev: 0.6.1
+    rev: 0.7.1
     hooks:
       - id: nbstripout","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 83786366..8ed45be3 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -130,7 +130,7 @@ repos:
 
   # Strip output from Jupyter notebooks
   - repo: https://github.com/kynan/nbstripout
-    rev: 0.6.1
+    rev: 0.7.1
     hooks:
       - id: nbstripout",Yes
tests/minimal-notebook/data/notebook_math.ipynb,tests/minimal-notebook/data/notebook_math.ipynb,949af9bbd57db732804059d3ad3ac374ef73b4e8,ce08d9e3483fdc8bc661ef0f33ee888d0b434fcd,[pre-commit.ci] pre-commit autoupdate (#2090),"diff --git a/tests/minimal-notebook/data/notebook_math.ipynb b/tests/minimal-notebook/data/notebook_math.ipynb
index 5b028b1d..019d645f 100644
--- a/tests/minimal-notebook/data/notebook_math.ipynb
+++ b/tests/minimal-notebook/data/notebook_math.ipynb
@@ -2,7 +2,7 @@
  ""cells"": [
   {
    ""cell_type"": ""markdown"",
-   ""id"": ""a69ceb22"",
+   ""id"": ""0"",
    ""metadata"": {},
    ""source"": [
     ""# A simple SymPy example""
@@ -10,7 +10,7 @@
   },
   {
    ""cell_type"": ""markdown"",
-   ""id"": ""3c43c88e"",
+   ""id"": ""1"",
    ""metadata"": {},
    ""source"": [
     ""First we import SymPy and initialize printing:""
@@ -19,7 +19,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""7b561917"",
+   ""id"": ""2"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false
@@ -33,7 +33,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""d6454356-d5a6-481f-aaac-9abcc101026a"",
+   ""id"": ""3"",
    ""metadata"": {},
    ""outputs"": [],
    ""source"": [
@@ -42,7 +42,7 @@
   },
   {
    ""cell_type"": ""markdown"",
-   ""id"": ""fbe0a2f3"",
+   ""id"": ""4"",
    ""metadata"": {},
    ""source"": [
     ""Create a few symbols:""
@@ -51,7 +51,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""c99d7f17"",
+   ""id"": ""5"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false
@@ -64,7 +64,7 @@
   },
   {
    ""cell_type"": ""markdown"",
-   ""id"": ""f61dddac"",
+   ""id"": ""6"",
    ""metadata"": {},
    ""source"": [
     ""Here is a basic expression:""
@@ -73,7 +73,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""0cfde73c"",
+   ""id"": ""7"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false
@@ -88,7 +88,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""cb7eb1ad"",
+   ""id"": ""8"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false
@@ -102,7 +102,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""07441ea9"",
+   ""id"": ""9"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false","diff --git a/tests/minimal-notebook/data/notebook_math.ipynb b/tests/minimal-notebook/data/notebook_math.ipynb
index 5b028b1d..019d645f 100644
--- a/tests/minimal-notebook/data/notebook_math.ipynb
+++ b/tests/minimal-notebook/data/notebook_math.ipynb
@@ -2,7 +2,7 @@
  ""cells"": [
   {
    ""cell_type"": ""markdown"",
-   ""id"": ""a69ceb22"",
+   ""id"": ""0"",
    ""metadata"": {},
    ""source"": [
     ""# A simple SymPy example""
@@ -10,7 +10,7 @@
   },
   {
    ""cell_type"": ""markdown"",
-   ""id"": ""3c43c88e"",
+   ""id"": ""1"",
    ""metadata"": {},
    ""source"": [
     ""First we import SymPy and initialize printing:""
@@ -19,7 +19,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""7b561917"",
+   ""id"": ""2"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false
@@ -33,7 +33,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""d6454356-d5a6-481f-aaac-9abcc101026a"",
+   ""id"": ""3"",
    ""metadata"": {},
    ""outputs"": [],
    ""source"": [
@@ -42,7 +42,7 @@
   },
   {
    ""cell_type"": ""markdown"",
-   ""id"": ""fbe0a2f3"",
+   ""id"": ""4"",
    ""metadata"": {},
    ""source"": [
     ""Create a few symbols:""
@@ -51,7 +51,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""c99d7f17"",
+   ""id"": ""5"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false
@@ -64,7 +64,7 @@
   },
   {
    ""cell_type"": ""markdown"",
-   ""id"": ""f61dddac"",
+   ""id"": ""6"",
    ""metadata"": {},
    ""source"": [
     ""Here is a basic expression:""
@@ -73,7 +73,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""0cfde73c"",
+   ""id"": ""7"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false
@@ -88,7 +88,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""cb7eb1ad"",
+   ""id"": ""8"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false
@@ -102,7 +102,7 @@
   {
    ""cell_type"": ""code"",
    ""execution_count"": null,
-   ""id"": ""07441ea9"",
+   ""id"": ""9"",
    ""metadata"": {
     ""jupyter"": {
      ""outputs_hidden"": false",Yes
Makefile,Makefile,8da0523b50e6d55e1cdcd08dd7b043c8eda50699,949af9bbd57db732804059d3ad3ac374ef73b4e8,Add ROOT_CONTAINER param to Makerfile,"diff --git a/Makefile b/Makefile
index 7965b641..63c8eb44 100644
--- a/Makefile
+++ b/Makefile
@@ -36,6 +36,7 @@ help:
 
 
 build/%: DOCKER_BUILD_ARGS?=
+build/%: ROOT_CONTAINER?=ubuntu:22.04
 build/%: ## build the latest image for a stack using the system's architecture
 	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)""
 	@echo -n ""Built image size: ""","diff --git a/Makefile b/Makefile
index 7965b641..63c8eb44 100644
--- a/Makefile
+++ b/Makefile
@@ -36,6 +36,7 @@ help:
 
 
 build/%: DOCKER_BUILD_ARGS?=
+build/%: ROOT_CONTAINER?=ubuntu:22.04
 build/%: ## build the latest image for a stack using the system's architecture
 	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)""
 	@echo -n ""Built image size: """,Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,c2159f4118f39e7201282628131dad3b25d40ba6,8da0523b50e6d55e1cdcd08dd7b043c8eda50699,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 8ed45be3..5887d2ca 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.1.1
+    rev: 24.2.0
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -95,7 +95,7 @@ repos:
 
   # Lint: YAML
   - repo: https://github.com/adrienverge/yamllint
-    rev: v1.33.0
+    rev: v1.35.1
     hooks:
       - id: yamllint
         args: [""-d {extends: relaxed, rules: {line-length: disable}}"", ""-s""]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 8ed45be3..5887d2ca 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.1.1
+    rev: 24.2.0
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -95,7 +95,7 @@ repos:
 
   # Lint: YAML
   - repo: https://github.com/adrienverge/yamllint
-    rev: v1.33.0
+    rev: v1.35.1
     hooks:
       - id: yamllint
         args: [""-d {extends: relaxed, rules: {line-length: disable}}"", ""-s""]",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,fe2195458f5176b36e3f4da228fbfa8011976a3c,c2159f4118f39e7201282628131dad3b25d40ba6,Don't default to US-specific locale settings (#2096),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 68450ac1..f6b38c8c 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -38,6 +38,7 @@ RUN apt-get update --yes && \
     wget && \
     apt-get clean && rm -rf /var/lib/apt/lists/* && \
     echo ""en_US.UTF-8 UTF-8"" > /etc/locale.gen && \
+    echo ""C.UTF-8 UTF-8"" >> /etc/locale.gen && \
     locale-gen
 
 # Configure environment
@@ -46,9 +47,9 @@ ENV CONDA_DIR=/opt/conda \
     NB_USER=""${NB_USER}"" \
     NB_UID=${NB_UID} \
     NB_GID=${NB_GID} \
-    LC_ALL=en_US.UTF-8 \
-    LANG=en_US.UTF-8 \
-    LANGUAGE=en_US.UTF-8
+    LC_ALL=C.UTF-8 \
+    LANG=C.UTF-8 \
+    LANGUAGE=C.UTF-8
 ENV PATH=""${CONDA_DIR}/bin:${PATH}"" \
     HOME=""/home/${NB_USER}""","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 68450ac1..f6b38c8c 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -38,6 +38,7 @@ RUN apt-get update --yes && \
     wget && \
     apt-get clean && rm -rf /var/lib/apt/lists/* && \
     echo ""en_US.UTF-8 UTF-8"" > /etc/locale.gen && \
+    echo ""C.UTF-8 UTF-8"" >> /etc/locale.gen && \
     locale-gen
 
 # Configure environment
@@ -46,9 +47,9 @@ ENV CONDA_DIR=/opt/conda \
     NB_USER=""${NB_USER}"" \
     NB_UID=${NB_UID} \
     NB_GID=${NB_GID} \
-    LC_ALL=en_US.UTF-8 \
-    LANG=en_US.UTF-8 \
-    LANGUAGE=en_US.UTF-8
+    LC_ALL=C.UTF-8 \
+    LANG=C.UTF-8 \
+    LANGUAGE=C.UTF-8
 ENV PATH=""${CONDA_DIR}/bin:${PATH}"" \
     HOME=""/home/${NB_USER}""",Yes
.github/actions/load-image/action.yml,.github/actions/load-image/action.yml,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index cbf5a8a5..cf53e4a6 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -8,6 +8,9 @@ inputs:
   platform:
     description: Image platform
     required: true
+  variant:
+    description: Variant tag prefix
+    required: true
 
 runs:
   using: composite
@@ -15,10 +18,10 @@ runs:
     - name: Download built image 📥
       uses: actions/download-artifact@v4
       with:
-        name: ${{ inputs.image }}-${{ inputs.platform }}
+        name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}
         path: /tmp/jupyter/images/
     - name: Load downloaded image to docker 📥
       run: |
-        zstd --uncompress --stdout --rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst | docker load
+        zstd --uncompress --stdout --rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}.tar.zst | docker load
         docker image ls --all
       shell: bash","diff --git a/.github/actions/load-image/action.yml b/.github/actions/load-image/action.yml
index cbf5a8a5..cf53e4a6 100644
--- a/.github/actions/load-image/action.yml
+++ b/.github/actions/load-image/action.yml
@@ -8,6 +8,9 @@ inputs:
   platform:
     description: Image platform
     required: true
+  variant:
+    description: Variant tag prefix
+    required: true
 
 runs:
   using: composite
@@ -15,10 +18,10 @@ runs:
     - name: Download built image 📥
       uses: actions/download-artifact@v4
       with:
-        name: ${{ inputs.image }}-${{ inputs.platform }}
+        name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}
         path: /tmp/jupyter/images/
     - name: Load downloaded image to docker 📥
       run: |
-        zstd --uncompress --stdout --rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst | docker load
+        zstd --uncompress --stdout --rm /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}.tar.zst | docker load
         docker image ls --all
       shell: bash",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 01520d34..c1fcae98 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -11,10 +11,20 @@ on:
         description: Parent image name
         required: true
         type: string
+      parent-variant:
+        description: Parent variant tag prefix
+        required: false
+        type: string
+        default: default
       image:
         description: Image name
         required: true
         type: string
+      variant:
+        description: Variant tag prefix
+        required: false
+        type: string
+        default: default
       platform:
         description: Image platform
         required: true
@@ -29,6 +39,19 @@ jobs:
     runs-on: ${{ inputs.runs-on }}
 
     steps:
+      # Image with CUDA needs extra disk space
+      - name: Free disk space 🧹
+        if: contains(inputs.variant, 'cuda') && inputs.platform == 'x86_64'
+        uses: jlumbroso/free-disk-space@54081f138730dfa15788a46383842cd2f914a1be
+        with:
+          tool-cache: false
+          android: true
+          dotnet: true
+          haskell: true
+          large-packages: false
+          docker-images: false
+          swap-storage: false
+
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v4
       - name: Create dev environment 📦
@@ -52,6 +75,7 @@ jobs:
         with:
           image: ${{ inputs.parent-image }}
           platform: ${{ inputs.platform }}
+          variant: ${{ inputs.parent-variant }}
 
       - name: Pull ubuntu:22.04 image 📥
         if: inputs.parent-image == ''
@@ -59,7 +83,7 @@ jobs:
         shell: bash
 
       - name: Build image 🛠
-        run: docker build --rm --force-rm --tag ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/ --build-arg REGISTRY=${{ env.REGISTRY }} --build-arg OWNER=${{ env.OWNER }}
+        run: docker build --rm --force-rm --tag ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/${{ inputs.variant != 'default' && inputs.variant || '.' }}/ --build-arg REGISTRY=${{ env.REGISTRY }} --build-arg OWNER=${{ env.OWNER }}
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build
@@ -72,39 +96,39 @@ jobs:
 
       - name: Write tags file 🏷
         run: |
-          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }} --variant ${{ inputs.variant }}
         shell: bash
       - name: Upload tags file 💾
         uses: actions/upload-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}-tags
-          path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-tags
+          path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.variant }}-${{ inputs.image }}.txt
           retention-days: 3
 
       - name: Write manifest and build history file 🏷
-        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }} --variant ${{ inputs.variant }}
         shell: bash
       - name: Upload manifest file 💾
         uses: actions/upload-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
-          path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-manifest
+          path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.variant }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
         uses: actions/upload-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
-          path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-history_line
+          path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.variant }}-${{ inputs.image }}-*.txt
           retention-days: 3
 
       - name: Save image as a tar for later use 💾
         run: |
           mkdir -p /tmp/jupyter/images/
-          docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
+          docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
         uses: actions/upload-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}
-          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}
+          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}.tar.zst
           retention-days: 3","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 01520d34..c1fcae98 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -11,10 +11,20 @@ on:
         description: Parent image name
         required: true
         type: string
+      parent-variant:
+        description: Parent variant tag prefix
+        required: false
+        type: string
+        default: default
       image:
         description: Image name
         required: true
         type: string
+      variant:
+        description: Variant tag prefix
+        required: false
+        type: string
+        default: default
       platform:
         description: Image platform
         required: true
@@ -29,6 +39,19 @@ jobs:
     runs-on: ${{ inputs.runs-on }}
 
     steps:
+      # Image with CUDA needs extra disk space
+      - name: Free disk space 🧹
+        if: contains(inputs.variant, 'cuda') && inputs.platform == 'x86_64'
+        uses: jlumbroso/free-disk-space@54081f138730dfa15788a46383842cd2f914a1be
+        with:
+          tool-cache: false
+          android: true
+          dotnet: true
+          haskell: true
+          large-packages: false
+          docker-images: false
+          swap-storage: false
+
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v4
       - name: Create dev environment 📦
@@ -52,6 +75,7 @@ jobs:
         with:
           image: ${{ inputs.parent-image }}
           platform: ${{ inputs.platform }}
+          variant: ${{ inputs.parent-variant }}
 
       - name: Pull ubuntu:22.04 image 📥
         if: inputs.parent-image == ''
@@ -59,7 +83,7 @@ jobs:
         shell: bash
 
       - name: Build image 🛠
-        run: docker build --rm --force-rm --tag ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/ --build-arg REGISTRY=${{ env.REGISTRY }} --build-arg OWNER=${{ env.OWNER }}
+        run: docker build --rm --force-rm --tag ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} images/${{ inputs.image }}/${{ inputs.variant != 'default' && inputs.variant || '.' }}/ --build-arg REGISTRY=${{ env.REGISTRY }} --build-arg OWNER=${{ env.OWNER }}
         env:
           DOCKER_BUILDKIT: 1
           # Full logs for CI build
@@ -72,39 +96,39 @@ jobs:
 
       - name: Write tags file 🏷
         run: |
-          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+          python3 -m tagging.write_tags_file --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }} --variant ${{ inputs.variant }}
         shell: bash
       - name: Upload tags file 💾
         uses: actions/upload-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}-tags
-          path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.image }}.txt
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-tags
+          path: /tmp/jupyter/tags/${{ inputs.platform }}-${{ inputs.variant }}-${{ inputs.image }}.txt
           retention-days: 3
 
       - name: Write manifest and build history file 🏷
-        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.write_manifest --short-image-name ${{ inputs.image }} --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }} --variant ${{ inputs.variant }}
         shell: bash
       - name: Upload manifest file 💾
         uses: actions/upload-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}-manifest
-          path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.image }}-*.md
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-manifest
+          path: /tmp/jupyter/manifests/${{ inputs.platform }}-${{ inputs.variant }}-${{ inputs.image }}-*.md
           retention-days: 3
       - name: Upload build history line 💾
         uses: actions/upload-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}-history_line
-          path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.image }}-*.txt
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-history_line
+          path: /tmp/jupyter/hist_lines/${{ inputs.platform }}-${{ inputs.variant }}-${{ inputs.image }}-*.txt
           retention-days: 3
 
       - name: Save image as a tar for later use 💾
         run: |
           mkdir -p /tmp/jupyter/images/
-          docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
+          docker save ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }} | zstd > /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}.tar.zst
         shell: bash
       - name: Upload image as artifact 💾
         uses: actions/upload-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}
-          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}.tar.zst
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}
+          path: /tmp/jupyter/images/${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}.tar.zst
           retention-days: 3",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 038dbff1..07107a4c 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -7,6 +7,10 @@ env:
 on:
   workflow_call:
     inputs:
+      variant:
+        description: Variant tag prefix
+        required: true
+        type: string
       image:
         description: Image name
         required: true
@@ -30,13 +34,14 @@ jobs:
       - name: Download x86_64 tags file 📥
         uses: actions/download-artifact@v4
         with:
-          name: ${{ inputs.image }}-x86_64-tags
+          name: ${{ inputs.image }}-x86_64-${{ inputs.variant }}-tags
           path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
         uses: actions/download-artifact@v4
         with:
-          name: ${{ inputs.image }}-aarch64-tags
+          name: ${{ inputs.image }}-aarch64-${{ inputs.variant }}-tags
           path: /tmp/jupyter/tags/
+        if: github.repository_owner == 'jupyter' && !contains(inputs.variant, 'cuda')
 
       # Docker might be stuck when pulling images
       # https://github.com/docker/for-mac/issues/2083
@@ -57,5 +62,5 @@ jobs:
 
       - name: Merge tags for the images 🔀
         if: env.PUSH_TO_REGISTRY == 'true'
-        run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/
+        run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --variant ${{ inputs.variant }}
         shell: bash","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 038dbff1..07107a4c 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -7,6 +7,10 @@ env:
 on:
   workflow_call:
     inputs:
+      variant:
+        description: Variant tag prefix
+        required: true
+        type: string
       image:
         description: Image name
         required: true
@@ -30,13 +34,14 @@ jobs:
       - name: Download x86_64 tags file 📥
         uses: actions/download-artifact@v4
         with:
-          name: ${{ inputs.image }}-x86_64-tags
+          name: ${{ inputs.image }}-x86_64-${{ inputs.variant }}-tags
           path: /tmp/jupyter/tags/
       - name: Download aarch64 tags file 📥
         uses: actions/download-artifact@v4
         with:
-          name: ${{ inputs.image }}-aarch64-tags
+          name: ${{ inputs.image }}-aarch64-${{ inputs.variant }}-tags
           path: /tmp/jupyter/tags/
+        if: github.repository_owner == 'jupyter' && !contains(inputs.variant, 'cuda')
 
       # Docker might be stuck when pulling images
       # https://github.com/docker/for-mac/issues/2083
@@ -57,5 +62,5 @@ jobs:
 
       - name: Merge tags for the images 🔀
         if: env.PUSH_TO_REGISTRY == 'true'
-        run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/
+        run: python3 -m tagging.merge_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --variant ${{ inputs.variant }}
         shell: bash",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index b68a8d1a..c0093e69 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -16,6 +16,10 @@ on:
         description: Image platform
         required: true
         type: string
+      variant:
+        description: Variant tag prefix
+        required: true
+        type: string
     secrets:
       REGISTRY_USERNAME:
         required: true
@@ -27,6 +31,19 @@ jobs:
     runs-on: ubuntu-latest
 
     steps:
+      # Image with CUDA needs extra disk space
+      - name: Free disk space 🧹
+        if: contains(inputs.variant, 'cuda') && inputs.platform == 'x86_64'
+        uses: jlumbroso/free-disk-space@54081f138730dfa15788a46383842cd2f914a1be
+        with:
+          tool-cache: false
+          android: true
+          dotnet: true
+          haskell: true
+          large-packages: false
+          docker-images: false
+          swap-storage: false
+
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v4
       - name: Create dev environment 📦
@@ -36,6 +53,7 @@ jobs:
         with:
           image: ${{ inputs.image }}
           platform: ${{ inputs.platform }}
+          variant: ${{ inputs.variant }}
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
@@ -48,10 +66,10 @@ jobs:
       - name: Download tags file 📥
         uses: actions/download-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}-tags
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-tags
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
-        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --variant ${{ inputs.variant }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
       # This step is needed to prevent pushing non-multi-arch ""latest"" tag
       - name: Remove the ""latest"" tag from the image 🗑️
         run: docker image rmi ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}:latest","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index b68a8d1a..c0093e69 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -16,6 +16,10 @@ on:
         description: Image platform
         required: true
         type: string
+      variant:
+        description: Variant tag prefix
+        required: true
+        type: string
     secrets:
       REGISTRY_USERNAME:
         required: true
@@ -27,6 +31,19 @@ jobs:
     runs-on: ubuntu-latest
 
     steps:
+      # Image with CUDA needs extra disk space
+      - name: Free disk space 🧹
+        if: contains(inputs.variant, 'cuda') && inputs.platform == 'x86_64'
+        uses: jlumbroso/free-disk-space@54081f138730dfa15788a46383842cd2f914a1be
+        with:
+          tool-cache: false
+          android: true
+          dotnet: true
+          haskell: true
+          large-packages: false
+          docker-images: false
+          swap-storage: false
+
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v4
       - name: Create dev environment 📦
@@ -36,6 +53,7 @@ jobs:
         with:
           image: ${{ inputs.image }}
           platform: ${{ inputs.platform }}
+          variant: ${{ inputs.variant }}
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
@@ -48,10 +66,10 @@ jobs:
       - name: Download tags file 📥
         uses: actions/download-artifact@v4
         with:
-          name: ${{ inputs.image }}-${{ inputs.platform }}-tags
+          name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-tags
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
-        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --variant ${{ inputs.variant }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
       # This step is needed to prevent pushing non-multi-arch ""latest"" tag
       - name: Remove the ""latest"" tag from the image 🗑️
         run: docker image rmi ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}:latest",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index a38058c7..22a34b70 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -216,6 +216,28 @@ jobs:
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
+  x86_64-pytorch-cuda11:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: pytorch-notebook
+      variant: cuda11
+      platform: x86_64
+      runs-on: ubuntu-latest
+    needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
+  x86_64-pytorch-cuda12:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: pytorch-notebook
+      variant: cuda12
+      platform: x86_64
+      runs-on: ubuntu-latest
+    needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
   aarch64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
@@ -280,25 +302,26 @@ jobs:
     uses: ./.github/workflows/docker-tag-push.yml
     with:
       platform: aarch64
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image:
+        image-variant:
           [
-            docker-stacks-foundation,
-            base-notebook,
-            minimal-notebook,
-            scipy-notebook,
-            r-notebook,
-            julia-notebook,
-            tensorflow-notebook,
-            pytorch-notebook,
-            datascience-notebook,
-            pyspark-notebook,
-            all-spark-notebook,
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+            { image: minimal-notebook, variant: default },
+            { image: scipy-notebook, variant: default },
+            { image: r-notebook, variant: default },
+            { image: julia-notebook, variant: default },
+            { image: tensorflow-notebook, variant: default },
+            { image: pytorch-notebook, variant: default },
+            { image: datascience-notebook, variant: default },
+            { image: pyspark-notebook, variant: default },
+            { image: all-spark-notebook, variant: default },
           ]
     needs:
       [
@@ -320,13 +343,18 @@ jobs:
     uses: ./.github/workflows/docker-tag-push.yml
     with:
       platform: aarch64
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image: [docker-stacks-foundation, base-notebook]
+        image-variant:
+          [
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+          ]
     needs: [aarch64-foundation, aarch64-base]
     if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -334,25 +362,28 @@ jobs:
     uses: ./.github/workflows/docker-tag-push.yml
     with:
       platform: x86_64
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image:
+        image-variant:
           [
-            docker-stacks-foundation,
-            base-notebook,
-            minimal-notebook,
-            scipy-notebook,
-            r-notebook,
-            julia-notebook,
-            tensorflow-notebook,
-            pytorch-notebook,
-            datascience-notebook,
-            pyspark-notebook,
-            all-spark-notebook,
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+            { image: minimal-notebook, variant: default },
+            { image: scipy-notebook, variant: default },
+            { image: r-notebook, variant: default },
+            { image: julia-notebook, variant: default },
+            { image: tensorflow-notebook, variant: default },
+            { image: pytorch-notebook, variant: default },
+            { image: pytorch-notebook, variant: cuda11 },
+            { image: pytorch-notebook, variant: cuda12 },
+            { image: datascience-notebook, variant: default },
+            { image: pyspark-notebook, variant: default },
+            { image: all-spark-notebook, variant: default },
           ]
     needs:
       [
@@ -374,54 +405,75 @@ jobs:
     uses: ./.github/workflows/docker-tag-push.yml
     with:
       platform: x86_64
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image: [docker-stacks-foundation, base-notebook]
+        image-variant:
+          [
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+          ]
     needs: [x86_64-foundation, x86_64-base]
     if: contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   merge-tags:
     uses: ./.github/workflows/docker-merge-tags.yml
     with:
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image:
+        image-variant:
           [
-            docker-stacks-foundation,
-            base-notebook,
-            minimal-notebook,
-            scipy-notebook,
-            r-notebook,
-            julia-notebook,
-            tensorflow-notebook,
-            pytorch-notebook,
-            datascience-notebook,
-            pyspark-notebook,
-            all-spark-notebook,
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+            { image: minimal-notebook, variant: default },
+            { image: scipy-notebook, variant: default },
+            { image: r-notebook, variant: default },
+            { image: julia-notebook, variant: default },
+            { image: tensorflow-notebook, variant: default },
+            { image: pytorch-notebook, variant: default },
+            { image: pytorch-notebook, variant: cuda11 },
+            { image: pytorch-notebook, variant: cuda12 },
+            { image: datascience-notebook, variant: default },
+            { image: pyspark-notebook, variant: default },
+            { image: all-spark-notebook, variant: default },
           ]
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+    if: |
+      always() &&
+      needs.x86_64-images-tag-push.result == 'success' &&
+      (needs.aarch64-images-tag-push.result == 'success' || needs.aarch64-images-tag-push.result == 'skipped') &&
+      !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   merge-tags-fast:
     uses: ./.github/workflows/docker-merge-tags.yml
     with:
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image: [docker-stacks-foundation, base-notebook]
+        image-variant:
+          [
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+          ]
     needs: [aarch64-images-tag-push-fast, x86_64-images-tag-push-fast]
-    if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
+    if: |
+      always() &&
+      needs.x86_64-images-tag-push-fast.result == 'success' &&
+      (needs.aarch64-images-tag-push-fast.result == 'success' || needs.aarch64-images-tag-push-fast.result == 'skipped') &&
+      contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   wiki-update:
     uses: ./.github/workflows/docker-wiki-update.yml","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index a38058c7..22a34b70 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -216,6 +216,28 @@ jobs:
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
+  x86_64-pytorch-cuda11:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: pytorch-notebook
+      variant: cuda11
+      platform: x86_64
+      runs-on: ubuntu-latest
+    needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
+  x86_64-pytorch-cuda12:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: pytorch-notebook
+      variant: cuda12
+      platform: x86_64
+      runs-on: ubuntu-latest
+    needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
   aarch64-datascience:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
@@ -280,25 +302,26 @@ jobs:
     uses: ./.github/workflows/docker-tag-push.yml
     with:
       platform: aarch64
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image:
+        image-variant:
           [
-            docker-stacks-foundation,
-            base-notebook,
-            minimal-notebook,
-            scipy-notebook,
-            r-notebook,
-            julia-notebook,
-            tensorflow-notebook,
-            pytorch-notebook,
-            datascience-notebook,
-            pyspark-notebook,
-            all-spark-notebook,
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+            { image: minimal-notebook, variant: default },
+            { image: scipy-notebook, variant: default },
+            { image: r-notebook, variant: default },
+            { image: julia-notebook, variant: default },
+            { image: tensorflow-notebook, variant: default },
+            { image: pytorch-notebook, variant: default },
+            { image: datascience-notebook, variant: default },
+            { image: pyspark-notebook, variant: default },
+            { image: all-spark-notebook, variant: default },
           ]
     needs:
       [
@@ -320,13 +343,18 @@ jobs:
     uses: ./.github/workflows/docker-tag-push.yml
     with:
       platform: aarch64
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image: [docker-stacks-foundation, base-notebook]
+        image-variant:
+          [
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+          ]
     needs: [aarch64-foundation, aarch64-base]
     if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
 
@@ -334,25 +362,28 @@ jobs:
     uses: ./.github/workflows/docker-tag-push.yml
     with:
       platform: x86_64
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image:
+        image-variant:
           [
-            docker-stacks-foundation,
-            base-notebook,
-            minimal-notebook,
-            scipy-notebook,
-            r-notebook,
-            julia-notebook,
-            tensorflow-notebook,
-            pytorch-notebook,
-            datascience-notebook,
-            pyspark-notebook,
-            all-spark-notebook,
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+            { image: minimal-notebook, variant: default },
+            { image: scipy-notebook, variant: default },
+            { image: r-notebook, variant: default },
+            { image: julia-notebook, variant: default },
+            { image: tensorflow-notebook, variant: default },
+            { image: pytorch-notebook, variant: default },
+            { image: pytorch-notebook, variant: cuda11 },
+            { image: pytorch-notebook, variant: cuda12 },
+            { image: datascience-notebook, variant: default },
+            { image: pyspark-notebook, variant: default },
+            { image: all-spark-notebook, variant: default },
           ]
     needs:
       [
@@ -374,54 +405,75 @@ jobs:
     uses: ./.github/workflows/docker-tag-push.yml
     with:
       platform: x86_64
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image: [docker-stacks-foundation, base-notebook]
+        image-variant:
+          [
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+          ]
     needs: [x86_64-foundation, x86_64-base]
     if: contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   merge-tags:
     uses: ./.github/workflows/docker-merge-tags.yml
     with:
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image:
+        image-variant:
           [
-            docker-stacks-foundation,
-            base-notebook,
-            minimal-notebook,
-            scipy-notebook,
-            r-notebook,
-            julia-notebook,
-            tensorflow-notebook,
-            pytorch-notebook,
-            datascience-notebook,
-            pyspark-notebook,
-            all-spark-notebook,
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+            { image: minimal-notebook, variant: default },
+            { image: scipy-notebook, variant: default },
+            { image: r-notebook, variant: default },
+            { image: julia-notebook, variant: default },
+            { image: tensorflow-notebook, variant: default },
+            { image: pytorch-notebook, variant: default },
+            { image: pytorch-notebook, variant: cuda11 },
+            { image: pytorch-notebook, variant: cuda12 },
+            { image: datascience-notebook, variant: default },
+            { image: pyspark-notebook, variant: default },
+            { image: all-spark-notebook, variant: default },
           ]
     needs: [aarch64-images-tag-push, x86_64-images-tag-push]
-    if: github.repository_owner == 'jupyter' && !contains(github.event.pull_request.title, '[FAST_BUILD]')
+    if: |
+      always() &&
+      needs.x86_64-images-tag-push.result == 'success' &&
+      (needs.aarch64-images-tag-push.result == 'success' || needs.aarch64-images-tag-push.result == 'skipped') &&
+      !contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   merge-tags-fast:
     uses: ./.github/workflows/docker-merge-tags.yml
     with:
-      image: ${{ matrix.image }}
+      image: ${{ matrix.image-variant.image }}
+      variant: ${{ matrix.image-variant.variant }}
     secrets:
       REGISTRY_USERNAME: ${{ secrets.QUAY_USERNAME }}
       REGISTRY_TOKEN: ${{ secrets.QUAY_ROBOT_TOKEN }}
     strategy:
       matrix:
-        image: [docker-stacks-foundation, base-notebook]
+        image-variant:
+          [
+            { image: docker-stacks-foundation, variant: default },
+            { image: base-notebook, variant: default },
+          ]
     needs: [aarch64-images-tag-push-fast, x86_64-images-tag-push-fast]
-    if: github.repository_owner == 'jupyter' && contains(github.event.pull_request.title, '[FAST_BUILD]')
+    if: |
+      always() &&
+      needs.x86_64-images-tag-push-fast.result == 'success' &&
+      (needs.aarch64-images-tag-push-fast.result == 'success' || needs.aarch64-images-tag-push-fast.result == 'skipped') &&
+      contains(github.event.pull_request.title, '[FAST_BUILD]')
 
   wiki-update:
     uses: ./.github/workflows/docker-wiki-update.yml",Yes
Makefile,Makefile,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/Makefile b/Makefile
index 63c8eb44..98fa4d65 100644
--- a/Makefile
+++ b/Makefile
@@ -68,10 +68,11 @@ linkcheck-docs: ## check broken links
 
 
 
+hook/%: VARIANT?=default
 hook/%: ## run post-build hooks for an image
-	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
+	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)"" && \
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)"" && \
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --variant ""$(VARIANT)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images","diff --git a/Makefile b/Makefile
index 63c8eb44..98fa4d65 100644
--- a/Makefile
+++ b/Makefile
@@ -68,10 +68,11 @@ linkcheck-docs: ## check broken links
 
 
 
+hook/%: VARIANT?=default
 hook/%: ## run post-build hooks for an image
-	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" && \
-	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
+	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)"" && \
+	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)"" && \
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --variant ""$(VARIANT)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images",Yes
docs/using/selecting.md,docs/using/selecting.md,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index d44f4562..8d03fa5e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -197,6 +197,8 @@ It contains:
 - Everything in `jupyter/scipy-notebook` and its ancestor images
 - [pytorch](https://pytorch.org/) machine learning library
 
+> **GPU Acceleration:** Append a CUDA version prefix (`cuda11-` for CUDA 11 or `cuda12-` for CUDA 12) to the image tag to allow PyTorch operations to use compatible NVIDIA GPUs for accelerated computation.
+
 ### jupyter/datascience-notebook
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |
@@ -317,7 +319,7 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 [almond]: https://almond.sh
 [almond_b]: https://mybinder.org/v2/gh/almond-sh/examples/master?urlpath=lab%2Ftree%2Fnotebooks%2Findex.ipynb
 
-### GPU-accelerated notebooks
+### Other GPU-accelerated notebooks
 
 | Flavor             | Description                                                                                                                                                                                                                                                                                                                                                  |
 | ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index d44f4562..8d03fa5e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -197,6 +197,8 @@ It contains:
 - Everything in `jupyter/scipy-notebook` and its ancestor images
 - [pytorch](https://pytorch.org/) machine learning library
 
+> **GPU Acceleration:** Append a CUDA version prefix (`cuda11-` for CUDA 11 or `cuda12-` for CUDA 12) to the image tag to allow PyTorch operations to use compatible NVIDIA GPUs for accelerated computation.
+
 ### jupyter/datascience-notebook
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |
@@ -317,7 +319,7 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 [almond]: https://almond.sh
 [almond_b]: https://mybinder.org/v2/gh/almond-sh/examples/master?urlpath=lab%2Ftree%2Fnotebooks%2Findex.ipynb
 
-### GPU-accelerated notebooks
+### Other GPU-accelerated notebooks
 
 | Flavor             | Description                                                                                                                                                                                                                                                                                                                                                  |
 | ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |",Yes
images/pytorch-notebook/Dockerfile,images/pytorch-notebook/Dockerfile,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/images/pytorch-notebook/Dockerfile b/images/pytorch-notebook/Dockerfile
index f1a5c540..922e6389 100644
--- a/images/pytorch-notebook/Dockerfile
+++ b/images/pytorch-notebook/Dockerfile
@@ -11,7 +11,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-# Install PyTorch with pip
+# Install PyTorch with pip (https://pytorch.org/get-started/locally/)
 # hadolint ignore=DL3013
 RUN pip install --no-cache-dir --index-url 'https://download.pytorch.org/whl/cpu' \
     'torch' \","diff --git a/images/pytorch-notebook/Dockerfile b/images/pytorch-notebook/Dockerfile
index f1a5c540..922e6389 100644
--- a/images/pytorch-notebook/Dockerfile
+++ b/images/pytorch-notebook/Dockerfile
@@ -11,7 +11,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-# Install PyTorch with pip
+# Install PyTorch with pip (https://pytorch.org/get-started/locally/)
 # hadolint ignore=DL3013
 RUN pip install --no-cache-dir --index-url 'https://download.pytorch.org/whl/cpu' \
     'torch' \",Yes
,images/pytorch-notebook/cuda11/Dockerfile,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
new file mode 100644
index 00000000..de0ef1ec
--- /dev/null
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -0,0 +1,25 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=quay.io
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install PyTorch with pip (https://pytorch.org/get-started/locally/)
+# hadolint ignore=DL3013
+RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu118' \
+    'torch' \
+    'torchvision' \
+    'torchaudio'  && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
+ENV NVIDIA_VISIBLE_DEVICES all
+ENV NVIDIA_DRIVER_CAPABILITIES compute,utility","diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
new file mode 100644
index 00000000..de0ef1ec
--- /dev/null
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -0,0 +1,25 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=quay.io
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install PyTorch with pip (https://pytorch.org/get-started/locally/)
+# hadolint ignore=DL3013
+RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu118' \
+    'torch' \
+    'torchvision' \
+    'torchaudio'  && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
+ENV NVIDIA_VISIBLE_DEVICES all
+ENV NVIDIA_DRIVER_CAPABILITIES compute,utility",Yes
,images/pytorch-notebook/cuda12/Dockerfile,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
new file mode 100644
index 00000000..c574e42d
--- /dev/null
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -0,0 +1,25 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=quay.io
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install PyTorch with pip (https://pytorch.org/get-started/locally/)
+# hadolint ignore=DL3013
+RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu121' \
+    'torch' \
+    'torchvision' \
+    'torchaudio'  && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
+ENV NVIDIA_VISIBLE_DEVICES all
+ENV NVIDIA_DRIVER_CAPABILITIES compute,utility","diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
new file mode 100644
index 00000000..c574e42d
--- /dev/null
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -0,0 +1,25 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=quay.io
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install PyTorch with pip (https://pytorch.org/get-started/locally/)
+# hadolint ignore=DL3013
+RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu121' \
+    'torch' \
+    'torchvision' \
+    'torchaudio'  && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
+ENV NVIDIA_VISIBLE_DEVICES all
+ENV NVIDIA_DRIVER_CAPABILITIES compute,utility",Yes
tagging/apply_tags.py,tagging/apply_tags.py,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 1c33a8fe..9c50cd0e 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -8,6 +8,7 @@ from pathlib import Path
 import plumbum
 
 from tagging.get_platform import unify_aarch64
+from tagging.get_prefix import get_file_prefix_for_platform
 
 docker = plumbum.local[""docker""]
 
@@ -20,14 +21,16 @@ def apply_tags(
     owner: str,
     tags_dir: Path,
     platform: str,
+    variant: str,
 ) -> None:
     """"""
     Tags <registry>/<owner>/<short_image_name>:latest with the tags reported by all taggers for this image
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")
 
+    file_prefix = get_file_prefix_for_platform(platform, variant)
     image = f""{registry}/{owner}/{short_image_name}:latest""
-    filename = f""{platform}-{short_image_name}.txt""
+    filename = f""{file_prefix}-{short_image_name}.txt""
     tags = (tags_dir / filename).read_text().splitlines()
 
     for tag in tags:
@@ -69,9 +72,19 @@ if __name__ == ""__main__"":
         required=True,
         help=""Owner of the image"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     args = arg_parser.parse_args()
     args.platform = unify_aarch64(args.platform)
 
     apply_tags(
-        args.short_image_name, args.registry, args.owner, args.tags_dir, args.platform
+        args.short_image_name,
+        args.registry,
+        args.owner,
+        args.tags_dir,
+        args.platform,
+        args.variant,
     )","diff --git a/tagging/apply_tags.py b/tagging/apply_tags.py
index 1c33a8fe..9c50cd0e 100755
--- a/tagging/apply_tags.py
+++ b/tagging/apply_tags.py
@@ -8,6 +8,7 @@ from pathlib import Path
 import plumbum
 
 from tagging.get_platform import unify_aarch64
+from tagging.get_prefix import get_file_prefix_for_platform
 
 docker = plumbum.local[""docker""]
 
@@ -20,14 +21,16 @@ def apply_tags(
     owner: str,
     tags_dir: Path,
     platform: str,
+    variant: str,
 ) -> None:
     """"""
     Tags <registry>/<owner>/<short_image_name>:latest with the tags reported by all taggers for this image
     """"""
     LOGGER.info(f""Tagging image: {short_image_name}"")
 
+    file_prefix = get_file_prefix_for_platform(platform, variant)
     image = f""{registry}/{owner}/{short_image_name}:latest""
-    filename = f""{platform}-{short_image_name}.txt""
+    filename = f""{file_prefix}-{short_image_name}.txt""
     tags = (tags_dir / filename).read_text().splitlines()
 
     for tag in tags:
@@ -69,9 +72,19 @@ if __name__ == ""__main__"":
         required=True,
         help=""Owner of the image"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     args = arg_parser.parse_args()
     args.platform = unify_aarch64(args.platform)
 
     apply_tags(
-        args.short_image_name, args.registry, args.owner, args.tags_dir, args.platform
+        args.short_image_name,
+        args.registry,
+        args.owner,
+        args.tags_dir,
+        args.platform,
+        args.variant,
     )",Yes
,tagging/get_prefix.py,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/tagging/get_prefix.py b/tagging/get_prefix.py
new file mode 100644
index 00000000..6e7c7185
--- /dev/null
+++ b/tagging/get_prefix.py
@@ -0,0 +1,25 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+from tagging.get_platform import get_platform
+
+DEFAULT_VARIANT = ""default""
+
+
+def get_file_prefix_for_platform(platform: str, variant: str) -> str:
+    return f""{platform}-{variant}""
+
+
+def get_tag_prefix_for_platform(platform: str, variant: str) -> str:
+    if variant == DEFAULT_VARIANT:
+        return platform
+    return f""{platform}-{variant}""
+
+
+def get_file_prefix(variant: str) -> str:
+    platform = get_platform()
+    return get_file_prefix_for_platform(platform, variant)
+
+
+def get_tag_prefix(variant: str) -> str:
+    platform = get_platform()
+    return get_tag_prefix_for_platform(platform, variant)","diff --git a/tagging/get_prefix.py b/tagging/get_prefix.py
new file mode 100644
index 00000000..6e7c7185
--- /dev/null
+++ b/tagging/get_prefix.py
@@ -0,0 +1,25 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+from tagging.get_platform import get_platform
+
+DEFAULT_VARIANT = ""default""
+
+
+def get_file_prefix_for_platform(platform: str, variant: str) -> str:
+    return f""{platform}-{variant}""
+
+
+def get_tag_prefix_for_platform(platform: str, variant: str) -> str:
+    if variant == DEFAULT_VARIANT:
+        return platform
+    return f""{platform}-{variant}""
+
+
+def get_file_prefix(variant: str) -> str:
+    platform = get_platform()
+    return get_file_prefix_for_platform(platform, variant)
+
+
+def get_tag_prefix(variant: str) -> str:
+    platform = get_platform()
+    return get_tag_prefix_for_platform(platform, variant)",Yes
tagging/merge_tags.py,tagging/merge_tags.py,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/tagging/merge_tags.py b/tagging/merge_tags.py
index 885a4821..06b18e70 100755
--- a/tagging/merge_tags.py
+++ b/tagging/merge_tags.py
@@ -8,6 +8,7 @@ from pathlib import Path
 import plumbum
 
 from tagging.get_platform import ALL_PLATFORMS
+from tagging.get_prefix import get_file_prefix_for_platform
 
 docker = plumbum.local[""docker""]
 
@@ -16,6 +17,7 @@ LOGGER = logging.getLogger(__name__)
 
 def merge_tags(
     short_image_name: str,
+    variant: str,
     tags_dir: Path,
 ) -> None:
     """"""
@@ -26,9 +28,12 @@ def merge_tags(
     all_tags: set[str] = set()
 
     for platform in ALL_PLATFORMS:
-        filename = f""{platform}-{short_image_name}.txt""
-        tags = (tags_dir / filename).read_text().splitlines()
-        all_tags.update(tag.replace(platform + ""-"", """") for tag in tags)
+        file_prefix = get_file_prefix_for_platform(platform, variant)
+        filename = f""{file_prefix}-{short_image_name}.txt""
+        file_path = tags_dir / filename
+        if file_path.exists():
+            tags = file_path.read_text().splitlines()
+            all_tags.update(tag.replace(platform + ""-"", """") for tag in tags)
 
     LOGGER.info(f""Got tags: {all_tags}"")
 
@@ -61,6 +66,11 @@ if __name__ == ""__main__"":
         required=True,
         help=""Short image name"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     arg_parser.add_argument(
         ""--tags-dir"",
         required=True,
@@ -69,4 +79,4 @@ if __name__ == ""__main__"":
     )
     args = arg_parser.parse_args()
 
-    merge_tags(args.short_image_name, args.tags_dir)
+    merge_tags(args.short_image_name, args.variant, args.tags_dir)","diff --git a/tagging/merge_tags.py b/tagging/merge_tags.py
index 885a4821..06b18e70 100755
--- a/tagging/merge_tags.py
+++ b/tagging/merge_tags.py
@@ -8,6 +8,7 @@ from pathlib import Path
 import plumbum
 
 from tagging.get_platform import ALL_PLATFORMS
+from tagging.get_prefix import get_file_prefix_for_platform
 
 docker = plumbum.local[""docker""]
 
@@ -16,6 +17,7 @@ LOGGER = logging.getLogger(__name__)
 
 def merge_tags(
     short_image_name: str,
+    variant: str,
     tags_dir: Path,
 ) -> None:
     """"""
@@ -26,9 +28,12 @@ def merge_tags(
     all_tags: set[str] = set()
 
     for platform in ALL_PLATFORMS:
-        filename = f""{platform}-{short_image_name}.txt""
-        tags = (tags_dir / filename).read_text().splitlines()
-        all_tags.update(tag.replace(platform + ""-"", """") for tag in tags)
+        file_prefix = get_file_prefix_for_platform(platform, variant)
+        filename = f""{file_prefix}-{short_image_name}.txt""
+        file_path = tags_dir / filename
+        if file_path.exists():
+            tags = file_path.read_text().splitlines()
+            all_tags.update(tag.replace(platform + ""-"", """") for tag in tags)
 
     LOGGER.info(f""Got tags: {all_tags}"")
 
@@ -61,6 +66,11 @@ if __name__ == ""__main__"":
         required=True,
         help=""Short image name"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     arg_parser.add_argument(
         ""--tags-dir"",
         required=True,
@@ -69,4 +79,4 @@ if __name__ == ""__main__"":
     )
     args = arg_parser.parse_args()
 
-    merge_tags(args.short_image_name, args.tags_dir)
+    merge_tags(args.short_image_name, args.variant, args.tags_dir)",Yes
tagging/write_manifest.py,tagging/write_manifest.py,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index c4605fd7..cdf51a77 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -9,7 +9,7 @@ from pathlib import Path
 from docker.models.containers import Container
 
 from tagging.docker_runner import DockerRunner
-from tagging.get_platform import get_platform
+from tagging.get_prefix import get_file_prefix, get_tag_prefix
 from tagging.get_taggers_and_manifests import get_taggers_and_manifests
 from tagging.git_helper import GitHelper
 from tagging.manifests import ManifestHeader, ManifestInterface
@@ -73,6 +73,7 @@ def write_manifest(
     short_image_name: str,
     registry: str,
     owner: str,
+    variant: str,
     hist_lines_dir: Path,
     manifests_dir: Path,
 ) -> None:
@@ -81,12 +82,12 @@ def write_manifest(
 
     image = f""{registry}/{owner}/{short_image_name}:latest""
 
-    file_prefix = get_platform()
+    file_prefix = get_file_prefix(variant)
     commit_hash_tag = GitHelper.commit_hash_tag()
     filename = f""{file_prefix}-{short_image_name}-{commit_hash_tag}""
 
     with DockerRunner(image) as container:
-        tags_prefix = get_platform()
+        tags_prefix = get_tag_prefix(variant)
         all_tags = [
             tags_prefix + ""-"" + tagger.tag_value(container) for tagger in taggers
         ]
@@ -137,6 +138,11 @@ if __name__ == ""__main__"":
         required=True,
         help=""Owner of the image"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     args = arg_parser.parse_args()
 
     LOGGER.info(f""Current build timestamp: {BUILD_TIMESTAMP}"")
@@ -145,6 +151,7 @@ if __name__ == ""__main__"":
         args.short_image_name,
         args.registry,
         args.owner,
+        args.variant,
         args.hist_lines_dir,
         args.manifests_dir,
     )","diff --git a/tagging/write_manifest.py b/tagging/write_manifest.py
index c4605fd7..cdf51a77 100755
--- a/tagging/write_manifest.py
+++ b/tagging/write_manifest.py
@@ -9,7 +9,7 @@ from pathlib import Path
 from docker.models.containers import Container
 
 from tagging.docker_runner import DockerRunner
-from tagging.get_platform import get_platform
+from tagging.get_prefix import get_file_prefix, get_tag_prefix
 from tagging.get_taggers_and_manifests import get_taggers_and_manifests
 from tagging.git_helper import GitHelper
 from tagging.manifests import ManifestHeader, ManifestInterface
@@ -73,6 +73,7 @@ def write_manifest(
     short_image_name: str,
     registry: str,
     owner: str,
+    variant: str,
     hist_lines_dir: Path,
     manifests_dir: Path,
 ) -> None:
@@ -81,12 +82,12 @@ def write_manifest(
 
     image = f""{registry}/{owner}/{short_image_name}:latest""
 
-    file_prefix = get_platform()
+    file_prefix = get_file_prefix(variant)
     commit_hash_tag = GitHelper.commit_hash_tag()
     filename = f""{file_prefix}-{short_image_name}-{commit_hash_tag}""
 
     with DockerRunner(image) as container:
-        tags_prefix = get_platform()
+        tags_prefix = get_tag_prefix(variant)
         all_tags = [
             tags_prefix + ""-"" + tagger.tag_value(container) for tagger in taggers
         ]
@@ -137,6 +138,11 @@ if __name__ == ""__main__"":
         required=True,
         help=""Owner of the image"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     args = arg_parser.parse_args()
 
     LOGGER.info(f""Current build timestamp: {BUILD_TIMESTAMP}"")
@@ -145,6 +151,7 @@ if __name__ == ""__main__"":
         args.short_image_name,
         args.registry,
         args.owner,
+        args.variant,
         args.hist_lines_dir,
         args.manifests_dir,
     )",Yes
tagging/write_tags_file.py,tagging/write_tags_file.py,eccda243c30a7d85a6313b99648a3e7bc39b215e,fe2195458f5176b36e3f4da228fbfa8011976a3c,"Add pytorch-notebook image variants with cuda 11 and 12 (x86_64 versions only) (#2091)

* feat: build cuda variants of pytorch

* feat: build with variant tag

* style: remove unused import

* refactor: rename get_prefix params

(cherry picked from commit 12b50af258c2f331d4100fb63fd41ad1a30acb1d)

* revert: drop ROOT_CONTAINER addition from Makefile

(cherry picked from commit f42314513df2855957a05c6ba0c748d2df26d7b0)

* style: use consistent three empty lines in Makefile

(cherry picked from commit 446b45aab37a37720462b5df305ce96b139cf67a)

* refactor: add default value for parent-image

(cherry picked from commit 32955cec99c7202f0ce50647dfc61ec98f57f741)

* revert: use original workflow structure

(cherry picked from commit 68c6744513636ec93d14f9bd0bbd123907efd13b)

* refactor: use single build image step

(cherry picked from commit 5f1ac0aeedcb5969a6d4b2a5bc939817378ab55d)

* fix: run merge tags regardless of repository owner

(cherry picked from commit 3fce366a98adc5db0d127f28ddf3157d13297a0f)

* refactor: build cuda12 instead of cuda tag

(cherry picked from commit 217144ecd322356376f04efb92792a20b4380177)

* docs: add note about CUDA tags to documentation

* refactor: add default value for variant in build-test-upload

* refactor: swap ordering of cuda11/cuda12 variants

* refactor: remove optional str type in arg parser

* fix: add proper env variables to CUDA Dockerfiles

* fix: remove CUDA build for aarch64

* fix: use latest NVIDIA documentation link

* fix: skip aarch64 tags file for CUDA variants

---------

Co-authored-by: zynaa <7562909-zynaa@users.noreply.gitlab.com>","diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index 880fec40..21c127cd 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -6,7 +6,7 @@ import logging
 from pathlib import Path
 
 from tagging.docker_runner import DockerRunner
-from tagging.get_platform import get_platform
+from tagging.get_prefix import get_file_prefix, get_tag_prefix
 from tagging.get_taggers_and_manifests import get_taggers_and_manifests
 
 LOGGER = logging.getLogger(__name__)
@@ -16,6 +16,7 @@ def write_tags_file(
     short_image_name: str,
     registry: str,
     owner: str,
+    variant: str,
     tags_dir: Path,
 ) -> None:
     """"""
@@ -25,9 +26,10 @@ def write_tags_file(
     taggers, _ = get_taggers_and_manifests(short_image_name)
 
     image = f""{registry}/{owner}/{short_image_name}:latest""
-    tags_prefix = get_platform()
-    filename = f""{tags_prefix}-{short_image_name}.txt""
+    file_prefix = get_file_prefix(variant)
+    filename = f""{file_prefix}-{short_image_name}.txt""
 
+    tags_prefix = get_tag_prefix(variant)
     tags = [f""{registry}/{owner}/{short_image_name}:{tags_prefix}-latest""]
     with DockerRunner(image) as container:
         for tagger in taggers:
@@ -70,6 +72,17 @@ if __name__ == ""__main__"":
         required=True,
         help=""Owner of the image"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     args = arg_parser.parse_args()
 
-    write_tags_file(args.short_image_name, args.registry, args.owner, args.tags_dir)
+    write_tags_file(
+        args.short_image_name,
+        args.registry,
+        args.owner,
+        args.variant,
+        args.tags_dir,
+    )","diff --git a/tagging/write_tags_file.py b/tagging/write_tags_file.py
index 880fec40..21c127cd 100755
--- a/tagging/write_tags_file.py
+++ b/tagging/write_tags_file.py
@@ -6,7 +6,7 @@ import logging
 from pathlib import Path
 
 from tagging.docker_runner import DockerRunner
-from tagging.get_platform import get_platform
+from tagging.get_prefix import get_file_prefix, get_tag_prefix
 from tagging.get_taggers_and_manifests import get_taggers_and_manifests
 
 LOGGER = logging.getLogger(__name__)
@@ -16,6 +16,7 @@ def write_tags_file(
     short_image_name: str,
     registry: str,
     owner: str,
+    variant: str,
     tags_dir: Path,
 ) -> None:
     """"""
@@ -25,9 +26,10 @@ def write_tags_file(
     taggers, _ = get_taggers_and_manifests(short_image_name)
 
     image = f""{registry}/{owner}/{short_image_name}:latest""
-    tags_prefix = get_platform()
-    filename = f""{tags_prefix}-{short_image_name}.txt""
+    file_prefix = get_file_prefix(variant)
+    filename = f""{file_prefix}-{short_image_name}.txt""
 
+    tags_prefix = get_tag_prefix(variant)
     tags = [f""{registry}/{owner}/{short_image_name}:{tags_prefix}-latest""]
     with DockerRunner(image) as container:
         for tagger in taggers:
@@ -70,6 +72,17 @@ if __name__ == ""__main__"":
         required=True,
         help=""Owner of the image"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     args = arg_parser.parse_args()
 
-    write_tags_file(args.short_image_name, args.registry, args.owner, args.tags_dir)
+    write_tags_file(
+        args.short_image_name,
+        args.registry,
+        args.owner,
+        args.variant,
+        args.tags_dir,
+    )",Yes
README.md,README.md,315224efffd73322d3225893a4fcd7662854805a,eccda243c30a7d85a6313b99648a3e7bc39b215e,Fix redirect links,"diff --git a/README.md b/README.md
index 018bdff9..936a8bc9 100644
--- a/README.md
+++ b/README.md
@@ -61,11 +61,11 @@ The server logs appear in the terminal.
 
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab.
 
-Due to the usage of [the `--rm` flag](https://docs.docker.com/engine/reference/commandline/container_run/#rm)
+Due to the usage of [the `--rm` flag](https://docs.docker.com/reference/cli/docker/container/run/#rm)
 Docker automatically cleans up the container and removes the file system when the container exits,
 but any changes made to the `~/work` directory and its files in the container will remain intact on the host.
-[The `-i` flag](https://docs.docker.com/engine/reference/commandline/container_run/#interactive) keeps the container's `STDIN` open, and lets you send input to the container through standard input.
-[The `-t` flag](https://docs.docker.com/engine/reference/commandline/container_run/#tty) attaches a pseudo-TTY to the container.
+[The `-i` flag](https://docs.docker.com/reference/cli/docker/container/run/#interactive) keeps the container's `STDIN` open, and lets you send input to the container through standard input.
+[The `-t` flag](https://docs.docker.com/reference/cli/docker/container/run/#tty) attaches a pseudo-TTY to the container.
 
 ```{note}
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.","diff --git a/README.md b/README.md
index 018bdff9..936a8bc9 100644
--- a/README.md
+++ b/README.md
@@ -61,11 +61,11 @@ The server logs appear in the terminal.
 
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab.
 
-Due to the usage of [the `--rm` flag](https://docs.docker.com/engine/reference/commandline/container_run/#rm)
+Due to the usage of [the `--rm` flag](https://docs.docker.com/reference/cli/docker/container/run/#rm)
 Docker automatically cleans up the container and removes the file system when the container exits,
 but any changes made to the `~/work` directory and its files in the container will remain intact on the host.
-[The `-i` flag](https://docs.docker.com/engine/reference/commandline/container_run/#interactive) keeps the container's `STDIN` open, and lets you send input to the container through standard input.
-[The `-t` flag](https://docs.docker.com/engine/reference/commandline/container_run/#tty) attaches a pseudo-TTY to the container.
+[The `-i` flag](https://docs.docker.com/reference/cli/docker/container/run/#interactive) keeps the container's `STDIN` open, and lets you send input to the container through standard input.
+[The `-t` flag](https://docs.docker.com/reference/cli/docker/container/run/#tty) attaches a pseudo-TTY to the container.
 
 ```{note}
 By default, [jupyter's root_dir](https://jupyter-server.readthedocs.io/en/latest/other/full-config.html) is `/home/jovyan`.",Yes
README.md,README.md,0d7cc47609c26bc6945c5d1b61e33777687a0263,315224efffd73322d3225893a4fcd7662854805a,Update example tag,"diff --git a/README.md b/README.md
index 936a8bc9..2f83b00e 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-15
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-02-24
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-01-15
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-02-24
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index 936a8bc9..2f83b00e 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-01-15
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-02-24
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-01-15
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-02-24
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,0d7cc47609c26bc6945c5d1b61e33777687a0263,315224efffd73322d3225893a4fcd7662854805a,Update example tag,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index cad1fd47..dd06527c 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-01-15
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-02-24
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-01-15""
+ENV TAG=""2024-02-24""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index cad1fd47..dd06527c 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-01-15
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-02-24
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-01-15""
+ENV TAG=""2024-02-24""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,0d7cc47609c26bc6945c5d1b61e33777687a0263,315224efffd73322d3225893a4fcd7662854805a,Update example tag,"diff --git a/docs/using/running.md b/docs/using/running.md
index b652b92a..becc8534 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-01-15
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-02-24
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-01-15   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-02-24   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-01-15
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-02-24
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-01-15
+    quay.io/jupyter/r-notebook:2024-02-24
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index b652b92a..becc8534 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-01-15
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-02-24
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-01-15   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-02-24   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-01-15
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-02-24
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-01-15` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-01-15
+    quay.io/jupyter/r-notebook:2024-02-24
 ```
 
 ```{warning}",Yes
README.md,README.md,d44add21d53f4e4730c1abee9f0d3c361ba54155,0d7cc47609c26bc6945c5d1b61e33777687a0263,Improve CUDA enabled images docs and add a policy (#2097),"diff --git a/README.md b/README.md
index 2f83b00e..d2b655af 100644
--- a/README.md
+++ b/README.md
@@ -101,6 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
+- Starting from `2024-02-24`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images","diff --git a/README.md b/README.md
index 2f83b00e..d2b655af 100644
--- a/README.md
+++ b/README.md
@@ -101,6 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
+- Starting from `2024-02-24`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images",Yes
docs/using/selecting.md,docs/using/selecting.md,d44add21d53f4e4730c1abee9f0d3c361ba54155,0d7cc47609c26bc6945c5d1b61e33777687a0263,Improve CUDA enabled images docs and add a policy (#2097),"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 8d03fa5e..ab720dec 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -16,6 +16,14 @@ This section provides details about the first.
 The Jupyter team maintains a set of Docker image definitions in the <https://github.com/jupyter/docker-stacks> GitHub repository.
 The following sections describe these images, including their contents, relationships, and versioning strategy.
 
+## CUDA enabled variant
+
+We provide CUDA accelerated version of `pytorch-notebook` image.
+Prepend a CUDA version prefix (like `cuda12-`) to the image tag to allow PyTorch operations to use compatible NVIDIA GPUs for accelerated computation.
+We only build images for 2 last major versions of CUDA.
+
+For example, you can use an image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8`
+
 ### jupyter/docker-stacks-foundation
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/docker-stacks-foundation) |
@@ -197,8 +205,6 @@ It contains:
 - Everything in `jupyter/scipy-notebook` and its ancestor images
 - [pytorch](https://pytorch.org/) machine learning library
 
-> **GPU Acceleration:** Append a CUDA version prefix (`cuda11-` for CUDA 11 or `cuda12-` for CUDA 12) to the image tag to allow PyTorch operations to use compatible NVIDIA GPUs for accelerated computation.
-
 ### jupyter/datascience-notebook
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 8d03fa5e..ab720dec 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -16,6 +16,14 @@ This section provides details about the first.
 The Jupyter team maintains a set of Docker image definitions in the <https://github.com/jupyter/docker-stacks> GitHub repository.
 The following sections describe these images, including their contents, relationships, and versioning strategy.
 
+## CUDA enabled variant
+
+We provide CUDA accelerated version of `pytorch-notebook` image.
+Prepend a CUDA version prefix (like `cuda12-`) to the image tag to allow PyTorch operations to use compatible NVIDIA GPUs for accelerated computation.
+We only build images for 2 last major versions of CUDA.
+
+For example, you can use an image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8`
+
 ### jupyter/docker-stacks-foundation
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/docker-stacks-foundation) |
@@ -197,8 +205,6 @@ It contains:
 - Everything in `jupyter/scipy-notebook` and its ancestor images
 - [pytorch](https://pytorch.org/) machine learning library
 
-> **GPU Acceleration:** Append a CUDA version prefix (`cuda11-` for CUDA 11 or `cuda12-` for CUDA 12) to the image tag to allow PyTorch operations to use compatible NVIDIA GPUs for accelerated computation.
-
 ### jupyter/datascience-notebook
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/datascience-notebook) |",Yes
docs/using/selecting.md,docs/using/selecting.md,07dc2d08734b384ab7370956d47909bda9bc928b,d44add21d53f4e4730c1abee9f0d3c361ba54155,Fix redirect links,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index ab720dec..28544e41 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -242,7 +242,7 @@ It contains:
 - Everything in `jupyter/pyspark-notebook` and its ancestor images
 - [IRKernel](https://irkernel.github.io/) to support R code in Jupyter notebooks
 - [rcurl](https://cran.r-project.org/web/packages/RCurl/index.html),
-  [sparklyr](https://spark.rstudio.com),
+  [sparklyr](https://spark.posit.co),
   [ggplot2](https://ggplot2.tidyverse.org)
   packages","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index ab720dec..28544e41 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -242,7 +242,7 @@ It contains:
 - Everything in `jupyter/pyspark-notebook` and its ancestor images
 - [IRKernel](https://irkernel.github.io/) to support R code in Jupyter notebooks
 - [rcurl](https://cran.r-project.org/web/packages/RCurl/index.html),
-  [sparklyr](https://spark.rstudio.com),
+  [sparklyr](https://spark.posit.co),
   [ggplot2](https://ggplot2.tidyverse.org)
   packages",Yes
docs/using/specifics.md,docs/using/specifics.md,07dc2d08734b384ab7370956d47909bda9bc928b,d44add21d53f4e4730c1abee9f0d3c361ba54155,Fix redirect links,"diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index c578e378..4df770f1 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -303,5 +303,5 @@ sess.run(hello)
 ```
 
 [sparkr]: https://spark.apache.org/docs/latest/sparkr.html
-[sparklyr]: https://spark.rstudio.com/
+[sparklyr]: https://spark.posit.co
 [spark-conf]: https://spark.apache.org/docs/latest/configuration.html","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index c578e378..4df770f1 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -303,5 +303,5 @@ sess.run(hello)
 ```
 
 [sparkr]: https://spark.apache.org/docs/latest/sparkr.html
-[sparklyr]: https://spark.rstudio.com/
+[sparklyr]: https://spark.posit.co
 [spark-conf]: https://spark.apache.org/docs/latest/configuration.html",Yes
README.md,README.md,ebea7a82009a75deec5a502ebf5712d8c0d7d2f1,07dc2d08734b384ab7370956d47909bda9bc928b,Update example tag,"diff --git a/README.md b/README.md
index d2b655af..448abab8 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-02-24
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-03-14
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-02-24
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-03-14
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -101,7 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-02-24`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-03-14`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images","diff --git a/README.md b/README.md
index d2b655af..448abab8 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-02-24
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-03-14
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-02-24
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-03-14
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -101,7 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-02-24`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-03-14`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images",Yes
binder/Dockerfile,binder/Dockerfile,ebea7a82009a75deec5a502ebf5712d8c0d7d2f1,07dc2d08734b384ab7370956d47909bda9bc928b,Update example tag,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index dd06527c..c64e159c 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-02-24
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-03-14
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-02-24""
+ENV TAG=""2024-03-14""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index dd06527c..c64e159c 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-02-24
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-03-14
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-02-24""
+ENV TAG=""2024-03-14""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,ebea7a82009a75deec5a502ebf5712d8c0d7d2f1,07dc2d08734b384ab7370956d47909bda9bc928b,Update example tag,"diff --git a/docs/using/running.md b/docs/using/running.md
index becc8534..50e9d917 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-02-24
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-03-14
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-02-24   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-03-14   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-02-24
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-03-14
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-02-24
+    quay.io/jupyter/r-notebook:2024-03-14
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index becc8534..50e9d917 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-02-24
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-03-14
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-02-24   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-03-14   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-02-24
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-03-14
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-02-24` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-02-24
+    quay.io/jupyter/r-notebook:2024-03-14
 ```
 
 ```{warning}",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,4bef1a8f1ca9635e1fa8a811c222b1a1a39eb3a3,ebea7a82009a75deec5a502ebf5712d8c0d7d2f1,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 5887d2ca..b9a0d66e 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.15.0
+    rev: v3.15.1
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.8.0
+    rev: v1.9.0
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -137,7 +137,7 @@ repos:
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.7.1
+    rev: 1.8.4
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 5887d2ca..b9a0d66e 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.15.0
+    rev: v3.15.1
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.8.0
+    rev: v1.9.0
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -137,7 +137,7 @@ repos:
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.7.1
+    rev: 1.8.4
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,dd06b93abc41a5de327f8fbe3e597e4ed4c1bc0d,4bef1a8f1ca9635e1fa8a811c222b1a1a39eb3a3,"Bump docker/login-action from 3.0.0 to 3.1.0 (#2102)

Bumps [docker/login-action](https://github.com/docker/login-action) from 3.0.0 to 3.1.0.
- [Release notes](https://github.com/docker/login-action/releases)
- [Commits](https://github.com/docker/login-action/compare/343f7c4344506bcbf9b4de18042ae17996df046d...e92390c5fb421da1463c202d546fed0ec5c39f20)

---
updated-dependencies:
- dependency-name: docker/login-action
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 07107a4c..8f2ec92c 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -54,7 +54,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
+        uses: docker/login-action@e92390c5fb421da1463c202d546fed0ec5c39f20 # v3.1.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 07107a4c..8f2ec92c 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -54,7 +54,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
+        uses: docker/login-action@e92390c5fb421da1463c202d546fed0ec5c39f20 # v3.1.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,dd06b93abc41a5de327f8fbe3e597e4ed4c1bc0d,4bef1a8f1ca9635e1fa8a811c222b1a1a39eb3a3,"Bump docker/login-action from 3.0.0 to 3.1.0 (#2102)

Bumps [docker/login-action](https://github.com/docker/login-action) from 3.0.0 to 3.1.0.
- [Release notes](https://github.com/docker/login-action/releases)
- [Commits](https://github.com/docker/login-action/compare/343f7c4344506bcbf9b4de18042ae17996df046d...e92390c5fb421da1463c202d546fed0ec5c39f20)

---
updated-dependencies:
- dependency-name: docker/login-action
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index c0093e69..7f82304c 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -57,7 +57,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
+        uses: docker/login-action@e92390c5fb421da1463c202d546fed0ec5c39f20 # v3.1.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index c0093e69..7f82304c 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -57,7 +57,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@343f7c4344506bcbf9b4de18042ae17996df046d # v3.0.0
+        uses: docker/login-action@e92390c5fb421da1463c202d546fed0ec5c39f20 # v3.1.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}",Yes
.github/workflows/docker.yml,.github/workflows/docker.yml,b9553a8e5d33a8d59eac52b0d8790d3f46f6f03c,dd06b93abc41a5de327f8fbe3e597e4ed4c1bc0d,"Add cuda12 variant of tensorflow-notebook (#2100)

* Add cuda12 variant for tensorflow-notebook

* Reduce size of CPU version of tensorflow-notebook

* Try to fix tests

* Update docs/using/selecting.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update images/tensorflow-notebook/cuda12/Dockerfile

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update tests/docker-stacks-foundation/test_packages.py

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Remove obsolete XLA_FLAGS env var

* Install CUDA and cuDNN using pip instead of mamba

* Fix pre-commit shell checks

* Change tensorflow variant name from cuda12 to cuda

* Update selecting.md

* Update selecting.md

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 22a34b70..e25d5e8b 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -196,6 +196,17 @@ jobs:
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
+  x86_64-tensorflow-cuda:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: tensorflow-notebook
+      variant: cuda
+      platform: x86_64
+      runs-on: ubuntu-latest
+    needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
   aarch64-pytorch:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
@@ -378,6 +389,7 @@ jobs:
             { image: r-notebook, variant: default },
             { image: julia-notebook, variant: default },
             { image: tensorflow-notebook, variant: default },
+            { image: tensorflow-notebook, variant: cuda },
             { image: pytorch-notebook, variant: default },
             { image: pytorch-notebook, variant: cuda11 },
             { image: pytorch-notebook, variant: cuda12 },
@@ -439,6 +451,7 @@ jobs:
             { image: r-notebook, variant: default },
             { image: julia-notebook, variant: default },
             { image: tensorflow-notebook, variant: default },
+            { image: tensorflow-notebook, variant: cuda },
             { image: pytorch-notebook, variant: default },
             { image: pytorch-notebook, variant: cuda11 },
             { image: pytorch-notebook, variant: cuda12 },","diff --git a/.github/workflows/docker.yml b/.github/workflows/docker.yml
index 22a34b70..e25d5e8b 100644
--- a/.github/workflows/docker.yml
+++ b/.github/workflows/docker.yml
@@ -196,6 +196,17 @@ jobs:
     needs: [x86_64-scipy]
     if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
 
+  x86_64-tensorflow-cuda:
+    uses: ./.github/workflows/docker-build-test-upload.yml
+    with:
+      parent-image: scipy-notebook
+      image: tensorflow-notebook
+      variant: cuda
+      platform: x86_64
+      runs-on: ubuntu-latest
+    needs: [x86_64-scipy]
+    if: ${{ !contains(github.event.pull_request.title, '[FAST_BUILD]') }}
+
   aarch64-pytorch:
     uses: ./.github/workflows/docker-build-test-upload.yml
     with:
@@ -378,6 +389,7 @@ jobs:
             { image: r-notebook, variant: default },
             { image: julia-notebook, variant: default },
             { image: tensorflow-notebook, variant: default },
+            { image: tensorflow-notebook, variant: cuda },
             { image: pytorch-notebook, variant: default },
             { image: pytorch-notebook, variant: cuda11 },
             { image: pytorch-notebook, variant: cuda12 },
@@ -439,6 +451,7 @@ jobs:
             { image: r-notebook, variant: default },
             { image: julia-notebook, variant: default },
             { image: tensorflow-notebook, variant: default },
+            { image: tensorflow-notebook, variant: cuda },
             { image: pytorch-notebook, variant: default },
             { image: pytorch-notebook, variant: cuda11 },
             { image: pytorch-notebook, variant: cuda12 },",Yes
docs/using/selecting.md,docs/using/selecting.md,b9553a8e5d33a8d59eac52b0d8790d3f46f6f03c,dd06b93abc41a5de327f8fbe3e597e4ed4c1bc0d,"Add cuda12 variant of tensorflow-notebook (#2100)

* Add cuda12 variant for tensorflow-notebook

* Reduce size of CPU version of tensorflow-notebook

* Try to fix tests

* Update docs/using/selecting.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update images/tensorflow-notebook/cuda12/Dockerfile

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update tests/docker-stacks-foundation/test_packages.py

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Remove obsolete XLA_FLAGS env var

* Install CUDA and cuDNN using pip instead of mamba

* Fix pre-commit shell checks

* Change tensorflow variant name from cuda12 to cuda

* Update selecting.md

* Update selecting.md

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 28544e41..b1f69dd2 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -18,11 +18,12 @@ The following sections describe these images, including their contents, relation
 
 ## CUDA enabled variant
 
-We provide CUDA accelerated version of `pytorch-notebook` image.
-Prepend a CUDA version prefix (like `cuda12-`) to the image tag to allow PyTorch operations to use compatible NVIDIA GPUs for accelerated computation.
-We only build images for 2 last major versions of CUDA.
+We provide CUDA accelerated version of `pytorch-notebook` and `tensorflow-notebook` images.
+Prepend a CUDA version prefix (like `cuda12-` for `pytorch-notebook` or `cuda-` for `tensorflow-notebook`) to the image tag
+to allow PyTorch or TensorFlow operations to use compatible NVIDIA GPUs for accelerated computation.
+Note: We only build `pytorch-notebook` for 2 last major versions of CUDA, `tensorflow-notebook` image only supports the latest CUDA version listed in the [officially tested build configurations](https://www.tensorflow.org/install/source#gpu).
 
-For example, you can use an image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8`
+For example, you can use an image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8` or `quay.io/jupyter/tensorflow-notebook:cuda-latest`
 
 ### jupyter/docker-stacks-foundation","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 28544e41..b1f69dd2 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -18,11 +18,12 @@ The following sections describe these images, including their contents, relation
 
 ## CUDA enabled variant
 
-We provide CUDA accelerated version of `pytorch-notebook` image.
-Prepend a CUDA version prefix (like `cuda12-`) to the image tag to allow PyTorch operations to use compatible NVIDIA GPUs for accelerated computation.
-We only build images for 2 last major versions of CUDA.
+We provide CUDA accelerated version of `pytorch-notebook` and `tensorflow-notebook` images.
+Prepend a CUDA version prefix (like `cuda12-` for `pytorch-notebook` or `cuda-` for `tensorflow-notebook`) to the image tag
+to allow PyTorch or TensorFlow operations to use compatible NVIDIA GPUs for accelerated computation.
+Note: We only build `pytorch-notebook` for 2 last major versions of CUDA, `tensorflow-notebook` image only supports the latest CUDA version listed in the [officially tested build configurations](https://www.tensorflow.org/install/source#gpu).
 
-For example, you can use an image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8`
+For example, you can use an image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8` or `quay.io/jupyter/tensorflow-notebook:cuda-latest`
 
 ### jupyter/docker-stacks-foundation",Yes
images/tensorflow-notebook/Dockerfile,images/tensorflow-notebook/Dockerfile,b9553a8e5d33a8d59eac52b0d8790d3f46f6f03c,dd06b93abc41a5de327f8fbe3e597e4ed4c1bc0d,"Add cuda12 variant of tensorflow-notebook (#2100)

* Add cuda12 variant for tensorflow-notebook

* Reduce size of CPU version of tensorflow-notebook

* Try to fix tests

* Update docs/using/selecting.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update images/tensorflow-notebook/cuda12/Dockerfile

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update tests/docker-stacks-foundation/test_packages.py

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Remove obsolete XLA_FLAGS env var

* Install CUDA and cuDNN using pip instead of mamba

* Fix pre-commit shell checks

* Change tensorflow variant name from cuda12 to cuda

* Update selecting.md

* Update selecting.md

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index 7038f084..be366d49 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -11,7 +11,8 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-# Install Tensorflow with pip
-RUN pip install --no-cache-dir tensorflow && \
+# Install tensorflow with pip, on x86_64 tensorflow-cpu
+RUN [[ $(uname -m) = x86_64 ]] && TF_POSTFIX=""-cpu"" || TF_POSTFIX="""" && \
+    pip install --no-cache-dir ""tensorflow${TF_POSTFIX}"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index 7038f084..be366d49 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -11,7 +11,8 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-# Install Tensorflow with pip
-RUN pip install --no-cache-dir tensorflow && \
+# Install tensorflow with pip, on x86_64 tensorflow-cpu
+RUN [[ $(uname -m) = x86_64 ]] && TF_POSTFIX=""-cpu"" || TF_POSTFIX="""" && \
+    pip install --no-cache-dir ""tensorflow${TF_POSTFIX}"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
,images/tensorflow-notebook/cuda/Dockerfile,b9553a8e5d33a8d59eac52b0d8790d3f46f6f03c,dd06b93abc41a5de327f8fbe3e597e4ed4c1bc0d,"Add cuda12 variant of tensorflow-notebook (#2100)

* Add cuda12 variant for tensorflow-notebook

* Reduce size of CPU version of tensorflow-notebook

* Try to fix tests

* Update docs/using/selecting.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update images/tensorflow-notebook/cuda12/Dockerfile

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update tests/docker-stacks-foundation/test_packages.py

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Remove obsolete XLA_FLAGS env var

* Install CUDA and cuDNN using pip instead of mamba

* Fix pre-commit shell checks

* Change tensorflow variant name from cuda12 to cuda

* Update selecting.md

* Update selecting.md

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
new file mode 100644
index 00000000..7e6e65f1
--- /dev/null
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -0,0 +1,27 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=quay.io
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install TensorFlow, CUDA and cuDNN with pip
+RUN pip install --no-cache-dir ""tensorflow[and-cuda]"" && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# workaround for https://github.com/tensorflow/tensorflow/issues/63362
+RUN mkdir -p ""${CONDA_DIR}/etc/conda/activate.d/"" && \
+    fix-permissions ""${CONDA_DIR}""
+
+COPY --chown=""${NB_UID}:${NB_GID}"" nvidia-lib-dirs.sh ""${CONDA_DIR}/etc/conda/activate.d/""
+
+# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
+ENV NVIDIA_VISIBLE_DEVICES=""all"" \
+    NVIDIA_DRIVER_CAPABILITIES=""compute,utility""","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
new file mode 100644
index 00000000..7e6e65f1
--- /dev/null
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -0,0 +1,27 @@
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+ARG REGISTRY=quay.io
+ARG OWNER=jupyter
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_CONTAINER
+
+LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
+
+# Fix: https://github.com/hadolint/hadolint/wiki/DL4006
+# Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
+SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
+
+# Install TensorFlow, CUDA and cuDNN with pip
+RUN pip install --no-cache-dir ""tensorflow[and-cuda]"" && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# workaround for https://github.com/tensorflow/tensorflow/issues/63362
+RUN mkdir -p ""${CONDA_DIR}/etc/conda/activate.d/"" && \
+    fix-permissions ""${CONDA_DIR}""
+
+COPY --chown=""${NB_UID}:${NB_GID}"" nvidia-lib-dirs.sh ""${CONDA_DIR}/etc/conda/activate.d/""
+
+# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
+ENV NVIDIA_VISIBLE_DEVICES=""all"" \
+    NVIDIA_DRIVER_CAPABILITIES=""compute,utility""",Yes
,images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh,b9553a8e5d33a8d59eac52b0d8790d3f46f6f03c,dd06b93abc41a5de327f8fbe3e597e4ed4c1bc0d,"Add cuda12 variant of tensorflow-notebook (#2100)

* Add cuda12 variant for tensorflow-notebook

* Reduce size of CPU version of tensorflow-notebook

* Try to fix tests

* Update docs/using/selecting.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update images/tensorflow-notebook/cuda12/Dockerfile

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update tests/docker-stacks-foundation/test_packages.py

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Remove obsolete XLA_FLAGS env var

* Install CUDA and cuDNN using pip instead of mamba

* Fix pre-commit shell checks

* Change tensorflow variant name from cuda12 to cuda

* Update selecting.md

* Update selecting.md

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh b/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
new file mode 100644
index 00000000..efd1b142
--- /dev/null
+++ b/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
@@ -0,0 +1,9 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# This adds the NVIDIA libraries to the LD_LIBRARY_PATH. Workaround for
+# https://github.com/tensorflow/tensorflow/issues/63362
+NVIDIA_DIR=$(dirname ""$(python -c 'import nvidia;print(nvidia.__file__)')"")
+LD_LIBRARY_PATH=$(echo ""${NVIDIA_DIR}""/*/lib/ | sed -r 's/\s+/:/g')${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
+export LD_LIBRARY_PATH","diff --git a/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh b/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
new file mode 100644
index 00000000..efd1b142
--- /dev/null
+++ b/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
@@ -0,0 +1,9 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+# This adds the NVIDIA libraries to the LD_LIBRARY_PATH. Workaround for
+# https://github.com/tensorflow/tensorflow/issues/63362
+NVIDIA_DIR=$(dirname ""$(python -c 'import nvidia;print(nvidia.__file__)')"")
+LD_LIBRARY_PATH=$(echo ""${NVIDIA_DIR}""/*/lib/ | sed -r 's/\s+/:/g')${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
+export LD_LIBRARY_PATH",Yes
tagging/taggers.py,tagging/taggers.py,b9553a8e5d33a8d59eac52b0d8790d3f46f6f03c,dd06b93abc41a5de327f8fbe3e597e4ed4c1bc0d,"Add cuda12 variant of tensorflow-notebook (#2100)

* Add cuda12 variant for tensorflow-notebook

* Reduce size of CPU version of tensorflow-notebook

* Try to fix tests

* Update docs/using/selecting.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update images/tensorflow-notebook/cuda12/Dockerfile

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Update tests/docker-stacks-foundation/test_packages.py

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

* Remove obsolete XLA_FLAGS env var

* Install CUDA and cuDNN using pip instead of mamba

* Fix pre-commit shell checks

* Change tensorflow variant name from cuda12 to cuda

* Update selecting.md

* Update selecting.md

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tagging/taggers.py b/tagging/taggers.py
index 1aa6705d..a42c9d05 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -98,7 +98,10 @@ class RVersionTagger(TaggerInterface):
 class TensorflowVersionTagger(TaggerInterface):
     @staticmethod
     def tag_value(container: Container) -> str:
-        return ""tensorflow-"" + _get_pip_package_version(container, ""tensorflow"")
+        try:
+            return ""tensorflow-"" + _get_pip_package_version(container, ""tensorflow"")
+        except AssertionError:
+            return ""tensorflow-"" + _get_pip_package_version(container, ""tensorflow-cpu"")
 
 
 class PytorchVersionTagger(TaggerInterface):","diff --git a/tagging/taggers.py b/tagging/taggers.py
index 1aa6705d..a42c9d05 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -98,7 +98,10 @@ class RVersionTagger(TaggerInterface):
 class TensorflowVersionTagger(TaggerInterface):
     @staticmethod
     def tag_value(container: Container) -> str:
-        return ""tensorflow-"" + _get_pip_package_version(container, ""tensorflow"")
+        try:
+            return ""tensorflow-"" + _get_pip_package_version(container, ""tensorflow"")
+        except AssertionError:
+            return ""tensorflow-"" + _get_pip_package_version(container, ""tensorflow-cpu"")
 
 
 class PytorchVersionTagger(TaggerInterface):",Yes
images/minimal-notebook/setup-scripts/setup-julia-packages.bash,images/minimal-notebook/setup-scripts/setup-julia-packages.bash,b2efa3cd8ce7a2b900f76ff4a17e11a000666cea,b9553a8e5d33a8d59eac52b0d8790d3f46f6f03c,"Update JULIA_CPU_TARGET for precompiling packages (#2104)

* Update JULIA_CPU_TARGET for precompiling packages

* Update links

* Also update link for aarch64","diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 5e8f7e80..14a77407 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -11,20 +11,20 @@ set -exuo pipefail
 # container runs on a host that's the same architecture, but a *different*
 # generation of CPU than what the build host was, the precompilation is useless
 # and Julia takes a long long time to start up. This specific multitarget comes
-# from https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L20-L76,
+# from https://github.com/JuliaCI/julia-buildkite/blob/9f354745a1f2bf31a5952462aa1ff2d869507cb8/utilities/build_envs.sh#L20-L82,
 # and may need to be updated as new CPU generations come out.
 # If the architecture the container runs on is different,
 # precompilation may still have to be re-done on first startup - but this
 # *should* catch most of the issues.  See
 # https://github.com/jupyter/docker-stacks/issues/2015 for more information
 if [ ""$(uname -m)"" == ""x86_64"" ]; then
-    # See https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L24
+    # See https://github.com/JuliaCI/julia-buildkite/blob/9f354745a1f2bf31a5952462aa1ff2d869507cb8/utilities/build_envs.sh#L23
     # for an explanation of these options
-    export JULIA_CPU_TARGET=""generic;sandybridge,-xsaveopt,clone_all;haswell,-rdrnd,base(1)""
+    export JULIA_CPU_TARGET=""generic;sandybridge,-xsaveopt,clone_all;haswell,-rdrnd,base(1);x86-64-v4,-rdrnd,base(1)""
 elif [ ""$(uname -m)"" == ""aarch64"" ]; then
-    # See https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L54
+    # See https://github.com/JuliaCI/julia-buildkite/blob/9f354745a1f2bf31a5952462aa1ff2d869507cb8/utilities/build_envs.sh#L56
     # for an explanation of these options
-    export JULIA_CPU_TARGET=""generic;cortex-a57;thunderx2t99;carmel""
+    export JULIA_CPU_TARGET=""generic;cortex-a57;thunderx2t99;carmel,clone_all;apple-m1,base(3);neoverse-512tvb,base(3)""
 fi
 
 # Install base Julia packages","diff --git a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
index 5e8f7e80..14a77407 100755
--- a/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
+++ b/images/minimal-notebook/setup-scripts/setup-julia-packages.bash
@@ -11,20 +11,20 @@ set -exuo pipefail
 # container runs on a host that's the same architecture, but a *different*
 # generation of CPU than what the build host was, the precompilation is useless
 # and Julia takes a long long time to start up. This specific multitarget comes
-# from https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L20-L76,
+# from https://github.com/JuliaCI/julia-buildkite/blob/9f354745a1f2bf31a5952462aa1ff2d869507cb8/utilities/build_envs.sh#L20-L82,
 # and may need to be updated as new CPU generations come out.
 # If the architecture the container runs on is different,
 # precompilation may still have to be re-done on first startup - but this
 # *should* catch most of the issues.  See
 # https://github.com/jupyter/docker-stacks/issues/2015 for more information
 if [ ""$(uname -m)"" == ""x86_64"" ]; then
-    # See https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L24
+    # See https://github.com/JuliaCI/julia-buildkite/blob/9f354745a1f2bf31a5952462aa1ff2d869507cb8/utilities/build_envs.sh#L23
     # for an explanation of these options
-    export JULIA_CPU_TARGET=""generic;sandybridge,-xsaveopt,clone_all;haswell,-rdrnd,base(1)""
+    export JULIA_CPU_TARGET=""generic;sandybridge,-xsaveopt,clone_all;haswell,-rdrnd,base(1);x86-64-v4,-rdrnd,base(1)""
 elif [ ""$(uname -m)"" == ""aarch64"" ]; then
-    # See https://github.com/JuliaCI/julia-buildkite/blob/70bde73f6cb17d4381b62236fc2d96b1c7acbba7/utilities/build_envs.sh#L54
+    # See https://github.com/JuliaCI/julia-buildkite/blob/9f354745a1f2bf31a5952462aa1ff2d869507cb8/utilities/build_envs.sh#L56
     # for an explanation of these options
-    export JULIA_CPU_TARGET=""generic;cortex-a57;thunderx2t99;carmel""
+    export JULIA_CPU_TARGET=""generic;cortex-a57;thunderx2t99;carmel,clone_all;apple-m1,base(3);neoverse-512tvb,base(3)""
 fi
 
 # Install base Julia packages",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,275ad774c263ca36c70f12e03be95ed223dd0215,b2efa3cd8ce7a2b900f76ff4a17e11a000666cea,"[pre-commit.ci] pre-commit autoupdate (#2105)

updates:
- [github.com/asottile/pyupgrade: v3.15.1 → v3.15.2](https://github.com/asottile/pyupgrade/compare/v3.15.1...v3.15.2)
- [github.com/psf/black: 24.2.0 → 24.3.0](https://github.com/psf/black/compare/24.2.0...24.3.0)
- [github.com/shellcheck-py/shellcheck-py: v0.9.0.6 → v0.10.0.1](https://github.com/shellcheck-py/shellcheck-py/compare/v0.9.0.6...v0.10.0.1)
- [github.com/nbQA-dev/nbQA: 1.8.4 → 1.8.5](https://github.com/nbQA-dev/nbQA/compare/1.8.4...1.8.5)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index b9a0d66e..5742ea93 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.15.1
+    rev: v3.15.2
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.2.0
+    rev: 24.3.0
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -110,7 +110,7 @@ repos:
 
   # Lint: Shell scripts
   - repo: https://github.com/shellcheck-py/shellcheck-py
-    rev: v0.9.0.6
+    rev: v0.10.0.1
     hooks:
       - id: shellcheck
         args: [""-x""]
@@ -137,7 +137,7 @@ repos:
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.8.4
+    rev: 1.8.5
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index b9a0d66e..5742ea93 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.15.1
+    rev: v3.15.2
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,7 +28,7 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.2.0
+    rev: 24.3.0
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -110,7 +110,7 @@ repos:
 
   # Lint: Shell scripts
   - repo: https://github.com/shellcheck-py/shellcheck-py
-    rev: v0.9.0.6
+    rev: v0.10.0.1
     hooks:
       - id: shellcheck
         args: [""-x""]
@@ -137,7 +137,7 @@ repos:
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.8.4
+    rev: 1.8.5
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]",Yes
docs/using/selecting.md,docs/using/selecting.md,e838ff397a2d9c2ad0faae051ef0ec4f20732320,275ad774c263ca36c70f12e03be95ed223dd0215,Improve CUDA enabled images docs,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index b1f69dd2..354f8183 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -19,7 +19,7 @@ The following sections describe these images, including their contents, relation
 ## CUDA enabled variant
 
 We provide CUDA accelerated version of `pytorch-notebook` and `tensorflow-notebook` images.
-Prepend a CUDA version prefix (like `cuda12-` for `pytorch-notebook` or `cuda-` for `tensorflow-notebook`) to the image tag
+Prepend a CUDA prefix (versioned prefix like `cuda12-` for `pytorch-notebook` or just `cuda-` for `tensorflow-notebook`) to the image tag
 to allow PyTorch or TensorFlow operations to use compatible NVIDIA GPUs for accelerated computation.
 Note: We only build `pytorch-notebook` for 2 last major versions of CUDA, `tensorflow-notebook` image only supports the latest CUDA version listed in the [officially tested build configurations](https://www.tensorflow.org/install/source#gpu).","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index b1f69dd2..354f8183 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -19,7 +19,7 @@ The following sections describe these images, including their contents, relation
 ## CUDA enabled variant
 
 We provide CUDA accelerated version of `pytorch-notebook` and `tensorflow-notebook` images.
-Prepend a CUDA version prefix (like `cuda12-` for `pytorch-notebook` or `cuda-` for `tensorflow-notebook`) to the image tag
+Prepend a CUDA prefix (versioned prefix like `cuda12-` for `pytorch-notebook` or just `cuda-` for `tensorflow-notebook`) to the image tag
 to allow PyTorch or TensorFlow operations to use compatible NVIDIA GPUs for accelerated computation.
 Note: We only build `pytorch-notebook` for 2 last major versions of CUDA, `tensorflow-notebook` image only supports the latest CUDA version listed in the [officially tested build configurations](https://www.tensorflow.org/install/source#gpu).",Yes
docs/using/selecting.md,docs/using/selecting.md,d7193318a38cff4e7d24786162b77e0d9e18f510,e838ff397a2d9c2ad0faae051ef0ec4f20732320,"Update selecting.md with TH Lübecks (University of Applied Sciences Lübeck) image collection (#2110)

* Update selecting.md

Adding TH Lübeck universities image collection

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update docs/using/selecting.md

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update selecting.md

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Update selecting.md

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 354f8183..4f31292c 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -328,13 +328,16 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 
 ### Other GPU-accelerated notebooks
 
-| Flavor             | Description                                                                                                                                                                                                                                                                                                                                                  |
-| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
-| [GPU-Jupyter][gpu] | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule, and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
-| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                         |
-| [b-data][b-data]   | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].         |
+| Flavor                            | Description                                                                                                                                                                                                                                                                                                                                                  |
+| --------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
+| [GPU-Jupyter][gpu]                | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule, and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
+| [myLab TH Lübeck Images][gpu_thl] | Images based on the **jupyter/docker-stacks**, built and maintained at the [myLab TH Lübeck][gpu_mylab] using build scripts similar to iot-salzburg. Several images include GPU libraries.                                                                                                                                                                   |
+| [PRP-GPU][prp_gpu]                | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                         |
+| [b-data][b-data]                  | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].         |
 
 [gpu]: https://github.com/iot-salzburg/gpu-jupyter
+[gpu_thl]: https://hub.docker.com/r/hanseware/jhub-images
+[gpu_mylab]: https://mylab.th-luebeck.de
 [prp_gpu]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/-/tree/prp
 [prp_reg]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/container_registry
 [b-data]: https://github.com/b-data","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 354f8183..4f31292c 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -328,13 +328,16 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 
 ### Other GPU-accelerated notebooks
 
-| Flavor             | Description                                                                                                                                                                                                                                                                                                                                                  |
-| ------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
-| [GPU-Jupyter][gpu] | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule, and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
-| [PRP-GPU][prp_gpu] | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                         |
-| [b-data][b-data]   | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].         |
+| Flavor                            | Description                                                                                                                                                                                                                                                                                                                                                  |
+| --------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
+| [GPU-Jupyter][gpu]                | Power of your NVIDIA GPU and GPU calculations using Tensorflow and Pytorch in collaborative notebooks. This is done by generating a Dockerfile that consists of the **nvidia/cuda** base image, the well-maintained **docker-stacks** that is integrated as a submodule, and GPU-able libraries like **Tensorflow**, **Keras** and **PyTorch** on top of it. |
+| [myLab TH Lübeck Images][gpu_thl] | Images based on the **jupyter/docker-stacks**, built and maintained at the [myLab TH Lübeck][gpu_mylab] using build scripts similar to iot-salzburg. Several images include GPU libraries.                                                                                                                                                                   |
+| [PRP-GPU][prp_gpu]                | PRP (Pacific Research Platform) maintained [registry][prp_reg] for jupyter stack based on NVIDIA CUDA-enabled image. Added the PRP image with Pytorch and some other Python packages and GUI Desktop notebook based on <https://github.com/jupyterhub/jupyter-remote-desktop-proxy>.                                                                         |
+| [b-data][b-data]                  | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].         |
 
 [gpu]: https://github.com/iot-salzburg/gpu-jupyter
+[gpu_thl]: https://hub.docker.com/r/hanseware/jhub-images
+[gpu_mylab]: https://mylab.th-luebeck.de
 [prp_gpu]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/-/tree/prp
 [prp_reg]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/container_registry
 [b-data]: https://github.com/b-data",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,abea5caf78da2dbe1af0ded0b1e184191016ba57,d7193318a38cff4e7d24786162b77e0d9e18f510,"Bump stefanzweifel/git-auto-commit-action from 5.0.0 to 5.0.1 (#2109)

Bumps [stefanzweifel/git-auto-commit-action](https://github.com/stefanzweifel/git-auto-commit-action) from 5.0.0 to 5.0.1.
- [Release notes](https://github.com/stefanzweifel/git-auto-commit-action/releases)
- [Changelog](https://github.com/stefanzweifel/git-auto-commit-action/blob/master/CHANGELOG.md)
- [Commits](https://github.com/stefanzweifel/git-auto-commit-action/compare/8756aa072ef5b4a080af5dc8fef36c5d586e521d...8621497c8c39c72f3e2a999a26b4ca1b5058a842)

---
updated-dependencies:
- dependency-name: stefanzweifel/git-auto-commit-action
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index b5bd0cb3..b0abefc5 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -42,7 +42,7 @@ jobs:
 
       - name: Push Wiki to GitHub 📤
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: stefanzweifel/git-auto-commit-action@8756aa072ef5b4a080af5dc8fef36c5d586e521d # v5.0.0
+        uses: stefanzweifel/git-auto-commit-action@8621497c8c39c72f3e2a999a26b4ca1b5058a842 # v5.0.1
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""
           repository: wiki/","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index b5bd0cb3..b0abefc5 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -42,7 +42,7 @@ jobs:
 
       - name: Push Wiki to GitHub 📤
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: stefanzweifel/git-auto-commit-action@8756aa072ef5b4a080af5dc8fef36c5d586e521d # v5.0.0
+        uses: stefanzweifel/git-auto-commit-action@8621497c8c39c72f3e2a999a26b4ca1b5058a842 # v5.0.1
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""
           repository: wiki/",Yes
images/base-notebook/docker_healthcheck.py,images/base-notebook/docker_healthcheck.py,3be7274ee8ae56a7ddeaf55c0e9b160ead954470,abea5caf78da2dbe1af0ded0b1e184191016ba57,Fix typos,"diff --git a/images/base-notebook/docker_healthcheck.py b/images/base-notebook/docker_healthcheck.py
index 7dd3de02..b0db1a81 100755
--- a/images/base-notebook/docker_healthcheck.py
+++ b/images/base-notebook/docker_healthcheck.py
@@ -9,9 +9,9 @@ from pathlib import Path
 import requests
 
 # Several operations below deliberately don't check for possible errors
-# As this is a healthcheck, it should succeed or raise an exception on error
+# As this is a health check, it should succeed or raise an exception on error
 
-# Docker runs healtchecks using an exec
+# Docker runs health checks using an exec
 # It uses the default user configured when running the image: root for the case of a custom NB_USER or jovyan for the case of the default image user.
 # We manually change HOME to make `jupyter --runtime-dir` report a correct path
 # More information: <https://github.com/jupyter/docker-stacks/pull/2074#issuecomment-1879778409>","diff --git a/images/base-notebook/docker_healthcheck.py b/images/base-notebook/docker_healthcheck.py
index 7dd3de02..b0db1a81 100755
--- a/images/base-notebook/docker_healthcheck.py
+++ b/images/base-notebook/docker_healthcheck.py
@@ -9,9 +9,9 @@ from pathlib import Path
 import requests
 
 # Several operations below deliberately don't check for possible errors
-# As this is a healthcheck, it should succeed or raise an exception on error
+# As this is a health check, it should succeed or raise an exception on error
 
-# Docker runs healtchecks using an exec
+# Docker runs health checks using an exec
 # It uses the default user configured when running the image: root for the case of a custom NB_USER or jovyan for the case of the default image user.
 # We manually change HOME to make `jupyter --runtime-dir` report a correct path
 # More information: <https://github.com/jupyter/docker-stacks/pull/2074#issuecomment-1879778409>",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,feeb4e78ef4d299b937a60261bb1a9f97a7a2b8f,3be7274ee8ae56a7ddeaf55c0e9b160ead954470,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 5742ea93..d78c9bf3 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.3.0
+    rev: 24.4.2
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.9.0
+    rev: v1.10.0
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -68,7 +68,7 @@ repos:
 
   # `pre-commit sample-config` default hooks
   - repo: https://github.com/pre-commit/pre-commit-hooks
-    rev: v4.5.0
+    rev: v4.6.0
     hooks:
       - id: check-added-large-files
       - id: end-of-file-fixer
@@ -77,7 +77,7 @@ repos:
 
   # Lint: Dockerfile
   - repo: https://github.com/hadolint/hadolint
-    rev: v2.12.1-beta
+    rev: v2.13.0-beta
     hooks:
       - id: hadolint-docker
         entry: hadolint/hadolint:v2.12.1-beta hadolint
@@ -85,7 +85,7 @@ repos:
   # Lint: Dockerfile
   # We're linting .dockerfile files as well
   - repo: https://github.com/hadolint/hadolint
-    rev: v2.12.1-beta
+    rev: v2.13.0-beta
     hooks:
       - id: hadolint-docker
         name: Lint *.dockerfile Dockerfiles
@@ -123,7 +123,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.39.0
+    rev: v0.40.0
     hooks:
       - id: markdownlint
         args: [""--fix""]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 5742ea93..d78c9bf3 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.3.0
+    rev: 24.4.2
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.9.0
+    rev: v1.10.0
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -68,7 +68,7 @@ repos:
 
   # `pre-commit sample-config` default hooks
   - repo: https://github.com/pre-commit/pre-commit-hooks
-    rev: v4.5.0
+    rev: v4.6.0
     hooks:
       - id: check-added-large-files
       - id: end-of-file-fixer
@@ -77,7 +77,7 @@ repos:
 
   # Lint: Dockerfile
   - repo: https://github.com/hadolint/hadolint
-    rev: v2.12.1-beta
+    rev: v2.13.0-beta
     hooks:
       - id: hadolint-docker
         entry: hadolint/hadolint:v2.12.1-beta hadolint
@@ -85,7 +85,7 @@ repos:
   # Lint: Dockerfile
   # We're linting .dockerfile files as well
   - repo: https://github.com/hadolint/hadolint
-    rev: v2.12.1-beta
+    rev: v2.13.0-beta
     hooks:
       - id: hadolint-docker
         name: Lint *.dockerfile Dockerfiles
@@ -123,7 +123,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.39.0
+    rev: v0.40.0
     hooks:
       - id: markdownlint
         args: [""--fix""]",Yes
README.md,README.md,44a19543290b85da5891556537b4579019e24804,feeb4e78ef4d299b937a60261bb1a9f97a7a2b8f,Update tag example,"diff --git a/README.md b/README.md
index 448abab8..ab8fc94c 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-03-14
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-04-29
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-03-14
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-04-29
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -101,7 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-03-14`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-04-29`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images","diff --git a/README.md b/README.md
index 448abab8..ab8fc94c 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-03-14
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-04-29
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-03-14
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-04-29
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -101,7 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-03-14`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-04-29`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images",Yes
binder/Dockerfile,binder/Dockerfile,44a19543290b85da5891556537b4579019e24804,feeb4e78ef4d299b937a60261bb1a9f97a7a2b8f,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index c64e159c..62a22133 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-03-14
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-04-29
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-03-14""
+ENV TAG=""2024-04-29""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index c64e159c..62a22133 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-03-14
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-04-29
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-03-14""
+ENV TAG=""2024-04-29""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,44a19543290b85da5891556537b4579019e24804,feeb4e78ef4d299b937a60261bb1a9f97a7a2b8f,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index 50e9d917..f2e26126 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-03-14
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-04-29
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-03-14   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-04-29   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-03-14
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-04-29
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-03-14
+    quay.io/jupyter/r-notebook:2024-04-29
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 50e9d917..f2e26126 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-03-14
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-04-29
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-03-14   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-04-29   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-03-14
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-04-29
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-03-14` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-03-14
+    quay.io/jupyter/r-notebook:2024-04-29
 ```
 
 ```{warning}",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,41ded6e8a3a66377bbbd5de36209956b20196a7e,44a19543290b85da5891556537b4579019e24804,Update oracledb example,"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 85564d0a..e03444c1 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -12,7 +12,7 @@ RUN apt-get update --yes && \
 
 # Oracle
 ARG INSTANTCLIENT_MAJOR_VERSION=21
-ARG INSTANTCLIENT_VERSION=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1
+ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1.el8.x86_64.rpm
 ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2111000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools, and JDBC.
@@ -20,14 +20,14 @@ ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclie
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
 RUN mkdir ""/opt/oracle""
 WORKDIR ""/opt/oracle""
-RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclite-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-basiclite-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-sqlplus-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-tools-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-tools-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-jdbc-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-jdbc-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclite-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    alien --install --scripts ""oracle-instantclient-basiclite-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-tools-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    alien --install --scripts ""oracle-instantclient-tools-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-jdbc-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    alien --install --scripts ""oracle-instantclient-jdbc-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     chown -R ""${NB_UID}"":""${NB_GID}"" ""${HOME}/.rpmdb"" && \
     rm -f ./*.rpm","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 85564d0a..e03444c1 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -12,7 +12,7 @@ RUN apt-get update --yes && \
 
 # Oracle
 ARG INSTANTCLIENT_MAJOR_VERSION=21
-ARG INSTANTCLIENT_VERSION=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1
+ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1.el8.x86_64.rpm
 ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2111000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools, and JDBC.
@@ -20,14 +20,14 @@ ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclie
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
 RUN mkdir ""/opt/oracle""
 WORKDIR ""/opt/oracle""
-RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclite-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-basiclite-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-sqlplus-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-tools-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-tools-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-jdbc-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
-    alien --install --scripts ""oracle-instantclient-jdbc-${INSTANTCLIENT_VERSION}.el8.x86_64.rpm"" && \
+RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclite-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    alien --install --scripts ""oracle-instantclient-basiclite-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-tools-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    alien --install --scripts ""oracle-instantclient-tools-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-jdbc-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    alien --install --scripts ""oracle-instantclient-jdbc-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     chown -R ""${NB_UID}"":""${NB_GID}"" ""${HOME}/.rpmdb"" && \
     rm -f ./*.rpm",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,dd744ea6071653bc8f017827c4e44570014f4548,41ded6e8a3a66377bbbd5de36209956b20196a7e,[TMP] Disable installing sqlplus as it gives errors,"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index e03444c1..8e66f8cb 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -20,10 +20,11 @@ ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclie
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
 RUN mkdir ""/opt/oracle""
 WORKDIR ""/opt/oracle""
+# alien doesn't work well with sqlplus, so skipping it for now
 RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclite-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     alien --install --scripts ""oracle-instantclient-basiclite-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
-    alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    # alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-tools-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     alien --install --scripts ""oracle-instantclient-tools-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-jdbc-${INSTANTCLIENT_BIN_SUFFIX}"" && \","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index e03444c1..8e66f8cb 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -20,10 +20,11 @@ ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclie
 # See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
 RUN mkdir ""/opt/oracle""
 WORKDIR ""/opt/oracle""
+# alien doesn't work well with sqlplus, so skipping it for now
 RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclite-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     alien --install --scripts ""oracle-instantclient-basiclite-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
-    alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
+    # alien --install --scripts ""oracle-instantclient-sqlplus-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-tools-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     alien --install --scripts ""oracle-instantclient-tools-${INSTANTCLIENT_BIN_SUFFIX}"" && \
     wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-jdbc-${INSTANTCLIENT_BIN_SUFFIX}"" && \",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,996fae1248fcdd583a6a85be1f753d09acce9e25,dd744ea6071653bc8f017827c4e44570014f4548,Update oracledb client version,"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 8e66f8cb..8846fe6c 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -11,9 +11,9 @@ RUN apt-get update --yes && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
 # Oracle
-ARG INSTANTCLIENT_MAJOR_VERSION=21
-ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1.el8.x86_64.rpm
-ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2111000
+ARG INSTANTCLIENT_MAJOR_VERSION=23
+ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.4.0.24.05-1.el9.x86_64.rpm
+ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2340000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools, and JDBC.
 # Note: You may need to change the URL to a newer version.","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 8e66f8cb..8846fe6c 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -11,9 +11,9 @@ RUN apt-get update --yes && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
 # Oracle
-ARG INSTANTCLIENT_MAJOR_VERSION=21
-ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.11.0.0.0-1.el8.x86_64.rpm
-ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2111000
+ARG INSTANTCLIENT_MAJOR_VERSION=23
+ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.4.0.24.05-1.el9.x86_64.rpm
+ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2340000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools, and JDBC.
 # Note: You may need to change the URL to a newer version.",Yes
README.md,README.md,95eda6aaeeea6f9800bc1283cef7d6195f22f014,996fae1248fcdd583a6a85be1f753d09acce9e25,Update example date,"diff --git a/README.md b/README.md
index ab8fc94c..cd16d88c 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-04-29
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-05-27
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-04-29
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-05-27
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -101,7 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-04-29`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-05-27`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images","diff --git a/README.md b/README.md
index ab8fc94c..cd16d88c 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-04-29
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-05-27
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-04-29
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-05-27
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.
@@ -101,7 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-04-29`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-05-27`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images",Yes
binder/Dockerfile,binder/Dockerfile,95eda6aaeeea6f9800bc1283cef7d6195f22f014,996fae1248fcdd583a6a85be1f753d09acce9e25,Update example date,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 62a22133..25cba9d9 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-04-29
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-05-27
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-04-29""
+ENV TAG=""2024-05-27""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 62a22133..25cba9d9 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-04-29
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-05-27
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,6 +13,6 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-04-29""
+ENV TAG=""2024-05-27""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,95eda6aaeeea6f9800bc1283cef7d6195f22f014,996fae1248fcdd583a6a85be1f753d09acce9e25,Update example date,"diff --git a/docs/using/running.md b/docs/using/running.md
index f2e26126..e44d32bd 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-04-29
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-05-27
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-04-29   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-05-27   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-04-29
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-05-27
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-04-29
+    quay.io/jupyter/r-notebook:2024-05-27
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index f2e26126..e44d32bd 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-04-29
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-05-27
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-04-29   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-05-27   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-04-29
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-05-27
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-04-29` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-04-29
+    quay.io/jupyter/r-notebook:2024-05-27
 ```
 
 ```{warning}",Yes
binder/Dockerfile,binder/Dockerfile,93ead907e5925ad61943ebeff372d026d815a1da,95eda6aaeeea6f9800bc1283cef7d6195f22f014,Disable jupyter announcements in binder example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 25cba9d9..cc407eec 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -16,3 +16,5 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 ENV TAG=""2024-05-27""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb
+
+RUN jupyter labextension disable ""@jupyterlab/apputils-extension:announcements""","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 25cba9d9..cc407eec 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -16,3 +16,5 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 ENV TAG=""2024-05-27""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb
+
+RUN jupyter labextension disable ""@jupyterlab/apputils-extension:announcements""",Yes
docs/using/selecting.md,docs/using/selecting.md,1c44e6d6e8f7549c69fd37121dfbd75c6a789a33,93ead907e5925ad61943ebeff372d026d815a1da,Updated header level to fit rest of the page (#2119),"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 4f31292c..a975332e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -16,7 +16,7 @@ This section provides details about the first.
 The Jupyter team maintains a set of Docker image definitions in the <https://github.com/jupyter/docker-stacks> GitHub repository.
 The following sections describe these images, including their contents, relationships, and versioning strategy.
 
-## CUDA enabled variant
+### CUDA enabled variant
 
 We provide CUDA accelerated version of `pytorch-notebook` and `tensorflow-notebook` images.
 Prepend a CUDA prefix (versioned prefix like `cuda12-` for `pytorch-notebook` or just `cuda-` for `tensorflow-notebook`) to the image tag","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 4f31292c..a975332e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -16,7 +16,7 @@ This section provides details about the first.
 The Jupyter team maintains a set of Docker image definitions in the <https://github.com/jupyter/docker-stacks> GitHub repository.
 The following sections describe these images, including their contents, relationships, and versioning strategy.
 
-## CUDA enabled variant
+### CUDA enabled variant
 
 We provide CUDA accelerated version of `pytorch-notebook` and `tensorflow-notebook` images.
 Prepend a CUDA prefix (versioned prefix like `cuda12-` for `pytorch-notebook` or just `cuda-` for `tensorflow-notebook`) to the image tag",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,9fe10a3d51ff7a605f49795f02f2f3ea6ecdba59,1c44e6d6e8f7549c69fd37121dfbd75c6a789a33,"[pre-commit.ci] pre-commit autoupdate

updates:
- [github.com/igorshubovych/markdownlint-cli: v0.40.0 → v0.41.0](https://github.com/igorshubovych/markdownlint-cli/compare/v0.40.0...v0.41.0)","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index d78c9bf3..70e91f83 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -123,7 +123,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.40.0
+    rev: v0.41.0
     hooks:
       - id: markdownlint
         args: [""--fix""]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index d78c9bf3..70e91f83 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -123,7 +123,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.40.0
+    rev: v0.41.0
     hooks:
       - id: markdownlint
         args: [""--fix""]",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,1ff0f37561b78589616cbd8ef2e6d67591efd76d,3f48d4f759f90ec546c0d5d353fea9f3db95cc91,Bump docker/login-action from 3.1.0 to 3.2.0 (#2120),"diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 8f2ec92c..cf597811 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -54,7 +54,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@e92390c5fb421da1463c202d546fed0ec5c39f20 # v3.1.0
+        uses: docker/login-action@0d4c9c5ea7693da7b068278f7b52bda2a190a446 # v3.2.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index 8f2ec92c..cf597811 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -54,7 +54,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@e92390c5fb421da1463c202d546fed0ec5c39f20 # v3.1.0
+        uses: docker/login-action@0d4c9c5ea7693da7b068278f7b52bda2a190a446 # v3.2.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,1ff0f37561b78589616cbd8ef2e6d67591efd76d,3f48d4f759f90ec546c0d5d353fea9f3db95cc91,Bump docker/login-action from 3.1.0 to 3.2.0 (#2120),"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 7f82304c..b7593554 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -57,7 +57,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@e92390c5fb421da1463c202d546fed0ec5c39f20 # v3.1.0
+        uses: docker/login-action@0d4c9c5ea7693da7b068278f7b52bda2a190a446 # v3.2.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 7f82304c..b7593554 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -57,7 +57,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@e92390c5fb421da1463c202d546fed0ec5c39f20 # v3.1.0
+        uses: docker/login-action@0d4c9c5ea7693da7b068278f7b52bda2a190a446 # v3.2.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}",Yes
docs/contributing/lint.md,docs/contributing/lint.md,b070fb6bd9ffd3e4413db18075e09f2e0fa3fd2a,1ff0f37561b78589616cbd8ef2e6d67591efd76d,Fix redirect link,"diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index fe838084..7b449179 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -44,7 +44,7 @@ More information can be found in [`.pre-commit-config.yaml` file](https://github
 
 ## Image Lint
 
-To comply with [Docker best practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices),
+To comply with [Docker best practices](https://docs.docker.com/build/building/best-practices/),
 we are using the [Hadolint](https://github.com/hadolint/hadolint) tool to analyze each `Dockerfile`.
 
 ### Ignoring Rules","diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index fe838084..7b449179 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -44,7 +44,7 @@ More information can be found in [`.pre-commit-config.yaml` file](https://github
 
 ## Image Lint
 
-To comply with [Docker best practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices),
+To comply with [Docker best practices](https://docs.docker.com/build/building/best-practices/),
 we are using the [Hadolint](https://github.com/hadolint/hadolint) tool to analyze each `Dockerfile`.
 
 ### Ignoring Rules",Yes
docs/using/selecting.md,docs/using/selecting.md,f5b5d0af511301c89450ce518e98b240b9e61182,b070fb6bd9ffd3e4413db18075e09f2e0fa3fd2a,"Update selecting.md (#2122)

Changing path to renamed repository as mentioned by @mathbunnyru in comments of #2110","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index a975332e..fb2ec53b 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -336,7 +336,7 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 | [b-data][b-data]                  | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].         |
 
 [gpu]: https://github.com/iot-salzburg/gpu-jupyter
-[gpu_thl]: https://hub.docker.com/r/hanseware/jhub-images
+[gpu_thl]: https://hub.docker.com/r/hanseware/jlab-images
 [gpu_mylab]: https://mylab.th-luebeck.de
 [prp_gpu]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/-/tree/prp
 [prp_reg]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/container_registry","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index a975332e..fb2ec53b 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -336,7 +336,7 @@ See the [contributing guide](../contributing/stacks.md) for information about ho
 | [b-data][b-data]                  | GPU accelerated, multi-arch (`linux/amd64`, `linux/arm64/v8`) docker images for [R][r_cuda], [Python][python_cuda] and [Julia][julia_cuda]. Derived from nvidia/cuda `devel`-flavored images, including TensortRT and TensorRT plugin libraries. With [code-server][code-server] next to JupyterLab. Just Python – no [Conda][conda]/[Mamba][mamba].         |
 
 [gpu]: https://github.com/iot-salzburg/gpu-jupyter
-[gpu_thl]: https://hub.docker.com/r/hanseware/jhub-images
+[gpu_thl]: https://hub.docker.com/r/hanseware/jlab-images
 [gpu_mylab]: https://mylab.th-luebeck.de
 [prp_gpu]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/-/tree/prp
 [prp_reg]: https://gitlab.nrp-nautilus.io/prp/jupyter-stack/container_registry",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,b7fb3d15c96d79ed581b24dd2075f928e9d0d591,f5b5d0af511301c89450ce518e98b240b9e61182,Update mypy pre-commit hook,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 70e91f83..d0c6e5d9 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.10.0
+    rev: v1.10.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 70e91f83..d0c6e5d9 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.10.0
+    rev: v1.10.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]",Yes
docs/conf.py,docs/conf.py,37c03eb03ca65106e0f54de5ade7a2a330917110,b7fb3d15c96d79ed581b24dd2075f928e9d0d591,Exclude packages.ubuntu.com from linkcheck,"diff --git a/docs/conf.py b/docs/conf.py
index efe904b8..7957c246 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -66,6 +66,7 @@ linkcheck_ignore = [
     r""https://github\.com/jupyter/docker-stacks/settings/actions/runners/new\?arch=arm64\&amp;os=linux"",  # only works for users with permissions to change runners
     r""http://127\.0\.0\.1:.*"",  # various examples
     r""https://mybinder\.org/v2/gh/.*"",  # lots of 500 errors
+    r""https://packages\.ubuntu\.com/search\?keywords=openjdk"",  # frequent read timeouts
 ]
 
 linkcheck_allowed_redirects = {","diff --git a/docs/conf.py b/docs/conf.py
index efe904b8..7957c246 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -66,6 +66,7 @@ linkcheck_ignore = [
     r""https://github\.com/jupyter/docker-stacks/settings/actions/runners/new\?arch=arm64\&amp;os=linux"",  # only works for users with permissions to change runners
     r""http://127\.0\.0\.1:.*"",  # various examples
     r""https://mybinder\.org/v2/gh/.*"",  # lots of 500 errors
+    r""https://packages\.ubuntu\.com/search\?keywords=openjdk"",  # frequent read timeouts
 ]
 
 linkcheck_allowed_redirects = {",Yes
images/pytorch-notebook/cuda11/Dockerfile,images/pytorch-notebook/cuda11/Dockerfile,3fef15446f217d783341e4949e9c1ecc520935cd,37c03eb03ca65106e0f54de5ade7a2a330917110,"Put nvidia-smi on path for cuda image variants (#2124)

* Put nvidia-smi on path for cuda image variants

* Improve comments style

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
index de0ef1ec..3894f1b4 100644
--- a/images/pytorch-notebook/cuda11/Dockerfile
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -23,3 +23,8 @@ RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
 ENV NVIDIA_VISIBLE_DEVICES all
 ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
+
+# Puts the nvidia-smi binary (system management interface) on path
+# with associated library files to execute it
+ENV PATH=${PATH}:/usr/local/nvidia/bin
+ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64","diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
index de0ef1ec..3894f1b4 100644
--- a/images/pytorch-notebook/cuda11/Dockerfile
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -23,3 +23,8 @@ RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
 ENV NVIDIA_VISIBLE_DEVICES all
 ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
+
+# Puts the nvidia-smi binary (system management interface) on path
+# with associated library files to execute it
+ENV PATH=${PATH}:/usr/local/nvidia/bin
+ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64",Yes
images/pytorch-notebook/cuda12/Dockerfile,images/pytorch-notebook/cuda12/Dockerfile,3fef15446f217d783341e4949e9c1ecc520935cd,37c03eb03ca65106e0f54de5ade7a2a330917110,"Put nvidia-smi on path for cuda image variants (#2124)

* Put nvidia-smi on path for cuda image variants

* Improve comments style

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index c574e42d..99416a26 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -23,3 +23,8 @@ RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
 ENV NVIDIA_VISIBLE_DEVICES all
 ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
+
+# Puts the nvidia-smi binary (system management interface) on path
+# with associated library files to execute it
+ENV PATH=${PATH}:/usr/local/nvidia/bin
+ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64","diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index c574e42d..99416a26 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -23,3 +23,8 @@ RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
 ENV NVIDIA_VISIBLE_DEVICES all
 ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
+
+# Puts the nvidia-smi binary (system management interface) on path
+# with associated library files to execute it
+ENV PATH=${PATH}:/usr/local/nvidia/bin
+ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64",Yes
images/tensorflow-notebook/cuda/Dockerfile,images/tensorflow-notebook/cuda/Dockerfile,3fef15446f217d783341e4949e9c1ecc520935cd,37c03eb03ca65106e0f54de5ade7a2a330917110,"Put nvidia-smi on path for cuda image variants (#2124)

* Put nvidia-smi on path for cuda image variants

* Improve comments style

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index 7e6e65f1..a21d7e94 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -25,3 +25,8 @@ COPY --chown=""${NB_UID}:${NB_GID}"" nvidia-lib-dirs.sh ""${CONDA_DIR}/etc/conda/ac
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
 ENV NVIDIA_VISIBLE_DEVICES=""all"" \
     NVIDIA_DRIVER_CAPABILITIES=""compute,utility""
+
+# Puts the nvidia-smi binary (system management interface) on path
+# with associated library files to execute it
+ENV PATH=${PATH}:/usr/local/nvidia/bin
+ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index 7e6e65f1..a21d7e94 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -25,3 +25,8 @@ COPY --chown=""${NB_UID}:${NB_GID}"" nvidia-lib-dirs.sh ""${CONDA_DIR}/etc/conda/ac
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
 ENV NVIDIA_VISIBLE_DEVICES=""all"" \
     NVIDIA_DRIVER_CAPABILITIES=""compute,utility""
+
+# Puts the nvidia-smi binary (system management interface) on path
+# with associated library files to execute it
+ENV PATH=${PATH}:/usr/local/nvidia/bin
+ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64",Yes
images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh,images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh,3fef15446f217d783341e4949e9c1ecc520935cd,37c03eb03ca65106e0f54de5ade7a2a330917110,"Put nvidia-smi on path for cuda image variants (#2124)

* Put nvidia-smi on path for cuda image variants

* Improve comments style

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh b/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
index efd1b142..1927bd06 100644
--- a/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
+++ b/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
@@ -2,8 +2,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 
-# This adds the NVIDIA libraries to the LD_LIBRARY_PATH. Workaround for
-# https://github.com/tensorflow/tensorflow/issues/63362
+# This adds NVIDIA Python package libraries to the LD_LIBRARY_PATH.
+# Workaround for https://github.com/tensorflow/tensorflow/issues/63362
 NVIDIA_DIR=$(dirname ""$(python -c 'import nvidia;print(nvidia.__file__)')"")
 LD_LIBRARY_PATH=$(echo ""${NVIDIA_DIR}""/*/lib/ | sed -r 's/\s+/:/g')${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
 export LD_LIBRARY_PATH","diff --git a/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh b/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
index efd1b142..1927bd06 100644
--- a/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
+++ b/images/tensorflow-notebook/cuda/nvidia-lib-dirs.sh
@@ -2,8 +2,8 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 
-# This adds the NVIDIA libraries to the LD_LIBRARY_PATH. Workaround for
-# https://github.com/tensorflow/tensorflow/issues/63362
+# This adds NVIDIA Python package libraries to the LD_LIBRARY_PATH.
+# Workaround for https://github.com/tensorflow/tensorflow/issues/63362
 NVIDIA_DIR=$(dirname ""$(python -c 'import nvidia;print(nvidia.__file__)')"")
 LD_LIBRARY_PATH=$(echo ""${NVIDIA_DIR}""/*/lib/ | sed -r 's/\s+/:/g')${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
 export LD_LIBRARY_PATH",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,77acaad3eae6ae53ffa1f8ad75dc5e106aad5076,3fef15446f217d783341e4949e9c1ecc520935cd,[pre-commit.ci] pre-commit autoupdate (#2125),"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index d0c6e5d9..276311ba 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.15.2
+    rev: v3.16.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -117,7 +117,7 @@ repos:
 
   # Lint: Python
   - repo: https://github.com/PyCQA/flake8
-    rev: 7.0.0
+    rev: 7.1.0
     hooks:
       - id: flake8
 
@@ -148,7 +148,7 @@ repos:
 
   # Run black on python code blocks in documentation files.
   - repo: https://github.com/adamchainz/blacken-docs
-    rev: 1.16.0
+    rev: 1.18.0
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index d0c6e5d9..276311ba 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.15.2
+    rev: v3.16.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -117,7 +117,7 @@ repos:
 
   # Lint: Python
   - repo: https://github.com/PyCQA/flake8
-    rev: 7.0.0
+    rev: 7.1.0
     hooks:
       - id: flake8
 
@@ -148,7 +148,7 @@ repos:
 
   # Run black on python code blocks in documentation files.
   - repo: https://github.com/adamchainz/blacken-docs
-    rev: 1.16.0
+    rev: 1.18.0
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if",Yes
tests/scipy-notebook/data/matplotlib/matplotlib_1.py,tests/scipy-notebook/data/matplotlib/matplotlib_1.py,615b8cc01b3347da6536cc3c73303a27bc623135,77acaad3eae6ae53ffa1f8ad75dc5e106aad5076,Ignore mypy in files with numpy,"diff --git a/tests/scipy-notebook/data/matplotlib/matplotlib_1.py b/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
index 8ccf369e..a7d98fbb 100644
--- a/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
+++ b/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
@@ -1,3 +1,4 @@
+# type: ignore
 # Matplotlib: Create a simple plot example.
 # Refs: https://matplotlib.org/stable/gallery/lines_bars_and_markers/simple_plot.html","diff --git a/tests/scipy-notebook/data/matplotlib/matplotlib_1.py b/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
index 8ccf369e..a7d98fbb 100644
--- a/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
+++ b/tests/scipy-notebook/data/matplotlib/matplotlib_1.py
@@ -1,3 +1,4 @@
+# type: ignore
 # Matplotlib: Create a simple plot example.
 # Refs: https://matplotlib.org/stable/gallery/lines_bars_and_markers/simple_plot.html",Yes
tests/scipy-notebook/units/unit_pandas.py,tests/scipy-notebook/units/unit_pandas.py,615b8cc01b3347da6536cc3c73303a27bc623135,77acaad3eae6ae53ffa1f8ad75dc5e106aad5076,Ignore mypy in files with numpy,"diff --git a/tests/scipy-notebook/units/unit_pandas.py b/tests/scipy-notebook/units/unit_pandas.py
index 2190a0b5..a211de50 100644
--- a/tests/scipy-notebook/units/unit_pandas.py
+++ b/tests/scipy-notebook/units/unit_pandas.py
@@ -1,5 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+# type: ignore
 import numpy as np
 import pandas as pd","diff --git a/tests/scipy-notebook/units/unit_pandas.py b/tests/scipy-notebook/units/unit_pandas.py
index 2190a0b5..a211de50 100644
--- a/tests/scipy-notebook/units/unit_pandas.py
+++ b/tests/scipy-notebook/units/unit_pandas.py
@@ -1,5 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+# type: ignore
 import numpy as np
 import pandas as pd",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,06fac8278099eb07c20dcb7506945201d08b8ce2,615b8cc01b3347da6536cc3c73303a27bc623135,Slighty better code quotes,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index d9497ed2..8f2c3ac9 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -200,7 +200,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
 
    where:
 
-   - `""$(id -u)"" and ""$(id -g)""` will dynamically assign the `UID` and `GID` of the user executing the `docker run` command to the new user (`callisto`)
+   - `""$(id -u)""` and `""$(id -g)""` will dynamically assign the `UID` and `GID` of the user executing the `docker run` command to the new user (`callisto`)
 
 ## Additional tips and troubleshooting commands for permission-related errors","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index d9497ed2..8f2c3ac9 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -200,7 +200,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
 
    where:
 
-   - `""$(id -u)"" and ""$(id -g)""` will dynamically assign the `UID` and `GID` of the user executing the `docker run` command to the new user (`callisto`)
+   - `""$(id -u)""` and `""$(id -g)""` will dynamically assign the `UID` and `GID` of the user executing the `docker run` command to the new user (`callisto`)
 
 ## Additional tips and troubleshooting commands for permission-related errors",Yes
docs/maintaining/aarch64-runner.md,docs/maintaining/aarch64-runner.md,483c68771d95fd487594a49aa091311ed8d2973f,06fac8278099eb07c20dcb7506945201d08b8ce2,Fix redirect link,"diff --git a/docs/maintaining/aarch64-runner.md b/docs/maintaining/aarch64-runner.md
index a0beed19..1f27d084 100644
--- a/docs/maintaining/aarch64-runner.md
+++ b/docs/maintaining/aarch64-runner.md
@@ -6,7 +6,7 @@ Each runner is recommended to have at least _2 cores_ and _30 GB_ of disk space.
 
 Add a new runner:
 
-- To use [Oracle OCI](https://www.oracle.com/cloud/), create a compute instance `VM.Standard.A1.Flex`.
+- To use [Oracle OCI](https://www.oracle.com/cloud-0/), create a compute instance `VM.Standard.A1.Flex`.
 - To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-arm-vm-instance#armpublicimage).
 
 Configure your runner:","diff --git a/docs/maintaining/aarch64-runner.md b/docs/maintaining/aarch64-runner.md
index a0beed19..1f27d084 100644
--- a/docs/maintaining/aarch64-runner.md
+++ b/docs/maintaining/aarch64-runner.md
@@ -6,7 +6,7 @@ Each runner is recommended to have at least _2 cores_ and _30 GB_ of disk space.
 
 Add a new runner:
 
-- To use [Oracle OCI](https://www.oracle.com/cloud/), create a compute instance `VM.Standard.A1.Flex`.
+- To use [Oracle OCI](https://www.oracle.com/cloud-0/), create a compute instance `VM.Standard.A1.Flex`.
 - To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-arm-vm-instance#armpublicimage).
 
 Configure your runner:",Yes
.github/workflows/docker-merge-tags.yml,.github/workflows/docker-merge-tags.yml,7f6f16c24c99923cd52a54015c302ed1fb7756c5,483c68771d95fd487594a49aa091311ed8d2973f,"Bump docker/login-action from 3.2.0 to 3.3.0 (#2127)

Bumps [docker/login-action](https://github.com/docker/login-action) from 3.2.0 to 3.3.0.
- [Release notes](https://github.com/docker/login-action/releases)
- [Commits](https://github.com/docker/login-action/compare/0d4c9c5ea7693da7b068278f7b52bda2a190a446...9780b0c442fbb1117ed29e0efdff1e18412f7567)

---
updated-dependencies:
- dependency-name: docker/login-action
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index cf597811..a4768794 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -54,7 +54,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@0d4c9c5ea7693da7b068278f7b52bda2a190a446 # v3.2.0
+        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567 # v3.3.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}","diff --git a/.github/workflows/docker-merge-tags.yml b/.github/workflows/docker-merge-tags.yml
index cf597811..a4768794 100644
--- a/.github/workflows/docker-merge-tags.yml
+++ b/.github/workflows/docker-merge-tags.yml
@@ -54,7 +54,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@0d4c9c5ea7693da7b068278f7b52bda2a190a446 # v3.2.0
+        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567 # v3.3.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,7f6f16c24c99923cd52a54015c302ed1fb7756c5,483c68771d95fd487594a49aa091311ed8d2973f,"Bump docker/login-action from 3.2.0 to 3.3.0 (#2127)

Bumps [docker/login-action](https://github.com/docker/login-action) from 3.2.0 to 3.3.0.
- [Release notes](https://github.com/docker/login-action/releases)
- [Commits](https://github.com/docker/login-action/compare/0d4c9c5ea7693da7b068278f7b52bda2a190a446...9780b0c442fbb1117ed29e0efdff1e18412f7567)

---
updated-dependencies:
- dependency-name: docker/login-action
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index b7593554..887e2d2e 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -57,7 +57,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@0d4c9c5ea7693da7b068278f7b52bda2a190a446 # v3.2.0
+        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567 # v3.3.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index b7593554..887e2d2e 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -57,7 +57,7 @@ jobs:
 
       - name: Login to Registry 🔐
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: docker/login-action@0d4c9c5ea7693da7b068278f7b52bda2a190a446 # v3.2.0
+        uses: docker/login-action@9780b0c442fbb1117ed29e0efdff1e18412f7567 # v3.3.0
         with:
           registry: quay.io
           username: ${{ secrets.REGISTRY_USERNAME }}",Yes
docs/using/selecting.md,docs/using/selecting.md,1ad688e4213cc8de3607bfc01b5d050a13764019,7f6f16c24c99923cd52a54015c302ed1fb7756c5,"Improve handling of tensorboard (#2126)

* Improve handling of tensorboard

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Improve style

* Move bash file to cuda-subdir

* Update tensorflow-notebook info

* Fix redirect link

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index fb2ec53b..d4cd71dc 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -193,7 +193,8 @@ It contains:
 `jupyter/tensorflow-notebook` includes popular Python deep learning libraries.
 
 - Everything in `jupyter/scipy-notebook` and its ancestor images
-- [tensorflow](https://www.tensorflow.org/) machine learning library
+- [TensorFlow](https://www.tensorflow.org/) machine learning library
+- [Jupyter Server Proxy](https://jupyter-server-proxy.readthedocs.io/en/latest/) to support [TensorBoard](https://www.tensorflow.org/tensorboard)
 
 ### jupyter/pytorch-notebook","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index fb2ec53b..d4cd71dc 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -193,7 +193,8 @@ It contains:
 `jupyter/tensorflow-notebook` includes popular Python deep learning libraries.
 
 - Everything in `jupyter/scipy-notebook` and its ancestor images
-- [tensorflow](https://www.tensorflow.org/) machine learning library
+- [TensorFlow](https://www.tensorflow.org/) machine learning library
+- [Jupyter Server Proxy](https://jupyter-server-proxy.readthedocs.io/en/latest/) to support [TensorBoard](https://www.tensorflow.org/tensorboard)
 
 ### jupyter/pytorch-notebook",Yes
images/tensorflow-notebook/Dockerfile,images/tensorflow-notebook/Dockerfile,1ad688e4213cc8de3607bfc01b5d050a13764019,7f6f16c24c99923cd52a54015c302ed1fb7756c5,"Improve handling of tensorboard (#2126)

* Improve handling of tensorboard

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Improve style

* Move bash file to cuda-subdir

* Update tensorflow-notebook info

* Fix redirect link

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index be366d49..01ace0f1 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -13,6 +13,10 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install tensorflow with pip, on x86_64 tensorflow-cpu
 RUN [[ $(uname -m) = x86_64 ]] && TF_POSTFIX=""-cpu"" || TF_POSTFIX="""" && \
-    pip install --no-cache-dir ""tensorflow${TF_POSTFIX}"" && \
+    pip install --no-cache-dir \
+    ""tensorflow${TF_POSTFIX}"" \
+    ""jupyter-server-proxy"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
+
+COPY --chown=""${NB_UID}:${NB_GID}"" cuda/20tensorboard-proxy-env.sh /usr/local/bin/before-notebook.d/","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index be366d49..01ace0f1 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -13,6 +13,10 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install tensorflow with pip, on x86_64 tensorflow-cpu
 RUN [[ $(uname -m) = x86_64 ]] && TF_POSTFIX=""-cpu"" || TF_POSTFIX="""" && \
-    pip install --no-cache-dir ""tensorflow${TF_POSTFIX}"" && \
+    pip install --no-cache-dir \
+    ""tensorflow${TF_POSTFIX}"" \
+    ""jupyter-server-proxy"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
+
+COPY --chown=""${NB_UID}:${NB_GID}"" cuda/20tensorboard-proxy-env.sh /usr/local/bin/before-notebook.d/",Yes
,images/tensorflow-notebook/cuda/20tensorboard-proxy-env.sh,1ad688e4213cc8de3607bfc01b5d050a13764019,7f6f16c24c99923cd52a54015c302ed1fb7756c5,"Improve handling of tensorboard (#2126)

* Improve handling of tensorboard

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Improve style

* Move bash file to cuda-subdir

* Update tensorflow-notebook info

* Fix redirect link

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/tensorflow-notebook/cuda/20tensorboard-proxy-env.sh b/images/tensorflow-notebook/cuda/20tensorboard-proxy-env.sh
new file mode 100644
index 00000000..f31c7488
--- /dev/null
+++ b/images/tensorflow-notebook/cuda/20tensorboard-proxy-env.sh
@@ -0,0 +1,10 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+# Initialize the TENSORBOARD_PROXY_URL with the appropriate path
+# to use jupyter-server-proxy.
+
+export TENSORBOARD_PROXY_URL=""${JUPYTERHUB_SERVICE_PREFIX:-/}proxy/%PORT%/""","diff --git a/images/tensorflow-notebook/cuda/20tensorboard-proxy-env.sh b/images/tensorflow-notebook/cuda/20tensorboard-proxy-env.sh
new file mode 100644
index 00000000..f31c7488
--- /dev/null
+++ b/images/tensorflow-notebook/cuda/20tensorboard-proxy-env.sh
@@ -0,0 +1,10 @@
+#!/bin/bash
+# Copyright (c) Jupyter Development Team.
+# Distributed under the terms of the Modified BSD License.
+
+set -e
+
+# Initialize the TENSORBOARD_PROXY_URL with the appropriate path
+# to use jupyter-server-proxy.
+
+export TENSORBOARD_PROXY_URL=""${JUPYTERHUB_SERVICE_PREFIX:-/}proxy/%PORT%/""",Yes
images/tensorflow-notebook/cuda/Dockerfile,images/tensorflow-notebook/cuda/Dockerfile,1ad688e4213cc8de3607bfc01b5d050a13764019,7f6f16c24c99923cd52a54015c302ed1fb7756c5,"Improve handling of tensorboard (#2126)

* Improve handling of tensorboard

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Improve style

* Move bash file to cuda-subdir

* Update tensorflow-notebook info

* Fix redirect link

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index a21d7e94..88542761 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -12,10 +12,14 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install TensorFlow, CUDA and cuDNN with pip
-RUN pip install --no-cache-dir ""tensorflow[and-cuda]"" && \
+RUN pip install --no-cache-dir \
+    ""tensorflow[and-cuda]"" \
+    ""jupyter-server-proxy"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
+COPY --chown=""${NB_UID}:${NB_GID}"" 20tensorboard-proxy-env.sh /usr/local/bin/before-notebook.d/
+
 # workaround for https://github.com/tensorflow/tensorflow/issues/63362
 RUN mkdir -p ""${CONDA_DIR}/etc/conda/activate.d/"" && \
     fix-permissions ""${CONDA_DIR}""","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index a21d7e94..88542761 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -12,10 +12,14 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install TensorFlow, CUDA and cuDNN with pip
-RUN pip install --no-cache-dir ""tensorflow[and-cuda]"" && \
+RUN pip install --no-cache-dir \
+    ""tensorflow[and-cuda]"" \
+    ""jupyter-server-proxy"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""
 
+COPY --chown=""${NB_UID}:${NB_GID}"" 20tensorboard-proxy-env.sh /usr/local/bin/before-notebook.d/
+
 # workaround for https://github.com/tensorflow/tensorflow/issues/63362
 RUN mkdir -p ""${CONDA_DIR}/etc/conda/activate.d/"" && \
     fix-permissions ""${CONDA_DIR}""",Yes
docs/contributing/stacks.md,docs/contributing/stacks.md,7a918f53599a896ec45cb6886c515be7adaee6c3,1ad688e4213cc8de3607bfc01b5d050a13764019,Update redirect link,"diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index af551991..37b474e6 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -71,7 +71,7 @@ git push -u origin main
 
 1. By default, the newly `.github/workflows/docker.yaml` will trigger the CI pipeline whenever you push to your `main` branch
    and when any Pull Requests are made to your repository.
-   For more details on this configuration, visit the [GitHub actions documentation on triggers](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows).
+   For more details on this configuration, visit the [GitHub actions documentation on triggers](https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/events-that-trigger-workflows).
 
 2. Go to your repository and click on the **Actions** tab.
    From there, you can click on the workflows on the left-hand side of the screen.","diff --git a/docs/contributing/stacks.md b/docs/contributing/stacks.md
index af551991..37b474e6 100644
--- a/docs/contributing/stacks.md
+++ b/docs/contributing/stacks.md
@@ -71,7 +71,7 @@ git push -u origin main
 
 1. By default, the newly `.github/workflows/docker.yaml` will trigger the CI pipeline whenever you push to your `main` branch
    and when any Pull Requests are made to your repository.
-   For more details on this configuration, visit the [GitHub actions documentation on triggers](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows).
+   For more details on this configuration, visit the [GitHub actions documentation on triggers](https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/events-that-trigger-workflows).
 
 2. Go to your repository and click on the **Actions** tab.
    From there, you can click on the workflows on the left-hand side of the screen.",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,6ed34af77aa40408faf079d0ec6cd790d430750a,7a918f53599a896ec45cb6886c515be7adaee6c3,"Add netbase to docker-stacks-foundation image - fixes #2128 (#2129)

* Add netbase to docker-stacks-foundation image - fixes #2128

* Add a comment describing netbase","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index f6b38c8c..84d57235 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -30,6 +30,10 @@ RUN apt-get update --yes && \
     bzip2 \
     ca-certificates \
     locales \
+    # - `netbase` provides /etc/{protocols,rpc,services}, part of POSIX
+    #   and required by various C functions like getservbyname and getprotobyname
+    #   https://github.com/jupyter/docker-stacks/pull/2129
+    netbase \
     sudo \
     # - `tini` is installed as a helpful container entrypoint,
     #   that reaps zombie processes and such of the actual executable we want to start","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index f6b38c8c..84d57235 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -30,6 +30,10 @@ RUN apt-get update --yes && \
     bzip2 \
     ca-certificates \
     locales \
+    # - `netbase` provides /etc/{protocols,rpc,services}, part of POSIX
+    #   and required by various C functions like getservbyname and getprotobyname
+    #   https://github.com/jupyter/docker-stacks/pull/2129
+    netbase \
     sudo \
     # - `tini` is installed as a helpful container entrypoint,
     #   that reaps zombie processes and such of the actual executable we want to start",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,e6b5e74ba41fbc92c7e537d3253c32bd072faca7,6ed34af77aa40408faf079d0ec6cd790d430750a,"[pre-commit.ci] pre-commit autoupdate (#2130)

updates:
- [github.com/asottile/pyupgrade: v3.16.0 → v3.17.0](https://github.com/asottile/pyupgrade/compare/v3.16.0...v3.17.0)
- [github.com/psf/black: 24.4.2 → 24.8.0](https://github.com/psf/black/compare/24.4.2...24.8.0)
- [github.com/pre-commit/mirrors-mypy: v1.10.1 → v1.11.1](https://github.com/pre-commit/mirrors-mypy/compare/v1.10.1...v1.11.1)
- [github.com/PyCQA/flake8: 7.1.0 → 7.1.1](https://github.com/PyCQA/flake8/compare/7.1.0...7.1.1)
- [github.com/nbQA-dev/nbQA: 1.8.5 → 1.8.7](https://github.com/nbQA-dev/nbQA/compare/1.8.5...1.8.7)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 276311ba..7e18a374 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.16.0
+    rev: v3.17.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.4.2
+    rev: 24.8.0
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.10.1
+    rev: v1.11.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -117,7 +117,7 @@ repos:
 
   # Lint: Python
   - repo: https://github.com/PyCQA/flake8
-    rev: 7.1.0
+    rev: 7.1.1
     hooks:
       - id: flake8
 
@@ -137,7 +137,7 @@ repos:
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.8.5
+    rev: 1.8.7
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 276311ba..7e18a374 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.16.0
+    rev: v3.17.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.4.2
+    rev: 24.8.0
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.10.1
+    rev: v1.11.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -117,7 +117,7 @@ repos:
 
   # Lint: Python
   - repo: https://github.com/PyCQA/flake8
-    rev: 7.1.0
+    rev: 7.1.1
     hooks:
       - id: flake8
 
@@ -137,7 +137,7 @@ repos:
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.8.5
+    rev: 1.8.7
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]",Yes
images/docker-stacks-foundation/start.sh,images/docker-stacks-foundation/start.sh,6f74c72a92f229ced23b73c138cc9580ca89ea22,e6b5e74ba41fbc92c7e537d3253c32bd072faca7,"[FAST_BUILD] No sudo when run with rootless triplet (#2132)

* No sudo when run with rootless triplet

-  rootless triplet: -e NB_USER=root -e NB_UID=0 -e NB_GID=0

* Add tests for rootless triplet

* Update tests for rootless triplet

* Fix tests for rootless triplet","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 33d12d80..295ee263 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -155,11 +155,14 @@ if [ ""$(id -u)"" == 0 ]; then
     unset_explicit_env_vars
 
     _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
-    exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
-        LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}"" \
-        PATH=""${PATH}"" \
-        PYTHONPATH=""${PYTHONPATH:-}"" \
-        ""${cmd[@]}""
+    if [ ""${NB_USER}"" = ""root"" ] && [ ""${NB_UID}"" = ""$(id -u ""${NB_USER}"")"" ] && [ ""${NB_GID}"" = ""$(id -g ""${NB_USER}"")"" ]; then
+        HOME=""/home/root"" exec ""${cmd[@]}""
+    else
+        exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
+            LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}"" \
+            PATH=""${PATH}"" \
+            PYTHONPATH=""${PYTHONPATH:-}"" \
+            ""${cmd[@]}""
         # Notes on how we ensure that the environment that this container is started
         # with is preserved (except vars listed in JUPYTER_ENV_VARS_TO_UNSET) when
         # we transition from running as root to running as NB_USER.
@@ -187,6 +190,7 @@ if [ ""$(id -u)"" == 0 ]; then
         #   above in /etc/sudoers.d/path. Thus PATH is irrelevant to how the above
         #   sudo command resolves the path of `${cmd[@]}`. The PATH will be relevant
         #   for resolving paths of any subprocesses spawned by `${cmd[@]}`.
+    fi
 
 # The container didn't start as the root user, so we will have to act as the
 # user we started as.","diff --git a/images/docker-stacks-foundation/start.sh b/images/docker-stacks-foundation/start.sh
index 33d12d80..295ee263 100755
--- a/images/docker-stacks-foundation/start.sh
+++ b/images/docker-stacks-foundation/start.sh
@@ -155,11 +155,14 @@ if [ ""$(id -u)"" == 0 ]; then
     unset_explicit_env_vars
 
     _log ""Running as ${NB_USER}:"" ""${cmd[@]}""
-    exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
-        LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}"" \
-        PATH=""${PATH}"" \
-        PYTHONPATH=""${PYTHONPATH:-}"" \
-        ""${cmd[@]}""
+    if [ ""${NB_USER}"" = ""root"" ] && [ ""${NB_UID}"" = ""$(id -u ""${NB_USER}"")"" ] && [ ""${NB_GID}"" = ""$(id -g ""${NB_USER}"")"" ]; then
+        HOME=""/home/root"" exec ""${cmd[@]}""
+    else
+        exec sudo --preserve-env --set-home --user ""${NB_USER}"" \
+            LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}"" \
+            PATH=""${PATH}"" \
+            PYTHONPATH=""${PYTHONPATH:-}"" \
+            ""${cmd[@]}""
         # Notes on how we ensure that the environment that this container is started
         # with is preserved (except vars listed in JUPYTER_ENV_VARS_TO_UNSET) when
         # we transition from running as root to running as NB_USER.
@@ -187,6 +190,7 @@ if [ ""$(id -u)"" == 0 ]; then
         #   above in /etc/sudoers.d/path. Thus PATH is irrelevant to how the above
         #   sudo command resolves the path of `${cmd[@]}`. The PATH will be relevant
         #   for resolving paths of any subprocesses spawned by `${cmd[@]}`.
+    fi
 
 # The container didn't start as the root user, so we will have to act as the
 # user we started as.",Yes
tests/docker-stacks-foundation/test_user_options.py,tests/docker-stacks-foundation/test_user_options.py,6f74c72a92f229ced23b73c138cc9580ca89ea22,e6b5e74ba41fbc92c7e537d3253c32bd072faca7,"[FAST_BUILD] No sudo when run with rootless triplet (#2132)

* No sudo when run with rootless triplet

-  rootless triplet: -e NB_USER=root -e NB_UID=0 -e NB_GID=0

* Add tests for rootless triplet

* Update tests for rootless triplet

* Fix tests for rootless triplet","diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index fb2b4625..1ef6ada3 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -305,3 +305,42 @@ def test_startsh_multiple_exec(container: TrackedContainer) -> None:
         ""WARNING: start.sh is the default ENTRYPOINT, do not include it in CMD""
         in warnings[0]
     )
+
+
+def test_rootless_triplet_change(container: TrackedContainer) -> None:
+    """"""Container should change the username (`NB_USER`), the UID and the GID of the default user.""""""
+    logs = container.run_and_wait(
+        timeout=10,
+        tty=True,
+        user=""root"",
+        environment=[""NB_USER=root"", ""NB_UID=0"", ""NB_GID=0""],
+        command=[""id""],
+    )
+    assert ""uid=0(root)"" in logs
+    assert ""gid=0(root)"" in logs
+    assert ""groups=0(root)"" in logs
+
+
+def test_rootless_triplet_home(container: TrackedContainer) -> None:
+    """"""Container should change the home directory for triplet NB_USER=root, NB_UID=0, NB_GID=0.""""""
+    logs = container.run_and_wait(
+        timeout=10,
+        tty=True,
+        user=""root"",
+        environment=[""NB_USER=root"", ""NB_UID=0"", ""NB_GID=0""],
+        command=[""bash"", ""-c"", ""echo HOME=${HOME} && getent passwd root""],
+    )
+    assert ""HOME=/home/root"" in logs
+    assert ""root:x:0:0:root:/home/root:/bin/bash"" in logs
+
+
+def test_rootless_triplet_sudo(container: TrackedContainer) -> None:
+    """"""Container should not be started with sudo for triplet NB_USER=root, NB_UID=0, NB_GID=0.""""""
+    logs = container.run_and_wait(
+        timeout=10,
+        tty=True,
+        user=""root"",
+        environment=[""NB_USER=root"", ""NB_UID=0"", ""NB_GID=0""],
+        command=[""env""],
+    )
+    assert ""SUDO"" not in logs","diff --git a/tests/docker-stacks-foundation/test_user_options.py b/tests/docker-stacks-foundation/test_user_options.py
index fb2b4625..1ef6ada3 100644
--- a/tests/docker-stacks-foundation/test_user_options.py
+++ b/tests/docker-stacks-foundation/test_user_options.py
@@ -305,3 +305,42 @@ def test_startsh_multiple_exec(container: TrackedContainer) -> None:
         ""WARNING: start.sh is the default ENTRYPOINT, do not include it in CMD""
         in warnings[0]
     )
+
+
+def test_rootless_triplet_change(container: TrackedContainer) -> None:
+    """"""Container should change the username (`NB_USER`), the UID and the GID of the default user.""""""
+    logs = container.run_and_wait(
+        timeout=10,
+        tty=True,
+        user=""root"",
+        environment=[""NB_USER=root"", ""NB_UID=0"", ""NB_GID=0""],
+        command=[""id""],
+    )
+    assert ""uid=0(root)"" in logs
+    assert ""gid=0(root)"" in logs
+    assert ""groups=0(root)"" in logs
+
+
+def test_rootless_triplet_home(container: TrackedContainer) -> None:
+    """"""Container should change the home directory for triplet NB_USER=root, NB_UID=0, NB_GID=0.""""""
+    logs = container.run_and_wait(
+        timeout=10,
+        tty=True,
+        user=""root"",
+        environment=[""NB_USER=root"", ""NB_UID=0"", ""NB_GID=0""],
+        command=[""bash"", ""-c"", ""echo HOME=${HOME} && getent passwd root""],
+    )
+    assert ""HOME=/home/root"" in logs
+    assert ""root:x:0:0:root:/home/root:/bin/bash"" in logs
+
+
+def test_rootless_triplet_sudo(container: TrackedContainer) -> None:
+    """"""Container should not be started with sudo for triplet NB_USER=root, NB_UID=0, NB_GID=0.""""""
+    logs = container.run_and_wait(
+        timeout=10,
+        tty=True,
+        user=""root"",
+        environment=[""NB_USER=root"", ""NB_UID=0"", ""NB_GID=0""],
+        command=[""env""],
+    )
+    assert ""SUDO"" not in logs",Yes
Makefile,Makefile,a966c0a94123d733525736fdd460ad5e685960a5,6f74c72a92f229ced23b73c138cc9580ca89ea22,Use root container arg in Makefile (#2133),"diff --git a/Makefile b/Makefile
index 98fa4d65..6f68b955 100644
--- a/Makefile
+++ b/Makefile
@@ -38,7 +38,7 @@ help:
 build/%: DOCKER_BUILD_ARGS?=
 build/%: ROOT_CONTAINER?=ubuntu:22.04
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)""
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)"" --build-arg ROOT_CONTAINER=""$(ROOT_CONTAINER)""
 	@echo -n ""Built image size: ""
 	@docker images ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks","diff --git a/Makefile b/Makefile
index 98fa4d65..6f68b955 100644
--- a/Makefile
+++ b/Makefile
@@ -38,7 +38,7 @@ help:
 build/%: DOCKER_BUILD_ARGS?=
 build/%: ROOT_CONTAINER?=ubuntu:22.04
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)""
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)"" --build-arg ROOT_CONTAINER=""$(ROOT_CONTAINER)""
 	@echo -n ""Built image size: ""
 	@docker images ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks",Yes
docs/using/recipe_code/microsoft_odbc.dockerfile,docs/using/recipe_code/microsoft_odbc.dockerfile,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,a966c0a94123d733525736fdd460ad5e685960a5,Unify ENV command in Dockerfiles (#2135),"diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index 1138d69f..b0970372 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -6,7 +6,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-ENV MSSQL_DRIVER ""ODBC Driver 18 for SQL Server""
+ENV MSSQL_DRIVER=""ODBC Driver 18 for SQL Server""
 ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
 
 RUN apt-get update --yes && \","diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index 1138d69f..b0970372 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -6,7 +6,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 USER root
 
-ENV MSSQL_DRIVER ""ODBC Driver 18 for SQL Server""
+ENV MSSQL_DRIVER=""ODBC Driver 18 for SQL Server""
 ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
 
 RUN apt-get update --yes && \",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,a966c0a94123d733525736fdd460ad5e685960a5,Unify ENV command in Dockerfiles (#2135),"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 8846fe6c..5684e2a0 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -34,8 +34,8 @@ RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclit
 
 # And configure variables
 RUN echo ""ORACLE_HOME=/usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64"" >> ""${HOME}/.bashrc"" && \
-    echo ""PATH=${ORACLE_HOME}/bin:${PATH}"" >> ""${HOME}/.bashrc"" && \
-    echo ""LD_LIBRARY_PATH=${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}"" >> ""${HOME}/.bashrc"" && \
+    echo ""PATH=\""${ORACLE_HOME}/bin:${PATH}\"""" >> ""${HOME}/.bashrc"" && \
+    echo ""LD_LIBRARY_PATH=\""${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}\"""" >> ""${HOME}/.bashrc"" && \
     echo ""export ORACLE_HOME"" >> ""${HOME}/.bashrc"" && \
     echo ""export PATH"" >> ""${HOME}/.bashrc"" && \
     echo ""export LD_LIBRARY_PATH"" >> ""${HOME}/.bashrc""","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 8846fe6c..5684e2a0 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -34,8 +34,8 @@ RUN wget --progress=dot:giga ""${INSTANTCLIENT_URL}/oracle-instantclient-basiclit
 
 # And configure variables
 RUN echo ""ORACLE_HOME=/usr/lib/oracle/${INSTANTCLIENT_MAJOR_VERSION}/client64"" >> ""${HOME}/.bashrc"" && \
-    echo ""PATH=${ORACLE_HOME}/bin:${PATH}"" >> ""${HOME}/.bashrc"" && \
-    echo ""LD_LIBRARY_PATH=${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}"" >> ""${HOME}/.bashrc"" && \
+    echo ""PATH=\""${ORACLE_HOME}/bin:${PATH}\"""" >> ""${HOME}/.bashrc"" && \
+    echo ""LD_LIBRARY_PATH=\""${ORACLE_HOME}/lib:${LD_LIBRARY_PATH}\"""" >> ""${HOME}/.bashrc"" && \
     echo ""export ORACLE_HOME"" >> ""${HOME}/.bashrc"" && \
     echo ""export PATH"" >> ""${HOME}/.bashrc"" && \
     echo ""export LD_LIBRARY_PATH"" >> ""${HOME}/.bashrc""",Yes
docs/using/recipes.md,docs/using/recipes.md,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,a966c0a94123d733525736fdd460ad5e685960a5,Unify ENV command in Dockerfiles (#2135),"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index f42696d0..3abbd6c0 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -301,10 +301,10 @@ This recipe is not tested and might be broken.
 FROM quay.io/jupyter/all-spark-notebook
 
 # Set env vars for pydoop
-ENV HADOOP_HOME /usr/local/hadoop-2.7.3
-ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
-ENV HADOOP_CONF_HOME /usr/local/hadoop-2.7.3/etc/hadoop
-ENV HADOOP_CONF_DIR /usr/local/hadoop-2.7.3/etc/hadoop
+ENV HADOOP_HOME=/usr/local/hadoop-2.7.3
+ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ENV HADOOP_CONF_HOME=/usr/local/hadoop-2.7.3/etc/hadoop
+ENV HADOOP_CONF_DIR=/usr/local/hadoop-2.7.3/etc/hadoop
 
 USER root
 # Add proper open-jdk-8 not the jre only, needed for pydoop","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index f42696d0..3abbd6c0 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -301,10 +301,10 @@ This recipe is not tested and might be broken.
 FROM quay.io/jupyter/all-spark-notebook
 
 # Set env vars for pydoop
-ENV HADOOP_HOME /usr/local/hadoop-2.7.3
-ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
-ENV HADOOP_CONF_HOME /usr/local/hadoop-2.7.3/etc/hadoop
-ENV HADOOP_CONF_DIR /usr/local/hadoop-2.7.3/etc/hadoop
+ENV HADOOP_HOME=/usr/local/hadoop-2.7.3
+ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
+ENV HADOOP_CONF_HOME=/usr/local/hadoop-2.7.3/etc/hadoop
+ENV HADOOP_CONF_DIR=/usr/local/hadoop-2.7.3/etc/hadoop
 
 USER root
 # Add proper open-jdk-8 not the jre only, needed for pydoop",Yes
images/all-spark-notebook/Dockerfile,images/all-spark-notebook/Dockerfile,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,a966c0a94123d733525736fdd460ad5e685960a5,Unify ENV command in Dockerfiles (#2135),"diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
index 1a97294b..53f3c8a6 100644
--- a/images/all-spark-notebook/Dockerfile
+++ b/images/all-spark-notebook/Dockerfile
@@ -14,7 +14,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 USER root
 
 # RSpark config
-ENV R_LIBS_USER ""${SPARK_HOME}/R/lib""
+ENV R_LIBS_USER=""${SPARK_HOME}/R/lib""
 RUN fix-permissions ""${R_LIBS_USER}""
 
 # R pre-requisites","diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
index 1a97294b..53f3c8a6 100644
--- a/images/all-spark-notebook/Dockerfile
+++ b/images/all-spark-notebook/Dockerfile
@@ -14,7 +14,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 USER root
 
 # RSpark config
-ENV R_LIBS_USER ""${SPARK_HOME}/R/lib""
+ENV R_LIBS_USER=""${SPARK_HOME}/R/lib""
 RUN fix-permissions ""${R_LIBS_USER}""
 
 # R pre-requisites",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,a966c0a94123d733525736fdd460ad5e685960a5,Unify ENV command in Dockerfiles (#2135),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 84d57235..7852fe9d 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -20,7 +20,7 @@ USER root
 
 # Install all OS dependencies for the Server that starts
 # but lacks all features (e.g., download as all possible file formats)
-ENV DEBIAN_FRONTEND noninteractive
+ENV DEBIAN_FRONTEND=noninteractive
 RUN apt-get update --yes && \
     # - `apt-get upgrade` is run to patch known vulnerabilities in system packages
     #   as the Ubuntu base image is rebuilt too seldom sometimes (less than once a month)","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 84d57235..7852fe9d 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -20,7 +20,7 @@ USER root
 
 # Install all OS dependencies for the Server that starts
 # but lacks all features (e.g., download as all possible file formats)
-ENV DEBIAN_FRONTEND noninteractive
+ENV DEBIAN_FRONTEND=noninteractive
 RUN apt-get update --yes && \
     # - `apt-get upgrade` is run to patch known vulnerabilities in system packages
     #   as the Ubuntu base image is rebuilt too seldom sometimes (less than once a month)",Yes
images/pytorch-notebook/cuda11/Dockerfile,images/pytorch-notebook/cuda11/Dockerfile,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,a966c0a94123d733525736fdd460ad5e685960a5,Unify ENV command in Dockerfiles (#2135),"diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
index 3894f1b4..d19d0f12 100644
--- a/images/pytorch-notebook/cuda11/Dockerfile
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -21,10 +21,10 @@ RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index
     fix-permissions ""/home/${NB_USER}""
 
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
-ENV NVIDIA_VISIBLE_DEVICES all
-ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
+ENV NVIDIA_VISIBLE_DEVICES=""all"" \
+    NVIDIA_DRIVER_CAPABILITIES=""compute,utility""
 
 # Puts the nvidia-smi binary (system management interface) on path
 # with associated library files to execute it
-ENV PATH=${PATH}:/usr/local/nvidia/bin
-ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64
+ENV PATH=""${PATH}:/usr/local/nvidia/bin"" \
+    LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64""","diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
index 3894f1b4..d19d0f12 100644
--- a/images/pytorch-notebook/cuda11/Dockerfile
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -21,10 +21,10 @@ RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index
     fix-permissions ""/home/${NB_USER}""
 
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
-ENV NVIDIA_VISIBLE_DEVICES all
-ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
+ENV NVIDIA_VISIBLE_DEVICES=""all"" \
+    NVIDIA_DRIVER_CAPABILITIES=""compute,utility""
 
 # Puts the nvidia-smi binary (system management interface) on path
 # with associated library files to execute it
-ENV PATH=${PATH}:/usr/local/nvidia/bin
-ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64
+ENV PATH=""${PATH}:/usr/local/nvidia/bin"" \
+    LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64""",Yes
images/pytorch-notebook/cuda12/Dockerfile,images/pytorch-notebook/cuda12/Dockerfile,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,a966c0a94123d733525736fdd460ad5e685960a5,Unify ENV command in Dockerfiles (#2135),"diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index 99416a26..36b60d38 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -21,10 +21,10 @@ RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index
     fix-permissions ""/home/${NB_USER}""
 
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
-ENV NVIDIA_VISIBLE_DEVICES all
-ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
+ENV NVIDIA_VISIBLE_DEVICES=""all"" \
+    NVIDIA_DRIVER_CAPABILITIES=""compute,utility""
 
 # Puts the nvidia-smi binary (system management interface) on path
 # with associated library files to execute it
-ENV PATH=${PATH}:/usr/local/nvidia/bin
-ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64
+ENV PATH=""${PATH}:/usr/local/nvidia/bin"" \
+    LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64""","diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index 99416a26..36b60d38 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -21,10 +21,10 @@ RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index
     fix-permissions ""/home/${NB_USER}""
 
 # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html#dockerfiles
-ENV NVIDIA_VISIBLE_DEVICES all
-ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
+ENV NVIDIA_VISIBLE_DEVICES=""all"" \
+    NVIDIA_DRIVER_CAPABILITIES=""compute,utility""
 
 # Puts the nvidia-smi binary (system management interface) on path
 # with associated library files to execute it
-ENV PATH=${PATH}:/usr/local/nvidia/bin
-ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64
+ENV PATH=""${PATH}:/usr/local/nvidia/bin"" \
+    LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64""",Yes
images/tensorflow-notebook/cuda/Dockerfile,images/tensorflow-notebook/cuda/Dockerfile,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,a966c0a94123d733525736fdd460ad5e685960a5,Unify ENV command in Dockerfiles (#2135),"diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index 88542761..f27ba2bd 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -32,5 +32,5 @@ ENV NVIDIA_VISIBLE_DEVICES=""all"" \
 
 # Puts the nvidia-smi binary (system management interface) on path
 # with associated library files to execute it
-ENV PATH=${PATH}:/usr/local/nvidia/bin
-ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64
+ENV PATH=""${PATH}:/usr/local/nvidia/bin"" \
+    LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64""","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index 88542761..f27ba2bd 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -32,5 +32,5 @@ ENV NVIDIA_VISIBLE_DEVICES=""all"" \
 
 # Puts the nvidia-smi binary (system management interface) on path
 # with associated library files to execute it
-ENV PATH=${PATH}:/usr/local/nvidia/bin
-ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64
+ENV PATH=""${PATH}:/usr/local/nvidia/bin"" \
+    LD_LIBRARY_PATH=""${LD_LIBRARY_PATH}:/usr/local/nvidia/lib64""",Yes
README.md,README.md,5fbcb0dff55174d275532647853545c0921b6ab7,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,Fix redirect docker docs links,"diff --git a/README.md b/README.md
index cd16d88c..2a875fa2 100644
--- a/README.md
+++ b/README.md
@@ -37,7 +37,7 @@ It then starts a container running a Jupyter Server with the JupyterLab frontend
 docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-05-27
 ```
 
-You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
+You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
 
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab,
 where:","diff --git a/README.md b/README.md
index cd16d88c..2a875fa2 100644
--- a/README.md
+++ b/README.md
@@ -37,7 +37,7 @@ It then starts a container running a Jupyter Server with the JupyterLab frontend
 docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-05-27
 ```
 
-You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/reference/run/#exposed-ports) to `-p 8888:8888`.
+You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
 
 Visiting `http://<hostname>:10000/?token=<token>` in a browser loads JupyterLab,
 where:",Yes
docs/using/common.md,docs/using/common.md,5fbcb0dff55174d275532647853545c0921b6ab7,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,Fix redirect docker docs links,"diff --git a/docs/using/common.md b/docs/using/common.md
index b3b314c9..8fa8f6b8 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -62,8 +62,8 @@ You do so by passing arguments to the `docker run` command.
   This feature is useful when mounting host volumes with specific owner permissions.
   You **must** run the container with `--user root` for this option to take effect.
   (The startup script will `su ${NB_USER}` after adjusting the user ID.)
-  Instead, you might consider using the modern Docker-native options [`--user`](https://docs.docker.com/engine/reference/run/#user) and
-  [`--group-add`](https://docs.docker.com/engine/reference/run/#additional-groups) - see the last bullet in this section for more details.
+  Instead, you might consider using the modern Docker-native options [`--user`](https://docs.docker.com/engine/containers/run/#user) and
+  [`--group-add`](https://docs.docker.com/engine/containers/run/#additional-groups) - see the last bullet in this section for more details.
   See bullet points regarding `--user` and `--group-add`.
 
 - `-e NB_GID=<numeric gid>` - Instructs the startup script to change the primary group of `${NB_USER}` to `${NB_GID}`","diff --git a/docs/using/common.md b/docs/using/common.md
index b3b314c9..8fa8f6b8 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -62,8 +62,8 @@ You do so by passing arguments to the `docker run` command.
   This feature is useful when mounting host volumes with specific owner permissions.
   You **must** run the container with `--user root` for this option to take effect.
   (The startup script will `su ${NB_USER}` after adjusting the user ID.)
-  Instead, you might consider using the modern Docker-native options [`--user`](https://docs.docker.com/engine/reference/run/#user) and
-  [`--group-add`](https://docs.docker.com/engine/reference/run/#additional-groups) - see the last bullet in this section for more details.
+  Instead, you might consider using the modern Docker-native options [`--user`](https://docs.docker.com/engine/containers/run/#user) and
+  [`--group-add`](https://docs.docker.com/engine/containers/run/#additional-groups) - see the last bullet in this section for more details.
   See bullet points regarding `--user` and `--group-add`.
 
 - `-e NB_GID=<numeric gid>` - Instructs the startup script to change the primary group of `${NB_USER}` to `${NB_GID}`",Yes
docs/using/faq.md,docs/using/faq.md,5fbcb0dff55174d275532647853545c0921b6ab7,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,Fix redirect docker docs links,"diff --git a/docs/using/faq.md b/docs/using/faq.md
index a8b71688..7f45d73e 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -17,8 +17,8 @@ There are 2 types of data, which you might want to persist.
 
 2. If you want to persist user data (files created by you, like `Python` scripts, notebooks, text files, and so on),
    then you should use a
-   [Docker bind mount](https://docs.docker.com/storage/bind-mounts/) or
-   [Docker Volume](https://docs.docker.com/storage/volumes/).
+   [Docker bind mount](https://docs.docker.com/engine/storage/bind-mounts/) or
+   [Docker Volume](https://docs.docker.com/engine/storage/volumes/).
    You can find [an example of using a bind mount here](./running.md#example-2).
    There is also [a mount troubleshooting section](./troubleshooting.md#permission-denied-when-mounting-volumes) if you experience any issues.","diff --git a/docs/using/faq.md b/docs/using/faq.md
index a8b71688..7f45d73e 100644
--- a/docs/using/faq.md
+++ b/docs/using/faq.md
@@ -17,8 +17,8 @@ There are 2 types of data, which you might want to persist.
 
 2. If you want to persist user data (files created by you, like `Python` scripts, notebooks, text files, and so on),
    then you should use a
-   [Docker bind mount](https://docs.docker.com/storage/bind-mounts/) or
-   [Docker Volume](https://docs.docker.com/storage/volumes/).
+   [Docker bind mount](https://docs.docker.com/engine/storage/bind-mounts/) or
+   [Docker Volume](https://docs.docker.com/engine/storage/volumes/).
    You can find [an example of using a bind mount here](./running.md#example-2).
    There is also [a mount troubleshooting section](./troubleshooting.md#permission-denied-when-mounting-volumes) if you experience any issues.",Yes
docs/using/running.md,docs/using/running.md,5fbcb0dff55174d275532647853545c0921b6ab7,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,Fix redirect docker docs links,"diff --git a/docs/using/running.md b/docs/using/running.md
index e44d32bd..c727a8ad 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -9,7 +9,7 @@ This section provides details about the second.
 
 ## Using the Docker CLI
 
-You can launch a local Docker container from the Jupyter Docker Stacks using the [Docker command-line interface](https://docs.docker.com/engine/reference/commandline/cli/).
+You can launch a local Docker container from the Jupyter Docker Stacks using the [Docker command-line interface](https://docs.docker.com/reference/cli/docker/).
 There are numerous ways to configure containers using CLI.
 The following are some common patterns.","diff --git a/docs/using/running.md b/docs/using/running.md
index e44d32bd..c727a8ad 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -9,7 +9,7 @@ This section provides details about the second.
 
 ## Using the Docker CLI
 
-You can launch a local Docker container from the Jupyter Docker Stacks using the [Docker command-line interface](https://docs.docker.com/engine/reference/commandline/cli/).
+You can launch a local Docker container from the Jupyter Docker Stacks using the [Docker command-line interface](https://docs.docker.com/reference/cli/docker/).
 There are numerous ways to configure containers using CLI.
 The following are some common patterns.",Yes
docs/using/troubleshooting.md,docs/using/troubleshooting.md,5fbcb0dff55174d275532647853545c0921b6ab7,4d4ed0e0bf2685d301c98992e2ad7ccd2df8a839,Fix redirect docker docs links,"diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 8f2c3ac9..f06577e5 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -77,7 +77,7 @@ The following sections cover a few of these scenarios and how to fix them.
       - If you are mounting your volume inside the `/home/` directory, you can use the `-e CHOWN_HOME=yes` and `CHOWN_HOME_OPTS=""-R""` flags
       instead of the `-e CHOWN_EXTRA` and `-e CHOWN_EXTRA_OPTS` in the example above.
       - This solution should work in most cases where you have created a docker volume
-      (i.e. using the [`docker volume create --name <my-volume>`command](https://docs.docker.com/storage/volumes/#create-and-manage-volumes)) and mounted it using the `-v` flag in `docker run`.
+      (i.e. using the [`docker volume create --name <my-volume>`command](https://docs.docker.com/engine/storage/volumes/#create-and-manage-volumes)) and mounted it using the `-v` flag in `docker run`.
    ```
 
 2. **Matching the container's UID/GID with the host's**
@@ -229,7 +229,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
   to modify the files in the default `/home` and `/opt/conda` directories.
   Further avoiding issues when trying to `conda install` additional packages.
 
-- Use `docker inspect <container_id>` and look for the [`Mounts` section](https://docs.docker.com/storage/volumes/#start-a-container-with-a-volume)
+- Use `docker inspect <container_id>` and look for the [`Mounts` section](https://docs.docker.com/engine/storage/volumes/#start-a-container-with-a-volume)
   to verify that the volume was created and mounted accordingly:
 
   ```json","diff --git a/docs/using/troubleshooting.md b/docs/using/troubleshooting.md
index 8f2c3ac9..f06577e5 100644
--- a/docs/using/troubleshooting.md
+++ b/docs/using/troubleshooting.md
@@ -77,7 +77,7 @@ The following sections cover a few of these scenarios and how to fix them.
       - If you are mounting your volume inside the `/home/` directory, you can use the `-e CHOWN_HOME=yes` and `CHOWN_HOME_OPTS=""-R""` flags
       instead of the `-e CHOWN_EXTRA` and `-e CHOWN_EXTRA_OPTS` in the example above.
       - This solution should work in most cases where you have created a docker volume
-      (i.e. using the [`docker volume create --name <my-volume>`command](https://docs.docker.com/storage/volumes/#create-and-manage-volumes)) and mounted it using the `-v` flag in `docker run`.
+      (i.e. using the [`docker volume create --name <my-volume>`command](https://docs.docker.com/engine/storage/volumes/#create-and-manage-volumes)) and mounted it using the `-v` flag in `docker run`.
    ```
 
 2. **Matching the container's UID/GID with the host's**
@@ -229,7 +229,7 @@ If you have also **created a new user**, you might be experiencing any of the fo
   to modify the files in the default `/home` and `/opt/conda` directories.
   Further avoiding issues when trying to `conda install` additional packages.
 
-- Use `docker inspect <container_id>` and look for the [`Mounts` section](https://docs.docker.com/storage/volumes/#start-a-container-with-a-volume)
+- Use `docker inspect <container_id>` and look for the [`Mounts` section](https://docs.docker.com/engine/storage/volumes/#start-a-container-with-a-volume)
   to verify that the volume was created and mounted accordingly:
 
   ```json",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,7f8cdf851ab9173175dbc477f9cc38890c390e2e,5fbcb0dff55174d275532647853545c0921b6ab7,Cleaner logs,"diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index c1fcae98..8d94ec4d 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -77,7 +77,7 @@ jobs:
           platform: ${{ inputs.platform }}
           variant: ${{ inputs.parent-variant }}
 
-      - name: Pull ubuntu:22.04 image 📥
+      - name: Pull base ubuntu image 📥
         if: inputs.parent-image == ''
         run: docker pull ubuntu:22.04
         shell: bash","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index c1fcae98..8d94ec4d 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -77,7 +77,7 @@ jobs:
           platform: ${{ inputs.platform }}
           variant: ${{ inputs.parent-variant }}
 
-      - name: Pull ubuntu:22.04 image 📥
+      - name: Pull base ubuntu image 📥
         if: inputs.parent-image == ''
         run: docker pull ubuntu:22.04
         shell: bash",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,5ea1adbfd8fd96dbebc9cfb550edeaae71f59bc4,7f8cdf851ab9173175dbc477f9cc38890c390e2e,Improve Dockerfiles codestyle,"diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 07903b94..672f66b0 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -31,7 +31,7 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
-# Install JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
+# Install JupyterHub, JupyterLab, NBClassic and Jupyter Notebook
 # Generate a Jupyter Server config
 # Cleanup temporary files
 # Correct permissions
@@ -39,10 +39,10 @@ USER ${NB_UID}
 # files across image layers when the permissions change
 WORKDIR /tmp
 RUN mamba install --yes \
-    'jupyterlab' \
-    'notebook' \
     'jupyterhub' \
-    'nbclassic' && \
+    'jupyterlab' \
+    'nbclassic' \
+    'notebook' && \
     jupyter server --generate-config && \
     mamba clean --all -f -y && \
     npm cache clean --force && \","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 07903b94..672f66b0 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -31,7 +31,7 @@ RUN apt-get update --yes && \
 
 USER ${NB_UID}
 
-# Install JupyterLab, Jupyter Notebook, JupyterHub and NBClassic
+# Install JupyterHub, JupyterLab, NBClassic and Jupyter Notebook
 # Generate a Jupyter Server config
 # Cleanup temporary files
 # Correct permissions
@@ -39,10 +39,10 @@ USER ${NB_UID}
 # files across image layers when the permissions change
 WORKDIR /tmp
 RUN mamba install --yes \
-    'jupyterlab' \
-    'notebook' \
     'jupyterhub' \
-    'nbclassic' && \
+    'jupyterlab' \
+    'nbclassic' \
+    'notebook' && \
     jupyter server --generate-config && \
     mamba clean --all -f -y && \
     npm cache clean --force && \",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,5ea1adbfd8fd96dbebc9cfb550edeaae71f59bc4,7f8cdf851ab9173175dbc477f9cc38890c390e2e,Improve Dockerfiles codestyle,"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 7852fe9d..fafc3cd3 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -117,9 +117,9 @@ RUN set -x && \
         --root-prefix=""${CONDA_DIR}"" \
         --prefix=""${CONDA_DIR}"" \
         --yes \
-        ""${PYTHON_SPECIFIER}"" \
+        'jupyter_core' \
         'mamba' \
-        'jupyter_core' && \
+        ""${PYTHON_SPECIFIER}"" && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python
     # https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#preventing-packages-from-updating-pinning","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 7852fe9d..fafc3cd3 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -117,9 +117,9 @@ RUN set -x && \
         --root-prefix=""${CONDA_DIR}"" \
         --prefix=""${CONDA_DIR}"" \
         --yes \
-        ""${PYTHON_SPECIFIER}"" \
+        'jupyter_core' \
         'mamba' \
-        'jupyter_core' && \
+        ""${PYTHON_SPECIFIER}"" && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python
     # https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#preventing-packages-from-updating-pinning",Yes
images/pytorch-notebook/Dockerfile,images/pytorch-notebook/Dockerfile,5ea1adbfd8fd96dbebc9cfb550edeaae71f59bc4,7f8cdf851ab9173175dbc477f9cc38890c390e2e,Improve Dockerfiles codestyle,"diff --git a/images/pytorch-notebook/Dockerfile b/images/pytorch-notebook/Dockerfile
index 922e6389..13d1a181 100644
--- a/images/pytorch-notebook/Dockerfile
+++ b/images/pytorch-notebook/Dockerfile
@@ -15,7 +15,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # hadolint ignore=DL3013
 RUN pip install --no-cache-dir --index-url 'https://download.pytorch.org/whl/cpu' \
     'torch' \
-    'torchvision' \
-    'torchaudio'  && \
+    'torchaudio' \
+    'torchvision' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/pytorch-notebook/Dockerfile b/images/pytorch-notebook/Dockerfile
index 922e6389..13d1a181 100644
--- a/images/pytorch-notebook/Dockerfile
+++ b/images/pytorch-notebook/Dockerfile
@@ -15,7 +15,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # hadolint ignore=DL3013
 RUN pip install --no-cache-dir --index-url 'https://download.pytorch.org/whl/cpu' \
     'torch' \
-    'torchvision' \
-    'torchaudio'  && \
+    'torchaudio' \
+    'torchvision' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
images/pytorch-notebook/cuda11/Dockerfile,images/pytorch-notebook/cuda11/Dockerfile,5ea1adbfd8fd96dbebc9cfb550edeaae71f59bc4,7f8cdf851ab9173175dbc477f9cc38890c390e2e,Improve Dockerfiles codestyle,"diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
index d19d0f12..d1a5b990 100644
--- a/images/pytorch-notebook/cuda11/Dockerfile
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -15,8 +15,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # hadolint ignore=DL3013
 RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu118' \
     'torch' \
-    'torchvision' \
-    'torchaudio'  && \
+    'torchaudio' \
+    'torchvision' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
index d19d0f12..d1a5b990 100644
--- a/images/pytorch-notebook/cuda11/Dockerfile
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -15,8 +15,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # hadolint ignore=DL3013
 RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu118' \
     'torch' \
-    'torchvision' \
-    'torchaudio'  && \
+    'torchaudio' \
+    'torchvision' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
images/pytorch-notebook/cuda12/Dockerfile,images/pytorch-notebook/cuda12/Dockerfile,5ea1adbfd8fd96dbebc9cfb550edeaae71f59bc4,7f8cdf851ab9173175dbc477f9cc38890c390e2e,Improve Dockerfiles codestyle,"diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index 36b60d38..59081e38 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -15,8 +15,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # hadolint ignore=DL3013
 RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu121' \
     'torch' \
-    'torchvision' \
-    'torchaudio'  && \
+    'torchaudio' \
+    'torchvision' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index 36b60d38..59081e38 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -15,8 +15,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # hadolint ignore=DL3013
 RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu121' \
     'torch' \
-    'torchvision' \
-    'torchaudio'  && \
+    'torchaudio' \
+    'torchvision' && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
images/scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,5ea1adbfd8fd96dbebc9cfb550edeaae71f59bc4,7f8cdf851ab9173175dbc477f9cc38890c390e2e,Improve Dockerfiles codestyle,"diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 1c8003d4..ad2d838f 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -38,7 +38,7 @@ RUN mamba install --yes \
     'dask' \
     'dill' \
     'h5py' \
-    'ipympl'\
+    'ipympl' \
     'ipywidgets' \
     'jupyterlab-git' \
     'matplotlib-base' \
@@ -56,7 +56,7 @@ RUN mamba install --yes \
     'sqlalchemy' \
     'statsmodels' \
     'sympy' \
-    'widgetsnbextension'\
+    'widgetsnbextension' \
     'xlrd' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index 1c8003d4..ad2d838f 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -38,7 +38,7 @@ RUN mamba install --yes \
     'dask' \
     'dill' \
     'h5py' \
-    'ipympl'\
+    'ipympl' \
     'ipywidgets' \
     'jupyterlab-git' \
     'matplotlib-base' \
@@ -56,7 +56,7 @@ RUN mamba install --yes \
     'sqlalchemy' \
     'statsmodels' \
     'sympy' \
-    'widgetsnbextension'\
+    'widgetsnbextension' \
     'xlrd' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \",Yes
images/tensorflow-notebook/Dockerfile,images/tensorflow-notebook/Dockerfile,5ea1adbfd8fd96dbebc9cfb550edeaae71f59bc4,7f8cdf851ab9173175dbc477f9cc38890c390e2e,Improve Dockerfiles codestyle,"diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index 01ace0f1..d6c0b78a 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -14,8 +14,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # Install tensorflow with pip, on x86_64 tensorflow-cpu
 RUN [[ $(uname -m) = x86_64 ]] && TF_POSTFIX=""-cpu"" || TF_POSTFIX="""" && \
     pip install --no-cache-dir \
-    ""tensorflow${TF_POSTFIX}"" \
-    ""jupyter-server-proxy"" && \
+    ""jupyter-server-proxy"" \
+    ""tensorflow${TF_POSTFIX}"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index 01ace0f1..d6c0b78a 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -14,8 +14,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # Install tensorflow with pip, on x86_64 tensorflow-cpu
 RUN [[ $(uname -m) = x86_64 ]] && TF_POSTFIX=""-cpu"" || TF_POSTFIX="""" && \
     pip install --no-cache-dir \
-    ""tensorflow${TF_POSTFIX}"" \
-    ""jupyter-server-proxy"" && \
+    ""jupyter-server-proxy"" \
+    ""tensorflow${TF_POSTFIX}"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
images/tensorflow-notebook/cuda/Dockerfile,images/tensorflow-notebook/cuda/Dockerfile,5ea1adbfd8fd96dbebc9cfb550edeaae71f59bc4,7f8cdf851ab9173175dbc477f9cc38890c390e2e,Improve Dockerfiles codestyle,"diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index f27ba2bd..f71f6416 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -13,8 +13,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install TensorFlow, CUDA and cuDNN with pip
 RUN pip install --no-cache-dir \
-    ""tensorflow[and-cuda]"" \
-    ""jupyter-server-proxy"" && \
+    ""jupyter-server-proxy"" \
+    ""tensorflow[and-cuda]"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index f27ba2bd..f71f6416 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -13,8 +13,8 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install TensorFlow, CUDA and cuDNN with pip
 RUN pip install --no-cache-dir \
-    ""tensorflow[and-cuda]"" \
-    ""jupyter-server-proxy"" && \
+    ""jupyter-server-proxy"" \
+    ""tensorflow[and-cuda]"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
README.md,README.md,bed6d6396cfb9eff6f19f2f094bd81b47fcfedc2,5ea1adbfd8fd96dbebc9cfb550edeaae71f59bc4,Fix date when cuda pytorch-notebook was added,"diff --git a/README.md b/README.md
index 2a875fa2..ae9e1dad 100644
--- a/README.md
+++ b/README.md
@@ -101,7 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-05-27`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-02-24`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images","diff --git a/README.md b/README.md
index 2a875fa2..ae9e1dad 100644
--- a/README.md
+++ b/README.md
@@ -101,7 +101,7 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-05-27`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-02-24`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
 
 ## Using old images",Yes
README.md,README.md,c18c46593c828ff85aa2c311d2891e10167906d8,bed6d6396cfb9eff6f19f2f094bd81b47fcfedc2,Update tag example,"diff --git a/README.md b/README.md
index ae9e1dad..9a1804c9 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-05-27
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-08-19
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-05-27
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-08-19
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index ae9e1dad..9a1804c9 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-05-27
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-08-19
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-05-27
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-08-19
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,c18c46593c828ff85aa2c311d2891e10167906d8,bed6d6396cfb9eff6f19f2f094bd81b47fcfedc2,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index cc407eec..75e42642 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-05-27
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-08-19
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-05-27""
+ENV TAG=""2024-08-19""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index cc407eec..75e42642 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-05-27
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-08-19
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-05-27""
+ENV TAG=""2024-08-19""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,c18c46593c828ff85aa2c311d2891e10167906d8,bed6d6396cfb9eff6f19f2f094bd81b47fcfedc2,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index c727a8ad..7d9f282e 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-05-27
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-08-19
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-05-27   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-08-19   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-05-27
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-08-19
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-05-27
+    quay.io/jupyter/r-notebook:2024-08-19
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index c727a8ad..7d9f282e 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-05-27
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-08-19
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-05-27   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-08-19   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-05-27
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-08-19
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-05-27` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-05-27
+    quay.io/jupyter/r-notebook:2024-08-19
 ```
 
 ```{warning}",Yes
README.md,README.md,4edd4d36c0bfd13b1102b65d15134783544f1c65,c18c46593c828ff85aa2c311d2891e10167906d8,Update info about CUDA enabled images,"diff --git a/README.md b/README.md
index 9a1804c9..859a7912 100644
--- a/README.md
+++ b/README.md
@@ -101,7 +101,8 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-02-24`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-02-24`, we create CUDA enabled variants of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-03-26`, we create CUDA enabled variant of `tensorflow-notebook` image for `x86_64` platform
 
 ## Using old images","diff --git a/README.md b/README.md
index 9a1804c9..859a7912 100644
--- a/README.md
+++ b/README.md
@@ -101,7 +101,8 @@ more information is available in the [documentation](https://jupyter-docker-stac
 - Single-platform images have either `aarch64-` or `x86_64-` tag prefixes, for example, `quay.io/jupyter/base-notebook:aarch64-python-3.11.6`
 - Starting from `2022-09-21`, we create multi-platform images (except `tensorflow-notebook`)
 - Starting from `2023-06-01`, we create a multi-platform `tensorflow-notebook` image as well
-- Starting from `2024-02-24`, we create CUDA enabled variant of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-02-24`, we create CUDA enabled variants of `pytorch-notebook` image for `x86_64` platform
+- Starting from `2024-03-26`, we create CUDA enabled variant of `tensorflow-notebook` image for `x86_64` platform
 
 ## Using old images",Yes
README.md,README.md,aabaa58072623dcc62a71c9e84e3501ab11f5e9d,4edd4d36c0bfd13b1102b65d15134783544f1c65,Fix redirect docker docs link,"diff --git a/README.md b/README.md
index 859a7912..1a8a50e9 100644
--- a/README.md
+++ b/README.md
@@ -18,7 +18,7 @@ You can use a stack image to do any of the following (and more):
 ## Quick Start
 
 You can [try a relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb).
-Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
+Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-started/get-docker/),
 know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use, and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.","diff --git a/README.md b/README.md
index 859a7912..1a8a50e9 100644
--- a/README.md
+++ b/README.md
@@ -18,7 +18,7 @@ You can use a stack image to do any of the following (and more):
 ## Quick Start
 
 You can [try a relatively recent build of the quay.io/jupyter/base-notebook image on mybinder.org](https://mybinder.org/v2/gh/jupyter/docker-stacks/main?urlpath=lab/tree/README.ipynb).
-Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-docker/),
+Otherwise, the examples below may help you get started if you [have Docker installed](https://docs.docker.com/get-started/get-docker/),
 know [which Docker image](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html) you want to use, and want to launch a single Jupyter Application in a container.
 
 The [User Guide on ReadTheDocs](https://jupyter-docker-stacks.readthedocs.io/en/latest/) describes additional uses and features in detail.",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,00987883e58d139b5ed01f803f95e639c59bf340,aabaa58072623dcc62a71c9e84e3501ab11f5e9d,Improve comment for user creation in Dockerfile,"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index fafc3cd3..031acb16 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -68,7 +68,7 @@ RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashr
     # and docs: https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html
     echo 'eval ""$(conda shell.bash hook)""' >> /etc/skel/.bashrc
 
-# Create NB_USER with name jovyan user with UID=1000 and in the 'users' group
+# Create ""${NB_USER}"" user (`jovyan` by default) with UID=""${NB_UID}"" (`1000` by default) and in the 'users' group
 # and make sure these dirs are writable by the `users` group.
 RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
     sed -i.bak -e 's/^%admin/#%admin/' /etc/sudoers && \","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index fafc3cd3..031acb16 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -68,7 +68,7 @@ RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashr
     # and docs: https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html
     echo 'eval ""$(conda shell.bash hook)""' >> /etc/skel/.bashrc
 
-# Create NB_USER with name jovyan user with UID=1000 and in the 'users' group
+# Create ""${NB_USER}"" user (`jovyan` by default) with UID=""${NB_UID}"" (`1000` by default) and in the 'users' group
 # and make sure these dirs are writable by the `users` group.
 RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
     sed -i.bak -e 's/^%admin/#%admin/' /etc/sudoers && \",Yes
.github/workflows/docker-build-test-upload.yml,.github/workflows/docker-build-test-upload.yml,e51895bcbdbcec97eb52798b952190a30a02707a,00987883e58d139b5ed01f803f95e639c59bf340,"Upgrade to Ubuntu 24.04 Image base (#2131)

* fixed

* Update .github/workflows/docker-build-test-upload.yml

* Only remove user with uid 1000 if it exists

* Update Dockerfile

* Update Dockerfile

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 8d94ec4d..a7bb1950 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -79,7 +79,7 @@ jobs:
 
       - name: Pull base ubuntu image 📥
         if: inputs.parent-image == ''
-        run: docker pull ubuntu:22.04
+        run: docker pull ubuntu:24.04
         shell: bash
 
       - name: Build image 🛠","diff --git a/.github/workflows/docker-build-test-upload.yml b/.github/workflows/docker-build-test-upload.yml
index 8d94ec4d..a7bb1950 100644
--- a/.github/workflows/docker-build-test-upload.yml
+++ b/.github/workflows/docker-build-test-upload.yml
@@ -79,7 +79,7 @@ jobs:
 
       - name: Pull base ubuntu image 📥
         if: inputs.parent-image == ''
-        run: docker pull ubuntu:22.04
+        run: docker pull ubuntu:24.04
         shell: bash
 
       - name: Build image 🛠",Yes
Makefile,Makefile,e51895bcbdbcec97eb52798b952190a30a02707a,00987883e58d139b5ed01f803f95e639c59bf340,"Upgrade to Ubuntu 24.04 Image base (#2131)

* fixed

* Update .github/workflows/docker-build-test-upload.yml

* Only remove user with uid 1000 if it exists

* Update Dockerfile

* Update Dockerfile

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/Makefile b/Makefile
index 6f68b955..0bf19610 100644
--- a/Makefile
+++ b/Makefile
@@ -36,7 +36,7 @@ help:
 
 
 build/%: DOCKER_BUILD_ARGS?=
-build/%: ROOT_CONTAINER?=ubuntu:22.04
+build/%: ROOT_CONTAINER?=ubuntu:24.04
 build/%: ## build the latest image for a stack using the system's architecture
 	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)"" --build-arg ROOT_CONTAINER=""$(ROOT_CONTAINER)""
 	@echo -n ""Built image size: ""","diff --git a/Makefile b/Makefile
index 6f68b955..0bf19610 100644
--- a/Makefile
+++ b/Makefile
@@ -36,7 +36,7 @@ help:
 
 
 build/%: DOCKER_BUILD_ARGS?=
-build/%: ROOT_CONTAINER?=ubuntu:22.04
+build/%: ROOT_CONTAINER?=ubuntu:24.04
 build/%: ## build the latest image for a stack using the system's architecture
 	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)"" --build-arg ROOT_CONTAINER=""$(ROOT_CONTAINER)""
 	@echo -n ""Built image size: """,Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,e51895bcbdbcec97eb52798b952190a30a02707a,00987883e58d139b5ed01f803f95e639c59bf340,"Upgrade to Ubuntu 24.04 Image base (#2131)

* fixed

* Update .github/workflows/docker-build-test-upload.yml

* Only remove user with uid 1000 if it exists

* Update Dockerfile

* Update Dockerfile

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 031acb16..7ffaadb8 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -1,9 +1,9 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 
-# Ubuntu 22.04 (jammy)
-# https://hub.docker.com/_/ubuntu/tags?page=1&name=jammy
-ARG ROOT_CONTAINER=ubuntu:22.04
+# Ubuntu 24.04 (noble)
+# https://hub.docker.com/_/ubuntu/tags?page=1&name=noble
+ARG ROOT_CONTAINER=ubuntu:24.04
 
 FROM $ROOT_CONTAINER
 
@@ -68,6 +68,12 @@ RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashr
     # and docs: https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html
     echo 'eval ""$(conda shell.bash hook)""' >> /etc/skel/.bashrc
 
+# Delete existing user with UID=""${NB_UID}"" if it exists
+# hadolint ignore=SC2046
+RUN if grep -q ""${NB_UID}"" /etc/passwd; then \
+        userdel --remove $(id -un ""${NB_UID}""); \
+    fi
+
 # Create ""${NB_USER}"" user (`jovyan` by default) with UID=""${NB_UID}"" (`1000` by default) and in the 'users' group
 # and make sure these dirs are writable by the `users` group.
 RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 031acb16..7ffaadb8 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -1,9 +1,9 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 
-# Ubuntu 22.04 (jammy)
-# https://hub.docker.com/_/ubuntu/tags?page=1&name=jammy
-ARG ROOT_CONTAINER=ubuntu:22.04
+# Ubuntu 24.04 (noble)
+# https://hub.docker.com/_/ubuntu/tags?page=1&name=noble
+ARG ROOT_CONTAINER=ubuntu:24.04
 
 FROM $ROOT_CONTAINER
 
@@ -68,6 +68,12 @@ RUN sed -i 's/^#force_color_prompt=yes/force_color_prompt=yes/' /etc/skel/.bashr
     # and docs: https://docs.conda.io/projects/conda/en/latest/dev-guide/deep-dives/activation.html
     echo 'eval ""$(conda shell.bash hook)""' >> /etc/skel/.bashrc
 
+# Delete existing user with UID=""${NB_UID}"" if it exists
+# hadolint ignore=SC2046
+RUN if grep -q ""${NB_UID}"" /etc/passwd; then \
+        userdel --remove $(id -un ""${NB_UID}""); \
+    fi
+
 # Create ""${NB_USER}"" user (`jovyan` by default) with UID=""${NB_UID}"" (`1000` by default) and in the 'users' group
 # and make sure these dirs are writable by the `users` group.
 RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,f7978e28df0ec795d92193a5c4773cc641381055,e51895bcbdbcec97eb52798b952190a30a02707a,Temporarily switch to ubuntu 22.04 in oracledb example,"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 5684e2a0..44ff2cd4 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook:ubuntu-22.04
 
 USER root","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 5684e2a0..44ff2cd4 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook:ubuntu-22.04
 
 USER root",Yes
docs/using/recipe_code/microsoft_odbc.dockerfile,docs/using/recipe_code/microsoft_odbc.dockerfile,823cf92db4ede8f5a4836c5b7ea761e4ea3923c7,f7978e28df0ec795d92193a5c4773cc641381055,Temporarily switch to ubuntu 22.04 in microsoft odbc example instead of oracle,"diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index b0970372..8642fdf4 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook:ubuntu-22.04
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014","diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index b0970372..8642fdf4 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook:ubuntu-22.04
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,823cf92db4ede8f5a4836c5b7ea761e4ea3923c7,f7978e28df0ec795d92193a5c4773cc641381055,Temporarily switch to ubuntu 22.04 in microsoft odbc example instead of oracle,"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 44ff2cd4..5684e2a0 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook:ubuntu-22.04
+FROM quay.io/jupyter/base-notebook
 
 USER root","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 44ff2cd4..5684e2a0 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook:ubuntu-22.04
+FROM quay.io/jupyter/base-notebook
 
 USER root",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,f78d97a3a83cd5eeea5e42b0687d731d6bf6d274,823cf92db4ede8f5a4836c5b7ea761e4ea3923c7,Temporarily switch to ubuntu 22.04 in oracledb example,"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 5684e2a0..44ff2cd4 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook:ubuntu-22.04
 
 USER root","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 5684e2a0..44ff2cd4 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook
+FROM quay.io/jupyter/base-notebook:ubuntu-22.04
 
 USER root",Yes
.github/workflows/contributed-recipes.yml,.github/workflows/contributed-recipes.yml,e136ad7574797c46940902cbe739c6165942f02b,f78d97a3a83cd5eeea5e42b0687d731d6bf6d274,Build contributed recipes in mathbunnyru fork as well,"diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 100ed11c..6a4ba74d 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -31,11 +31,13 @@ jobs:
       - name: Calculate recipes matrix 🛠
         id: set-matrix
         run: docs/using/recipe_code/generate_matrix.py >> ""${GITHUB_OUTPUT}""
+        env:
+          REPOSITORY_OWNER: ${{ github.repository_owner }}
 
   test-recipes:
     runs-on: ${{ matrix.runs-on }}
     needs: generate-matrix
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
 
     steps:
       - name: Checkout Repo ⚡️","diff --git a/.github/workflows/contributed-recipes.yml b/.github/workflows/contributed-recipes.yml
index 100ed11c..6a4ba74d 100644
--- a/.github/workflows/contributed-recipes.yml
+++ b/.github/workflows/contributed-recipes.yml
@@ -31,11 +31,13 @@ jobs:
       - name: Calculate recipes matrix 🛠
         id: set-matrix
         run: docs/using/recipe_code/generate_matrix.py >> ""${GITHUB_OUTPUT}""
+        env:
+          REPOSITORY_OWNER: ${{ github.repository_owner }}
 
   test-recipes:
     runs-on: ${{ matrix.runs-on }}
     needs: generate-matrix
-    if: github.repository_owner == 'jupyter'
+    if: github.repository_owner == 'jupyter' || github.repository_owner == 'mathbunnyru'
 
     steps:
       - name: Checkout Repo ⚡️",Yes
docs/using/recipe_code/generate_matrix.py,docs/using/recipe_code/generate_matrix.py,e136ad7574797c46940902cbe739c6165942f02b,f78d97a3a83cd5eeea5e42b0687d731d6bf6d274,Build contributed recipes in mathbunnyru fork as well,"diff --git a/docs/using/recipe_code/generate_matrix.py b/docs/using/recipe_code/generate_matrix.py
index 62159f30..f44736d2 100755
--- a/docs/using/recipe_code/generate_matrix.py
+++ b/docs/using/recipe_code/generate_matrix.py
@@ -2,17 +2,22 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 import json
+import os
 from pathlib import Path
 from typing import Any
 
 THIS_DIR = Path(__file__).parent.resolve()
+REPOSITORY_OWNER = os.environ[""REPOSITORY_OWNER""]
 
 
 def generate_matrix() -> dict[str, Any]:
     dockerfiles = sorted(file.name for file in THIS_DIR.glob(""*.dockerfile""))
+    runs_on = [""ubuntu-latest""]
+    if REPOSITORY_OWNER == ""jupyter"":
+        runs_on.append(""ARM64"")
     return {
         ""dockerfile"": dockerfiles,
-        ""runs-on"": [""ubuntu-latest"", ""ARM64""],
+        ""runs-on"": runs_on,
         ""exclude"": [{""dockerfile"": ""oracledb.dockerfile"", ""runs-on"": ""ARM64""}],
     }","diff --git a/docs/using/recipe_code/generate_matrix.py b/docs/using/recipe_code/generate_matrix.py
index 62159f30..f44736d2 100755
--- a/docs/using/recipe_code/generate_matrix.py
+++ b/docs/using/recipe_code/generate_matrix.py
@@ -2,17 +2,22 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 import json
+import os
 from pathlib import Path
 from typing import Any
 
 THIS_DIR = Path(__file__).parent.resolve()
+REPOSITORY_OWNER = os.environ[""REPOSITORY_OWNER""]
 
 
 def generate_matrix() -> dict[str, Any]:
     dockerfiles = sorted(file.name for file in THIS_DIR.glob(""*.dockerfile""))
+    runs_on = [""ubuntu-latest""]
+    if REPOSITORY_OWNER == ""jupyter"":
+        runs_on.append(""ARM64"")
     return {
         ""dockerfile"": dockerfiles,
-        ""runs-on"": [""ubuntu-latest"", ""ARM64""],
+        ""runs-on"": runs_on,
         ""exclude"": [{""dockerfile"": ""oracledb.dockerfile"", ""runs-on"": ""ARM64""}],
     }",Yes
README.md,README.md,3215aa83945048ee2e72341bc658066593724649,e136ad7574797c46940902cbe739c6165942f02b,Update information about old images,"diff --git a/README.md b/README.md
index 1a8a50e9..300592fa 100644
--- a/README.md
+++ b/README.md
@@ -119,7 +119,8 @@ If you want to use the older `Ubuntu` and/or `Python` version, you can use the f
 | 2022-10-09   | 22.04  | 3.8    | `7285848c0a11` |
 | 2022-10-09   | 22.04  | 3.9    | `ed2908bbb62e` |
 | 2023-05-30   | 22.04  | 3.10   | `4d70cf8da953` |
-| weekly build | 22.04  | 3.11   | `latest`       |
+| 2024-08-26   | 22.04  | 3.11   | `00987883e58d` |
+| weekly build | 24.04  | 3.11   | `latest`       |
 
 ## Contributing","diff --git a/README.md b/README.md
index 1a8a50e9..300592fa 100644
--- a/README.md
+++ b/README.md
@@ -119,7 +119,8 @@ If you want to use the older `Ubuntu` and/or `Python` version, you can use the f
 | 2022-10-09   | 22.04  | 3.8    | `7285848c0a11` |
 | 2022-10-09   | 22.04  | 3.9    | `ed2908bbb62e` |
 | 2023-05-30   | 22.04  | 3.10   | `4d70cf8da953` |
-| weekly build | 22.04  | 3.11   | `latest`       |
+| 2024-08-26   | 22.04  | 3.11   | `00987883e58d` |
+| weekly build | 24.04  | 3.11   | `latest`       |
 
 ## Contributing",Yes
README.md,README.md,4e47f292617d18b21e46767eb96ebff04c5ec5c9,3215aa83945048ee2e72341bc658066593724649,Update tag example,"diff --git a/README.md b/README.md
index 300592fa..0fc18e3a 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-08-19
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-08-30
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-08-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-08-30
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index 300592fa..0fc18e3a 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-08-19
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-08-30
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-08-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-08-30
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,4e47f292617d18b21e46767eb96ebff04c5ec5c9,3215aa83945048ee2e72341bc658066593724649,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 75e42642..543bea36 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-08-19
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-08-30
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-08-19""
+ENV TAG=""2024-08-30""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 75e42642..543bea36 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-08-19
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-08-30
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-08-19""
+ENV TAG=""2024-08-30""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,4e47f292617d18b21e46767eb96ebff04c5ec5c9,3215aa83945048ee2e72341bc658066593724649,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index 7d9f282e..9f71e487 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-08-19
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-08-30
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-08-19   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-08-30   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-08-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-08-30
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-08-19
+    quay.io/jupyter/r-notebook:2024-08-30
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 7d9f282e..9f71e487 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-08-19
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-08-30
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-08-19   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-08-30   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-08-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-08-30
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-08-19` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-08-19
+    quay.io/jupyter/r-notebook:2024-08-30
 ```
 
 ```{warning}",Yes
,docs/using/recipe_code/docker-bake.python312.hcl,d4235b48ae0b3125c791210b65ed77dc9477f637,4e47f292617d18b21e46767eb96ebff04c5ec5c9,"Recipe using bake to build with custom arguments (#2141)

* Example using bake to build with custom arguments

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add missing language markers

* Unify markdown style in recipes.md

* Update docs/using/recipe_code/docker-bake.python312.hcl

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/recipe_code/docker-bake.python312.hcl b/docs/using/recipe_code/docker-bake.python312.hcl
new file mode 100644
index 00000000..2b9a200e
--- /dev/null
+++ b/docs/using/recipe_code/docker-bake.python312.hcl
@@ -0,0 +1,45 @@
+group ""default"" {
+    targets = [""custom-notebook""]
+}
+
+target ""foundation"" {
+    context = ""https://github.com/jupyter/docker-stacks.git#main:images/docker-stacks-foundation""
+    args = {
+        PYTHON_VERSION = ""3.12""
+    }
+    tags = [""docker-stacks-foundation""]
+}
+
+
+target ""base-notebook"" {
+    context = ""https://github.com/jupyter/docker-stacks.git#main:images/base-notebook""
+    contexts = {
+        docker-stacks-foundation = ""target:foundation""
+    }
+    args = {
+        BASE_CONTAINER = ""docker-stacks-foundation""
+    }
+    tags = [""base-notebook""]
+}
+
+target ""minimal-notebook"" {
+    context = ""https://github.com/jupyter/docker-stacks.git#main:images/minimal-notebook""
+    contexts = {
+        base-notebook = ""target:base-notebook""
+    }
+    args = {
+        BASE_CONTAINER = ""base-notebook""
+    }
+    tags = [""minimal-notebook""]
+}
+
+target ""custom-notebook"" {
+    context = "".""
+    contexts = {
+        minimal-notebook = ""target:minimal-notebook""
+    }
+    args = {
+        BASE_CONTAINER = ""minimal-notebook""
+    }
+    tags = [""custom-jupyter""]
+}","diff --git a/docs/using/recipe_code/docker-bake.python312.hcl b/docs/using/recipe_code/docker-bake.python312.hcl
new file mode 100644
index 00000000..2b9a200e
--- /dev/null
+++ b/docs/using/recipe_code/docker-bake.python312.hcl
@@ -0,0 +1,45 @@
+group ""default"" {
+    targets = [""custom-notebook""]
+}
+
+target ""foundation"" {
+    context = ""https://github.com/jupyter/docker-stacks.git#main:images/docker-stacks-foundation""
+    args = {
+        PYTHON_VERSION = ""3.12""
+    }
+    tags = [""docker-stacks-foundation""]
+}
+
+
+target ""base-notebook"" {
+    context = ""https://github.com/jupyter/docker-stacks.git#main:images/base-notebook""
+    contexts = {
+        docker-stacks-foundation = ""target:foundation""
+    }
+    args = {
+        BASE_CONTAINER = ""docker-stacks-foundation""
+    }
+    tags = [""base-notebook""]
+}
+
+target ""minimal-notebook"" {
+    context = ""https://github.com/jupyter/docker-stacks.git#main:images/minimal-notebook""
+    contexts = {
+        base-notebook = ""target:base-notebook""
+    }
+    args = {
+        BASE_CONTAINER = ""base-notebook""
+    }
+    tags = [""minimal-notebook""]
+}
+
+target ""custom-notebook"" {
+    context = "".""
+    contexts = {
+        minimal-notebook = ""target:minimal-notebook""
+    }
+    args = {
+        BASE_CONTAINER = ""minimal-notebook""
+    }
+    tags = [""custom-jupyter""]
+}",Yes
docs/using/recipes.md,docs/using/recipes.md,d4235b48ae0b3125c791210b65ed77dc9477f637,4e47f292617d18b21e46767eb96ebff04c5ec5c9,"Recipe using bake to build with custom arguments (#2141)

* Example using bake to build with custom arguments

* [pre-commit.ci] auto fixes from pre-commit.com hooks

for more information, see https://pre-commit.ci

* Add missing language markers

* Unify markdown style in recipes.md

* Update docs/using/recipe_code/docker-bake.python312.hcl

---------

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>
Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 3abbd6c0..a4e5408c 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -525,3 +525,57 @@ they may be explained in the ""Installation instructions"" section of the Download
 ```{literalinclude} recipe_code/oracledb.dockerfile
 :language: docker
 ```
+
+## Building stack images with custom arguments
+
+A selection of prebuilt images are available from Quay.io,
+however, it's impossible to cater to everybody's needs.
+For extensive customization with an automated build pipeline,
+you may wish to create a [community-maintained stack](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html),
+however, for minor customizations, this may be overkill.
+For example, you may wish to use the same jupyter stacks but built on a different base image,
+or build with a different Python version.
+
+To achieve this you can use [Docker Bake](https://docs.docker.com/build/bake/)
+to build the stacks locally with custom arguments.
+
+```{note}
+Custom arguments may result in build errors due to incompatibility.
+If so your use-case may require a fully customized stack.
+```
+
+As a basic example, if you want to build a custom image based on the `minimal-notebook` image using `Python 3.12`,
+then with a Dockerfile like:
+
+```{code-block} Dockerfile
+:caption: Dockerfile
+
+ARG BASE_CONTAINER=minimal-notebook
+FROM $BASE_CONTAINER
+...
+```
+
+Include the below file in your project:
+
+```{literalinclude} recipe_code/docker-bake.python312.hcl
+:force:
+:language: hcl
+:caption: docker-bake.hcl
+```
+
+To build this stack, in the same directory run:
+
+```bash
+docker buildx bake
+```
+
+Docker Bake then determines the correct build order from the `contexts` parameters
+and builds the stack as requested.
+
+This image can then be run using:
+
+```bash
+docker run custom-jupyter
+```
+
+or referenced in a docker compose file.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 3abbd6c0..a4e5408c 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -525,3 +525,57 @@ they may be explained in the ""Installation instructions"" section of the Download
 ```{literalinclude} recipe_code/oracledb.dockerfile
 :language: docker
 ```
+
+## Building stack images with custom arguments
+
+A selection of prebuilt images are available from Quay.io,
+however, it's impossible to cater to everybody's needs.
+For extensive customization with an automated build pipeline,
+you may wish to create a [community-maintained stack](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html),
+however, for minor customizations, this may be overkill.
+For example, you may wish to use the same jupyter stacks but built on a different base image,
+or build with a different Python version.
+
+To achieve this you can use [Docker Bake](https://docs.docker.com/build/bake/)
+to build the stacks locally with custom arguments.
+
+```{note}
+Custom arguments may result in build errors due to incompatibility.
+If so your use-case may require a fully customized stack.
+```
+
+As a basic example, if you want to build a custom image based on the `minimal-notebook` image using `Python 3.12`,
+then with a Dockerfile like:
+
+```{code-block} Dockerfile
+:caption: Dockerfile
+
+ARG BASE_CONTAINER=minimal-notebook
+FROM $BASE_CONTAINER
+...
+```
+
+Include the below file in your project:
+
+```{literalinclude} recipe_code/docker-bake.python312.hcl
+:force:
+:language: hcl
+:caption: docker-bake.hcl
+```
+
+To build this stack, in the same directory run:
+
+```bash
+docker buildx bake
+```
+
+Docker Bake then determines the correct build order from the `contexts` parameters
+and builds the stack as requested.
+
+This image can then be run using:
+
+```bash
+docker run custom-jupyter
+```
+
+or referenced in a docker compose file.",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,348cc096434b27ed906c76adfc8274d124f1506c,d4235b48ae0b3125c791210b65ed77dc9477f637,"[pre-commit.ci] pre-commit autoupdate (#2142)

updates:
- [github.com/pre-commit/mirrors-mypy: v1.11.1 → v1.11.2](https://github.com/pre-commit/mirrors-mypy/compare/v1.11.1...v1.11.2)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 7e18a374..a8ddb6b6 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.11.1
+    rev: v1.11.2
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 7e18a374..a8ddb6b6 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.11.1
+    rev: v1.11.2
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]",Yes
,docs/using/recipe_code/ijavascript.dockerfile,8890fc557a2cfc1c2ec7ab1025c7ac6bad6fbcd3,348cc096434b27ed906c76adfc8274d124f1506c,"Fix ijavascript example (#2143)

* Fix ijavascript example

* Better naming","diff --git a/docs/using/recipe_code/ijavascript.dockerfile b/docs/using/recipe_code/ijavascript.dockerfile
new file mode 100644
index 00000000..362fffdd
--- /dev/null
+++ b/docs/using/recipe_code/ijavascript.dockerfile
@@ -0,0 +1,23 @@
+FROM quay.io/jupyter/base-notebook
+
+USER root
+
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    make \
+    g++ && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# NodeJS <= 20 is required
+# https://github.com/n-riesco/ijavascript/issues/184
+RUN mamba install --yes nodejs=20.* && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# hadolint ignore=DL3016
+RUN npm install -g ijavascript
+# hadolint ignore=DL3059
+RUN ijsinstall","diff --git a/docs/using/recipe_code/ijavascript.dockerfile b/docs/using/recipe_code/ijavascript.dockerfile
new file mode 100644
index 00000000..362fffdd
--- /dev/null
+++ b/docs/using/recipe_code/ijavascript.dockerfile
@@ -0,0 +1,23 @@
+FROM quay.io/jupyter/base-notebook
+
+USER root
+
+RUN apt-get update --yes && \
+    apt-get install --yes --no-install-recommends \
+    make \
+    g++ && \
+    apt-get clean && rm -rf /var/lib/apt/lists/*
+
+USER ${NB_UID}
+
+# NodeJS <= 20 is required
+# https://github.com/n-riesco/ijavascript/issues/184
+RUN mamba install --yes nodejs=20.* && \
+    mamba clean --all -f -y && \
+    fix-permissions ""${CONDA_DIR}"" && \
+    fix-permissions ""/home/${NB_USER}""
+
+# hadolint ignore=DL3016
+RUN npm install -g ijavascript
+# hadolint ignore=DL3059
+RUN ijsinstall",Yes
docs/using/recipes.md,docs/using/recipes.md,8890fc557a2cfc1c2ec7ab1025c7ac6bad6fbcd3,348cc096434b27ed906c76adfc8274d124f1506c,"Fix ijavascript example (#2143)

* Fix ijavascript example

* Better naming","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index a4e5408c..46c6edb6 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -482,18 +482,10 @@ docker run -it --rm \
 
 ## Add ijavascript kernel to container
 
-```{warning}
-This recipe is not tested and might be broken.
-```
-
-The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
+The example below is a Dockerfile to install the [IJavascript kernel](https://github.com/n-riesco/ijavascript).
 
-```dockerfile
-FROM quay.io/jupyter/scipy-notebook
-
-# install ijavascript
-RUN npm install -g ijavascript
-RUN ijsinstall
+```{literalinclude} recipe_code/ijavascript.dockerfile
+:language: docker
 ```
 
 ## Add Microsoft SQL Server ODBC driver","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index a4e5408c..46c6edb6 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -482,18 +482,10 @@ docker run -it --rm \
 
 ## Add ijavascript kernel to container
 
-```{warning}
-This recipe is not tested and might be broken.
-```
+The example below is a Dockerfile to install the [IJavascript kernel](https://github.com/n-riesco/ijavascript).
 
-The example below is a Dockerfile to install the [ijavascript kernel](https://github.com/n-riesco/ijavascript).
-
-```dockerfile
-FROM quay.io/jupyter/scipy-notebook
-
-# install ijavascript
-RUN npm install -g ijavascript
-RUN ijsinstall
+```{literalinclude} recipe_code/ijavascript.dockerfile
+:language: docker
 ```
 
 ## Add Microsoft SQL Server ODBC driver",No
docs/using/recipe_code/docker-bake.python312.hcl,docs/using/recipe_code/docker-bake.python312.hcl,d7d7480b341daa8dd9286998f131291525a74d19,8890fc557a2cfc1c2ec7ab1025c7ac6bad6fbcd3,Remove double empty line,"diff --git a/docs/using/recipe_code/docker-bake.python312.hcl b/docs/using/recipe_code/docker-bake.python312.hcl
index 2b9a200e..10f3b936 100644
--- a/docs/using/recipe_code/docker-bake.python312.hcl
+++ b/docs/using/recipe_code/docker-bake.python312.hcl
@@ -10,7 +10,6 @@ target ""foundation"" {
     tags = [""docker-stacks-foundation""]
 }
 
-
 target ""base-notebook"" {
     context = ""https://github.com/jupyter/docker-stacks.git#main:images/base-notebook""
     contexts = {","diff --git a/docs/using/recipe_code/docker-bake.python312.hcl b/docs/using/recipe_code/docker-bake.python312.hcl
index 2b9a200e..10f3b936 100644
--- a/docs/using/recipe_code/docker-bake.python312.hcl
+++ b/docs/using/recipe_code/docker-bake.python312.hcl
@@ -10,7 +10,6 @@ target ""foundation"" {
     tags = [""docker-stacks-foundation""]
 }
 
-
 target ""base-notebook"" {
     context = ""https://github.com/jupyter/docker-stacks.git#main:images/base-notebook""
     contexts = {",Yes
docs/contributing/features.md,docs/contributing/features.md,1fb08d7114fed88a9663217fc3953ae873444db3,d7d7480b341daa8dd9286998f131291525a74d19,"Create a separate doc page on how to build a custom set of images (#2144)

* Create a separate doc page on how to build custom set of images

* Fix link

* Include new page in toctree

* Minor fix

* Rewrite

* Rewrite

* Apply suggestions from code review

Co-authored-by: Simon Li <orpheus+devel@gmail.com>

* Capitalize Quay.io

* Add info about old images

* Better text

---------

Co-authored-by: Simon Li <orpheus+devel@gmail.com>","diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index b4d68197..7da372de 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -12,6 +12,7 @@ Please follow the process below to suggest a new feature for inclusion in one of
    describing the feature you'd like to contribute.
 2. Discuss with the maintainers whether the addition makes sense
    in [one of the core stacks](../using/selecting.md#core-stacks),
+   as a [way to build a custom set of images](../using/custom-images.md),
    as a [recipe in the documentation](recipes.md),
    as a [community stack](stacks.md),
    or as something else entirely.","diff --git a/docs/contributing/features.md b/docs/contributing/features.md
index b4d68197..7da372de 100644
--- a/docs/contributing/features.md
+++ b/docs/contributing/features.md
@@ -12,6 +12,7 @@ Please follow the process below to suggest a new feature for inclusion in one of
    describing the feature you'd like to contribute.
 2. Discuss with the maintainers whether the addition makes sense
    in [one of the core stacks](../using/selecting.md#core-stacks),
+   as a [way to build a custom set of images](../using/custom-images.md),
    as a [recipe in the documentation](recipes.md),
    as a [community stack](stacks.md),
    or as something else entirely.",Yes
docs/index.rst,docs/index.rst,1fb08d7114fed88a9663217fc3953ae873444db3,d7d7480b341daa8dd9286998f131291525a74d19,"Create a separate doc page on how to build a custom set of images (#2144)

* Create a separate doc page on how to build custom set of images

* Fix link

* Include new page in toctree

* Minor fix

* Rewrite

* Rewrite

* Apply suggestions from code review

Co-authored-by: Simon Li <orpheus+devel@gmail.com>

* Capitalize Quay.io

* Add info about old images

* Better text

---------

Co-authored-by: Simon Li <orpheus+devel@gmail.com>","diff --git a/docs/index.rst b/docs/index.rst
index 896ca0f7..23aa0e90 100644
--- a/docs/index.rst
+++ b/docs/index.rst
@@ -13,6 +13,7 @@ Table of Contents
    using/common
    using/specifics
    using/recipes
+   using/custom-images
    using/troubleshooting
    using/faq","diff --git a/docs/index.rst b/docs/index.rst
index 896ca0f7..23aa0e90 100644
--- a/docs/index.rst
+++ b/docs/index.rst
@@ -13,6 +13,7 @@ Table of Contents
    using/common
    using/specifics
    using/recipes
+   using/custom-images
    using/troubleshooting
    using/faq",Yes
,docs/using/custom-images.md,1fb08d7114fed88a9663217fc3953ae873444db3,d7d7480b341daa8dd9286998f131291525a74d19,"Create a separate doc page on how to build a custom set of images (#2144)

* Create a separate doc page on how to build custom set of images

* Fix link

* Include new page in toctree

* Minor fix

* Rewrite

* Rewrite

* Apply suggestions from code review

Co-authored-by: Simon Li <orpheus+devel@gmail.com>

* Capitalize Quay.io

* Add info about old images

* Better text

---------

Co-authored-by: Simon Li <orpheus+devel@gmail.com>","diff --git a/docs/using/custom-images.md b/docs/using/custom-images.md
new file mode 100644
index 00000000..ad2ca87b
--- /dev/null
+++ b/docs/using/custom-images.md
@@ -0,0 +1,82 @@
+# Building a custom set of images
+
+This section describes how to build a custom set of images.
+It may be helpful if you need to change the Ubuntu or Python version, or to make a significant change to the build process itself.
+
+This project only builds one set of images at a time.
+If you want to use older images, take a look [here](https://jupyter-docker-stacks.readthedocs.io/en/latest/#using-old-images).
+
+## Automating your build using template cookiecutter project
+
+If you wish to build your own image on top of one of our images and automate your build process,
+please, [take a look at cookiecutter template](../contributing/stacks.md).
+
+## Custom arguments
+
+Existing customization points:
+
+- `ROOT_CONTAINER` - a docker argument of `docker-stacks-foundation` image
+- `PYTHON_VERSION` - a docker argument of `docker-stacks-foundation` image
+- `REGISTRY`, `OWNER`, `BASE_CONTAINER` - docker arguments for all the other images we build
+- `REGISTRY`, `OWNER` - part of `env` in most of our GitHub workflows
+
+## Building stack images with custom arguments
+
+A selection of prebuilt images are available from [Quay.io](https://quay.io/organization/jupyter),
+however, it's impossible to cater to everybody's needs.
+For extensive customization with an automated build pipeline,
+you may wish to create a [community-maintained stack](../contributing/stacks),
+however, for minor customizations, this may be overkill.
+For example, you may wish to use the same Jupyter stacks but built on a different base image,
+or built with a different Python version.
+
+To achieve this you can use [Docker Bake](https://docs.docker.com/build/bake/)
+to build the stacks locally with custom arguments.
+
+```{note}
+Custom arguments may result in build errors due to incompatibility.
+If so your use-case may require a fully customized stack.
+```
+
+As a basic example, if you want to build a custom image based on the `minimal-notebook` image using `Python 3.12`,
+then with a Dockerfile like:
+
+```{code-block} Dockerfile
+:caption: Dockerfile
+
+ARG BASE_CONTAINER=minimal-notebook
+FROM $BASE_CONTAINER
+...
+```
+
+Include the below file in your project:
+
+```{literalinclude} recipe_code/docker-bake.python312.hcl
+:force:
+:language: hcl
+:caption: docker-bake.hcl
+```
+
+To build this stack, in the same directory run:
+
+```bash
+docker buildx bake
+```
+
+Docker Bake then determines the correct build order from the `contexts` parameters
+and builds the stack as requested.
+
+This image can then be run the same way as any other image provided by this project, for example:
+
+```bash
+docker run -it --rm -p 8888:8888 custom-jupyter
+```
+
+or referenced in a Docker Compose file.
+
+## Forking our repository
+
+If for some reason, you need to change more things in our images, feel free to fork it and change it any way you want.
+If your customization is easy to backport to the main repo and might be helpful for other users, feel free to create a PR.
+
+It is almost always a great idea to keep your diff as small as possible and to merge/rebase the latest version of our repo in your project.","diff --git a/docs/using/custom-images.md b/docs/using/custom-images.md
new file mode 100644
index 00000000..ad2ca87b
--- /dev/null
+++ b/docs/using/custom-images.md
@@ -0,0 +1,82 @@
+# Building a custom set of images
+
+This section describes how to build a custom set of images.
+It may be helpful if you need to change the Ubuntu or Python version, or to make a significant change to the build process itself.
+
+This project only builds one set of images at a time.
+If you want to use older images, take a look [here](https://jupyter-docker-stacks.readthedocs.io/en/latest/#using-old-images).
+
+## Automating your build using template cookiecutter project
+
+If you wish to build your own image on top of one of our images and automate your build process,
+please, [take a look at cookiecutter template](../contributing/stacks.md).
+
+## Custom arguments
+
+Existing customization points:
+
+- `ROOT_CONTAINER` - a docker argument of `docker-stacks-foundation` image
+- `PYTHON_VERSION` - a docker argument of `docker-stacks-foundation` image
+- `REGISTRY`, `OWNER`, `BASE_CONTAINER` - docker arguments for all the other images we build
+- `REGISTRY`, `OWNER` - part of `env` in most of our GitHub workflows
+
+## Building stack images with custom arguments
+
+A selection of prebuilt images are available from [Quay.io](https://quay.io/organization/jupyter),
+however, it's impossible to cater to everybody's needs.
+For extensive customization with an automated build pipeline,
+you may wish to create a [community-maintained stack](../contributing/stacks),
+however, for minor customizations, this may be overkill.
+For example, you may wish to use the same Jupyter stacks but built on a different base image,
+or built with a different Python version.
+
+To achieve this you can use [Docker Bake](https://docs.docker.com/build/bake/)
+to build the stacks locally with custom arguments.
+
+```{note}
+Custom arguments may result in build errors due to incompatibility.
+If so your use-case may require a fully customized stack.
+```
+
+As a basic example, if you want to build a custom image based on the `minimal-notebook` image using `Python 3.12`,
+then with a Dockerfile like:
+
+```{code-block} Dockerfile
+:caption: Dockerfile
+
+ARG BASE_CONTAINER=minimal-notebook
+FROM $BASE_CONTAINER
+...
+```
+
+Include the below file in your project:
+
+```{literalinclude} recipe_code/docker-bake.python312.hcl
+:force:
+:language: hcl
+:caption: docker-bake.hcl
+```
+
+To build this stack, in the same directory run:
+
+```bash
+docker buildx bake
+```
+
+Docker Bake then determines the correct build order from the `contexts` parameters
+and builds the stack as requested.
+
+This image can then be run the same way as any other image provided by this project, for example:
+
+```bash
+docker run -it --rm -p 8888:8888 custom-jupyter
+```
+
+or referenced in a Docker Compose file.
+
+## Forking our repository
+
+If for some reason, you need to change more things in our images, feel free to fork it and change it any way you want.
+If your customization is easy to backport to the main repo and might be helpful for other users, feel free to create a PR.
+
+It is almost always a great idea to keep your diff as small as possible and to merge/rebase the latest version of our repo in your project.",Yes
docs/using/recipes.md,docs/using/recipes.md,1fb08d7114fed88a9663217fc3953ae873444db3,d7d7480b341daa8dd9286998f131291525a74d19,"Create a separate doc page on how to build a custom set of images (#2144)

* Create a separate doc page on how to build custom set of images

* Fix link

* Include new page in toctree

* Minor fix

* Rewrite

* Rewrite

* Apply suggestions from code review

Co-authored-by: Simon Li <orpheus+devel@gmail.com>

* Capitalize Quay.io

* Add info about old images

* Better text

---------

Co-authored-by: Simon Li <orpheus+devel@gmail.com>","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 46c6edb6..69ecf9e1 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -4,6 +4,9 @@ Users sometimes share interesting ways of using the Jupyter Docker Stacks.
 We encourage users to [contribute these recipes](../contributing/recipes.md) to the documentation in case they prove helpful to other community members by submitting a pull request to `docs/using/recipes.md`.
 The sections below capture this knowledge.
 
+All the recipes here assume you would like to use an image built by this project and install some things on top of it.
+If you would like to build a custom set of images, [take a look at the docs](custom-images.md).
+
 ## Using `sudo` within a container
 
 Password authentication is disabled for the `NB_USER` (e.g., `jovyan`).
@@ -517,57 +520,3 @@ they may be explained in the ""Installation instructions"" section of the Download
 ```{literalinclude} recipe_code/oracledb.dockerfile
 :language: docker
 ```
-
-## Building stack images with custom arguments
-
-A selection of prebuilt images are available from Quay.io,
-however, it's impossible to cater to everybody's needs.
-For extensive customization with an automated build pipeline,
-you may wish to create a [community-maintained stack](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html),
-however, for minor customizations, this may be overkill.
-For example, you may wish to use the same jupyter stacks but built on a different base image,
-or build with a different Python version.
-
-To achieve this you can use [Docker Bake](https://docs.docker.com/build/bake/)
-to build the stacks locally with custom arguments.
-
-```{note}
-Custom arguments may result in build errors due to incompatibility.
-If so your use-case may require a fully customized stack.
-```
-
-As a basic example, if you want to build a custom image based on the `minimal-notebook` image using `Python 3.12`,
-then with a Dockerfile like:
-
-```{code-block} Dockerfile
-:caption: Dockerfile
-
-ARG BASE_CONTAINER=minimal-notebook
-FROM $BASE_CONTAINER
-...
-```
-
-Include the below file in your project:
-
-```{literalinclude} recipe_code/docker-bake.python312.hcl
-:force:
-:language: hcl
-:caption: docker-bake.hcl
-```
-
-To build this stack, in the same directory run:
-
-```bash
-docker buildx bake
-```
-
-Docker Bake then determines the correct build order from the `contexts` parameters
-and builds the stack as requested.
-
-This image can then be run using:
-
-```bash
-docker run custom-jupyter
-```
-
-or referenced in a docker compose file.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 46c6edb6..69ecf9e1 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -4,6 +4,9 @@ Users sometimes share interesting ways of using the Jupyter Docker Stacks.
 We encourage users to [contribute these recipes](../contributing/recipes.md) to the documentation in case they prove helpful to other community members by submitting a pull request to `docs/using/recipes.md`.
 The sections below capture this knowledge.
 
+All the recipes here assume you would like to use an image built by this project and install some things on top of it.
+If you would like to build a custom set of images, [take a look at the docs](custom-images.md).
+
 ## Using `sudo` within a container
 
 Password authentication is disabled for the `NB_USER` (e.g., `jovyan`).
@@ -517,57 +520,3 @@ they may be explained in the ""Installation instructions"" section of the Download
 ```{literalinclude} recipe_code/oracledb.dockerfile
 :language: docker
 ```
-
-## Building stack images with custom arguments
-
-A selection of prebuilt images are available from Quay.io,
-however, it's impossible to cater to everybody's needs.
-For extensive customization with an automated build pipeline,
-you may wish to create a [community-maintained stack](https://jupyter-docker-stacks.readthedocs.io/en/latest/contributing/stacks.html),
-however, for minor customizations, this may be overkill.
-For example, you may wish to use the same jupyter stacks but built on a different base image,
-or build with a different Python version.
-
-To achieve this you can use [Docker Bake](https://docs.docker.com/build/bake/)
-to build the stacks locally with custom arguments.
-
-```{note}
-Custom arguments may result in build errors due to incompatibility.
-If so your use-case may require a fully customized stack.
-```
-
-As a basic example, if you want to build a custom image based on the `minimal-notebook` image using `Python 3.12`,
-then with a Dockerfile like:
-
-```{code-block} Dockerfile
-:caption: Dockerfile
-
-ARG BASE_CONTAINER=minimal-notebook
-FROM $BASE_CONTAINER
-...
-```
-
-Include the below file in your project:
-
-```{literalinclude} recipe_code/docker-bake.python312.hcl
-:force:
-:language: hcl
-:caption: docker-bake.hcl
-```
-
-To build this stack, in the same directory run:
-
-```bash
-docker buildx bake
-```
-
-Docker Bake then determines the correct build order from the `contexts` parameters
-and builds the stack as requested.
-
-This image can then be run using:
-
-```bash
-docker run custom-jupyter
-```
-
-or referenced in a docker compose file.",Yes
docs/using/selecting.md,docs/using/selecting.md,8f9b1b6a755c5b3509d8a19abd09319c9a4c8644,1fb08d7114fed88a9663217fc3953ae873444db3,"docs: Core Stacks: move CUDA docs to later in the page (#2145)

* Move `CUDA enabled variant` to lower down

* CUDA enabled variant: fix grammar","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index d4cd71dc..a3c77c7b 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -16,15 +16,6 @@ This section provides details about the first.
 The Jupyter team maintains a set of Docker image definitions in the <https://github.com/jupyter/docker-stacks> GitHub repository.
 The following sections describe these images, including their contents, relationships, and versioning strategy.
 
-### CUDA enabled variant
-
-We provide CUDA accelerated version of `pytorch-notebook` and `tensorflow-notebook` images.
-Prepend a CUDA prefix (versioned prefix like `cuda12-` for `pytorch-notebook` or just `cuda-` for `tensorflow-notebook`) to the image tag
-to allow PyTorch or TensorFlow operations to use compatible NVIDIA GPUs for accelerated computation.
-Note: We only build `pytorch-notebook` for 2 last major versions of CUDA, `tensorflow-notebook` image only supports the latest CUDA version listed in the [officially tested build configurations](https://www.tensorflow.org/install/source#gpu).
-
-For example, you can use an image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8` or `quay.io/jupyter/tensorflow-notebook:cuda-latest`
-
 ### jupyter/docker-stacks-foundation
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/docker-stacks-foundation) |
@@ -248,6 +239,16 @@ It contains:
   [ggplot2](https://ggplot2.tidyverse.org)
   packages
 
+### CUDA enabled variants
+
+We provide CUDA accelerated versions of the `pytorch-notebook` and `tensorflow-notebook` images.
+Prepend a CUDA prefix (versioned prefix like `cuda12-` for `pytorch-notebook` or just `cuda-` for `tensorflow-notebook`) to the image tag
+to allow PyTorch or TensorFlow operations to use compatible NVIDIA GPUs for accelerated computation.
+We only build `pytorch-notebook` for last two major versions of CUDA.
+The `tensorflow-notebook` image only supports the latest CUDA version listed in the [officially tested build configurations](https://www.tensorflow.org/install/source#gpu).
+
+For example, you could use the image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8` or `quay.io/jupyter/tensorflow-notebook:cuda-latest`.
+
 ### Image Relationships
 
 The following diagram depicts the build dependency tree of the core images. (i.e., the `FROM` statements in their Dockerfiles).","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index d4cd71dc..a3c77c7b 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -16,15 +16,6 @@ This section provides details about the first.
 The Jupyter team maintains a set of Docker image definitions in the <https://github.com/jupyter/docker-stacks> GitHub repository.
 The following sections describe these images, including their contents, relationships, and versioning strategy.
 
-### CUDA enabled variant
-
-We provide CUDA accelerated version of `pytorch-notebook` and `tensorflow-notebook` images.
-Prepend a CUDA prefix (versioned prefix like `cuda12-` for `pytorch-notebook` or just `cuda-` for `tensorflow-notebook`) to the image tag
-to allow PyTorch or TensorFlow operations to use compatible NVIDIA GPUs for accelerated computation.
-Note: We only build `pytorch-notebook` for 2 last major versions of CUDA, `tensorflow-notebook` image only supports the latest CUDA version listed in the [officially tested build configurations](https://www.tensorflow.org/install/source#gpu).
-
-For example, you can use an image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8` or `quay.io/jupyter/tensorflow-notebook:cuda-latest`
-
 ### jupyter/docker-stacks-foundation
 
 [Source on GitHub](https://github.com/jupyter/docker-stacks/tree/main/images/docker-stacks-foundation) |
@@ -248,6 +239,16 @@ It contains:
   [ggplot2](https://ggplot2.tidyverse.org)
   packages
 
+### CUDA enabled variants
+
+We provide CUDA accelerated versions of the `pytorch-notebook` and `tensorflow-notebook` images.
+Prepend a CUDA prefix (versioned prefix like `cuda12-` for `pytorch-notebook` or just `cuda-` for `tensorflow-notebook`) to the image tag
+to allow PyTorch or TensorFlow operations to use compatible NVIDIA GPUs for accelerated computation.
+We only build `pytorch-notebook` for last two major versions of CUDA.
+The `tensorflow-notebook` image only supports the latest CUDA version listed in the [officially tested build configurations](https://www.tensorflow.org/install/source#gpu).
+
+For example, you could use the image `quay.io/jupyter/pytorch-notebook:cuda12-python-3.11.8` or `quay.io/jupyter/tensorflow-notebook:cuda-latest`.
+
 ### Image Relationships
 
 The following diagram depicts the build dependency tree of the core images. (i.e., the `FROM` statements in their Dockerfiles).",Yes
docs/using/custom-images.md,docs/using/custom-images.md,3483dfaed1a6382f48564ef3b8069eafda385a13,8f9b1b6a755c5b3509d8a19abd09319c9a4c8644,Simplify docs in custom-images,"diff --git a/docs/using/custom-images.md b/docs/using/custom-images.md
index ad2ca87b..4bf7eda7 100644
--- a/docs/using/custom-images.md
+++ b/docs/using/custom-images.md
@@ -15,8 +15,7 @@ please, [take a look at cookiecutter template](../contributing/stacks.md).
 
 Existing customization points:
 
-- `ROOT_CONTAINER` - a docker argument of `docker-stacks-foundation` image
-- `PYTHON_VERSION` - a docker argument of `docker-stacks-foundation` image
+- `ROOT_CONTAINER`, `PYTHON_VERSION` - docker arguments of a `docker-stacks-foundation` image
 - `REGISTRY`, `OWNER`, `BASE_CONTAINER` - docker arguments for all the other images we build
 - `REGISTRY`, `OWNER` - part of `env` in most of our GitHub workflows","diff --git a/docs/using/custom-images.md b/docs/using/custom-images.md
index ad2ca87b..4bf7eda7 100644
--- a/docs/using/custom-images.md
+++ b/docs/using/custom-images.md
@@ -15,8 +15,7 @@ please, [take a look at cookiecutter template](../contributing/stacks.md).
 
 Existing customization points:
 
-- `ROOT_CONTAINER` - a docker argument of `docker-stacks-foundation` image
-- `PYTHON_VERSION` - a docker argument of `docker-stacks-foundation` image
+- `ROOT_CONTAINER`, `PYTHON_VERSION` - docker arguments of a `docker-stacks-foundation` image
 - `REGISTRY`, `OWNER`, `BASE_CONTAINER` - docker arguments for all the other images we build
 - `REGISTRY`, `OWNER` - part of `env` in most of our GitHub workflows",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,9e230b3b7d2418bd79c94d03bf5f45d2a601865f,3483dfaed1a6382f48564ef3b8069eafda385a13,Improve docs about pre-commit and mypy,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index a8ddb6b6..3b995d2f 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -51,13 +51,13 @@ repos:
             ""types-tabulate"",
             ""types-urllib3"",
           ]
-        # Unfortunately, `pre-commit` only runs on changed files
+        # Unfortunately, `pre-commit` only runs on modified files
         # This doesn't work well with `mypy --follow-imports error`
         # See: https://github.com/pre-commit/mirrors-mypy/issues/34#issuecomment-1062160321
         #
         # To work around this we run `mypy` only in manual mode
-        # So it won't run as part of `git commit` command
-        # But it will still be run as part of `pre-commit` workflow and give expected results
+        # So it won't run as part of `git commit` command,
+        # but it will still be run as part of `pre-commit` workflow and give expected results
         stages: [manual]
 
   # Autoformat: YAML, JSON, Markdown, etc.","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index a8ddb6b6..3b995d2f 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -51,13 +51,13 @@ repos:
             ""types-tabulate"",
             ""types-urllib3"",
           ]
-        # Unfortunately, `pre-commit` only runs on changed files
+        # Unfortunately, `pre-commit` only runs on modified files
         # This doesn't work well with `mypy --follow-imports error`
         # See: https://github.com/pre-commit/mirrors-mypy/issues/34#issuecomment-1062160321
         #
         # To work around this we run `mypy` only in manual mode
-        # So it won't run as part of `git commit` command
-        # But it will still be run as part of `pre-commit` workflow and give expected results
+        # So it won't run as part of `git commit` command,
+        # but it will still be run as part of `pre-commit` workflow and give expected results
         stages: [manual]
 
   # Autoformat: YAML, JSON, Markdown, etc.",Yes
docs/contributing/lint.md,docs/contributing/lint.md,9e230b3b7d2418bd79c94d03bf5f45d2a601865f,3483dfaed1a6382f48564ef3b8069eafda385a13,Improve docs about pre-commit and mypy,"diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 7b449179..350f07dd 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -38,7 +38,7 @@ pre-commit run --all-files --hook-stage manual
 ```
 
 ```{note}
-We're running `pre-commit` with `--hook-stage manual`, because works with changed files, which doesn't work well for mypy.
+We're running `pre-commit` with `--hook-stage manual`, because `pre-commit` is run on modified files only, which doesn't work well with `mypy --follow-imports error`.
 More information can be found in [`.pre-commit-config.yaml` file](https://github.com/jupyter/docker-stacks/blob/main/.pre-commit-config.yaml)
 ```","diff --git a/docs/contributing/lint.md b/docs/contributing/lint.md
index 7b449179..350f07dd 100644
--- a/docs/contributing/lint.md
+++ b/docs/contributing/lint.md
@@ -38,7 +38,7 @@ pre-commit run --all-files --hook-stage manual
 ```
 
 ```{note}
-We're running `pre-commit` with `--hook-stage manual`, because works with changed files, which doesn't work well for mypy.
+We're running `pre-commit` with `--hook-stage manual`, because `pre-commit` is run on modified files only, which doesn't work well with `mypy --follow-imports error`.
 More information can be found in [`.pre-commit-config.yaml` file](https://github.com/jupyter/docker-stacks/blob/main/.pre-commit-config.yaml)
 ```",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,5dd3a31645ea0a32244f76596fb51ee8c1bac045,9e230b3b7d2418bd79c94d03bf5f45d2a601865f,Do not install mamba 2.0.0,"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 7ffaadb8..7b77ffc2 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -124,7 +124,9 @@ RUN set -x && \
         --prefix=""${CONDA_DIR}"" \
         --yes \
         'jupyter_core' \
-        'mamba' \
+        # excluding mamba==2.0.0 due to a breaking change causing these errors:
+        # ""The following argument was not expected: --full-name""
+        'mamba!=2.0.0' \
         ""${PYTHON_SPECIFIER}"" && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 7ffaadb8..7b77ffc2 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -124,7 +124,9 @@ RUN set -x && \
         --prefix=""${CONDA_DIR}"" \
         --yes \
         'jupyter_core' \
-        'mamba' \
+        # excluding mamba==2.0.0 due to a breaking change causing these errors:
+        # ""The following argument was not expected: --full-name""
+        'mamba!=2.0.0' \
         ""${PYTHON_SPECIFIER}"" && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python",Yes
docs/using/common.md,docs/using/common.md,ea50ad3ffaee78a100addf8b7a6543682f73b0b8,5dd3a31645ea0a32244f76596fb51ee8c1bac045,Fix broken link,"diff --git a/docs/using/common.md b/docs/using/common.md
index 8fa8f6b8..ee8e5878 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -238,7 +238,7 @@ This script is handy when you derive a new Dockerfile from this image and instal
 
 ## Conda Environments
 
-The default Python 3.x [Conda environment](https://conda.io/projects/conda/en/latest/user-guide/concepts/environments.html) resides in `/opt/conda`.
+The default Python 3.x [Conda environment](https://docs.conda.io/projects/conda/en/latest/user-guide/concepts/environments.html) resides in `/opt/conda`.
 The `/opt/conda/bin` directory is part of the default `jovyan` user's `${PATH}`.
 That directory is also searched for binaries when run using `sudo` (`sudo my_binary` will search for `my_binary` in `/opt/conda/bin/`","diff --git a/docs/using/common.md b/docs/using/common.md
index 8fa8f6b8..ee8e5878 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -238,7 +238,7 @@ This script is handy when you derive a new Dockerfile from this image and instal
 
 ## Conda Environments
 
-The default Python 3.x [Conda environment](https://conda.io/projects/conda/en/latest/user-guide/concepts/environments.html) resides in `/opt/conda`.
+The default Python 3.x [Conda environment](https://docs.conda.io/projects/conda/en/latest/user-guide/concepts/environments.html) resides in `/opt/conda`.
 The `/opt/conda/bin` directory is part of the default `jovyan` user's `${PATH}`.
 That directory is also searched for binaries when run using `sudo` (`sudo my_binary` will search for `my_binary` in `/opt/conda/bin/`",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,55ea74f89f7a8e65f27cab87fd8340b25a5a14e5,ea50ad3ffaee78a100addf8b7a6543682f73b0b8,Exclude mamba package from tests,"diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index a1f7f755..2693270f 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -75,6 +75,7 @@ EXCLUDED_PACKAGES = [
     ""grpcio"",
     ""hdf5"",
     ""jupyterlab-git"",
+    ""mamba!"",
     ""openssl"",
     ""pandas[version='>"",
     ""protobuf"",","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index a1f7f755..2693270f 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -75,6 +75,7 @@ EXCLUDED_PACKAGES = [
     ""grpcio"",
     ""hdf5"",
     ""jupyterlab-git"",
+    ""mamba!"",
     ""openssl"",
     ""pandas[version='>"",
     ""protobuf"",",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,2f1a5615bb38c79ce0714befe04fadae13f2d9c4,55ea74f89f7a8e65f27cab87fd8340b25a5a14e5,Do not install mamba 2.X,"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 7b77ffc2..9c1a344f 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -124,9 +124,9 @@ RUN set -x && \
         --prefix=""${CONDA_DIR}"" \
         --yes \
         'jupyter_core' \
-        # excluding mamba==2.0.0 due to a breaking change causing these errors:
-        # ""The following argument was not expected: --full-name""
-        'mamba!=2.0.0' \
+        # excluding mamba 2.X due to several breaking changes
+        # https://github.com/jupyter/docker-stacks/pull/2147
+        'mamba<2.0.0' \
         ""${PYTHON_SPECIFIER}"" && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 7b77ffc2..9c1a344f 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -124,9 +124,9 @@ RUN set -x && \
         --prefix=""${CONDA_DIR}"" \
         --yes \
         'jupyter_core' \
-        # excluding mamba==2.0.0 due to a breaking change causing these errors:
-        # ""The following argument was not expected: --full-name""
-        'mamba!=2.0.0' \
+        # excluding mamba 2.X due to several breaking changes
+        # https://github.com/jupyter/docker-stacks/pull/2147
+        'mamba<2.0.0' \
         ""${PYTHON_SPECIFIER}"" && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,640938bd1f49ab3a9868ee5af1775cb116a9e991,2f1a5615bb38c79ce0714befe04fadae13f2d9c4,Fix test,"diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 2693270f..9b70be38 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -75,7 +75,7 @@ EXCLUDED_PACKAGES = [
     ""grpcio"",
     ""hdf5"",
     ""jupyterlab-git"",
-    ""mamba!"",
+    ""mamba[version='<2.0.0']"",
     ""openssl"",
     ""pandas[version='>"",
     ""protobuf"",","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 2693270f..9b70be38 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -75,7 +75,7 @@ EXCLUDED_PACKAGES = [
     ""grpcio"",
     ""hdf5"",
     ""jupyterlab-git"",
-    ""mamba!"",
+    ""mamba[version='<2.0.0']"",
     ""openssl"",
     ""pandas[version='>"",
     ""protobuf"",",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,41d0c3f5a406e1ca7cbd01f8befb4224c4fa2776,640938bd1f49ab3a9868ee5af1775cb116a9e991,Use mamba env export differently: --no-build(s) and no --json (#2150),"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 3b995d2f..25658fa1 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -47,6 +47,7 @@ repos:
             ""requests"",
             ""urllib3"",
             ""types-beautifulsoup4"",
+            ""types-PyYAML"",
             ""types-requests"",
             ""types-tabulate"",
             ""types-urllib3"",","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 3b995d2f..25658fa1 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -47,6 +47,7 @@ repos:
             ""requests"",
             ""urllib3"",
             ""types-beautifulsoup4"",
+            ""types-PyYAML"",
             ""types-requests"",
             ""types-tabulate"",
             ""types-urllib3"",",Yes
requirements-dev.txt,requirements-dev.txt,41d0c3f5a406e1ca7cbd01f8befb4224c4fa2776,640938bd1f49ab3a9868ee5af1775cb116a9e991,Use mamba env export differently: --no-build(s) and no --json (#2150),"diff --git a/requirements-dev.txt b/requirements-dev.txt
index 3ab2be95..9caa0df3 100644
--- a/requirements-dev.txt
+++ b/requirements-dev.txt
@@ -6,5 +6,6 @@ pytest-retry
 # `pytest-xdist` is a plugin that provides the `--numprocesses` flag,
 # allowing us to run `pytest` tests in parallel
 pytest-xdist
+PyYAML
 requests
 tabulate","diff --git a/requirements-dev.txt b/requirements-dev.txt
index 3ab2be95..9caa0df3 100644
--- a/requirements-dev.txt
+++ b/requirements-dev.txt
@@ -6,5 +6,6 @@ pytest-retry
 # `pytest-xdist` is a plugin that provides the `--numprocesses` flag,
 # allowing us to run `pytest` tests in parallel
 pytest-xdist
+PyYAML
 requests
 tabulate",Yes
tests/package_helper.py,tests/package_helper.py,41d0c3f5a406e1ca7cbd01f8befb4224c4fa2776,640938bd1f49ab3a9868ee5af1775cb116a9e991,Use mamba env export differently: --no-build(s) and no --json (#2150),"diff --git a/tests/package_helper.py b/tests/package_helper.py
index 2fe85f53..5f2f636c 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -22,13 +22,13 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
-import json
 import logging
 import re
 from collections import defaultdict
 from itertools import chain
 from typing import Any, Optional
 
+import yaml
 from docker.models.containers import Container
 from tabulate import tabulate
 
@@ -61,7 +61,7 @@ class CondaPackageHelper:
     @staticmethod
     def _conda_export_command(from_history: bool) -> list[str]:
         """"""Return the mamba export command with or without history""""""
-        cmd = [""mamba"", ""env"", ""export"", ""-n"", ""base"", ""--json"", ""--no-builds""]
+        cmd = [""mamba"", ""env"", ""export"", ""--no-build""]
         if from_history:
             cmd.append(""--from-history"")
         return cmd
@@ -70,7 +70,7 @@ class CondaPackageHelper:
         """"""Return the installed packages""""""
         if self.installed is None:
             LOGGER.info(""Grabbing the list of installed packages ..."")
-            self.installed = CondaPackageHelper._packages_from_json(
+            self.installed = CondaPackageHelper._parse_package_versions(
                 self._execute_command(
                     CondaPackageHelper._conda_export_command(from_history=False)
                 )
@@ -81,7 +81,7 @@ class CondaPackageHelper:
         """"""Return the requested package (i.e. `mamba install <package>`)""""""
         if self.requested is None:
             LOGGER.info(""Grabbing the list of manually requested packages ..."")
-            self.requested = CondaPackageHelper._packages_from_json(
+            self.requested = CondaPackageHelper._parse_package_versions(
                 self._execute_command(
                     CondaPackageHelper._conda_export_command(from_history=True)
                 )
@@ -94,12 +94,12 @@ class CondaPackageHelper:
         return rc.output.decode(""utf-8"")  # type: ignore
 
     @staticmethod
-    def _packages_from_json(env_export: str) -> dict[str, set[str]]:
+    def _parse_package_versions(env_export: str) -> dict[str, set[str]]:
         """"""Extract packages and versions from the lines returned by the list of specifications""""""
-        # dependencies = filter(lambda x: isinstance(x, str), json.loads(env_export).get(""dependencies""))
-        dependencies = json.loads(env_export).get(""dependencies"")
-        # Filtering packages installed through pip in this case it's a dict {'pip': ['toree==0.3.0']}
-        # Since we only manage packages installed through mamba here
+        dependencies = yaml.safe_load(env_export).get(""dependencies"")
+        # Filtering packages installed through pip
+        # since we only manage packages installed through mamba here
+        # They are represented by a dict with a key 'pip'
         dependencies = filter(lambda x: isinstance(x, str), dependencies)
         packages_dict: dict[str, set[str]] = dict()
         for split in map(lambda x: re.split(""=?="", x), dependencies):","diff --git a/tests/package_helper.py b/tests/package_helper.py
index 2fe85f53..5f2f636c 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -22,13 +22,13 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
-import json
 import logging
 import re
 from collections import defaultdict
 from itertools import chain
 from typing import Any, Optional
 
+import yaml
 from docker.models.containers import Container
 from tabulate import tabulate
 
@@ -61,7 +61,7 @@ class CondaPackageHelper:
     @staticmethod
     def _conda_export_command(from_history: bool) -> list[str]:
         """"""Return the mamba export command with or without history""""""
-        cmd = [""mamba"", ""env"", ""export"", ""-n"", ""base"", ""--json"", ""--no-builds""]
+        cmd = [""mamba"", ""env"", ""export"", ""--no-build""]
         if from_history:
             cmd.append(""--from-history"")
         return cmd
@@ -70,7 +70,7 @@ class CondaPackageHelper:
         """"""Return the installed packages""""""
         if self.installed is None:
             LOGGER.info(""Grabbing the list of installed packages ..."")
-            self.installed = CondaPackageHelper._packages_from_json(
+            self.installed = CondaPackageHelper._parse_package_versions(
                 self._execute_command(
                     CondaPackageHelper._conda_export_command(from_history=False)
                 )
@@ -81,7 +81,7 @@ class CondaPackageHelper:
         """"""Return the requested package (i.e. `mamba install <package>`)""""""
         if self.requested is None:
             LOGGER.info(""Grabbing the list of manually requested packages ..."")
-            self.requested = CondaPackageHelper._packages_from_json(
+            self.requested = CondaPackageHelper._parse_package_versions(
                 self._execute_command(
                     CondaPackageHelper._conda_export_command(from_history=True)
                 )
@@ -94,12 +94,12 @@ class CondaPackageHelper:
         return rc.output.decode(""utf-8"")  # type: ignore
 
     @staticmethod
-    def _packages_from_json(env_export: str) -> dict[str, set[str]]:
+    def _parse_package_versions(env_export: str) -> dict[str, set[str]]:
         """"""Extract packages and versions from the lines returned by the list of specifications""""""
-        # dependencies = filter(lambda x: isinstance(x, str), json.loads(env_export).get(""dependencies""))
-        dependencies = json.loads(env_export).get(""dependencies"")
-        # Filtering packages installed through pip in this case it's a dict {'pip': ['toree==0.3.0']}
-        # Since we only manage packages installed through mamba here
+        dependencies = yaml.safe_load(env_export).get(""dependencies"")
+        # Filtering packages installed through pip
+        # since we only manage packages installed through mamba here
+        # They are represented by a dict with a key 'pip'
         dependencies = filter(lambda x: isinstance(x, str), dependencies)
         packages_dict: dict[str, set[str]] = dict()
         for split in map(lambda x: re.split(""=?="", x), dependencies):",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,942ab9604663cac52f210fa358a7ad70bb753d98,41d0c3f5a406e1ca7cbd01f8befb4224c4fa2776,Use awk to pin python major.minor version (#2151),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 9c1a344f..3ed18442 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -131,7 +131,7 @@ RUN set -x && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python
     # https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#preventing-packages-from-updating-pinning
-    mamba list --full-name 'python' | tail -1 | tr -s ' ' | cut -d ' ' -f 1,2 | sed 's/\.[^.]*$/.*/' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    mamba list --full-name 'python' | awk 'END{sub(""[^.]*$"", ""*"", $2); print $1 "" "" $2}' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 9c1a344f..3ed18442 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -131,7 +131,7 @@ RUN set -x && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python
     # https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-pkgs.html#preventing-packages-from-updating-pinning
-    mamba list --full-name 'python' | tail -1 | tr -s ' ' | cut -d ' ' -f 1,2 | sed 's/\.[^.]*$/.*/' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
+    mamba list --full-name 'python' | awk 'END{sub(""[^.]*$"", ""*"", $2); print $1 "" "" $2}' >> ""${CONDA_DIR}/conda-meta/pinned"" && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
docs/images/inherit.svg,docs/images/inherit.svg,3c10aa546daa26e75abedcff163c4b71c52819d4,942ab9604663cac52f210fa358a7ad70bb753d98,Update inheritance diagram to include cuda options,"diff --git a/docs/images/inherit.svg b/docs/images/inherit.svg
index 5324df89..e98db380 100644
--- a/docs/images/inherit.svg
+++ b/docs/images/inherit.svg
@@ -36,9 +36,11 @@
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""448"" y=""360"" />
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""70"" x=""512"" y=""385"">julia-notebook</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""64"" y=""440"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""95"" x=""128"" y=""465"">tensorflow-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""95"" x=""128"" y=""459"">tensorflow-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""65"" x=""128"" y=""470"">+cuda variant</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""256"" y=""440"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""320"" y=""465"">pytorch-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""320"" y=""459"">pytorch-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""114"" x=""320"" y=""470"">+cuda11/cuda12 variants</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""448"" y=""440"" />
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""100"" x=""512"" y=""465"">datascience-notebook</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""640"" y=""440"" />
@@ -51,30 +53,30 @@
   <polygon fill=""rgb(0,0,0)"" points=""128,199 124,192 132,192 128,199"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 240 L 128 272"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""128,279 124,272 132,272 128,279"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 320 L 128 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""128,359 124,352 132,352 128,359"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 320 L 128 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 340 L 320 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 320 340 L 320 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""320,359 316,352 324,352 320,359"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 320 L 128 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""128,359 124,352 132,352 128,359"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 320 L 128 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 340 L 512 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 512 340 L 512 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""512,359 508,352 516,352 512,359"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 400 L 128 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""128,439 124,432 132,432 128,439"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 420 L 320 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 320 420 L 320 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""320,439 316,432 324,432 320,439"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 420 L 704 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 704 420 L 704 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""704,439 700,432 708,432 704,439"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 400 L 128 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""128,439 124,432 132,432 128,439"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 420 L 512 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 512 420 L 512 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""512,439 508,432 516,432 512,439"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 420 L 320 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 320 420 L 320 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""320,439 316,432 324,432 320,439"" stroke=""rgb(0,0,0)"" />
   <path d=""M 704 480 L 704 512"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""704,519 700,512 708,512 704,519"" stroke=""rgb(0,0,0)"" />
 </svg>","diff --git a/docs/images/inherit.svg b/docs/images/inherit.svg
index 5324df89..e98db380 100644
--- a/docs/images/inherit.svg
+++ b/docs/images/inherit.svg
@@ -36,9 +36,11 @@
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""448"" y=""360"" />
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""70"" x=""512"" y=""385"">julia-notebook</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""64"" y=""440"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""95"" x=""128"" y=""465"">tensorflow-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""95"" x=""128"" y=""459"">tensorflow-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""65"" x=""128"" y=""470"">+cuda variant</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""256"" y=""440"" />
-  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""320"" y=""465"">pytorch-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""80"" x=""320"" y=""459"">pytorch-notebook</text>
+  <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""114"" x=""320"" y=""470"">+cuda11/cuda12 variants</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""448"" y=""440"" />
   <text fill=""rgb(0,0,0)"" font-family=""sans-serif"" font-size=""9"" font-style=""normal"" font-weight=""normal"" text-anchor=""middle"" textLength=""100"" x=""512"" y=""465"">datascience-notebook</text>
   <rect fill=""rgb(255,255,255)"" height=""40"" stroke=""rgb(0,0,0)"" width=""128"" x=""640"" y=""440"" />
@@ -51,30 +53,30 @@
   <polygon fill=""rgb(0,0,0)"" points=""128,199 124,192 132,192 128,199"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 240 L 128 272"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""128,279 124,272 132,272 128,279"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 320 L 128 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""128,359 124,352 132,352 128,359"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 320 L 128 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 340 L 320 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 320 340 L 320 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""320,359 316,352 324,352 320,359"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 320 L 128 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""128,359 124,352 132,352 128,359"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 320 L 128 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 340 L 512 340"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 512 340 L 512 352"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""512,359 508,352 516,352 512,359"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 400 L 128 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""128,439 124,432 132,432 128,439"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 420 L 704 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 704 420 L 704 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""704,439 700,432 708,432 704,439"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 128 420 L 512 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <path d=""M 512 420 L 512 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
-  <polygon fill=""rgb(0,0,0)"" points=""512,439 508,432 516,432 512,439"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 128 420 L 320 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <path d=""M 320 420 L 320 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""320,439 316,432 324,432 320,439"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 420 L 704 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 704 420 L 704 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""704,439 700,432 708,432 704,439"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 400 L 128 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""128,439 124,432 132,432 128,439"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 400 L 128 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 128 420 L 512 420"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <path d=""M 512 420 L 512 432"" fill=""none"" stroke=""rgb(0,0,0)"" />
+  <polygon fill=""rgb(0,0,0)"" points=""512,439 508,432 516,432 512,439"" stroke=""rgb(0,0,0)"" />
   <path d=""M 704 480 L 704 512"" fill=""none"" stroke=""rgb(0,0,0)"" />
   <polygon fill=""rgb(0,0,0)"" points=""704,519 700,512 708,512 704,519"" stroke=""rgb(0,0,0)"" />
 </svg>",No
docs/using/selecting.md,docs/using/selecting.md,3c10aa546daa26e75abedcff163c4b71c52819d4,942ab9604663cac52f210fa358a7ad70bb753d98,Update inheritance diagram to include cuda options,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index a3c77c7b..3ea4e85e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -255,7 +255,7 @@ The following diagram depicts the build dependency tree of the core images. (i.e
 Any given image inherits the complete content of all ancestor images pointing to it.
 
 [![Image inheritance
-diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=deflate&src=eJyFz8FOwzAMgOH7nsLqCQ55ADTBE3CDIxJyU5eZZnaUOJoK2rsv4YCUSlOvv784yRjULxPjF_weACaasQT7nFUs8w_BMzwda9fEJIbGKjVFTZaQ7Xioo6GMRax8yMPr-xtc2E51zmKQKBBmehzAvcBUb6HksqFfspu1yPS3rS2_N2vnxrrBiRqNqkvDXWjizMJnDB3atuay57h2qi_NDEaSNc1BL_99uEPjapr8ac_Vr2CtJJ52n5h2xXcJjDufiGuOmJZObVtzGILbyusNkda3zw)
+diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=deflate&src=eJyFj0FqwzAQRfc5hfAqpYiS7kpoT9BdugyEsTxuplZmjDRqcEvvXinQggzGK8Gb97_4rRc3dATv5ntjTIc9JK-nXlgjfaF5Nk_7zCUQsoKScEajBA1Aut_kU5PaxJqOvH19O5gr6TnfidUE9AgR7xpjX0yXf8Fgo4Ibou0lcXdrK-VLt5Jrc4NlUWxFhiJXoBgXYrqAr6Q5K150NE6VVZPiNIocJfRerv_8yPcudWA-IRCwNgvJcVIJ7jyP7XYPt-fxLx8XCvJkyBTZ4eqUsGp8JE-wMnac4ghhqKw5Kx54b-fmzy_M3cYh)
 
 ### Builds","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index a3c77c7b..3ea4e85e 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -255,7 +255,7 @@ The following diagram depicts the build dependency tree of the core images. (i.e
 Any given image inherits the complete content of all ancestor images pointing to it.
 
 [![Image inheritance
-diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=deflate&src=eJyFz8FOwzAMgOH7nsLqCQ55ADTBE3CDIxJyU5eZZnaUOJoK2rsv4YCUSlOvv784yRjULxPjF_weACaasQT7nFUs8w_BMzwda9fEJIbGKjVFTZaQ7Xioo6GMRax8yMPr-xtc2E51zmKQKBBmehzAvcBUb6HksqFfspu1yPS3rS2_N2vnxrrBiRqNqkvDXWjizMJnDB3atuay57h2qi_NDEaSNc1BL_99uEPjapr8ac_Vr2CtJJ52n5h2xXcJjDufiGuOmJZObVtzGILbyusNkda3zw)
+diagram](../images/inherit.svg)](http://interactive.blockdiag.com/?compression=deflate&src=eJyFj0FqwzAQRfc5hfAqpYiS7kpoT9BdugyEsTxuplZmjDRqcEvvXinQggzGK8Gb97_4rRc3dATv5ntjTIc9JK-nXlgjfaF5Nk_7zCUQsoKScEajBA1Aut_kU5PaxJqOvH19O5gr6TnfidUE9AgR7xpjX0yXf8Fgo4Ibou0lcXdrK-VLt5Jrc4NlUWxFhiJXoBgXYrqAr6Q5K150NE6VVZPiNIocJfRerv_8yPcudWA-IRCwNgvJcVIJ7jyP7XYPt-fxLx8XCvJkyBTZ4eqUsGp8JE-wMnac4ghhqKw5Kx54b-fmzy_M3cYh)
 
 ### Builds",Yes
README.md,README.md,aa90bc864885b8a1e26bda7462f913bc6fd96286,3c10aa546daa26e75abedcff163c4b71c52819d4,Update tag example,"diff --git a/README.md b/README.md
index 0fc18e3a..90e82cc8 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-08-30
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-10-07
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-08-30
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-10-07
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index 0fc18e3a..90e82cc8 100644
--- a/README.md
+++ b/README.md
@@ -30,11 +30,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-08-30
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-10-07
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -49,11 +49,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-08-30
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-10-07
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,aa90bc864885b8a1e26bda7462f913bc6fd96286,3c10aa546daa26e75abedcff163c4b71c52819d4,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 543bea36..809ddbf8 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-08-30
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-10-07
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-08-30""
+ENV TAG=""2024-10-07""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 543bea36..809ddbf8 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-08-30
+ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-10-07
 FROM $BASE_CONTAINER
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-08-30""
+ENV TAG=""2024-10-07""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,aa90bc864885b8a1e26bda7462f913bc6fd96286,3c10aa546daa26e75abedcff163c4b71c52819d4,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index 9f71e487..4c2290ab 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-08-30
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-10-07
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-08-30   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-10-07   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-08-30
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-10-07
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-08-30
+    quay.io/jupyter/r-notebook:2024-10-07
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 9f71e487..4c2290ab 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-08-30
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-10-07
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-08-30   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-10-07   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-08-30
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-10-07
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-08-30` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-08-30
+    quay.io/jupyter/r-notebook:2024-10-07
 ```
 
 ```{warning}",Yes
docs/using/custom-images.md,docs/using/custom-images.md,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,aa90bc864885b8a1e26bda7462f913bc6fd96286,Describe custom arguments and add links for docker build args and GitHub env variables (#2153),"diff --git a/docs/using/custom-images.md b/docs/using/custom-images.md
index 4bf7eda7..90a80755 100644
--- a/docs/using/custom-images.md
+++ b/docs/using/custom-images.md
@@ -13,11 +13,18 @@ please, [take a look at cookiecutter template](../contributing/stacks.md).
 
 ## Custom arguments
 
-Existing customization points:
-
-- `ROOT_CONTAINER`, `PYTHON_VERSION` - docker arguments of a `docker-stacks-foundation` image
-- `REGISTRY`, `OWNER`, `BASE_CONTAINER` - docker arguments for all the other images we build
-- `REGISTRY`, `OWNER` - part of `env` in most of our GitHub workflows
+Our repository provides several customization points:
+
+- `ROOT_CONTAINER` (docker argument) - the parent image for `docker-stacks-foundation` image
+- `PYTHON_VERSION` (docker argument) - the Python version to install in `docker-stacks-foundation` image
+- `REGISTRY`, `OWNER`, `BASE_CONTAINER` (docker arguments) - they allow to specify parent image for all the other images
+- `REGISTRY`, `OWNER` (part of `env` in some GitHub workflows) - these allow to properly tag and refer to images during following steps:
+  [`build-test-upload`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-build-test-upload.yml),
+  [`tag-push`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-tag-push.yml) and
+  [`merge-tags`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-merge-tags.yml)
+
+These customization points can't be changed during runtime.
+Read more about [Docker build arguments](https://docs.docker.com/build/building/variables/#arg-usage-example) and [GitHub environment variables for a single workflow](https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/store-information-in-variables#defining-environment-variables-for-a-single-workflow).
 
 ## Building stack images with custom arguments","diff --git a/docs/using/custom-images.md b/docs/using/custom-images.md
index 4bf7eda7..90a80755 100644
--- a/docs/using/custom-images.md
+++ b/docs/using/custom-images.md
@@ -13,11 +13,18 @@ please, [take a look at cookiecutter template](../contributing/stacks.md).
 
 ## Custom arguments
 
-Existing customization points:
+Our repository provides several customization points:
 
-- `ROOT_CONTAINER`, `PYTHON_VERSION` - docker arguments of a `docker-stacks-foundation` image
-- `REGISTRY`, `OWNER`, `BASE_CONTAINER` - docker arguments for all the other images we build
-- `REGISTRY`, `OWNER` - part of `env` in most of our GitHub workflows
+- `ROOT_CONTAINER` (docker argument) - the parent image for `docker-stacks-foundation` image
+- `PYTHON_VERSION` (docker argument) - the Python version to install in `docker-stacks-foundation` image
+- `REGISTRY`, `OWNER`, `BASE_CONTAINER` (docker arguments) - they allow to specify parent image for all the other images
+- `REGISTRY`, `OWNER` (part of `env` in some GitHub workflows) - these allow to properly tag and refer to images during following steps:
+  [`build-test-upload`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-build-test-upload.yml),
+  [`tag-push`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-tag-push.yml) and
+  [`merge-tags`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-merge-tags.yml)
+
+These customization points can't be changed during runtime.
+Read more about [Docker build arguments](https://docs.docker.com/build/building/variables/#arg-usage-example) and [GitHub environment variables for a single workflow](https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/store-information-in-variables#defining-environment-variables-for-a-single-workflow).
 
 ## Building stack images with custom arguments",No
,CHANGELOG.md,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/CHANGELOG.md b/CHANGELOG.md
new file mode 100644
index 00000000..bbf2f7ae
--- /dev/null
+++ b/CHANGELOG.md
@@ -0,0 +1,9 @@
+# Changelog
+
+## 2024-10-09
+
+### Changed
+
+_This change might only breaking if you build your custom set of images._
+
+- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/pull/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))","diff --git a/CHANGELOG.md b/CHANGELOG.md
new file mode 100644
index 00000000..bbf2f7ae
--- /dev/null
+++ b/CHANGELOG.md
@@ -0,0 +1,9 @@
+# Changelog
+
+## 2024-10-09
+
+### Changed
+
+_This change might only breaking if you build your custom set of images._
+
+- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/pull/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))",Yes
Makefile,Makefile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/Makefile b/Makefile
index 0bf19610..9222d677 100644
--- a/Makefile
+++ b/Makefile
@@ -36,9 +36,9 @@ help:
 
 
 build/%: DOCKER_BUILD_ARGS?=
-build/%: ROOT_CONTAINER?=ubuntu:24.04
+build/%: ROOT_IMAGE?=ubuntu:24.04
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)"" --build-arg ROOT_CONTAINER=""$(ROOT_CONTAINER)""
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)"" --build-arg ROOT_IMAGE=""$(ROOT_IMAGE)""
 	@echo -n ""Built image size: ""
 	@docker images ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks","diff --git a/Makefile b/Makefile
index 0bf19610..9222d677 100644
--- a/Makefile
+++ b/Makefile
@@ -36,9 +36,9 @@ help:
 
 
 build/%: DOCKER_BUILD_ARGS?=
-build/%: ROOT_CONTAINER?=ubuntu:24.04
+build/%: ROOT_IMAGE?=ubuntu:24.04
 build/%: ## build the latest image for a stack using the system's architecture
-	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)"" --build-arg ROOT_CONTAINER=""$(ROOT_CONTAINER)""
+	docker build $(DOCKER_BUILD_ARGS) --rm --force-rm --tag ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" ""./images/$(notdir $@)"" --build-arg REGISTRY=""$(REGISTRY)"" --build-arg OWNER=""$(OWNER)"" --build-arg ROOT_IMAGE=""$(ROOT_IMAGE)""
 	@echo -n ""Built image size: ""
 	@docker images ""$(REGISTRY)/$(OWNER)/$(notdir $@):latest"" --format ""{{.Size}}""
 build-all: $(foreach I, $(ALL_IMAGES), build/$(I)) ## build all stacks",Yes
binder/Dockerfile,binder/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 809ddbf8..28ccdd9e 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,8 +4,8 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-10-07
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-10-07
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 809ddbf8..28ccdd9e 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,8 +4,8 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook:2024-10-07
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-10-07
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
docs/using/custom-images.md,docs/using/custom-images.md,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/docs/using/custom-images.md b/docs/using/custom-images.md
index 90a80755..0c61e36b 100644
--- a/docs/using/custom-images.md
+++ b/docs/using/custom-images.md
@@ -15,9 +15,9 @@ please, [take a look at cookiecutter template](../contributing/stacks.md).
 
 Our repository provides several customization points:
 
-- `ROOT_CONTAINER` (docker argument) - the parent image for `docker-stacks-foundation` image
+- `ROOT_IMAGE` (docker argument) - the parent image for `docker-stacks-foundation` image
 - `PYTHON_VERSION` (docker argument) - the Python version to install in `docker-stacks-foundation` image
-- `REGISTRY`, `OWNER`, `BASE_CONTAINER` (docker arguments) - they allow to specify parent image for all the other images
+- `REGISTRY`, `OWNER`, `BASE_IMAGE` (docker arguments) - they allow to specify parent image for all the other images
 - `REGISTRY`, `OWNER` (part of `env` in some GitHub workflows) - these allow to properly tag and refer to images during following steps:
   [`build-test-upload`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-build-test-upload.yml),
   [`tag-push`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-tag-push.yml) and
@@ -50,8 +50,8 @@ then with a Dockerfile like:
 ```{code-block} Dockerfile
 :caption: Dockerfile
 
-ARG BASE_CONTAINER=minimal-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=minimal-notebook
+FROM $BASE_IMAGE
 ...
 ```","diff --git a/docs/using/custom-images.md b/docs/using/custom-images.md
index 90a80755..0c61e36b 100644
--- a/docs/using/custom-images.md
+++ b/docs/using/custom-images.md
@@ -15,9 +15,9 @@ please, [take a look at cookiecutter template](../contributing/stacks.md).
 
 Our repository provides several customization points:
 
-- `ROOT_CONTAINER` (docker argument) - the parent image for `docker-stacks-foundation` image
+- `ROOT_IMAGE` (docker argument) - the parent image for `docker-stacks-foundation` image
 - `PYTHON_VERSION` (docker argument) - the Python version to install in `docker-stacks-foundation` image
-- `REGISTRY`, `OWNER`, `BASE_CONTAINER` (docker arguments) - they allow to specify parent image for all the other images
+- `REGISTRY`, `OWNER`, `BASE_IMAGE` (docker arguments) - they allow to specify parent image for all the other images
 - `REGISTRY`, `OWNER` (part of `env` in some GitHub workflows) - these allow to properly tag and refer to images during following steps:
   [`build-test-upload`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-build-test-upload.yml),
   [`tag-push`](https://github.com/jupyter/docker-stacks/blob/main/.github/workflows/docker-tag-push.yml) and
@@ -50,8 +50,8 @@ then with a Dockerfile like:
 ```{code-block} Dockerfile
 :caption: Dockerfile
 
-ARG BASE_CONTAINER=minimal-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=minimal-notebook
+FROM $BASE_IMAGE
 ...
 ```",Yes
docs/using/recipe_code/docker-bake.python312.hcl,docs/using/recipe_code/docker-bake.python312.hcl,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/docs/using/recipe_code/docker-bake.python312.hcl b/docs/using/recipe_code/docker-bake.python312.hcl
index 10f3b936..aadbd187 100644
--- a/docs/using/recipe_code/docker-bake.python312.hcl
+++ b/docs/using/recipe_code/docker-bake.python312.hcl
@@ -16,7 +16,7 @@ target ""base-notebook"" {
         docker-stacks-foundation = ""target:foundation""
     }
     args = {
-        BASE_CONTAINER = ""docker-stacks-foundation""
+        BASE_IMAGE = ""docker-stacks-foundation""
     }
     tags = [""base-notebook""]
 }
@@ -27,7 +27,7 @@ target ""minimal-notebook"" {
         base-notebook = ""target:base-notebook""
     }
     args = {
-        BASE_CONTAINER = ""base-notebook""
+        BASE_IMAGE = ""base-notebook""
     }
     tags = [""minimal-notebook""]
 }
@@ -38,7 +38,7 @@ target ""custom-notebook"" {
         minimal-notebook = ""target:minimal-notebook""
     }
     args = {
-        BASE_CONTAINER = ""minimal-notebook""
+        BASE_IMAGE = ""minimal-notebook""
     }
     tags = [""custom-jupyter""]
 }","diff --git a/docs/using/recipe_code/docker-bake.python312.hcl b/docs/using/recipe_code/docker-bake.python312.hcl
index 10f3b936..aadbd187 100644
--- a/docs/using/recipe_code/docker-bake.python312.hcl
+++ b/docs/using/recipe_code/docker-bake.python312.hcl
@@ -16,7 +16,7 @@ target ""base-notebook"" {
         docker-stacks-foundation = ""target:foundation""
     }
     args = {
-        BASE_CONTAINER = ""docker-stacks-foundation""
+        BASE_IMAGE = ""docker-stacks-foundation""
     }
     tags = [""base-notebook""]
 }
@@ -27,7 +27,7 @@ target ""minimal-notebook"" {
         base-notebook = ""target:base-notebook""
     }
     args = {
-        BASE_CONTAINER = ""base-notebook""
+        BASE_IMAGE = ""base-notebook""
     }
     tags = [""minimal-notebook""]
 }
@@ -38,7 +38,7 @@ target ""custom-notebook"" {
         minimal-notebook = ""target:minimal-notebook""
     }
     args = {
-        BASE_CONTAINER = ""minimal-notebook""
+        BASE_IMAGE = ""minimal-notebook""
     }
     tags = [""custom-jupyter""]
 }",Yes
images/all-spark-notebook/Dockerfile,images/all-spark-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
index 53f3c8a6..13eb5509 100644
--- a/images/all-spark-notebook/Dockerfile
+++ b/images/all-spark-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/pyspark-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/pyspark-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/all-spark-notebook/Dockerfile b/images/all-spark-notebook/Dockerfile
index 53f3c8a6..13eb5509 100644
--- a/images/all-spark-notebook/Dockerfile
+++ b/images/all-spark-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/pyspark-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/pyspark-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 672f66b0..0cde5b5d 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/docker-stacks-foundation
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/docker-stacks-foundation
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 672f66b0..0cde5b5d 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/docker-stacks-foundation
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/docker-stacks-foundation
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/datascience-notebook/Dockerfile,images/datascience-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
index 1d5f13ad..ab7a8454 100644
--- a/images/datascience-notebook/Dockerfile
+++ b/images/datascience-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/datascience-notebook/Dockerfile b/images/datascience-notebook/Dockerfile
index 1d5f13ad..ab7a8454 100644
--- a/images/datascience-notebook/Dockerfile
+++ b/images/datascience-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 3ed18442..284d43d4 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -3,9 +3,9 @@
 
 # Ubuntu 24.04 (noble)
 # https://hub.docker.com/_/ubuntu/tags?page=1&name=noble
-ARG ROOT_CONTAINER=ubuntu:24.04
+ARG ROOT_IMAGE=ubuntu:24.04
 
-FROM $ROOT_CONTAINER
+FROM $ROOT_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 ARG NB_USER=""jovyan""","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 3ed18442..284d43d4 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -3,9 +3,9 @@
 
 # Ubuntu 24.04 (noble)
 # https://hub.docker.com/_/ubuntu/tags?page=1&name=noble
-ARG ROOT_CONTAINER=ubuntu:24.04
+ARG ROOT_IMAGE=ubuntu:24.04
 
-FROM $ROOT_CONTAINER
+FROM $ROOT_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 ARG NB_USER=""jovyan""",Yes
images/julia-notebook/Dockerfile,images/julia-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
index 9dbfd7fc..bacf65ba 100644
--- a/images/julia-notebook/Dockerfile
+++ b/images/julia-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/minimal-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/julia-notebook/Dockerfile b/images/julia-notebook/Dockerfile
index 9dbfd7fc..bacf65ba 100644
--- a/images/julia-notebook/Dockerfile
+++ b/images/julia-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/minimal-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/minimal-notebook/Dockerfile,images/minimal-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index e77798c7..e1d7dc70 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/minimal-notebook/Dockerfile b/images/minimal-notebook/Dockerfile
index e77798c7..e1d7dc70 100644
--- a/images/minimal-notebook/Dockerfile
+++ b/images/minimal-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/base-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index c9c9326b..71b1c81c 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index c9c9326b..71b1c81c 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/pytorch-notebook/Dockerfile,images/pytorch-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/pytorch-notebook/Dockerfile b/images/pytorch-notebook/Dockerfile
index 13d1a181..d5c35983 100644
--- a/images/pytorch-notebook/Dockerfile
+++ b/images/pytorch-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/pytorch-notebook/Dockerfile b/images/pytorch-notebook/Dockerfile
index 13d1a181..d5c35983 100644
--- a/images/pytorch-notebook/Dockerfile
+++ b/images/pytorch-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/pytorch-notebook/cuda11/Dockerfile,images/pytorch-notebook/cuda11/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
index d1a5b990..d3af70f6 100644
--- a/images/pytorch-notebook/cuda11/Dockerfile
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/pytorch-notebook/cuda11/Dockerfile b/images/pytorch-notebook/cuda11/Dockerfile
index d1a5b990..d3af70f6 100644
--- a/images/pytorch-notebook/cuda11/Dockerfile
+++ b/images/pytorch-notebook/cuda11/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/pytorch-notebook/cuda12/Dockerfile,images/pytorch-notebook/cuda12/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index 59081e38..cdfd089a 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index 59081e38..cdfd089a 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/r-notebook/Dockerfile,images/r-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/r-notebook/Dockerfile b/images/r-notebook/Dockerfile
index bb7f0955..39cbebdd 100644
--- a/images/r-notebook/Dockerfile
+++ b/images/r-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/minimal-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/r-notebook/Dockerfile b/images/r-notebook/Dockerfile
index bb7f0955..39cbebdd 100644
--- a/images/r-notebook/Dockerfile
+++ b/images/r-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/minimal-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/scipy-notebook/Dockerfile,images/scipy-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index ad2d838f..2e667f3e 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/minimal-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/scipy-notebook/Dockerfile b/images/scipy-notebook/Dockerfile
index ad2d838f..2e667f3e 100644
--- a/images/scipy-notebook/Dockerfile
+++ b/images/scipy-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/minimal-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/minimal-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/tensorflow-notebook/Dockerfile,images/tensorflow-notebook/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index d6c0b78a..a433b2fa 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/tensorflow-notebook/Dockerfile b/images/tensorflow-notebook/Dockerfile
index d6c0b78a..a433b2fa 100644
--- a/images/tensorflow-notebook/Dockerfile
+++ b/images/tensorflow-notebook/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
images/tensorflow-notebook/cuda/Dockerfile,images/tensorflow-notebook/cuda/Dockerfile,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,b3ceb038e5dc7fd24110218bf2ab9d6f2d54a587,"Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE (#2155)

* Rename: ROOT_CONTAINER->ROOT_IMAGE, BASE_CONTAINER->BASE_IMAGE

* Add changelog","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index f71f6416..5018dee4 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index f71f6416..5018dee4 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -2,8 +2,8 @@
 # Distributed under the terms of the Modified BSD License.
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_CONTAINER=$REGISTRY/$OWNER/scipy-notebook
-FROM $BASE_CONTAINER
+ARG BASE_IMAGE=$REGISTRY/$OWNER/scipy-notebook
+FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""",Yes
.readthedocs.yaml,.readthedocs.yaml,a4047b30a9b4a15eac82742c2e20a6ab2e298a2d,5365b9f79fa4ffbb20f10133cc6ac5bec5046302,Do not use shallow clones in Read the Docs to properly show last updated time (#2157),"diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index 31dbf0d7..a1a47a13 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -13,6 +13,9 @@ build:
     # nodejs: ""20""
     # rust: ""1.70""
     # golang: ""1.20""
+  jobs:
+    post_checkout:
+      - git fetch --unshallow || true
 
 # Build documentation in the ""docs/"" directory with Sphinx
 sphinx:","diff --git a/.readthedocs.yaml b/.readthedocs.yaml
index 31dbf0d7..a1a47a13 100644
--- a/.readthedocs.yaml
+++ b/.readthedocs.yaml
@@ -13,6 +13,9 @@ build:
     # nodejs: ""20""
     # rust: ""1.70""
     # golang: ""1.20""
+  jobs:
+    post_checkout:
+      - git fetch --unshallow || true
 
 # Build documentation in the ""docs/"" directory with Sphinx
 sphinx:",Yes
docs/using/recipes.md,docs/using/recipes.md,9fd657a11b228674e75484eb8600d6e8ccdda3a0,a4047b30a9b4a15eac82742c2e20a6ab2e298a2d,Rename container to image in docs (#2156),"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 69ecf9e1..333aad6a 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -151,7 +151,7 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/199>
 
 ## Manpage installation
 
-Most containers, including our Ubuntu base image, ship without manpages installed to save space.
+Most images, including our Ubuntu base image, ship without manpages installed to save space.
 You can use the following Dockerfile to inherit from one of our images to enable manpages:
 
 ```{literalinclude} recipe_code/manpage_install.dockerfile
@@ -161,8 +161,8 @@ You can use the following Dockerfile to inherit from one of our images to enable
 Adding the documentation on top of the existing image wastes a lot of space
 and requires reinstalling every system package,
 which can take additional time and bandwidth.
-Enabling manpages in the base Ubuntu layer prevents this container bloat.
-To achieve this, use the previous `Dockerfile`'s commands with the original `ubuntu` image as your base container:
+Enabling manpages in the base Ubuntu layer prevents this image bloat.
+To achieve this, use the previous `Dockerfile`'s commands with the original `ubuntu` image as your base image:
 
 ```dockerfile
 FROM ubuntu:22.04
@@ -483,7 +483,7 @@ docker run -it --rm \
     quay.io/jupyter/minimal-notebook
 ```
 
-## Add ijavascript kernel to container
+## Install ijavascript kernel in your image
 
 The example below is a Dockerfile to install the [IJavascript kernel](https://github.com/n-riesco/ijavascript).","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 69ecf9e1..333aad6a 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -151,7 +151,7 @@ Ref: <https://github.com/jupyter/docker-stacks/issues/199>
 
 ## Manpage installation
 
-Most containers, including our Ubuntu base image, ship without manpages installed to save space.
+Most images, including our Ubuntu base image, ship without manpages installed to save space.
 You can use the following Dockerfile to inherit from one of our images to enable manpages:
 
 ```{literalinclude} recipe_code/manpage_install.dockerfile
@@ -161,8 +161,8 @@ You can use the following Dockerfile to inherit from one of our images to enable
 Adding the documentation on top of the existing image wastes a lot of space
 and requires reinstalling every system package,
 which can take additional time and bandwidth.
-Enabling manpages in the base Ubuntu layer prevents this container bloat.
-To achieve this, use the previous `Dockerfile`'s commands with the original `ubuntu` image as your base container:
+Enabling manpages in the base Ubuntu layer prevents this image bloat.
+To achieve this, use the previous `Dockerfile`'s commands with the original `ubuntu` image as your base image:
 
 ```dockerfile
 FROM ubuntu:22.04
@@ -483,7 +483,7 @@ docker run -it --rm \
     quay.io/jupyter/minimal-notebook
 ```
 
-## Add ijavascript kernel to container
+## Install ijavascript kernel in your image
 
 The example below is a Dockerfile to install the [IJavascript kernel](https://github.com/n-riesco/ijavascript).",Yes
examples/docker-compose/README.md,examples/docker-compose/README.md,9fd657a11b228674e75484eb8600d6e8ccdda3a0,a4047b30a9b4a15eac82742c2e20a6ab2e298a2d,Rename container to image in docs (#2156),"diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index d2c2e3ee..40300cac 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -12,7 +12,7 @@ See the [installation instructions](https://docs.docker.com/engine/installation/
 
 ## Quickstart
 
-Build and run a `jupyter/minimal-notebook` container on a VirtualBox VM on local desktop.
+Build and run a `jupyter/minimal-notebook` image on a VirtualBox VM on local desktop.
 
 ```bash
 # create a Docker Machine-controlled VirtualBox VM","diff --git a/examples/docker-compose/README.md b/examples/docker-compose/README.md
index d2c2e3ee..40300cac 100644
--- a/examples/docker-compose/README.md
+++ b/examples/docker-compose/README.md
@@ -12,7 +12,7 @@ See the [installation instructions](https://docs.docker.com/engine/installation/
 
 ## Quickstart
 
-Build and run a `jupyter/minimal-notebook` container on a VirtualBox VM on local desktop.
+Build and run a `jupyter/minimal-notebook` image on a VirtualBox VM on local desktop.
 
 ```bash
 # create a Docker Machine-controlled VirtualBox VM",Yes
docs/using/recipes.md,docs/using/recipes.md,b6b22e1546e85bbee3c4c57f2ef840c590a642ae,9fd657a11b228674e75484eb8600d6e8ccdda3a0,Update base image in the manpage installation recipe,"diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 333aad6a..76cb1dea 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -165,7 +165,7 @@ Enabling manpages in the base Ubuntu layer prevents this image bloat.
 To achieve this, use the previous `Dockerfile`'s commands with the original `ubuntu` image as your base image:
 
 ```dockerfile
-FROM ubuntu:22.04
+FROM ubuntu:24.04
 ```
 
 Be sure to check the current base image in `jupyter/docker-stacks-foundation` before building.","diff --git a/docs/using/recipes.md b/docs/using/recipes.md
index 333aad6a..76cb1dea 100644
--- a/docs/using/recipes.md
+++ b/docs/using/recipes.md
@@ -165,7 +165,7 @@ Enabling manpages in the base Ubuntu layer prevents this image bloat.
 To achieve this, use the previous `Dockerfile`'s commands with the original `ubuntu` image as your base image:
 
 ```dockerfile
-FROM ubuntu:22.04
+FROM ubuntu:24.04
 ```
 
 Be sure to check the current base image in `jupyter/docker-stacks-foundation` before building.",Yes
images/pyspark-notebook/setup_spark.py,images/pyspark-notebook/setup_spark.py,c4cb04ec370c1a520120c1f629d0b63ef730ae62,b6b22e1546e85bbee3c4c57f2ef840c590a642ae,Make Spark scripts more robust: support preview versions and Spark 4 output,"diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index a494b832..266f2f78 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -38,10 +38,18 @@ def get_latest_spark_version() -> str:
         for ref in all_refs
         if ref.startswith(""spark-"") and ""incubating"" not in ref and ""preview"" not in ref
     ]
+
     # Compare versions semantically
-    latest_version = max(
-        stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
-    )
+    def version_array(ver: str) -> tuple[int, int, int, str]:
+        # 3.5.3 -> [3, 5, 3, """"]
+        # 4.0.0-preview2 -> [4, 0, 0, ""preview2""]
+        arr = ver.split(""."")
+        assert len(arr) == 3, arr
+        major, minor = int(arr[0]), int(arr[1])
+        patch, _, preview = arr[2].partition(""-"")
+        return (major, minor, int(patch), preview)
+
+    latest_version = max(stable_versions, key=lambda ver: version_array(ver))
     LOGGER.info(f""Latest version: {latest_version}"")
     return latest_version","diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index a494b832..266f2f78 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -38,10 +38,18 @@ def get_latest_spark_version() -> str:
         for ref in all_refs
         if ref.startswith(""spark-"") and ""incubating"" not in ref and ""preview"" not in ref
     ]
+
     # Compare versions semantically
-    latest_version = max(
-        stable_versions, key=lambda ver: [int(sub_ver) for sub_ver in ver.split(""."")]
-    )
+    def version_array(ver: str) -> tuple[int, int, int, str]:
+        # 3.5.3 -> [3, 5, 3, """"]
+        # 4.0.0-preview2 -> [4, 0, 0, ""preview2""]
+        arr = ver.split(""."")
+        assert len(arr) == 3, arr
+        major, minor = int(arr[0]), int(arr[1])
+        patch, _, preview = arr[2].partition(""-"")
+        return (major, minor, int(patch), preview)
+
+    latest_version = max(stable_versions, key=lambda ver: version_array(ver))
     LOGGER.info(f""Latest version: {latest_version}"")
     return latest_version",Yes
tagging/taggers.py,tagging/taggers.py,c4cb04ec370c1a520120c1f629d0b63ef730ae62,b6b22e1546e85bbee3c4c57f2ef840c590a642ae,Make Spark scripts more robust: support preview versions and Spark 4 output,"diff --git a/tagging/taggers.py b/tagging/taggers.py
index a42c9d05..0f53827e 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -122,8 +122,12 @@ class SparkVersionTagger(TaggerInterface):
         SPARK_VERSION_LINE_PREFIX = r""   /___/ .__/\_,_/_/ /_/\_\   version""
 
         spark_version = _get_program_version(container, ""spark-submit"")
-        version_line = spark_version.split(""\n"")[4]
-        assert version_line.startswith(SPARK_VERSION_LINE_PREFIX)
+        version_line = next(
+            filter(
+                lambda line: line.startswith(SPARK_VERSION_LINE_PREFIX),
+                spark_version.split(""\n""),
+            )
+        )
         return ""spark-"" + version_line.split("" "")[-1]","diff --git a/tagging/taggers.py b/tagging/taggers.py
index a42c9d05..0f53827e 100644
--- a/tagging/taggers.py
+++ b/tagging/taggers.py
@@ -122,8 +122,12 @@ class SparkVersionTagger(TaggerInterface):
         SPARK_VERSION_LINE_PREFIX = r""   /___/ .__/\_,_/_/ /_/\_\   version""
 
         spark_version = _get_program_version(container, ""spark-submit"")
-        version_line = spark_version.split(""\n"")[4]
-        assert version_line.startswith(SPARK_VERSION_LINE_PREFIX)
+        version_line = next(
+            filter(
+                lambda line: line.startswith(SPARK_VERSION_LINE_PREFIX),
+                spark_version.split(""\n""),
+            )
+        )
         return ""spark-"" + version_line.split("" "")[-1]",Yes
CHANGELOG.md,CHANGELOG.md,79261f19a0aa9392b62ac846cd1b63cf97d40f58,c4cb04ec370c1a520120c1f629d0b63ef730ae62,Simplify changelog structure,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index bbf2f7ae..42ff0c0f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -2,8 +2,6 @@
 
 ## 2024-10-09
 
-### Changed
-
-_This change might only breaking if you build your custom set of images._
+Affected: users building a custom set of images
 
 - **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/pull/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))","diff --git a/CHANGELOG.md b/CHANGELOG.md
index bbf2f7ae..42ff0c0f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -2,8 +2,6 @@
 
 ## 2024-10-09
 
-### Changed
-
-_This change might only breaking if you build your custom set of images._
+Affected: users building a custom set of images
 
 - **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/pull/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))",Yes
.github/workflows/sphinx.yml,.github/workflows/sphinx.yml,eaf007b08db28dd25ab3c3bdf17f1fd1a167d941,79261f19a0aa9392b62ac846cd1b63cf97d40f58,"Include changelog in docs (#2161)

* Include changelog in docs

* Rename file

* Fix redirect link

* Fix

* Rename changelog link file","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index 9856b3ec..f3c21331 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -10,6 +10,7 @@ on:
 
       - ""docs/**""
       - ""README.md""
+      - ""CHANGELOG.md""
   push:
     branches:
       - main
@@ -18,6 +19,7 @@ on:
 
       - ""docs/**""
       - ""README.md""
+      - ""CHANGELOG.md""
   workflow_dispatch:
 
 jobs:","diff --git a/.github/workflows/sphinx.yml b/.github/workflows/sphinx.yml
index 9856b3ec..f3c21331 100644
--- a/.github/workflows/sphinx.yml
+++ b/.github/workflows/sphinx.yml
@@ -10,6 +10,7 @@ on:
 
       - ""docs/**""
       - ""README.md""
+      - ""CHANGELOG.md""
   push:
     branches:
       - main
@@ -18,6 +19,7 @@ on:
 
       - ""docs/**""
       - ""README.md""
+      - ""CHANGELOG.md""
   workflow_dispatch:
 
 jobs:",Yes
CHANGELOG.md,CHANGELOG.md,eaf007b08db28dd25ab3c3bdf17f1fd1a167d941,79261f19a0aa9392b62ac846cd1b63cf97d40f58,"Include changelog in docs (#2161)

* Include changelog in docs

* Rename file

* Fix redirect link

* Fix

* Rename changelog link file","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 42ff0c0f..51a43c5d 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,7 +1,10 @@
 # Changelog
 
+This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
+All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
+
 ## 2024-10-09
 
 Affected: users building a custom set of images
 
-- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/pull/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))
+- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 42ff0c0f..51a43c5d 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,7 +1,10 @@
 # Changelog
 
+This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
+All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
+
 ## 2024-10-09
 
 Affected: users building a custom set of images
 
-- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/pull/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))
+- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))",Yes
docs/index.rst,docs/index.rst,eaf007b08db28dd25ab3c3bdf17f1fd1a167d941,79261f19a0aa9392b62ac846cd1b63cf97d40f58,"Include changelog in docs (#2161)

* Include changelog in docs

* Rename file

* Fix redirect link

* Fix

* Rename changelog link file","diff --git a/docs/index.rst b/docs/index.rst
index 23aa0e90..5368a503 100644
--- a/docs/index.rst
+++ b/docs/index.rst
@@ -16,6 +16,7 @@ Table of Contents
    using/custom-images
    using/troubleshooting
    using/faq
+   using/changelog
 
 .. toctree::
    :maxdepth: 2","diff --git a/docs/index.rst b/docs/index.rst
index 23aa0e90..5368a503 100644
--- a/docs/index.rst
+++ b/docs/index.rst
@@ -16,6 +16,7 @@ Table of Contents
    using/custom-images
    using/troubleshooting
    using/faq
+   using/changelog
 
 .. toctree::
    :maxdepth: 2",Yes
,docs/using/changelog.md,eaf007b08db28dd25ab3c3bdf17f1fd1a167d941,79261f19a0aa9392b62ac846cd1b63cf97d40f58,"Include changelog in docs (#2161)

* Include changelog in docs

* Rename file

* Fix redirect link

* Fix

* Rename changelog link file","diff --git a/docs/using/changelog.md b/docs/using/changelog.md
new file mode 100644
index 00000000..a986f061
--- /dev/null
+++ b/docs/using/changelog.md
@@ -0,0 +1,5 @@
+```{include} ../../CHANGELOG.md
+
+```
+
+<!-- markdownlint-disable-file MD041 -->","diff --git a/docs/using/changelog.md b/docs/using/changelog.md
new file mode 100644
index 00000000..a986f061
--- /dev/null
+++ b/docs/using/changelog.md
@@ -0,0 +1,5 @@
+```{include} ../../CHANGELOG.md
+
+```
+
+<!-- markdownlint-disable-file MD041 -->",Yes
tests/conftest.py,tests/conftest.py,2f1cf2a2efd86e1effcaf7e5d3c5fe0463f05784,eaf007b08db28dd25ab3c3bdf17f1fd1a167d941,Expect warnings/errors when no_warnings/no_errors is False (#2160),"diff --git a/tests/conftest.py b/tests/conftest.py
index a151eb6b..1df04b60 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -116,10 +116,8 @@ class TrackedContainer:
         logs = running_container.logs().decode(""utf-8"")
         assert isinstance(logs, str)
         LOGGER.debug(logs)
-        if no_warnings:
-            assert not self.get_warnings(logs)
-        if no_errors:
-            assert not self.get_errors(logs)
+        assert no_warnings == (not self.get_warnings(logs))
+        assert no_errors == (not self.get_errors(logs))
         assert no_failure == (rv[""StatusCode""] == 0)
         return logs","diff --git a/tests/conftest.py b/tests/conftest.py
index a151eb6b..1df04b60 100644
--- a/tests/conftest.py
+++ b/tests/conftest.py
@@ -116,10 +116,8 @@ class TrackedContainer:
         logs = running_container.logs().decode(""utf-8"")
         assert isinstance(logs, str)
         LOGGER.debug(logs)
-        if no_warnings:
-            assert not self.get_warnings(logs)
-        if no_errors:
-            assert not self.get_errors(logs)
+        assert no_warnings == (not self.get_warnings(logs))
+        assert no_errors == (not self.get_errors(logs))
         assert no_failure == (rv[""StatusCode""] == 0)
         return logs",Yes
CHANGELOG.md,CHANGELOG.md,b74418220768a48580795b8fe1b580a63956498a,2f1cf2a2efd86e1effcaf7e5d3c5fe0463f05784,"Start using spark4-preview versions (#2159)

* Start using spark4-preview versions

* Allow to download preview versions

* Expect warnings in spark

* Disable local_sparklyr test for now","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 51a43c5d..8da0848a 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,15 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-10-22
+
+Affected: `pyspark-notebook` and `all-spark-notebook` images users
+
+- **Breaking:** Start using Spark 4.0.0 preview versions ([#2159](https://github.com/jupyter/docker-stacks/pull/2159)).
+  `sparklyr` doesn't seem to support Spark v4 yet when using Spark locally.
+
+  Reason: Spark v3 is not compatible with Python 3.12, and [the voting group has decided](https://github.com/jupyter/docker-stacks/pull/2072#issuecomment-2414123851) to switch to Spark v4 preview version.
+
 ## 2024-10-09
 
 Affected: users building a custom set of images","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 51a43c5d..8da0848a 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,15 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-10-22
+
+Affected: `pyspark-notebook` and `all-spark-notebook` images users
+
+- **Breaking:** Start using Spark 4.0.0 preview versions ([#2159](https://github.com/jupyter/docker-stacks/pull/2159)).
+  `sparklyr` doesn't seem to support Spark v4 yet when using Spark locally.
+
+  Reason: Spark v3 is not compatible with Python 3.12, and [the voting group has decided](https://github.com/jupyter/docker-stacks/pull/2072#issuecomment-2414123851) to switch to Spark v4 preview version.
+
 ## 2024-10-09
 
 Affected: users building a custom set of images",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,b74418220768a48580795b8fe1b580a63956498a,2f1cf2a2efd86e1effcaf7e5d3c5fe0463f05784,"Start using spark4-preview versions (#2159)

* Start using spark4-preview versions

* Allow to download preview versions

* Expect warnings in spark

* Disable local_sparklyr test for now","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 71b1c81c..8585232c 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -63,7 +63,7 @@ USER ${NB_UID}
 RUN mamba install --yes \
     'grpcio-status' \
     'grpcio' \
-    'pandas=2.0.3' \
+    'pandas=2.2.2' \
     'pyarrow' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 71b1c81c..8585232c 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -63,7 +63,7 @@ USER ${NB_UID}
 RUN mamba install --yes \
     'grpcio-status' \
     'grpcio' \
-    'pandas=2.0.3' \
+    'pandas=2.2.2' \
     'pyarrow' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \",Yes
images/pyspark-notebook/setup_spark.py,images/pyspark-notebook/setup_spark.py,b74418220768a48580795b8fe1b580a63956498a,2f1cf2a2efd86e1effcaf7e5d3c5fe0463f05784,"Start using spark4-preview versions (#2159)

* Start using spark4-preview versions

* Allow to download preview versions

* Expect warnings in spark

* Disable local_sparklyr test for now","diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index 266f2f78..79e571af 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -36,7 +36,7 @@ def get_latest_spark_version() -> str:
     stable_versions = [
         ref.removeprefix(""spark-"").removesuffix(""/"")
         for ref in all_refs
-        if ref.startswith(""spark-"") and ""incubating"" not in ref and ""preview"" not in ref
+        if ref.startswith(""spark-"") and ""incubating"" not in ref
     ]
 
     # Compare versions semantically","diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index 266f2f78..79e571af 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -36,7 +36,7 @@ def get_latest_spark_version() -> str:
     stable_versions = [
         ref.removeprefix(""spark-"").removesuffix(""/"")
         for ref in all_refs
-        if ref.startswith(""spark-"") and ""incubating"" not in ref and ""preview"" not in ref
+        if ref.startswith(""spark-"") and ""incubating"" not in ref
     ]
 
     # Compare versions semantically",Yes
tests/all-spark-notebook/test_spark_notebooks.py,tests/all-spark-notebook/test_spark_notebooks.py,b74418220768a48580795b8fe1b580a63956498a,2f1cf2a2efd86e1effcaf7e5d3c5fe0463f05784,"Start using spark4-preview versions (#2159)

* Start using spark4-preview versions

* Allow to download preview versions

* Expect warnings in spark

* Disable local_sparklyr test for now","diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index 7e54e5b0..81b17284 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -14,7 +14,7 @@ THIS_DIR = Path(__file__).parent.resolve()
 @pytest.mark.flaky(retries=3, delay=1)
 @pytest.mark.parametrize(
     ""test_file"",
-    [""issue_1168"", ""local_pyspark"", ""local_sparklyr"", ""local_sparkR""],
+    [""issue_1168"", ""local_pyspark"", ""local_sparkR""],
 )
 def test_nbconvert(container: TrackedContainer, test_file: str) -> None:
     """"""Check if Spark notebooks can be executed""""""
@@ -31,10 +31,14 @@ def test_nbconvert(container: TrackedContainer, test_file: str) -> None:
     )
     logs = container.run_and_wait(
         timeout=60,
+        no_warnings=False,
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
         command=[""bash"", ""-c"", command],
     )
+    warnings = TrackedContainer.get_warnings(logs)
+    assert len(warnings) == 1
+    assert ""Using incubator modules: jdk.incubator.vector"" in warnings[0]
 
     expected_file = f""{output_dir}/{test_file}.md""
     assert expected_file in logs, f""Expected file {expected_file} not generated""","diff --git a/tests/all-spark-notebook/test_spark_notebooks.py b/tests/all-spark-notebook/test_spark_notebooks.py
index 7e54e5b0..81b17284 100644
--- a/tests/all-spark-notebook/test_spark_notebooks.py
+++ b/tests/all-spark-notebook/test_spark_notebooks.py
@@ -14,7 +14,7 @@ THIS_DIR = Path(__file__).parent.resolve()
 @pytest.mark.flaky(retries=3, delay=1)
 @pytest.mark.parametrize(
     ""test_file"",
-    [""issue_1168"", ""local_pyspark"", ""local_sparklyr"", ""local_sparkR""],
+    [""issue_1168"", ""local_pyspark"", ""local_sparkR""],
 )
 def test_nbconvert(container: TrackedContainer, test_file: str) -> None:
     """"""Check if Spark notebooks can be executed""""""
@@ -31,10 +31,14 @@ def test_nbconvert(container: TrackedContainer, test_file: str) -> None:
     )
     logs = container.run_and_wait(
         timeout=60,
+        no_warnings=False,
         volumes={str(host_data_dir): {""bind"": cont_data_dir, ""mode"": ""ro""}},
         tty=True,
         command=[""bash"", ""-c"", command],
     )
+    warnings = TrackedContainer.get_warnings(logs)
+    assert len(warnings) == 1
+    assert ""Using incubator modules: jdk.incubator.vector"" in warnings[0]
 
     expected_file = f""{output_dir}/{test_file}.md""
     assert expected_file in logs, f""Expected file {expected_file} not generated""",Yes
tests/pyspark-notebook/test_spark.py,tests/pyspark-notebook/test_spark.py,b74418220768a48580795b8fe1b580a63956498a,2f1cf2a2efd86e1effcaf7e5d3c5fe0463f05784,"Start using spark4-preview versions (#2159)

* Start using spark4-preview versions

* Allow to download preview versions

* Expect warnings in spark

* Disable local_sparklyr test for now","diff --git a/tests/pyspark-notebook/test_spark.py b/tests/pyspark-notebook/test_spark.py
index 211432f0..2ba32cc9 100644
--- a/tests/pyspark-notebook/test_spark.py
+++ b/tests/pyspark-notebook/test_spark.py
@@ -3,12 +3,20 @@
 import logging
 
 from tests.conftest import TrackedContainer
-from tests.run_command import run_command
 
 LOGGER = logging.getLogger(__name__)
 
 
 def test_spark_shell(container: TrackedContainer) -> None:
     """"""Checking if Spark (spark-shell) is running properly""""""
-    logs = run_command(container, 'spark-shell <<< ""1+1""', timeout=60)
+    logs = container.run_and_wait(
+        timeout=60,
+        no_warnings=False,
+        tty=True,
+        command=[""bash"", ""-c"", 'spark-shell <<< ""1+1""'],
+    )
+    warnings = TrackedContainer.get_warnings(logs)
+    assert len(warnings) == 1
+    assert ""Using incubator modules: jdk.incubator.vector"" in warnings[0]
+
     assert ""res0: Int = 2"" in logs, ""spark-shell does not work""","diff --git a/tests/pyspark-notebook/test_spark.py b/tests/pyspark-notebook/test_spark.py
index 211432f0..2ba32cc9 100644
--- a/tests/pyspark-notebook/test_spark.py
+++ b/tests/pyspark-notebook/test_spark.py
@@ -3,12 +3,20 @@
 import logging
 
 from tests.conftest import TrackedContainer
-from tests.run_command import run_command
 
 LOGGER = logging.getLogger(__name__)
 
 
 def test_spark_shell(container: TrackedContainer) -> None:
     """"""Checking if Spark (spark-shell) is running properly""""""
-    logs = run_command(container, 'spark-shell <<< ""1+1""', timeout=60)
+    logs = container.run_and_wait(
+        timeout=60,
+        no_warnings=False,
+        tty=True,
+        command=[""bash"", ""-c"", 'spark-shell <<< ""1+1""'],
+    )
+    warnings = TrackedContainer.get_warnings(logs)
+    assert len(warnings) == 1
+    assert ""Using incubator modules: jdk.incubator.vector"" in warnings[0]
+
     assert ""res0: Int = 2"" in logs, ""spark-shell does not work""",Yes
tests/pyspark-notebook/units/unit_pandas_version.py,tests/pyspark-notebook/units/unit_pandas_version.py,b74418220768a48580795b8fe1b580a63956498a,2f1cf2a2efd86e1effcaf7e5d3c5fe0463f05784,"Start using spark4-preview versions (#2159)

* Start using spark4-preview versions

* Allow to download preview versions

* Expect warnings in spark

* Disable local_sparklyr test for now","diff --git a/tests/pyspark-notebook/units/unit_pandas_version.py b/tests/pyspark-notebook/units/unit_pandas_version.py
index 03920db4..802a2192 100644
--- a/tests/pyspark-notebook/units/unit_pandas_version.py
+++ b/tests/pyspark-notebook/units/unit_pandas_version.py
@@ -2,4 +2,4 @@
 # Distributed under the terms of the Modified BSD License.
 import pandas
 
-assert pandas.__version__ == ""2.0.3""
+assert pandas.__version__ == ""2.2.2""","diff --git a/tests/pyspark-notebook/units/unit_pandas_version.py b/tests/pyspark-notebook/units/unit_pandas_version.py
index 03920db4..802a2192 100644
--- a/tests/pyspark-notebook/units/unit_pandas_version.py
+++ b/tests/pyspark-notebook/units/unit_pandas_version.py
@@ -2,4 +2,4 @@
 # Distributed under the terms of the Modified BSD License.
 import pandas
 
-assert pandas.__version__ == ""2.0.3""
+assert pandas.__version__ == ""2.2.2""",Yes
CHANGELOG.md,CHANGELOG.md,86198681a543d1171fb174e502639b52f09fc7bc,b74418220768a48580795b8fe1b580a63956498a,Unify CHANGELOG style,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 8da0848a..aff4dab3 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -5,7 +5,7 @@ All image manifests can be found in [the wiki](https://github.com/jupyter/docker
 
 ## 2024-10-22
 
-Affected: `pyspark-notebook` and `all-spark-notebook` images users
+Affected: `pyspark-notebook` and `all-spark-notebook` images.
 
 - **Breaking:** Start using Spark 4.0.0 preview versions ([#2159](https://github.com/jupyter/docker-stacks/pull/2159)).
   `sparklyr` doesn't seem to support Spark v4 yet when using Spark locally.
@@ -14,6 +14,6 @@ Affected: `pyspark-notebook` and `all-spark-notebook` images users
 
 ## 2024-10-09
 
-Affected: users building a custom set of images
+Affected: users building a custom set of images.
 
-- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))
+- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155)).","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 8da0848a..aff4dab3 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -5,7 +5,7 @@ All image manifests can be found in [the wiki](https://github.com/jupyter/docker
 
 ## 2024-10-22
 
-Affected: `pyspark-notebook` and `all-spark-notebook` images users
+Affected: `pyspark-notebook` and `all-spark-notebook` images.
 
 - **Breaking:** Start using Spark 4.0.0 preview versions ([#2159](https://github.com/jupyter/docker-stacks/pull/2159)).
   `sparklyr` doesn't seem to support Spark v4 yet when using Spark locally.
@@ -14,6 +14,6 @@ Affected: `pyspark-notebook` and `all-spark-notebook` images users
 
 ## 2024-10-09
 
-Affected: users building a custom set of images
+Affected: users building a custom set of images.
 
-- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155))
+- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155)).",Yes
docs/using/common.md,docs/using/common.md,2b40f486b6d3658158d63f4fa794c3ec9e54a088,86198681a543d1171fb174e502639b52f09fc7bc,Update output example in documents,"diff --git a/docs/using/common.md b/docs/using/common.md
index ee8e5878..64a48eac 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -213,14 +213,20 @@ docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
     quay.io/jupyter/base-notebook
-# Executing the command: jupyter notebook ...
+
+# Executing the command: start-notebook.py
+# Executing: jupyter notebook
+# ...
 
 # Use Jupyter NBClassic frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=nbclassic \
     quay.io/jupyter/base-notebook
-# Executing the command: jupyter nbclassic ...
+
+# Executing the command: start-notebook.py
+# Executing: jupyter nbclassic
+# ...
 ```
 
 ### `start.sh`","diff --git a/docs/using/common.md b/docs/using/common.md
index ee8e5878..64a48eac 100644
--- a/docs/using/common.md
+++ b/docs/using/common.md
@@ -213,14 +213,20 @@ docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=notebook \
     quay.io/jupyter/base-notebook
-# Executing the command: jupyter notebook ...
+
+# Executing the command: start-notebook.py
+# Executing: jupyter notebook
+# ...
 
 # Use Jupyter NBClassic frontend
 docker run -it --rm \
     -p 8888:8888 \
     -e DOCKER_STACKS_JUPYTER_CMD=nbclassic \
     quay.io/jupyter/base-notebook
-# Executing the command: jupyter nbclassic ...
+
+# Executing the command: start-notebook.py
+# Executing: jupyter nbclassic
+# ...
 ```
 
 ### `start.sh`",Yes
CHANGELOG.md,CHANGELOG.md,a096c2b102c89d4fd5956c9f2abbba92542fdeab,2b40f486b6d3658158d63f4fa794c3ec9e54a088,Upgrade to Python 3.12 (#2072),"diff --git a/CHANGELOG.md b/CHANGELOG.md
index aff4dab3..fcda303f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,12 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-10-23
+
+Affected: all images.
+
+- **Breaking:** Switch to Python 3.12 ([#2072](https://github.com/jupyter/docker-stacks/pull/2072)).
+
 ## 2024-10-22
 
 Affected: `pyspark-notebook` and `all-spark-notebook` images.","diff --git a/CHANGELOG.md b/CHANGELOG.md
index aff4dab3..fcda303f 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,12 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-10-23
+
+Affected: all images.
+
+- **Breaking:** Switch to Python 3.12 ([#2072](https://github.com/jupyter/docker-stacks/pull/2072)).
+
 ## 2024-10-22
 
 Affected: `pyspark-notebook` and `all-spark-notebook` images.",Yes
README.md,README.md,a096c2b102c89d4fd5956c9f2abbba92542fdeab,2b40f486b6d3658158d63f4fa794c3ec9e54a088,Upgrade to Python 3.12 (#2072),"diff --git a/README.md b/README.md
index 90e82cc8..426d7bad 100644
--- a/README.md
+++ b/README.md
@@ -120,7 +120,8 @@ If you want to use the older `Ubuntu` and/or `Python` version, you can use the f
 | 2022-10-09   | 22.04  | 3.9    | `ed2908bbb62e` |
 | 2023-05-30   | 22.04  | 3.10   | `4d70cf8da953` |
 | 2024-08-26   | 22.04  | 3.11   | `00987883e58d` |
-| weekly build | 24.04  | 3.11   | `latest`       |
+| 2024-10-22   | 24.04  | 3.11   | `b74418220768` |
+| weekly build | 24.04  | 3.12   | `latest`       |
 
 ## Contributing","diff --git a/README.md b/README.md
index 90e82cc8..426d7bad 100644
--- a/README.md
+++ b/README.md
@@ -120,7 +120,8 @@ If you want to use the older `Ubuntu` and/or `Python` version, you can use the f
 | 2022-10-09   | 22.04  | 3.9    | `ed2908bbb62e` |
 | 2023-05-30   | 22.04  | 3.10   | `4d70cf8da953` |
 | 2024-08-26   | 22.04  | 3.11   | `00987883e58d` |
-| weekly build | 24.04  | 3.11   | `latest`       |
+| 2024-10-22   | 24.04  | 3.11   | `b74418220768` |
+| weekly build | 24.04  | 3.12   | `latest`       |
 
 ## Contributing",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,a096c2b102c89d4fd5956c9f2abbba92542fdeab,2b40f486b6d3658158d63f4fa794c3ec9e54a088,Upgrade to Python 3.12 (#2072),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 284d43d4..8dab6930 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -89,7 +89,7 @@ RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
 USER ${NB_UID}
 
 # Pin the Python version here, or set it to ""default""
-ARG PYTHON_VERSION=3.11
+ARG PYTHON_VERSION=3.12
 
 # Setup work directory for backward-compatibility
 RUN mkdir ""/home/${NB_USER}/work"" && \","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 284d43d4..8dab6930 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -89,7 +89,7 @@ RUN echo ""auth requisite pam_deny.so"" >> /etc/pam.d/su && \
 USER ${NB_UID}
 
 # Pin the Python version here, or set it to ""default""
-ARG PYTHON_VERSION=3.11
+ARG PYTHON_VERSION=3.12
 
 # Setup work directory for backward-compatibility
 RUN mkdir ""/home/${NB_USER}/work"" && \",Yes
tests/docker-stacks-foundation/test_python_version.py,tests/docker-stacks-foundation/test_python_version.py,a096c2b102c89d4fd5956c9f2abbba92542fdeab,2b40f486b6d3658158d63f4fa794c3ec9e54a088,Upgrade to Python 3.12 (#2072),"diff --git a/tests/docker-stacks-foundation/test_python_version.py b/tests/docker-stacks-foundation/test_python_version.py
index 559853ab..bf81df83 100644
--- a/tests/docker-stacks-foundation/test_python_version.py
+++ b/tests/docker-stacks-foundation/test_python_version.py
@@ -5,7 +5,7 @@ import logging
 from tests.conftest import TrackedContainer
 
 LOGGER = logging.getLogger(__name__)
-EXPECTED_PYTHON_VERSION = ""3.11""
+EXPECTED_PYTHON_VERSION = ""3.12""
 
 
 def test_python_version(container: TrackedContainer) -> None:","diff --git a/tests/docker-stacks-foundation/test_python_version.py b/tests/docker-stacks-foundation/test_python_version.py
index 559853ab..bf81df83 100644
--- a/tests/docker-stacks-foundation/test_python_version.py
+++ b/tests/docker-stacks-foundation/test_python_version.py
@@ -5,7 +5,7 @@ import logging
 from tests.conftest import TrackedContainer
 
 LOGGER = logging.getLogger(__name__)
-EXPECTED_PYTHON_VERSION = ""3.11""
+EXPECTED_PYTHON_VERSION = ""3.12""
 
 
 def test_python_version(container: TrackedContainer) -> None:",Yes
.gitignore,.gitignore,c8f5fbd61f26193c01d749abb4cfdf45a6cfa76d,a096c2b102c89d4fd5956c9f2abbba92542fdeab,Update gitignore,"diff --git a/.gitignore b/.gitignore
index 14241e2c..b0f3c848 100644
--- a/.gitignore
+++ b/.gitignore
@@ -106,8 +106,10 @@ ipython_config.py
 #pdm.lock
 #   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
 #   in version control.
-#   https://pdm.fming.dev/#use-with-ide
+#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
 .pdm.toml
+.pdm-python
+.pdm-build/
 
 # PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
 __pypackages__/","diff --git a/.gitignore b/.gitignore
index 14241e2c..b0f3c848 100644
--- a/.gitignore
+++ b/.gitignore
@@ -106,8 +106,10 @@ ipython_config.py
 #pdm.lock
 #   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
 #   in version control.
-#   https://pdm.fming.dev/#use-with-ide
+#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
 .pdm.toml
+.pdm-python
+.pdm-build/
 
 # PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
 __pypackages__/",Yes
tests/tensorflow-notebook/units/unit_tensorflow.py,tests/tensorflow-notebook/units/unit_tensorflow.py,a1265be650bff7d1d38f0f2f68c10e32c369aedf,c8f5fbd61f26193c01d749abb4cfdf45a6cfa76d,Get rid of abseil warnings,"diff --git a/tests/tensorflow-notebook/units/unit_tensorflow.py b/tests/tensorflow-notebook/units/unit_tensorflow.py
index 96446a5d..9271a0e3 100644
--- a/tests/tensorflow-notebook/units/unit_tensorflow.py
+++ b/tests/tensorflow-notebook/units/unit_tensorflow.py
@@ -1,6 +1,13 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+import os
+
 import tensorflow as tf
 
+# Suppress logging warnings
+# https://stackoverflow.com/a/78803598
+os.environ[""GRPC_VERBOSITY""] = ""ERROR""
+os.environ[""GLOG_minloglevel""] = ""2""
+
 print(tf.constant(""Hello, TensorFlow""))
 print(tf.reduce_sum(tf.random.normal([1000, 1000])))","diff --git a/tests/tensorflow-notebook/units/unit_tensorflow.py b/tests/tensorflow-notebook/units/unit_tensorflow.py
index 96446a5d..9271a0e3 100644
--- a/tests/tensorflow-notebook/units/unit_tensorflow.py
+++ b/tests/tensorflow-notebook/units/unit_tensorflow.py
@@ -1,6 +1,13 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
+import os
+
 import tensorflow as tf
 
+# Suppress logging warnings
+# https://stackoverflow.com/a/78803598
+os.environ[""GRPC_VERBOSITY""] = ""ERROR""
+os.environ[""GLOG_minloglevel""] = ""2""
+
 print(tf.constant(""Hello, TensorFlow""))
 print(tf.reduce_sum(tf.random.normal([1000, 1000])))",Yes
images/tensorflow-notebook/cuda/Dockerfile,images/tensorflow-notebook/cuda/Dockerfile,f74a764584b6dfd9446a3b5b617f628ff869ecb5,a1265be650bff7d1d38f0f2f68c10e32c369aedf,Do not install tensorflow 2.18.0 as it gives an error,"diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index 5018dee4..6a0dbd03 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -14,7 +14,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # Install TensorFlow, CUDA and cuDNN with pip
 RUN pip install --no-cache-dir \
     ""jupyter-server-proxy"" \
-    ""tensorflow[and-cuda]"" && \
+    ""tensorflow[and-cuda]<=2.17.1"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/images/tensorflow-notebook/cuda/Dockerfile b/images/tensorflow-notebook/cuda/Dockerfile
index 5018dee4..6a0dbd03 100644
--- a/images/tensorflow-notebook/cuda/Dockerfile
+++ b/images/tensorflow-notebook/cuda/Dockerfile
@@ -14,7 +14,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 # Install TensorFlow, CUDA and cuDNN with pip
 RUN pip install --no-cache-dir \
     ""jupyter-server-proxy"" \
-    ""tensorflow[and-cuda]"" && \
+    ""tensorflow[and-cuda]<=2.17.1"" && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
tests/tensorflow-notebook/units/unit_tensorflow.py,tests/tensorflow-notebook/units/unit_tensorflow.py,f74a764584b6dfd9446a3b5b617f628ff869ecb5,a1265be650bff7d1d38f0f2f68c10e32c369aedf,Do not install tensorflow 2.18.0 as it gives an error,"diff --git a/tests/tensorflow-notebook/units/unit_tensorflow.py b/tests/tensorflow-notebook/units/unit_tensorflow.py
index 9271a0e3..96446a5d 100644
--- a/tests/tensorflow-notebook/units/unit_tensorflow.py
+++ b/tests/tensorflow-notebook/units/unit_tensorflow.py
@@ -1,13 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-import os
-
 import tensorflow as tf
 
-# Suppress logging warnings
-# https://stackoverflow.com/a/78803598
-os.environ[""GRPC_VERBOSITY""] = ""ERROR""
-os.environ[""GLOG_minloglevel""] = ""2""
-
 print(tf.constant(""Hello, TensorFlow""))
 print(tf.reduce_sum(tf.random.normal([1000, 1000])))","diff --git a/tests/tensorflow-notebook/units/unit_tensorflow.py b/tests/tensorflow-notebook/units/unit_tensorflow.py
index 9271a0e3..96446a5d 100644
--- a/tests/tensorflow-notebook/units/unit_tensorflow.py
+++ b/tests/tensorflow-notebook/units/unit_tensorflow.py
@@ -1,13 +1,6 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
-import os
-
 import tensorflow as tf
 
-# Suppress logging warnings
-# https://stackoverflow.com/a/78803598
-os.environ[""GRPC_VERBOSITY""] = ""ERROR""
-os.environ[""GLOG_minloglevel""] = ""2""
-
 print(tf.constant(""Hello, TensorFlow""))
 print(tf.reduce_sum(tf.random.normal([1000, 1000])))",Yes
docs/using/specifics.md,docs/using/specifics.md,03e5fe572de01f0e825312b8bc49146aec8cdf6c,f74a764584b6dfd9446a3b5b617f628ff869ecb5,Fix docs: we're not installing stable version of spark anymore (#2165),"diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 4df770f1..0ed2f55d 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -49,7 +49,8 @@ You can build a `pyspark-notebook` image with a different `Spark` version by ove
     - This version needs to match the version supported by the Spark distribution used above.
     - See [Spark Overview](https://spark.apache.org/docs/latest/#downloading) and [Ubuntu packages](https://packages.ubuntu.com/search?keywords=openjdk).
   - `spark_version` (optional): The Spark version to install, for example `3.5.0`.
-    If not specified (this is the default), latest stable Spark will be installed.
+    If not specified (this is the default), latest Spark will be installed.
+    Note: to support Python 3.12, we currently install Spark v4 preview versions: <https://github.com/jupyter/docker-stacks/pull/2072#issuecomment-2414123851>.
   - `hadoop_version`: The Hadoop version (`3` by default).
     Note, that _Spark < 3.3_ require to specify `major.minor` Hadoop version (i.e. `3.2`).
   - `scala_version` (optional): The Scala version, for example `2.13` (not specified by default).","diff --git a/docs/using/specifics.md b/docs/using/specifics.md
index 4df770f1..0ed2f55d 100644
--- a/docs/using/specifics.md
+++ b/docs/using/specifics.md
@@ -49,7 +49,8 @@ You can build a `pyspark-notebook` image with a different `Spark` version by ove
     - This version needs to match the version supported by the Spark distribution used above.
     - See [Spark Overview](https://spark.apache.org/docs/latest/#downloading) and [Ubuntu packages](https://packages.ubuntu.com/search?keywords=openjdk).
   - `spark_version` (optional): The Spark version to install, for example `3.5.0`.
-    If not specified (this is the default), latest stable Spark will be installed.
+    If not specified (this is the default), latest Spark will be installed.
+    Note: to support Python 3.12, we currently install Spark v4 preview versions: <https://github.com/jupyter/docker-stacks/pull/2072#issuecomment-2414123851>.
   - `hadoop_version`: The Hadoop version (`3` by default).
     Note, that _Spark < 3.3_ require to specify `major.minor` Hadoop version (i.e. `3.2`).
   - `scala_version` (optional): The Scala version, for example `2.13` (not specified by default).",Yes
images/pyspark-notebook/Dockerfile,images/pyspark-notebook/Dockerfile,03e5fe572de01f0e825312b8bc49146aec8cdf6c,f74a764584b6dfd9446a3b5b617f628ff869ecb5,Fix docs: we're not installing stable version of spark anymore (#2165),"diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 8585232c..be4bdfa4 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -24,7 +24,7 @@ RUN apt-get update --yes && \
     ca-certificates-java && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
-# If spark_version is not set, latest stable Spark will be installed
+# If spark_version is not set, latest Spark will be installed
 ARG spark_version
 ARG hadoop_version=""3""
 # If scala_version is not set, Spark without Scala will be installed","diff --git a/images/pyspark-notebook/Dockerfile b/images/pyspark-notebook/Dockerfile
index 8585232c..be4bdfa4 100644
--- a/images/pyspark-notebook/Dockerfile
+++ b/images/pyspark-notebook/Dockerfile
@@ -24,7 +24,7 @@ RUN apt-get update --yes && \
     ca-certificates-java && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
-# If spark_version is not set, latest stable Spark will be installed
+# If spark_version is not set, latest Spark will be installed
 ARG spark_version
 ARG hadoop_version=""3""
 # If scala_version is not set, Spark without Scala will be installed",Yes
images/pyspark-notebook/setup_spark.py,images/pyspark-notebook/setup_spark.py,03e5fe572de01f0e825312b8bc49146aec8cdf6c,f74a764584b6dfd9446a3b5b617f628ff869ecb5,Fix docs: we're not installing stable version of spark anymore (#2165),"diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index 79e571af..c5b76433 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -29,11 +29,11 @@ def get_all_refs(url: str) -> list[str]:
 
 def get_latest_spark_version() -> str:
     """"""
-    Returns the last stable version of Spark using spark archive
+    Returns the last version of Spark using spark archive
     """"""
     LOGGER.info(""Downloading Spark versions information"")
     all_refs = get_all_refs(""https://archive.apache.org/dist/spark/"")
-    stable_versions = [
+    versions = [
         ref.removeprefix(""spark-"").removesuffix(""/"")
         for ref in all_refs
         if ref.startswith(""spark-"") and ""incubating"" not in ref
@@ -49,7 +49,7 @@ def get_latest_spark_version() -> str:
         patch, _, preview = arr[2].partition(""-"")
         return (major, minor, int(patch), preview)
 
-    latest_version = max(stable_versions, key=lambda ver: version_array(ver))
+    latest_version = max(versions, key=lambda ver: version_array(ver))
     LOGGER.info(f""Latest version: {latest_version}"")
     return latest_version","diff --git a/images/pyspark-notebook/setup_spark.py b/images/pyspark-notebook/setup_spark.py
index 79e571af..c5b76433 100755
--- a/images/pyspark-notebook/setup_spark.py
+++ b/images/pyspark-notebook/setup_spark.py
@@ -29,11 +29,11 @@ def get_all_refs(url: str) -> list[str]:
 
 def get_latest_spark_version() -> str:
     """"""
-    Returns the last stable version of Spark using spark archive
+    Returns the last version of Spark using spark archive
     """"""
     LOGGER.info(""Downloading Spark versions information"")
     all_refs = get_all_refs(""https://archive.apache.org/dist/spark/"")
-    stable_versions = [
+    versions = [
         ref.removeprefix(""spark-"").removesuffix(""/"")
         for ref in all_refs
         if ref.startswith(""spark-"") and ""incubating"" not in ref
@@ -49,7 +49,7 @@ def get_latest_spark_version() -> str:
         patch, _, preview = arr[2].partition(""-"")
         return (major, minor, int(patch), preview)
 
-    latest_version = max(stable_versions, key=lambda ver: version_array(ver))
+    latest_version = max(versions, key=lambda ver: version_array(ver))
     LOGGER.info(f""Latest version: {latest_version}"")
     return latest_version",Yes
docs/maintaining/aarch64-runner.md,docs/maintaining/aarch64-runner.md,5841857378358c3a708cc4646045ee02c6da687e,03e5fe572de01f0e825312b8bc49146aec8cdf6c,Fix broken link,"diff --git a/docs/maintaining/aarch64-runner.md b/docs/maintaining/aarch64-runner.md
index 1f27d084..3850760d 100644
--- a/docs/maintaining/aarch64-runner.md
+++ b/docs/maintaining/aarch64-runner.md
@@ -7,7 +7,7 @@ Each runner is recommended to have at least _2 cores_ and _30 GB_ of disk space.
 Add a new runner:
 
 - To use [Oracle OCI](https://www.oracle.com/cloud-0/), create a compute instance `VM.Standard.A1.Flex`.
-- To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-arm-vm-instance#armpublicimage).
+- To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-start-instance).
 
 Configure your runner:","diff --git a/docs/maintaining/aarch64-runner.md b/docs/maintaining/aarch64-runner.md
index 1f27d084..3850760d 100644
--- a/docs/maintaining/aarch64-runner.md
+++ b/docs/maintaining/aarch64-runner.md
@@ -7,7 +7,7 @@ Each runner is recommended to have at least _2 cores_ and _30 GB_ of disk space.
 Add a new runner:
 
 - To use [Oracle OCI](https://www.oracle.com/cloud-0/), create a compute instance `VM.Standard.A1.Flex`.
-- To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-arm-vm-instance#armpublicimage).
+- To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-start-instance).
 
 Configure your runner:",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,c2d9d1f06a35d56ffe84d2360fb562b8b3bf5165,5841857378358c3a708cc4646045ee02c6da687e,"Pin min notebook version (#2167)

* [TMP] Pin min notebook version

* Update Dockerfile","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 0cde5b5d..dd068c80 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -42,7 +42,11 @@ RUN mamba install --yes \
     'jupyterhub' \
     'jupyterlab' \
     'nbclassic' \
-    'notebook' && \
+    # Sometimes, when the new version of `jupyterlab` is released, latest `notebook` might not support it for some time
+    # Old versions of `notebook` (<v7) didn't have a restriction on the `jupyterlab` version, and old `notebook` is getting installed
+    # That's why we have to pin the minimum notebook version
+    # More info: https://github.com/jupyter/docker-stacks/pull/2167
+    'notebook>=7.2.2' && \
     jupyter server --generate-config && \
     mamba clean --all -f -y && \
     npm cache clean --force && \","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 0cde5b5d..dd068c80 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -42,7 +42,11 @@ RUN mamba install --yes \
     'jupyterhub' \
     'jupyterlab' \
     'nbclassic' \
-    'notebook' && \
+    # Sometimes, when the new version of `jupyterlab` is released, latest `notebook` might not support it for some time
+    # Old versions of `notebook` (<v7) didn't have a restriction on the `jupyterlab` version, and old `notebook` is getting installed
+    # That's why we have to pin the minimum notebook version
+    # More info: https://github.com/jupyter/docker-stacks/pull/2167
+    'notebook>=7.2.2' && \
     jupyter server --generate-config && \
     mamba clean --all -f -y && \
     npm cache clean --force && \",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,c2d9d1f06a35d56ffe84d2360fb562b8b3bf5165,5841857378358c3a708cc4646045ee02c6da687e,"Pin min notebook version (#2167)

* [TMP] Pin min notebook version

* Update Dockerfile","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 9b70be38..0508ff14 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -76,6 +76,7 @@ EXCLUDED_PACKAGES = [
     ""hdf5"",
     ""jupyterlab-git"",
     ""mamba[version='<2.0.0']"",
+    ""notebook[version='>"",
     ""openssl"",
     ""pandas[version='>"",
     ""protobuf"",","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 9b70be38..0508ff14 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -76,6 +76,7 @@ EXCLUDED_PACKAGES = [
     ""hdf5"",
     ""jupyterlab-git"",
     ""mamba[version='<2.0.0']"",
+    ""notebook[version='>"",
     ""openssl"",
     ""pandas[version='>"",
     ""protobuf"",",Yes
images/pytorch-notebook/cuda12/Dockerfile,images/pytorch-notebook/cuda12/Dockerfile,2c525aff70edc2cff2dc8f664facceb6a48a6179,c2d9d1f06a35d56ffe84d2360fb562b8b3bf5165,Use pytorch with cuda12.4 (#2168),"diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index cdfd089a..983c439a 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -13,7 +13,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install PyTorch with pip (https://pytorch.org/get-started/locally/)
 # hadolint ignore=DL3013
-RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu121' \
+RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu124' \
     'torch' \
     'torchaudio' \
     'torchvision' && \","diff --git a/images/pytorch-notebook/cuda12/Dockerfile b/images/pytorch-notebook/cuda12/Dockerfile
index cdfd089a..983c439a 100644
--- a/images/pytorch-notebook/cuda12/Dockerfile
+++ b/images/pytorch-notebook/cuda12/Dockerfile
@@ -13,7 +13,7 @@ SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
 # Install PyTorch with pip (https://pytorch.org/get-started/locally/)
 # hadolint ignore=DL3013
-RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu121' \
+RUN pip install --no-cache-dir --extra-index-url=https://pypi.nvidia.com --index-url 'https://download.pytorch.org/whl/cu124' \
     'torch' \
     'torchaudio' \
     'torchvision' && \",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,62a85b43b6b372e17ee0558587eec629c195e77b,2c525aff70edc2cff2dc8f664facceb6a48a6179,Update pre-commit hooks,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 25658fa1..549c39b2 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.17.0
+    rev: v3.19.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.8.0
+    rev: 24.10.0
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.11.2
+    rev: v1.13.0
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -69,7 +69,7 @@ repos:
 
   # `pre-commit sample-config` default hooks
   - repo: https://github.com/pre-commit/pre-commit-hooks
-    rev: v4.6.0
+    rev: v5.0.0
     hooks:
       - id: check-added-large-files
       - id: end-of-file-fixer
@@ -78,7 +78,7 @@ repos:
 
   # Lint: Dockerfile
   - repo: https://github.com/hadolint/hadolint
-    rev: v2.13.0-beta
+    rev: v2.13.1-beta
     hooks:
       - id: hadolint-docker
         entry: hadolint/hadolint:v2.12.1-beta hadolint
@@ -86,7 +86,7 @@ repos:
   # Lint: Dockerfile
   # We're linting .dockerfile files as well
   - repo: https://github.com/hadolint/hadolint
-    rev: v2.13.0-beta
+    rev: v2.13.1-beta
     hooks:
       - id: hadolint-docker
         name: Lint *.dockerfile Dockerfiles
@@ -124,14 +124,14 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.41.0
+    rev: v0.42.0
     hooks:
       - id: markdownlint
         args: [""--fix""]
 
   # Strip output from Jupyter notebooks
   - repo: https://github.com/kynan/nbstripout
-    rev: 0.7.1
+    rev: 0.8.0
     hooks:
       - id: nbstripout
 
@@ -149,7 +149,7 @@ repos:
 
   # Run black on python code blocks in documentation files.
   - repo: https://github.com/adamchainz/blacken-docs
-    rev: 1.18.0
+    rev: 1.19.1
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 25658fa1..549c39b2 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.17.0
+    rev: v3.19.0
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -28,14 +28,14 @@ repos:
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.8.0
+    rev: 24.10.0
     hooks:
       - id: black
         args: [--target-version=py39]
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.11.2
+    rev: v1.13.0
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]
@@ -69,7 +69,7 @@ repos:
 
   # `pre-commit sample-config` default hooks
   - repo: https://github.com/pre-commit/pre-commit-hooks
-    rev: v4.6.0
+    rev: v5.0.0
     hooks:
       - id: check-added-large-files
       - id: end-of-file-fixer
@@ -78,7 +78,7 @@ repos:
 
   # Lint: Dockerfile
   - repo: https://github.com/hadolint/hadolint
-    rev: v2.13.0-beta
+    rev: v2.13.1-beta
     hooks:
       - id: hadolint-docker
         entry: hadolint/hadolint:v2.12.1-beta hadolint
@@ -86,7 +86,7 @@ repos:
   # Lint: Dockerfile
   # We're linting .dockerfile files as well
   - repo: https://github.com/hadolint/hadolint
-    rev: v2.13.0-beta
+    rev: v2.13.1-beta
     hooks:
       - id: hadolint-docker
         name: Lint *.dockerfile Dockerfiles
@@ -124,14 +124,14 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.41.0
+    rev: v0.42.0
     hooks:
       - id: markdownlint
         args: [""--fix""]
 
   # Strip output from Jupyter notebooks
   - repo: https://github.com/kynan/nbstripout
-    rev: 0.7.1
+    rev: 0.8.0
     hooks:
       - id: nbstripout
 
@@ -149,7 +149,7 @@ repos:
 
   # Run black on python code blocks in documentation files.
   - repo: https://github.com/adamchainz/blacken-docs
-    rev: 1.18.0
+    rev: 1.19.1
     hooks:
       - id: blacken-docs
         # --skip-errors is added to allow us to have python syntax highlighting even if",Yes
README.md,README.md,62a85b43b6b372e17ee0558587eec629c195e77b,2c525aff70edc2cff2dc8f664facceb6a48a6179,Update pre-commit hooks,"diff --git a/README.md b/README.md
index 426d7bad..1c998030 100644
--- a/README.md
+++ b/README.md
@@ -1,7 +1,6 @@
 # Jupyter Docker Stacks
 
-[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)
-](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain ""Docker images build status"")
+[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain ""Docker images build status"")
 [![Read the Docs badge](https://img.shields.io/readthedocs/jupyter-docker-stacks.svg)](https://jupyter-docker-stacks.readthedocs.io/en/latest/ ""Documentation build status"")
 [![pre-commit.ci status](https://results.pre-commit.ci/badge/github/jupyter/docker-stacks/main.svg)](https://results.pre-commit.ci/latest/github/jupyter/docker-stacks/main ""pre-commit.ci build status"")
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")","diff --git a/README.md b/README.md
index 426d7bad..1c998030 100644
--- a/README.md
+++ b/README.md
@@ -1,7 +1,6 @@
 # Jupyter Docker Stacks
 
-[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)
-](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain ""Docker images build status"")
+[![GitHub actions badge](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml/badge.svg)](https://github.com/jupyter/docker-stacks/actions/workflows/docker.yml?query=branch%3Amain ""Docker images build status"")
 [![Read the Docs badge](https://img.shields.io/readthedocs/jupyter-docker-stacks.svg)](https://jupyter-docker-stacks.readthedocs.io/en/latest/ ""Documentation build status"")
 [![pre-commit.ci status](https://results.pre-commit.ci/badge/github/jupyter/docker-stacks/main.svg)](https://results.pre-commit.ci/latest/github/jupyter/docker-stacks/main ""pre-commit.ci build status"")
 [![Discourse badge](https://img.shields.io/discourse/users.svg?color=%23f37626&server=https%3A%2F%2Fdiscourse.jupyter.org)](https://discourse.jupyter.org/ ""Jupyter Discourse Forum"")",Yes
docs/using/recipe_code/jupyterhub_version.dockerfile,docs/using/recipe_code/jupyterhub_version.dockerfile,28a0b25bcec1a6ee25421ddf8a3e2d156259a3ed,62a85b43b6b372e17ee0558587eec629c195e77b,"Install jupyterhub-base instead of jupyterhub (#2171)

* Install jupyterhub-base instead of jupyterhub

* Update images/base-notebook/Dockerfile

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
index 7fd53018..22c9dfa1 100644
--- a/docs/using/recipe_code/jupyterhub_version.dockerfile
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -1,6 +1,6 @@
 FROM quay.io/jupyter/base-notebook
 
-RUN mamba install --yes 'jupyterhub==4.0.1' && \
+RUN mamba install --yes 'jupyterhub-base==4.0.1' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
index 7fd53018..22c9dfa1 100644
--- a/docs/using/recipe_code/jupyterhub_version.dockerfile
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -1,6 +1,6 @@
 FROM quay.io/jupyter/base-notebook
 
-RUN mamba install --yes 'jupyterhub==4.0.1' && \
+RUN mamba install --yes 'jupyterhub-base==4.0.1' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,28a0b25bcec1a6ee25421ddf8a3e2d156259a3ed,62a85b43b6b372e17ee0558587eec629c195e77b,"Install jupyterhub-base instead of jupyterhub (#2171)

* Install jupyterhub-base instead of jupyterhub

* Update images/base-notebook/Dockerfile

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index dd068c80..261cf3e6 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -39,9 +39,15 @@ USER ${NB_UID}
 # files across image layers when the permissions change
 WORKDIR /tmp
 RUN mamba install --yes \
-    'jupyterhub' \
+    'jupyterhub-base' \
     'jupyterlab' \
     'nbclassic' \
+    # nodejs has historically been installed indirectly as a dependency.
+    # When it was no longer getting installed indirectly,
+    # we started installing it explicitly to avoid introducing a breaking change
+    # for users building on top of these images.
+    # See: https://github.com/jupyter/docker-stacks/pull/2171
+    'nodejs' \
     # Sometimes, when the new version of `jupyterlab` is released, latest `notebook` might not support it for some time
     # Old versions of `notebook` (<v7) didn't have a restriction on the `jupyterlab` version, and old `notebook` is getting installed
     # That's why we have to pin the minimum notebook version","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index dd068c80..261cf3e6 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -39,9 +39,15 @@ USER ${NB_UID}
 # files across image layers when the permissions change
 WORKDIR /tmp
 RUN mamba install --yes \
-    'jupyterhub' \
+    'jupyterhub-base' \
     'jupyterlab' \
     'nbclassic' \
+    # nodejs has historically been installed indirectly as a dependency.
+    # When it was no longer getting installed indirectly,
+    # we started installing it explicitly to avoid introducing a breaking change
+    # for users building on top of these images.
+    # See: https://github.com/jupyter/docker-stacks/pull/2171
+    'nodejs' \
     # Sometimes, when the new version of `jupyterlab` is released, latest `notebook` might not support it for some time
     # Old versions of `notebook` (<v7) didn't have a restriction on the `jupyterlab` version, and old `notebook` is getting installed
     # That's why we have to pin the minimum notebook version",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,28a0b25bcec1a6ee25421ddf8a3e2d156259a3ed,62a85b43b6b372e17ee0558587eec629c195e77b,"Install jupyterhub-base instead of jupyterhub (#2171)

* Install jupyterhub-base instead of jupyterhub

* Update images/base-notebook/Dockerfile

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 0508ff14..a87d51f0 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -74,8 +74,10 @@ EXCLUDED_PACKAGES = [
     ""grpcio-status"",
     ""grpcio"",
     ""hdf5"",
+    ""jupyterhub-base"",
     ""jupyterlab-git"",
     ""mamba[version='<2.0.0']"",
+    ""nodejs"",
     ""notebook[version='>"",
     ""openssl"",
     ""pandas[version='>"",","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 0508ff14..a87d51f0 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -74,8 +74,10 @@ EXCLUDED_PACKAGES = [
     ""grpcio-status"",
     ""grpcio"",
     ""hdf5"",
+    ""jupyterhub-base"",
     ""jupyterlab-git"",
     ""mamba[version='<2.0.0']"",
+    ""nodejs"",
     ""notebook[version='>"",
     ""openssl"",
     ""pandas[version='>"",",Yes
CHANGELOG.md,CHANGELOG.md,ea849fa18f4818364bfcee999555757a44dc0154,28a0b25bcec1a6ee25421ddf8a3e2d156259a3ed,Update description of jupyter/base-notebook regarding jupyterhub-base and update changelog,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index fcda303f..6ba70a95 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,12 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-11-06
+
+Affected: all images except `docker-stacks-foundation`.
+
+- **Non-breaking** Install `jupyterhub-base` and `nodejs` packages instead of `jupyterhub` package ([#2171](https://github.com/jupyter/docker-stacks/pull/2171)).
+
 ## 2024-10-23
 
 Affected: all images.","diff --git a/CHANGELOG.md b/CHANGELOG.md
index fcda303f..6ba70a95 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,12 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-11-06
+
+Affected: all images except `docker-stacks-foundation`.
+
+- **Non-breaking** Install `jupyterhub-base` and `nodejs` packages instead of `jupyterhub` package ([#2171](https://github.com/jupyter/docker-stacks/pull/2171)).
+
 ## 2024-10-23
 
 Affected: all images.",Yes
docs/using/selecting.md,docs/using/selecting.md,ea849fa18f4818364bfcee999555757a44dc0154,28a0b25bcec1a6ee25421ddf8a3e2d156259a3ed,Update description of jupyter/base-notebook regarding jupyterhub-base and update changelog,"diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 3ea4e85e..c21a1036 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -54,7 +54,9 @@ It contains:
 
 - Everything in `jupyter/docker-stacks-foundation`
 - Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
-- `notebook`, `jupyterhub`, and `jupyterlab` packages
+- `notebook`, `jupyterhub-base`, and `jupyterlab` packages
+  Note: we're also installing `nodejs` as it has historically been installed indirectly as a dependency of `jupyterhub` package, which was used before.
+  See more at: <https://github.com/jupyter/docker-stacks/pull/2171>
 - A `start-notebook.py` script as the default command
 - A `start-singleuser.py` script useful for launching containers in JupyterHub
 - Options for a self-signed HTTPS certificate","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index 3ea4e85e..c21a1036 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -54,7 +54,9 @@ It contains:
 
 - Everything in `jupyter/docker-stacks-foundation`
 - Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
-- `notebook`, `jupyterhub`, and `jupyterlab` packages
+- `notebook`, `jupyterhub-base`, and `jupyterlab` packages
+  Note: we're also installing `nodejs` as it has historically been installed indirectly as a dependency of `jupyterhub` package, which was used before.
+  See more at: <https://github.com/jupyter/docker-stacks/pull/2171>
 - A `start-notebook.py` script as the default command
 - A `start-singleuser.py` script useful for launching containers in JupyterHub
 - Options for a self-signed HTTPS certificate",Yes
docs/conf.py,docs/conf.py,2c7e64abbb088d89d7147a4b0724da70c531491a,ea849fa18f4818364bfcee999555757a44dc0154,Do not run linkcheck on https://anaconda.org/conda-forge because of frequent read timeouts,"diff --git a/docs/conf.py b/docs/conf.py
index 7957c246..5cf59db1 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -67,6 +67,7 @@ linkcheck_ignore = [
     r""http://127\.0\.0\.1:.*"",  # various examples
     r""https://mybinder\.org/v2/gh/.*"",  # lots of 500 errors
     r""https://packages\.ubuntu\.com/search\?keywords=openjdk"",  # frequent read timeouts
+    r""https://anaconda\.org\/conda-forge"",  # frequent read timeouts
 ]
 
 linkcheck_allowed_redirects = {","diff --git a/docs/conf.py b/docs/conf.py
index 7957c246..5cf59db1 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -67,6 +67,7 @@ linkcheck_ignore = [
     r""http://127\.0\.0\.1:.*"",  # various examples
     r""https://mybinder\.org/v2/gh/.*"",  # lots of 500 errors
     r""https://packages\.ubuntu\.com/search\?keywords=openjdk"",  # frequent read timeouts
+    r""https://anaconda\.org\/conda-forge"",  # frequent read timeouts
 ]
 
 linkcheck_allowed_redirects = {",Yes
CHANGELOG.md,CHANGELOG.md,caf725210c47709d832b0e1b65d929eb27badc96,2c7e64abbb088d89d7147a4b0724da70c531491a,"base-notebook: stop installing nodejs from conda-forge (#2172)

* base-notebook: stop installing nodejs from conda-forge

nodejs was a conda dependency of jupyterhub, but by installing
jupyterhub-base we no longer need it and could opt to remove it.

By doing this, building base-notebook led to a reported size reduction
from 974MB to 828MB, which is a 146MB / 15% size reduction.

* Update CHANGELOG.md

* Update CHANGELOG.md

* Install jupyterhub-singleuser instead of jupyterhub-base

Note that jupyterhub-base is really whats the foundational need for this
image, where jupyterhub-singleuser the conda-forge package is building on
jupyterhub-base by also adding a depdendency on jupyterlab - but the
jupyterhub-singleuser command is provided by jupyterhub-base conda-forge
package.

* Update CHANGELOG.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 6ba70a95..0c1a910b 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,14 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-11-08
+
+Affected: all images except `docker-stacks-foundation`.
+
+- **Breaking:** `base-notebook`: stop installing `nodejs` from `conda-forge` ([#2172](https://github.com/jupyter/docker-stacks/pull/2172)).
+
+  Reason: It isn't a direct dependency on anything in the images any more, and increased the image size with ~150MB.
+
 ## 2024-11-06
 
 Affected: all images except `docker-stacks-foundation`.","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 6ba70a95..0c1a910b 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,14 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-11-08
+
+Affected: all images except `docker-stacks-foundation`.
+
+- **Breaking:** `base-notebook`: stop installing `nodejs` from `conda-forge` ([#2172](https://github.com/jupyter/docker-stacks/pull/2172)).
+
+  Reason: It isn't a direct dependency on anything in the images any more, and increased the image size with ~150MB.
+
 ## 2024-11-06
 
 Affected: all images except `docker-stacks-foundation`.",Yes
docs/using/recipe_code/jupyterhub_version.dockerfile,docs/using/recipe_code/jupyterhub_version.dockerfile,caf725210c47709d832b0e1b65d929eb27badc96,2c7e64abbb088d89d7147a4b0724da70c531491a,"base-notebook: stop installing nodejs from conda-forge (#2172)

* base-notebook: stop installing nodejs from conda-forge

nodejs was a conda dependency of jupyterhub, but by installing
jupyterhub-base we no longer need it and could opt to remove it.

By doing this, building base-notebook led to a reported size reduction
from 974MB to 828MB, which is a 146MB / 15% size reduction.

* Update CHANGELOG.md

* Update CHANGELOG.md

* Install jupyterhub-singleuser instead of jupyterhub-base

Note that jupyterhub-base is really whats the foundational need for this
image, where jupyterhub-singleuser the conda-forge package is building on
jupyterhub-base by also adding a depdendency on jupyterlab - but the
jupyterhub-singleuser command is provided by jupyterhub-base conda-forge
package.

* Update CHANGELOG.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
index 22c9dfa1..bc6b2c11 100644
--- a/docs/using/recipe_code/jupyterhub_version.dockerfile
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -1,6 +1,6 @@
 FROM quay.io/jupyter/base-notebook
 
-RUN mamba install --yes 'jupyterhub-base==4.0.1' && \
+RUN mamba install --yes 'jupyterhub-singleuser==4.0.1' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""","diff --git a/docs/using/recipe_code/jupyterhub_version.dockerfile b/docs/using/recipe_code/jupyterhub_version.dockerfile
index 22c9dfa1..bc6b2c11 100644
--- a/docs/using/recipe_code/jupyterhub_version.dockerfile
+++ b/docs/using/recipe_code/jupyterhub_version.dockerfile
@@ -1,6 +1,6 @@
 FROM quay.io/jupyter/base-notebook
 
-RUN mamba install --yes 'jupyterhub-base==4.0.1' && \
+RUN mamba install --yes 'jupyterhub-singleuser==4.0.1' && \
     mamba clean --all -f -y && \
     fix-permissions ""${CONDA_DIR}"" && \
     fix-permissions ""/home/${NB_USER}""",Yes
docs/using/selecting.md,docs/using/selecting.md,caf725210c47709d832b0e1b65d929eb27badc96,2c7e64abbb088d89d7147a4b0724da70c531491a,"base-notebook: stop installing nodejs from conda-forge (#2172)

* base-notebook: stop installing nodejs from conda-forge

nodejs was a conda dependency of jupyterhub, but by installing
jupyterhub-base we no longer need it and could opt to remove it.

By doing this, building base-notebook led to a reported size reduction
from 974MB to 828MB, which is a 146MB / 15% size reduction.

* Update CHANGELOG.md

* Update CHANGELOG.md

* Install jupyterhub-singleuser instead of jupyterhub-base

Note that jupyterhub-base is really whats the foundational need for this
image, where jupyterhub-singleuser the conda-forge package is building on
jupyterhub-base by also adding a depdendency on jupyterlab - but the
jupyterhub-singleuser command is provided by jupyterhub-base conda-forge
package.

* Update CHANGELOG.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index c21a1036..d02e1624 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -54,9 +54,7 @@ It contains:
 
 - Everything in `jupyter/docker-stacks-foundation`
 - Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
-- `notebook`, `jupyterhub-base`, and `jupyterlab` packages
-  Note: we're also installing `nodejs` as it has historically been installed indirectly as a dependency of `jupyterhub` package, which was used before.
-  See more at: <https://github.com/jupyter/docker-stacks/pull/2171>
+- `notebook`, `jupyterhub-singleuser`, and `jupyterlab` packages
 - A `start-notebook.py` script as the default command
 - A `start-singleuser.py` script useful for launching containers in JupyterHub
 - Options for a self-signed HTTPS certificate","diff --git a/docs/using/selecting.md b/docs/using/selecting.md
index c21a1036..d02e1624 100644
--- a/docs/using/selecting.md
+++ b/docs/using/selecting.md
@@ -54,9 +54,7 @@ It contains:
 
 - Everything in `jupyter/docker-stacks-foundation`
 - Minimally functional Server (e.g., no LaTeX support for saving notebooks as PDFs)
-- `notebook`, `jupyterhub-base`, and `jupyterlab` packages
-  Note: we're also installing `nodejs` as it has historically been installed indirectly as a dependency of `jupyterhub` package, which was used before.
-  See more at: <https://github.com/jupyter/docker-stacks/pull/2171>
+- `notebook`, `jupyterhub-singleuser`, and `jupyterlab` packages
 - A `start-notebook.py` script as the default command
 - A `start-singleuser.py` script useful for launching containers in JupyterHub
 - Options for a self-signed HTTPS certificate",Yes
images/base-notebook/Dockerfile,images/base-notebook/Dockerfile,caf725210c47709d832b0e1b65d929eb27badc96,2c7e64abbb088d89d7147a4b0724da70c531491a,"base-notebook: stop installing nodejs from conda-forge (#2172)

* base-notebook: stop installing nodejs from conda-forge

nodejs was a conda dependency of jupyterhub, but by installing
jupyterhub-base we no longer need it and could opt to remove it.

By doing this, building base-notebook led to a reported size reduction
from 974MB to 828MB, which is a 146MB / 15% size reduction.

* Update CHANGELOG.md

* Update CHANGELOG.md

* Install jupyterhub-singleuser instead of jupyterhub-base

Note that jupyterhub-base is really whats the foundational need for this
image, where jupyterhub-singleuser the conda-forge package is building on
jupyterhub-base by also adding a depdendency on jupyterlab - but the
jupyterhub-singleuser command is provided by jupyterhub-base conda-forge
package.

* Update CHANGELOG.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 261cf3e6..84014f7c 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -39,15 +39,9 @@ USER ${NB_UID}
 # files across image layers when the permissions change
 WORKDIR /tmp
 RUN mamba install --yes \
-    'jupyterhub-base' \
+    'jupyterhub-singleuser' \
     'jupyterlab' \
     'nbclassic' \
-    # nodejs has historically been installed indirectly as a dependency.
-    # When it was no longer getting installed indirectly,
-    # we started installing it explicitly to avoid introducing a breaking change
-    # for users building on top of these images.
-    # See: https://github.com/jupyter/docker-stacks/pull/2171
-    'nodejs' \
     # Sometimes, when the new version of `jupyterlab` is released, latest `notebook` might not support it for some time
     # Old versions of `notebook` (<v7) didn't have a restriction on the `jupyterlab` version, and old `notebook` is getting installed
     # That's why we have to pin the minimum notebook version
@@ -55,7 +49,6 @@ RUN mamba install --yes \
     'notebook>=7.2.2' && \
     jupyter server --generate-config && \
     mamba clean --all -f -y && \
-    npm cache clean --force && \
     jupyter lab clean && \
     rm -rf ""/home/${NB_USER}/.cache/yarn"" && \
     fix-permissions ""${CONDA_DIR}"" && \","diff --git a/images/base-notebook/Dockerfile b/images/base-notebook/Dockerfile
index 261cf3e6..84014f7c 100644
--- a/images/base-notebook/Dockerfile
+++ b/images/base-notebook/Dockerfile
@@ -39,15 +39,9 @@ USER ${NB_UID}
 # files across image layers when the permissions change
 WORKDIR /tmp
 RUN mamba install --yes \
-    'jupyterhub-base' \
+    'jupyterhub-singleuser' \
     'jupyterlab' \
     'nbclassic' \
-    # nodejs has historically been installed indirectly as a dependency.
-    # When it was no longer getting installed indirectly,
-    # we started installing it explicitly to avoid introducing a breaking change
-    # for users building on top of these images.
-    # See: https://github.com/jupyter/docker-stacks/pull/2171
-    'nodejs' \
     # Sometimes, when the new version of `jupyterlab` is released, latest `notebook` might not support it for some time
     # Old versions of `notebook` (<v7) didn't have a restriction on the `jupyterlab` version, and old `notebook` is getting installed
     # That's why we have to pin the minimum notebook version
@@ -55,7 +49,6 @@ RUN mamba install --yes \
     'notebook>=7.2.2' && \
     jupyter server --generate-config && \
     mamba clean --all -f -y && \
-    npm cache clean --force && \
     jupyter lab clean && \
     rm -rf ""/home/${NB_USER}/.cache/yarn"" && \
     fix-permissions ""${CONDA_DIR}"" && \",Yes
tests/base-notebook/test_npm_package_manager.py,tests/base-notebook/test_npm_package_manager.py,caf725210c47709d832b0e1b65d929eb27badc96,2c7e64abbb088d89d7147a4b0724da70c531491a,"base-notebook: stop installing nodejs from conda-forge (#2172)

* base-notebook: stop installing nodejs from conda-forge

nodejs was a conda dependency of jupyterhub, but by installing
jupyterhub-base we no longer need it and could opt to remove it.

By doing this, building base-notebook led to a reported size reduction
from 974MB to 828MB, which is a 146MB / 15% size reduction.

* Update CHANGELOG.md

* Update CHANGELOG.md

* Install jupyterhub-singleuser instead of jupyterhub-base

Note that jupyterhub-base is really whats the foundational need for this
image, where jupyterhub-singleuser the conda-forge package is building on
jupyterhub-base by also adding a depdendency on jupyterlab - but the
jupyterhub-singleuser command is provided by jupyterhub-base conda-forge
package.

* Update CHANGELOG.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/base-notebook/test_npm_package_manager.py b/tests/base-notebook/test_npm_package_manager.py
deleted file mode 100644
index 14f50957..00000000
--- a/tests/base-notebook/test_npm_package_manager.py
+++ /dev/null
@@ -1,9 +0,0 @@
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
-from tests.conftest import TrackedContainer
-from tests.run_command import run_command
-
-
-def test_npm_package_manager(container: TrackedContainer) -> None:
-    """"""Test that npm is installed and runs.""""""
-    run_command(container, ""npm --version"")","diff --git a/tests/base-notebook/test_npm_package_manager.py b/tests/base-notebook/test_npm_package_manager.py
deleted file mode 100644
index 14f50957..00000000
--- a/tests/base-notebook/test_npm_package_manager.py
+++ /dev/null
@@ -1,9 +0,0 @@
-# Copyright (c) Jupyter Development Team.
-# Distributed under the terms of the Modified BSD License.
-from tests.conftest import TrackedContainer
-from tests.run_command import run_command
-
-
-def test_npm_package_manager(container: TrackedContainer) -> None:
-    """"""Test that npm is installed and runs.""""""
-    run_command(container, ""npm --version"")",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,caf725210c47709d832b0e1b65d929eb27badc96,2c7e64abbb088d89d7147a4b0724da70c531491a,"base-notebook: stop installing nodejs from conda-forge (#2172)

* base-notebook: stop installing nodejs from conda-forge

nodejs was a conda dependency of jupyterhub, but by installing
jupyterhub-base we no longer need it and could opt to remove it.

By doing this, building base-notebook led to a reported size reduction
from 974MB to 828MB, which is a 146MB / 15% size reduction.

* Update CHANGELOG.md

* Update CHANGELOG.md

* Install jupyterhub-singleuser instead of jupyterhub-base

Note that jupyterhub-base is really whats the foundational need for this
image, where jupyterhub-singleuser the conda-forge package is building on
jupyterhub-base by also adding a depdendency on jupyterlab - but the
jupyterhub-singleuser command is provided by jupyterhub-base conda-forge
package.

* Update CHANGELOG.md

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>

---------

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index a87d51f0..87c3f4bc 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -74,10 +74,9 @@ EXCLUDED_PACKAGES = [
     ""grpcio-status"",
     ""grpcio"",
     ""hdf5"",
-    ""jupyterhub-base"",
+    ""jupyterhub-singleuser"",
     ""jupyterlab-git"",
     ""mamba[version='<2.0.0']"",
-    ""nodejs"",
     ""notebook[version='>"",
     ""openssl"",
     ""pandas[version='>"",","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index a87d51f0..87c3f4bc 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -74,10 +74,9 @@ EXCLUDED_PACKAGES = [
     ""grpcio-status"",
     ""grpcio"",
     ""hdf5"",
-    ""jupyterhub-base"",
+    ""jupyterhub-singleuser"",
     ""jupyterlab-git"",
     ""mamba[version='<2.0.0']"",
-    ""nodejs"",
     ""notebook[version='>"",
     ""openssl"",
     ""pandas[version='>"",",Yes
CHANGELOG.md,CHANGELOG.md,55942dfe466d65acaa3e63b72eb8a98839af8dfc,caf725210c47709d832b0e1b65d929eb27badc96,Unify changelog codestyle,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 0c1a910b..fb4ab733 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -15,19 +15,19 @@ Affected: all images except `docker-stacks-foundation`.
 
 Affected: all images except `docker-stacks-foundation`.
 
-- **Non-breaking** Install `jupyterhub-base` and `nodejs` packages instead of `jupyterhub` package ([#2171](https://github.com/jupyter/docker-stacks/pull/2171)).
+- **Non-breaking:** `base-notebook`: install `jupyterhub-base` and `nodejs` packages instead of `jupyterhub` package ([#2171](https://github.com/jupyter/docker-stacks/pull/2171)).
 
 ## 2024-10-23
 
 Affected: all images.
 
-- **Breaking:** Switch to Python 3.12 ([#2072](https://github.com/jupyter/docker-stacks/pull/2072)).
+- **Breaking:** `docker-stacks-foundation`: switch to Python 3.12 ([#2072](https://github.com/jupyter/docker-stacks/pull/2072)).
 
 ## 2024-10-22
 
 Affected: `pyspark-notebook` and `all-spark-notebook` images.
 
-- **Breaking:** Start using Spark 4.0.0 preview versions ([#2159](https://github.com/jupyter/docker-stacks/pull/2159)).
+- **Breaking:** `pyspark-notebook`: start using Spark 4.0.0 preview versions ([#2159](https://github.com/jupyter/docker-stacks/pull/2159)).
   `sparklyr` doesn't seem to support Spark v4 yet when using Spark locally.
 
   Reason: Spark v3 is not compatible with Python 3.12, and [the voting group has decided](https://github.com/jupyter/docker-stacks/pull/2072#issuecomment-2414123851) to switch to Spark v4 preview version.
@@ -36,4 +36,4 @@ Affected: `pyspark-notebook` and `all-spark-notebook` images.
 
 Affected: users building a custom set of images.
 
-- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155)).
+- **Breaking:** rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155)).","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 0c1a910b..fb4ab733 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -15,19 +15,19 @@ Affected: all images except `docker-stacks-foundation`.
 
 Affected: all images except `docker-stacks-foundation`.
 
-- **Non-breaking** Install `jupyterhub-base` and `nodejs` packages instead of `jupyterhub` package ([#2171](https://github.com/jupyter/docker-stacks/pull/2171)).
+- **Non-breaking:** `base-notebook`: install `jupyterhub-base` and `nodejs` packages instead of `jupyterhub` package ([#2171](https://github.com/jupyter/docker-stacks/pull/2171)).
 
 ## 2024-10-23
 
 Affected: all images.
 
-- **Breaking:** Switch to Python 3.12 ([#2072](https://github.com/jupyter/docker-stacks/pull/2072)).
+- **Breaking:** `docker-stacks-foundation`: switch to Python 3.12 ([#2072](https://github.com/jupyter/docker-stacks/pull/2072)).
 
 ## 2024-10-22
 
 Affected: `pyspark-notebook` and `all-spark-notebook` images.
 
-- **Breaking:** Start using Spark 4.0.0 preview versions ([#2159](https://github.com/jupyter/docker-stacks/pull/2159)).
+- **Breaking:** `pyspark-notebook`: start using Spark 4.0.0 preview versions ([#2159](https://github.com/jupyter/docker-stacks/pull/2159)).
   `sparklyr` doesn't seem to support Spark v4 yet when using Spark locally.
 
   Reason: Spark v3 is not compatible with Python 3.12, and [the voting group has decided](https://github.com/jupyter/docker-stacks/pull/2072#issuecomment-2414123851) to switch to Spark v4 preview version.
@@ -36,4 +36,4 @@ Affected: `pyspark-notebook` and `all-spark-notebook` images.
 
 Affected: users building a custom set of images.
 
-- **Breaking:** Rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155)).
+- **Breaking:** rename: `ROOT_CONTAINER`->`ROOT_IMAGE`, `BASE_CONTAINER`->`BASE_IMAGE` ([#2154](https://github.com/jupyter/docker-stacks/issues/2154), [#2155](https://github.com/jupyter/docker-stacks/pull/2155)).",Yes
README.md,README.md,918997f70999866517a0bb6dc6789f7eabf6a848,55942dfe466d65acaa3e63b72eb8a98839af8dfc,Update tag example,"diff --git a/README.md b/README.md
index 1c998030..ecb0a881 100644
--- a/README.md
+++ b/README.md
@@ -29,11 +29,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-10-07
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-11-19
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -48,11 +48,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-10-07
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-11-19
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index 1c998030..ecb0a881 100644
--- a/README.md
+++ b/README.md
@@ -29,11 +29,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-10-07
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-11-19
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -48,11 +48,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-10-07
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-11-19
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,918997f70999866517a0bb6dc6789f7eabf6a848,55942dfe466d65acaa3e63b72eb8a98839af8dfc,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 28ccdd9e..97aab3e3 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-10-07
+ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-11-19
 FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-10-07""
+ENV TAG=""2024-11-19""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 28ccdd9e..97aab3e3 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-10-07
+ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-11-19
 FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-10-07""
+ENV TAG=""2024-11-19""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,918997f70999866517a0bb6dc6789f7eabf6a848,55942dfe466d65acaa3e63b72eb8a98839af8dfc,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index 4c2290ab..c51c46a5 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-10-07
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-11-19
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-10-07   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-11-19   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-10-07
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-11-19
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-10-07
+    quay.io/jupyter/r-notebook:2024-11-19
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index 4c2290ab..c51c46a5 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-10-07
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-11-19
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-10-07   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-11-19   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-10-07
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-11-19
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-10-07` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-10-07
+    quay.io/jupyter/r-notebook:2024-11-19
 ```
 
 ```{warning}",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,ac8453913cafb6e4f23b9f2288c484620f97e999,918997f70999866517a0bb6dc6789f7eabf6a848,Use mamba env export with `--json` (#2162),"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 549c39b2..d834f013 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -47,7 +47,6 @@ repos:
             ""requests"",
             ""urllib3"",
             ""types-beautifulsoup4"",
-            ""types-PyYAML"",
             ""types-requests"",
             ""types-tabulate"",
             ""types-urllib3"",","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 549c39b2..d834f013 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -47,7 +47,6 @@ repos:
             ""requests"",
             ""urllib3"",
             ""types-beautifulsoup4"",
-            ""types-PyYAML"",
             ""types-requests"",
             ""types-tabulate"",
             ""types-urllib3"",",Yes
requirements-dev.txt,requirements-dev.txt,ac8453913cafb6e4f23b9f2288c484620f97e999,918997f70999866517a0bb6dc6789f7eabf6a848,Use mamba env export with `--json` (#2162),"diff --git a/requirements-dev.txt b/requirements-dev.txt
index 9caa0df3..3ab2be95 100644
--- a/requirements-dev.txt
+++ b/requirements-dev.txt
@@ -6,6 +6,5 @@ pytest-retry
 # `pytest-xdist` is a plugin that provides the `--numprocesses` flag,
 # allowing us to run `pytest` tests in parallel
 pytest-xdist
-PyYAML
 requests
 tabulate","diff --git a/requirements-dev.txt b/requirements-dev.txt
index 9caa0df3..3ab2be95 100644
--- a/requirements-dev.txt
+++ b/requirements-dev.txt
@@ -6,6 +6,5 @@ pytest-retry
 # `pytest-xdist` is a plugin that provides the `--numprocesses` flag,
 # allowing us to run `pytest` tests in parallel
 pytest-xdist
-PyYAML
 requests
 tabulate",Yes
tests/package_helper.py,tests/package_helper.py,ac8453913cafb6e4f23b9f2288c484620f97e999,918997f70999866517a0bb6dc6789f7eabf6a848,Use mamba env export with `--json` (#2162),"diff --git a/tests/package_helper.py b/tests/package_helper.py
index 5f2f636c..0c4f3ec3 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -22,13 +22,13 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
+import json
 import logging
 import re
 from collections import defaultdict
 from itertools import chain
 from typing import Any, Optional
 
-import yaml
 from docker.models.containers import Container
 from tabulate import tabulate
 
@@ -61,7 +61,7 @@ class CondaPackageHelper:
     @staticmethod
     def _conda_export_command(from_history: bool) -> list[str]:
         """"""Return the mamba export command with or without history""""""
-        cmd = [""mamba"", ""env"", ""export"", ""--no-build""]
+        cmd = [""mamba"", ""env"", ""export"", ""--no-build"", ""--json""]
         if from_history:
             cmd.append(""--from-history"")
         return cmd
@@ -96,7 +96,7 @@ class CondaPackageHelper:
     @staticmethod
     def _parse_package_versions(env_export: str) -> dict[str, set[str]]:
         """"""Extract packages and versions from the lines returned by the list of specifications""""""
-        dependencies = yaml.safe_load(env_export).get(""dependencies"")
+        dependencies = json.loads(env_export).get(""dependencies"")
         # Filtering packages installed through pip
         # since we only manage packages installed through mamba here
         # They are represented by a dict with a key 'pip'","diff --git a/tests/package_helper.py b/tests/package_helper.py
index 5f2f636c..0c4f3ec3 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -22,13 +22,13 @@
 # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 # SOFTWARE.
 
+import json
 import logging
 import re
 from collections import defaultdict
 from itertools import chain
 from typing import Any, Optional
 
-import yaml
 from docker.models.containers import Container
 from tabulate import tabulate
 
@@ -61,7 +61,7 @@ class CondaPackageHelper:
     @staticmethod
     def _conda_export_command(from_history: bool) -> list[str]:
         """"""Return the mamba export command with or without history""""""
-        cmd = [""mamba"", ""env"", ""export"", ""--no-build""]
+        cmd = [""mamba"", ""env"", ""export"", ""--no-build"", ""--json""]
         if from_history:
             cmd.append(""--from-history"")
         return cmd
@@ -96,7 +96,7 @@ class CondaPackageHelper:
     @staticmethod
     def _parse_package_versions(env_export: str) -> dict[str, set[str]]:
         """"""Extract packages and versions from the lines returned by the list of specifications""""""
-        dependencies = yaml.safe_load(env_export).get(""dependencies"")
+        dependencies = json.loads(env_export).get(""dependencies"")
         # Filtering packages installed through pip
         # since we only manage packages installed through mamba here
         # They are represented by a dict with a key 'pip'",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,7060f20fb5fbb94672191be0802f146f460895fb,ac8453913cafb6e4f23b9f2288c484620f97e999,Remove pandas from EXCLUDED_PACKAGES (#2176),"diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 87c3f4bc..a1f5a8f9 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -79,7 +79,6 @@ EXCLUDED_PACKAGES = [
     ""mamba[version='<2.0.0']"",
     ""notebook[version='>"",
     ""openssl"",
-    ""pandas[version='>"",
     ""protobuf"",
     ""python"",
     ""r-irkernel"",","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index 87c3f4bc..a1f5a8f9 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -79,7 +79,6 @@ EXCLUDED_PACKAGES = [
     ""mamba[version='<2.0.0']"",
     ""notebook[version='>"",
     ""openssl"",
-    ""pandas[version='>"",
     ""protobuf"",
     ""python"",
     ""r-irkernel"",",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,d056af4d0ca8cb063557b4176bde434fb620056c,7060f20fb5fbb94672191be0802f146f460895fb,[pre-commit.ci] pre-commit autoupdate (#2177),"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index d834f013..23518465 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -123,21 +123,21 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.42.0
+    rev: v0.43.0
     hooks:
       - id: markdownlint
         args: [""--fix""]
 
   # Strip output from Jupyter notebooks
   - repo: https://github.com/kynan/nbstripout
-    rev: 0.8.0
+    rev: 0.8.1
     hooks:
       - id: nbstripout
 
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.8.7
+    rev: 1.9.1
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index d834f013..23518465 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -123,21 +123,21 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.42.0
+    rev: v0.43.0
     hooks:
       - id: markdownlint
         args: [""--fix""]
 
   # Strip output from Jupyter notebooks
   - repo: https://github.com/kynan/nbstripout
-    rev: 0.8.0
+    rev: 0.8.1
     hooks:
       - id: nbstripout
 
   # nbQA provides tools from the Python ecosystem like
   # pyupgrade, isort, black, and flake8, adjusted for notebooks.
   - repo: https://github.com/nbQA-dev/nbQA
-    rev: 1.8.7
+    rev: 1.9.1
     hooks:
       - id: nbqa-pyupgrade
         args: [--py39-plus]",Yes
CHANGELOG.md,CHANGELOG.md,143db355da44764cf86786f34bc6518304f124a9,d056af4d0ca8cb063557b4176bde434fb620056c,Install mamba 2.0 (#2147),"diff --git a/CHANGELOG.md b/CHANGELOG.md
index fb4ab733..61835db2 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,13 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-12-03
+
+Affected: all images.
+
+- **Breaking:** Switch to `mamba` v2 ([#2147](https://github.com/jupyter/docker-stacks/pull/2147)).
+  More information about changes made: <https://mamba.readthedocs.io/en/latest/developer_zone/changes-2.0.html>.
+
 ## 2024-11-08
 
 Affected: all images except `docker-stacks-foundation`.","diff --git a/CHANGELOG.md b/CHANGELOG.md
index fb4ab733..61835db2 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -3,6 +3,13 @@
 This changelog only contains breaking and/or significant changes manually introduced to this repository (using Pull Requests).
 All image manifests can be found in [the wiki](https://github.com/jupyter/docker-stacks/wiki).
 
+## 2024-12-03
+
+Affected: all images.
+
+- **Breaking:** Switch to `mamba` v2 ([#2147](https://github.com/jupyter/docker-stacks/pull/2147)).
+  More information about changes made: <https://mamba.readthedocs.io/en/latest/developer_zone/changes-2.0.html>.
+
 ## 2024-11-08
 
 Affected: all images except `docker-stacks-foundation`.",Yes
images/docker-stacks-foundation/Dockerfile,images/docker-stacks-foundation/Dockerfile,143db355da44764cf86786f34bc6518304f124a9,d056af4d0ca8cb063557b4176bde434fb620056c,Install mamba 2.0 (#2147),"diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 8dab6930..270957d6 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -124,9 +124,8 @@ RUN set -x && \
         --prefix=""${CONDA_DIR}"" \
         --yes \
         'jupyter_core' \
-        # excluding mamba 2.X due to several breaking changes
-        # https://github.com/jupyter/docker-stacks/pull/2147
-        'mamba<2.0.0' \
+        'conda' \
+        'mamba' \
         ""${PYTHON_SPECIFIER}"" && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python","diff --git a/images/docker-stacks-foundation/Dockerfile b/images/docker-stacks-foundation/Dockerfile
index 8dab6930..270957d6 100644
--- a/images/docker-stacks-foundation/Dockerfile
+++ b/images/docker-stacks-foundation/Dockerfile
@@ -124,9 +124,8 @@ RUN set -x && \
         --prefix=""${CONDA_DIR}"" \
         --yes \
         'jupyter_core' \
-        # excluding mamba 2.X due to several breaking changes
-        # https://github.com/jupyter/docker-stacks/pull/2147
-        'mamba<2.0.0' \
+        'conda' \
+        'mamba' \
         ""${PYTHON_SPECIFIER}"" && \
     rm -rf /tmp/bin/ && \
     # Pin major.minor version of python",Yes
tests/docker-stacks-foundation/test_packages.py,tests/docker-stacks-foundation/test_packages.py,143db355da44764cf86786f34bc6518304f124a9,d056af4d0ca8cb063557b4176bde434fb620056c,Install mamba 2.0 (#2147),"diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index a1f5a8f9..b6b8e632 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -70,14 +70,14 @@ PACKAGE_MAPPING = {
 EXCLUDED_PACKAGES = [
     ""bzip2"",
     ""ca-certificates"",
-    ""conda-forge::blas[build=openblas]"",
+    ""conda-forge::blas=*"",
     ""grpcio-status"",
     ""grpcio"",
     ""hdf5"",
     ""jupyterhub-singleuser"",
     ""jupyterlab-git"",
-    ""mamba[version='<2.0.0']"",
-    ""notebook[version='>"",
+    ""mamba"",
+    ""notebook>"",
     ""openssl"",
     ""protobuf"",
     ""python"",","diff --git a/tests/docker-stacks-foundation/test_packages.py b/tests/docker-stacks-foundation/test_packages.py
index a1f5a8f9..b6b8e632 100644
--- a/tests/docker-stacks-foundation/test_packages.py
+++ b/tests/docker-stacks-foundation/test_packages.py
@@ -70,14 +70,14 @@ PACKAGE_MAPPING = {
 EXCLUDED_PACKAGES = [
     ""bzip2"",
     ""ca-certificates"",
-    ""conda-forge::blas[build=openblas]"",
+    ""conda-forge::blas=*"",
     ""grpcio-status"",
     ""grpcio"",
     ""hdf5"",
     ""jupyterhub-singleuser"",
     ""jupyterlab-git"",
-    ""mamba[version='<2.0.0']"",
-    ""notebook[version='>"",
+    ""mamba"",
+    ""notebook>"",
     ""openssl"",
     ""protobuf"",
     ""python"",",Yes
CHANGELOG.md,CHANGELOG.md,f632f54034c9c8d9ba756c47b92edaa67b49a03c,143db355da44764cf86786f34bc6518304f124a9,Minor changelog adjustments,"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 61835db2..a8d055f7 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,7 +7,7 @@ All image manifests can be found in [the wiki](https://github.com/jupyter/docker
 
 Affected: all images.
 
-- **Breaking:** Switch to `mamba` v2 ([#2147](https://github.com/jupyter/docker-stacks/pull/2147)).
+- **Breaking:** `docker-stacks-foundation`: switch to `mamba` v2 ([#2147](https://github.com/jupyter/docker-stacks/pull/2147)).
   More information about changes made: <https://mamba.readthedocs.io/en/latest/developer_zone/changes-2.0.html>.
 
 ## 2024-11-08
@@ -16,7 +16,7 @@ Affected: all images except `docker-stacks-foundation`.
 
 - **Breaking:** `base-notebook`: stop installing `nodejs` from `conda-forge` ([#2172](https://github.com/jupyter/docker-stacks/pull/2172)).
 
-  Reason: It isn't a direct dependency on anything in the images any more, and increased the image size with ~150MB.
+  Reason: It isn't a direct dependency on anything in the images anymore, and increased the image size by ~150MB.
 
 ## 2024-11-06","diff --git a/CHANGELOG.md b/CHANGELOG.md
index 61835db2..a8d055f7 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -7,7 +7,7 @@ All image manifests can be found in [the wiki](https://github.com/jupyter/docker
 
 Affected: all images.
 
-- **Breaking:** Switch to `mamba` v2 ([#2147](https://github.com/jupyter/docker-stacks/pull/2147)).
+- **Breaking:** `docker-stacks-foundation`: switch to `mamba` v2 ([#2147](https://github.com/jupyter/docker-stacks/pull/2147)).
   More information about changes made: <https://mamba.readthedocs.io/en/latest/developer_zone/changes-2.0.html>.
 
 ## 2024-11-08
@@ -16,7 +16,7 @@ Affected: all images except `docker-stacks-foundation`.
 
 - **Breaking:** `base-notebook`: stop installing `nodejs` from `conda-forge` ([#2172](https://github.com/jupyter/docker-stacks/pull/2172)).
 
-  Reason: It isn't a direct dependency on anything in the images any more, and increased the image size with ~150MB.
+  Reason: It isn't a direct dependency on anything in the images anymore, and increased the image size by ~150MB.
 
 ## 2024-11-06",Yes
images/minimal-notebook/setup-scripts/setup_julia.py,images/minimal-notebook/setup-scripts/setup_julia.py,7bdb19cc1be5d9fcd3f41ce317e2ac741830472a,f632f54034c9c8d9ba756c47b92edaa67b49a03c,Downgrade to Julia 1.11.1 (#2178),"diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index 114e64c0..e6221238 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -47,6 +47,11 @@ def get_latest_julia_url() -> tuple[str, str]:
     triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
     file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
     LOGGER.info(f""Latest version: {file_info['version']} url: {file_info['url']}"")
+    if file_info[""version""] == ""1.11.2"":
+        LOGGER.warning(
+            ""Not using Julia 1.11.2, because it hangs in GitHub self-hosted runners""
+        )
+        return file_info[""url""].replace(""1.11.2"", ""1.11.1""), ""1.11.1""
     return file_info[""url""], file_info[""version""]","diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index 114e64c0..e6221238 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -47,6 +47,11 @@ def get_latest_julia_url() -> tuple[str, str]:
     triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
     file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
     LOGGER.info(f""Latest version: {file_info['version']} url: {file_info['url']}"")
+    if file_info[""version""] == ""1.11.2"":
+        LOGGER.warning(
+            ""Not using Julia 1.11.2, because it hangs in GitHub self-hosted runners""
+        )
+        return file_info[""url""].replace(""1.11.2"", ""1.11.1""), ""1.11.1""
     return file_info[""url""], file_info[""version""]",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,976fbab11d760ea3766c241809f7b120bd8c2ec9,7bdb19cc1be5d9fcd3f41ce317e2ac741830472a,Use another repo for prettier pre-commit (#2180),"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 23518465..0522c6bc 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -61,8 +61,8 @@ repos:
         stages: [manual]
 
   # Autoformat: YAML, JSON, Markdown, etc.
-  - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v4.0.0-alpha.8
+  - repo: https://github.com/rbubley/mirrors-prettier
+    rev: v3.4.2
     hooks:
       - id: prettier","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 23518465..0522c6bc 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -61,8 +61,8 @@ repos:
         stages: [manual]
 
   # Autoformat: YAML, JSON, Markdown, etc.
-  - repo: https://github.com/pre-commit/mirrors-prettier
-    rev: v4.0.0-alpha.8
+  - repo: https://github.com/rbubley/mirrors-prettier
+    rev: v3.4.2
     hooks:
       - id: prettier",Yes
tests/base-notebook/test_healthcheck.py,tests/base-notebook/test_healthcheck.py,87b37b4fd818b219ecd4d42f2c14c8d454569d1b,976fbab11d760ea3766c241809f7b120bd8c2ec9,Specify protocol when using host.docker.internal proxy (#2181),"diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index d5874c9a..36a8a4dc 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -82,7 +82,10 @@ def test_healthy(
     ""env,cmd,user"",
     [
         (
-            [""HTTPS_PROXY=host.docker.internal"", ""HTTP_PROXY=host.docker.internal""],
+            [
+                ""HTTPS_PROXY=https://host.docker.internal"",
+                ""HTTP_PROXY=http://host.docker.internal"",
+            ],
             None,
             None,
         ),
@@ -91,8 +94,8 @@ def test_healthy(
                 ""NB_USER=testuser"",
                 ""CHOWN_HOME=1"",
                 ""JUPYTER_PORT=8123"",
-                ""HTTPS_PROXY=host.docker.internal"",
-                ""HTTP_PROXY=host.docker.internal"",
+                ""HTTPS_PROXY=https://host.docker.internal"",
+                ""HTTP_PROXY=http://host.docker.internal"",
             ],
             [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",","diff --git a/tests/base-notebook/test_healthcheck.py b/tests/base-notebook/test_healthcheck.py
index d5874c9a..36a8a4dc 100644
--- a/tests/base-notebook/test_healthcheck.py
+++ b/tests/base-notebook/test_healthcheck.py
@@ -82,7 +82,10 @@ def test_healthy(
     ""env,cmd,user"",
     [
         (
-            [""HTTPS_PROXY=host.docker.internal"", ""HTTP_PROXY=host.docker.internal""],
+            [
+                ""HTTPS_PROXY=https://host.docker.internal"",
+                ""HTTP_PROXY=http://host.docker.internal"",
+            ],
             None,
             None,
         ),
@@ -91,8 +94,8 @@ def test_healthy(
                 ""NB_USER=testuser"",
                 ""CHOWN_HOME=1"",
                 ""JUPYTER_PORT=8123"",
-                ""HTTPS_PROXY=host.docker.internal"",
-                ""HTTP_PROXY=host.docker.internal"",
+                ""HTTPS_PROXY=https://host.docker.internal"",
+                ""HTTP_PROXY=http://host.docker.internal"",
             ],
             [""start-notebook.py"", ""--ServerApp.base_url=/test""],
             ""root"",",Yes
.github/workflows/aarch64-setup.yml,.github/workflows/aarch64-setup.yml,8e44737b80c3fa77479e685d9f0ba9245e15aef7,87b37b4fd818b219ecd4d42f2c14c8d454569d1b,Run aarch64-setup on ubuntu-22.04,"diff --git a/.github/workflows/aarch64-setup.yml b/.github/workflows/aarch64-setup.yml
index 441a9aa2..2519d846 100644
--- a/.github/workflows/aarch64-setup.yml
+++ b/.github/workflows/aarch64-setup.yml
@@ -19,8 +19,8 @@ on:
 jobs:
   test-script:
     # The script itself is not aarch64-specific
-    # It is easier to test on ubuntu-latest
-    runs-on: ubuntu-latest
+    # It is easier to test on ubuntu-22.04
+    runs-on: ubuntu-22.04
 
     steps:
       - name: Checkout Repo ⚡️","diff --git a/.github/workflows/aarch64-setup.yml b/.github/workflows/aarch64-setup.yml
index 441a9aa2..2519d846 100644
--- a/.github/workflows/aarch64-setup.yml
+++ b/.github/workflows/aarch64-setup.yml
@@ -19,8 +19,8 @@ on:
 jobs:
   test-script:
     # The script itself is not aarch64-specific
-    # It is easier to test on ubuntu-latest
-    runs-on: ubuntu-latest
+    # It is easier to test on ubuntu-22.04
+    runs-on: ubuntu-22.04
 
     steps:
       - name: Checkout Repo ⚡️",Yes
README.md,README.md,f58ebf0cb9c7947a6be6aeeddfaa7a8b656b4220,8e44737b80c3fa77479e685d9f0ba9245e15aef7,Update tag example,"diff --git a/README.md b/README.md
index ecb0a881..fdadc016 100644
--- a/README.md
+++ b/README.md
@@ -29,11 +29,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-11-19
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-12-23
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -48,11 +48,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-11-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-12-23
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.","diff --git a/README.md b/README.md
index ecb0a881..fdadc016 100644
--- a/README.md
+++ b/README.md
@@ -29,11 +29,11 @@ Older images are available on Docker Hub, but they will no longer be updated.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the container's internal port `8888` to port `10000` of the host machine:
 
 ```bash
-docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-11-19
+docker run -p 10000:8888 quay.io/jupyter/scipy-notebook:2024-12-23
 ```
 
 You can modify the port on which the container's port is exposed by [changing the value of the `-p` option](https://docs.docker.com/engine/containers/run/#exposed-ports) to `-p 8888:8888`.
@@ -48,11 +48,11 @@ The container remains intact for restart after the Server exits.
 
 ### Example 2
 
-This command pulls the `jupyter/datascience-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/datascience-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts an _ephemeral_ container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-11-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/datascience-notebook:2024-12-23
 ```
 
 The use of the `-v` flag in the command mounts the current working directory on the host (`${PWD}` in the example command) as `/home/jovyan/work` in the container.",Yes
binder/Dockerfile,binder/Dockerfile,f58ebf0cb9c7947a6be6aeeddfaa7a8b656b4220,8e44737b80c3fa77479e685d9f0ba9245e15aef7,Update tag example,"diff --git a/binder/Dockerfile b/binder/Dockerfile
index 97aab3e3..0454263f 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-11-19
+ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-12-23
 FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-11-19""
+ENV TAG=""2024-12-23""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb","diff --git a/binder/Dockerfile b/binder/Dockerfile
index 97aab3e3..0454263f 100644
--- a/binder/Dockerfile
+++ b/binder/Dockerfile
@@ -4,7 +4,7 @@
 # https://quay.io/repository/jupyter/base-notebook?tab=tags
 ARG REGISTRY=quay.io
 ARG OWNER=jupyter
-ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-11-19
+ARG BASE_IMAGE=$REGISTRY/$OWNER/base-notebook:2024-12-23
 FROM $BASE_IMAGE
 
 LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
@@ -13,7 +13,7 @@ LABEL maintainer=""Jupyter Project <jupyter@googlegroups.com>""
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
 SHELL [""/bin/bash"", ""-o"", ""pipefail"", ""-c""]
 
-ENV TAG=""2024-11-19""
+ENV TAG=""2024-12-23""
 
 COPY --chown=${NB_UID}:${NB_GID} binder/README.ipynb ""${HOME}""/README.ipynb",Yes
docs/using/running.md,docs/using/running.md,f58ebf0cb9c7947a6be6aeeddfaa7a8b656b4220,8e44737b80c3fa77479e685d9f0ba9245e15aef7,Update tag example,"diff --git a/docs/using/running.md b/docs/using/running.md
index c51c46a5..8bc58b10 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-11-19
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-12-23
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-11-19   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-12-23   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-11-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-12-23
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-11-19
+    quay.io/jupyter/r-notebook:2024-12-23
 ```
 
 ```{warning}","diff --git a/docs/using/running.md b/docs/using/running.md
index c51c46a5..8bc58b10 100644
--- a/docs/using/running.md
+++ b/docs/using/running.md
@@ -15,12 +15,12 @@ The following are some common patterns.
 
 ### Example 1
 
-This command pulls the `jupyter/scipy-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/scipy-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts a container running Jupyter Server with the JupyterLab frontend and exposes the server on host port 8888.
 The server logs appear in the terminal and include a URL to the server.
 
 ```bash
-docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-11-19
+docker run -it -p 8888:8888 quay.io/jupyter/scipy-notebook:2024-12-23
 
 # Entered start.sh with args: jupyter lab
 
@@ -39,7 +39,7 @@ Pressing `Ctrl-C` twice shuts down the Server but leaves the container intact on
 # list containers
 docker ps --all
 # CONTAINER ID   IMAGE                                       COMMAND                  CREATED              STATUS                     PORTS     NAMES
-# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-11-19   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
+# eca4aa01751c   quay.io/jupyter/scipy-notebook:2024-12-23   ""tini -g -- start-no…""   About a minute ago   Exited (0) 5 seconds ago             silly_panini
 
 # start the stopped container
 docker start --attach -i eca4aa01751c
@@ -53,12 +53,12 @@ docker rm eca4aa01751c
 
 ### Example 2
 
-This command pulls the `jupyter/r-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `jupyter/r-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts a container running Server and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the Server but with the internal container port (8888) instead of the correct host port (10000).
 
 ```bash
-docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-11-19
+docker run -it --rm -p 10000:8888 -v ""${PWD}"":/home/jovyan/work quay.io/jupyter/r-notebook:2024-12-23
 ```
 
 Pressing `Ctrl-C` twice shuts down the Server and immediately destroys the Docker container.
@@ -138,7 +138,7 @@ subuidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.UIDMap }}+{{.Si
 subgidSize=$(( $(podman info --format ""{{ range .Host.IDMappings.GIDMap }}+{{.Size }}{{end }}"" ) - 1 ))
 ```
 
-This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-11-19` from Quay.io if it is not already present on the local host.
+This command pulls the `quay.io/jupyter/r-notebook` image tagged `2024-12-23` from Quay.io if it is not already present on the local host.
 It then starts a container running a Jupyter Server with the JupyterLab frontend and exposes the server on host port 10000.
 The server logs appear in the terminal and include a URL to the server but with the internal container port (8888) instead of the correct host port (10000).
 
@@ -147,7 +147,7 @@ podman run -it --rm -p 10000:8888 \
     -v ""${PWD}"":/home/jovyan/work --user $uid:$gid \
     --uidmap $uid:0:1 --uidmap 0:1:$uid --uidmap $(($uid+1)):$(($uid+1)):$(($subuidSize-$uid)) \
     --gidmap $gid:0:1 --gidmap 0:1:$gid --gidmap $(($gid+1)):$(($gid+1)):$(($subgidSize-$gid)) \
-    quay.io/jupyter/r-notebook:2024-11-19
+    quay.io/jupyter/r-notebook:2024-12-23
 ```
 
 ```{warning}",Yes
tagging/update_wiki.py,tagging/update_wiki.py,2ba3651be1434a119b589951fa09ac7b05010836,f58ebf0cb9c7947a6be6aeeddfaa7a8b656b4220,Put manifest files by to year/year-month/ dirs,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 292ee2d8..4ce091d8 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -9,33 +9,34 @@ from pathlib import Path
 LOGGER = logging.getLogger(__name__)
 
 
-def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
+def update_home_wiki_page(wiki_dir: Path, year_month: str) -> None:
     TABLE_BEGINNING = """"""\
 | Month                  |
 | ---------------------- |
 """"""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
-    month_line = f""| [`{month}`](./{month}) |\n""
-    if month_line not in wiki_home_content:
+    year_month_line = f""| [`{year_month}`](./{year_month}) |\n""
+    if year_month_line not in wiki_home_content:
         assert TABLE_BEGINNING in wiki_home_content
         wiki_home_content = wiki_home_content.replace(
-            TABLE_BEGINNING, TABLE_BEGINNING + month_line
+            TABLE_BEGINNING, TABLE_BEGINNING + year_month_line
         )
         wiki_home_file.write_text(wiki_home_content)
-        LOGGER.info(f""Updated wiki home page with month: {month}"")
+        LOGGER.info(f""Updated wiki home page with month: {year_month}"")
 
 
 def update_monthly_wiki_page(
-    wiki_dir: Path, month: str, build_history_line: str
+    wiki_dir: Path, year_month: str, build_history_line: str
 ) -> None:
     MONTHLY_PAGE_HEADER = f""""""\
-# Images built during {month}
+# Images built during {year_month}
 
 | Date | Image | Links |
 | - | - | - |
 """"""
-    monthly_page = wiki_dir / ""monthly-files"" / (month + "".md"")
+    year = year_month[:4]
+    monthly_page = wiki_dir / ""monthly-files"" / year / (year_month + "".md"")
     if not monthly_page.exists():
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
         LOGGER.info(f""Created monthly page: {monthly_page.relative_to(wiki_dir)}"")
@@ -62,7 +63,7 @@ def get_manifest_timestamp(manifest_file: Path) -> str:
     return timestamp
 
 
-def get_manifest_month(manifest_file: Path) -> str:
+def get_manifest_year_month(manifest_file: Path) -> str:
     return get_manifest_timestamp(manifest_file)[:7]
 
 
@@ -85,8 +86,9 @@ def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> No
     manifest_files = list(manifests_dir.rglob(""*.md""))
     assert manifest_files, ""expected to have some manifest files""
     for manifest_file in manifest_files:
-        month = get_manifest_month(manifest_file)
-        copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
+        year_month = get_manifest_year_month(manifest_file)
+        year = year_month[:4]
+        copy_to = wiki_dir / ""manifests"" / year / year_month / manifest_file.name
         copy_to.parent.mkdir(exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
@@ -96,9 +98,9 @@ def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> No
     for build_history_line_file in build_history_line_files:
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
-        month = build_history_line[3:10]
-        update_home_wiki_page(wiki_dir, month)
-        update_monthly_wiki_page(wiki_dir, month, build_history_line)
+        year_month = build_history_line[3:10]
+        update_home_wiki_page(wiki_dir, year_month)
+        update_monthly_wiki_page(wiki_dir, year_month, build_history_line)
 
     remove_old_manifests(wiki_dir)","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 292ee2d8..4ce091d8 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -9,33 +9,34 @@ from pathlib import Path
 LOGGER = logging.getLogger(__name__)
 
 
-def update_home_wiki_page(wiki_dir: Path, month: str) -> None:
+def update_home_wiki_page(wiki_dir: Path, year_month: str) -> None:
     TABLE_BEGINNING = """"""\
 | Month                  |
 | ---------------------- |
 """"""
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
-    month_line = f""| [`{month}`](./{month}) |\n""
-    if month_line not in wiki_home_content:
+    year_month_line = f""| [`{year_month}`](./{year_month}) |\n""
+    if year_month_line not in wiki_home_content:
         assert TABLE_BEGINNING in wiki_home_content
         wiki_home_content = wiki_home_content.replace(
-            TABLE_BEGINNING, TABLE_BEGINNING + month_line
+            TABLE_BEGINNING, TABLE_BEGINNING + year_month_line
         )
         wiki_home_file.write_text(wiki_home_content)
-        LOGGER.info(f""Updated wiki home page with month: {month}"")
+        LOGGER.info(f""Updated wiki home page with month: {year_month}"")
 
 
 def update_monthly_wiki_page(
-    wiki_dir: Path, month: str, build_history_line: str
+    wiki_dir: Path, year_month: str, build_history_line: str
 ) -> None:
     MONTHLY_PAGE_HEADER = f""""""\
-# Images built during {month}
+# Images built during {year_month}
 
 | Date | Image | Links |
 | - | - | - |
 """"""
-    monthly_page = wiki_dir / ""monthly-files"" / (month + "".md"")
+    year = year_month[:4]
+    monthly_page = wiki_dir / ""monthly-files"" / year / (year_month + "".md"")
     if not monthly_page.exists():
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
         LOGGER.info(f""Created monthly page: {monthly_page.relative_to(wiki_dir)}"")
@@ -62,7 +63,7 @@ def get_manifest_timestamp(manifest_file: Path) -> str:
     return timestamp
 
 
-def get_manifest_month(manifest_file: Path) -> str:
+def get_manifest_year_month(manifest_file: Path) -> str:
     return get_manifest_timestamp(manifest_file)[:7]
 
 
@@ -85,8 +86,9 @@ def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> No
     manifest_files = list(manifests_dir.rglob(""*.md""))
     assert manifest_files, ""expected to have some manifest files""
     for manifest_file in manifest_files:
-        month = get_manifest_month(manifest_file)
-        copy_to = wiki_dir / ""manifests"" / month / manifest_file.name
+        year_month = get_manifest_year_month(manifest_file)
+        year = year_month[:4]
+        copy_to = wiki_dir / ""manifests"" / year / year_month / manifest_file.name
         copy_to.parent.mkdir(exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
@@ -96,9 +98,9 @@ def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> No
     for build_history_line_file in build_history_line_files:
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
-        month = build_history_line[3:10]
-        update_home_wiki_page(wiki_dir, month)
-        update_monthly_wiki_page(wiki_dir, month, build_history_line)
+        year_month = build_history_line[3:10]
+        update_home_wiki_page(wiki_dir, year_month)
+        update_monthly_wiki_page(wiki_dir, year_month, build_history_line)
 
     remove_old_manifests(wiki_dir)",Yes
tagging/update_wiki.py,tagging/update_wiki.py,209a7464f4044665c59b3766cbb09f059ba9b7f4,2ba3651be1434a119b589951fa09ac7b05010836,Group build manifests by year,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 4ce091d8..3ae98da2 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -10,21 +10,36 @@ LOGGER = logging.getLogger(__name__)
 
 
 def update_home_wiki_page(wiki_dir: Path, year_month: str) -> None:
-    TABLE_BEGINNING = """"""\
+    YEAR_MONTHLY_TABLES = ""<!-- YEAR_MONTHLY_TABLES -->\n""
+
+    TABLE_HEADER = """"""\
 | Month                  |
 | ---------------------- |
 """"""
+
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
+
+    year = year_month[:4]
+    year_header = f""## {year}\n""
+    if year_header not in wiki_home_content:
+        assert YEAR_MONTHLY_TABLES in wiki_home_content
+        wiki_home_content = wiki_home_content.replace(
+            YEAR_MONTHLY_TABLES,
+            YEAR_MONTHLY_TABLES + f""\n{year_header}\n{TABLE_HEADER}"",
+        )
+        LOGGER.info(f""Updated wiki home page with year header for year: {year}"")
+
     year_month_line = f""| [`{year_month}`](./{year_month}) |\n""
     if year_month_line not in wiki_home_content:
-        assert TABLE_BEGINNING in wiki_home_content
+        assert TABLE_HEADER in wiki_home_content
         wiki_home_content = wiki_home_content.replace(
-            TABLE_BEGINNING, TABLE_BEGINNING + year_month_line
+            TABLE_HEADER, TABLE_HEADER + year_month_line
         )
-        wiki_home_file.write_text(wiki_home_content)
         LOGGER.info(f""Updated wiki home page with month: {year_month}"")
 
+    wiki_home_file.write_text(wiki_home_content)
+
 
 def update_monthly_wiki_page(
     wiki_dir: Path, year_month: str, build_history_line: str","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 4ce091d8..3ae98da2 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -10,21 +10,36 @@ LOGGER = logging.getLogger(__name__)
 
 
 def update_home_wiki_page(wiki_dir: Path, year_month: str) -> None:
-    TABLE_BEGINNING = """"""\
+    YEAR_MONTHLY_TABLES = ""<!-- YEAR_MONTHLY_TABLES -->\n""
+
+    TABLE_HEADER = """"""\
 | Month                  |
 | ---------------------- |
 """"""
+
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
+
+    year = year_month[:4]
+    year_header = f""## {year}\n""
+    if year_header not in wiki_home_content:
+        assert YEAR_MONTHLY_TABLES in wiki_home_content
+        wiki_home_content = wiki_home_content.replace(
+            YEAR_MONTHLY_TABLES,
+            YEAR_MONTHLY_TABLES + f""\n{year_header}\n{TABLE_HEADER}"",
+        )
+        LOGGER.info(f""Updated wiki home page with year header for year: {year}"")
+
     year_month_line = f""| [`{year_month}`](./{year_month}) |\n""
     if year_month_line not in wiki_home_content:
-        assert TABLE_BEGINNING in wiki_home_content
+        assert TABLE_HEADER in wiki_home_content
         wiki_home_content = wiki_home_content.replace(
-            TABLE_BEGINNING, TABLE_BEGINNING + year_month_line
+            TABLE_HEADER, TABLE_HEADER + year_month_line
         )
-        wiki_home_file.write_text(wiki_home_content)
         LOGGER.info(f""Updated wiki home page with month: {year_month}"")
 
+    wiki_home_file.write_text(wiki_home_content)
+
 
 def update_monthly_wiki_page(
     wiki_dir: Path, year_month: str, build_history_line: str",Yes
tagging/manifests.py,tagging/manifests.py,c175251fdbaa642ec5bcdeac90073d9fec17e714,209a7464f4044665c59b3766cbb09f059ba9b7f4,[FAST_BUILD] Run `mamba info` without `--quiet` and put `conda info` in build manifest files (#2191),"diff --git a/tagging/manifests.py b/tagging/manifests.py
index f043de05..b09db50b 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -11,10 +11,13 @@ docker = plumbum.local[""docker""]
 
 def quoted_output(container: Container, cmd: str) -> str:
     cmd_output = DockerRunner.run_simple_command(container, cmd, print_result=False)
-    # For example, `mamba info --quiet` adds redundant empty lines
+    # For example, `mamba info` adds redundant empty lines
     cmd_output = cmd_output.strip(""\n"")
     # For example, R packages list contains trailing backspaces
     cmd_output = ""\n"".join(line.rstrip() for line in cmd_output.split(""\n""))
+
+    assert cmd_output, f""Command `{cmd}` returned empty output""
+
     return f""""""\
 `{cmd}`:
 
@@ -76,7 +79,9 @@ class CondaEnvironmentManifest(ManifestInterface):
 
 {DockerRunner.run_simple_command(container, ""python --version"")}
 
-{quoted_output(container, ""mamba info --quiet"")}
+{quoted_output(container, ""conda info"")}
+
+{quoted_output(container, ""mamba info"")}
 
 {quoted_output(container, ""mamba list"")}""""""","diff --git a/tagging/manifests.py b/tagging/manifests.py
index f043de05..b09db50b 100644
--- a/tagging/manifests.py
+++ b/tagging/manifests.py
@@ -11,10 +11,13 @@ docker = plumbum.local[""docker""]
 
 def quoted_output(container: Container, cmd: str) -> str:
     cmd_output = DockerRunner.run_simple_command(container, cmd, print_result=False)
-    # For example, `mamba info --quiet` adds redundant empty lines
+    # For example, `mamba info` adds redundant empty lines
     cmd_output = cmd_output.strip(""\n"")
     # For example, R packages list contains trailing backspaces
     cmd_output = ""\n"".join(line.rstrip() for line in cmd_output.split(""\n""))
+
+    assert cmd_output, f""Command `{cmd}` returned empty output""
+
     return f""""""\
 `{cmd}`:
 
@@ -76,7 +79,9 @@ class CondaEnvironmentManifest(ManifestInterface):
 
 {DockerRunner.run_simple_command(container, ""python --version"")}
 
-{quoted_output(container, ""mamba info --quiet"")}
+{quoted_output(container, ""conda info"")}
+
+{quoted_output(container, ""mamba info"")}
 
 {quoted_output(container, ""mamba list"")}""""""",Yes
tagging/update_wiki.py,tagging/update_wiki.py,a41b6e80cef7c3729aebf9df2fb9ab73fc4f41a4,c175251fdbaa642ec5bcdeac90073d9fec17e714,Add some statistics to wiki page,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 3ae98da2..aeaa12f6 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -9,36 +9,43 @@ from pathlib import Path
 LOGGER = logging.getLogger(__name__)
 
 
-def update_home_wiki_page(wiki_dir: Path, year_month: str) -> None:
+def regenerate_home_wiki_page(wiki_dir: Path) -> None:
     YEAR_MONTHLY_TABLES = ""<!-- YEAR_MONTHLY_TABLES -->\n""
 
-    TABLE_HEADER = """"""\
-| Month                  |
-| ---------------------- |
+    YEAR_TABLE_HEADER = """"""\
+## {year}
+
+| Month                  | Builds | Images |
+| ---------------------- | ------ | ------ |
 """"""
 
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
 
-    year = year_month[:4]
-    year_header = f""## {year}\n""
-    if year_header not in wiki_home_content:
-        assert YEAR_MONTHLY_TABLES in wiki_home_content
-        wiki_home_content = wiki_home_content.replace(
-            YEAR_MONTHLY_TABLES,
-            YEAR_MONTHLY_TABLES + f""\n{year_header}\n{TABLE_HEADER}"",
-        )
-        LOGGER.info(f""Updated wiki home page with year header for year: {year}"")
-
-    year_month_line = f""| [`{year_month}`](./{year_month}) |\n""
-    if year_month_line not in wiki_home_content:
-        assert TABLE_HEADER in wiki_home_content
-        wiki_home_content = wiki_home_content.replace(
-            TABLE_HEADER, TABLE_HEADER + year_month_line
-        )
-        LOGGER.info(f""Updated wiki home page with month: {year_month}"")
+    assert YEAR_MONTHLY_TABLES in wiki_home_content
+    wiki_home_content = wiki_home_content[
+        : wiki_home_content.find(YEAR_MONTHLY_TABLES) + len(YEAR_MONTHLY_TABLES)
+    ]
+
+    all_year_dirs = sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True)
+    for year_dir in all_year_dirs:
+        wiki_home_content += ""\n"" + YEAR_TABLE_HEADER.format(year=year_dir.name)
+
+        all_year_month_files = sorted(year_dir.glob(""*.md""), reverse=True)
+        for year_month_file in all_year_month_files:
+            year_month_file_content = year_month_file.read_text()
+            images = year_month_file_content.count(""Build manifest"")
+            builds = sum(
+                ""jupyter/base-notebook"" in line and ""aarch64"" not in line
+                for line in year_month_file_content.split(""\n"")
+            )
+            year_month = year_month_file.stem
+            wiki_home_content += (
+                f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} |\n""
+            )
 
     wiki_home_file.write_text(wiki_home_content)
+    LOGGER.info(""Updated Home page"")
 
 
 def update_monthly_wiki_page(
@@ -114,9 +121,9 @@ def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> No
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
         year_month = build_history_line[3:10]
-        update_home_wiki_page(wiki_dir, year_month)
         update_monthly_wiki_page(wiki_dir, year_month, build_history_line)
 
+    regenerate_home_wiki_page(wiki_dir)
     remove_old_manifests(wiki_dir)","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 3ae98da2..aeaa12f6 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -9,36 +9,43 @@ from pathlib import Path
 LOGGER = logging.getLogger(__name__)
 
 
-def update_home_wiki_page(wiki_dir: Path, year_month: str) -> None:
+def regenerate_home_wiki_page(wiki_dir: Path) -> None:
     YEAR_MONTHLY_TABLES = ""<!-- YEAR_MONTHLY_TABLES -->\n""
 
-    TABLE_HEADER = """"""\
-| Month                  |
-| ---------------------- |
+    YEAR_TABLE_HEADER = """"""\
+## {year}
+
+| Month                  | Builds | Images |
+| ---------------------- | ------ | ------ |
 """"""
 
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
 
-    year = year_month[:4]
-    year_header = f""## {year}\n""
-    if year_header not in wiki_home_content:
-        assert YEAR_MONTHLY_TABLES in wiki_home_content
-        wiki_home_content = wiki_home_content.replace(
-            YEAR_MONTHLY_TABLES,
-            YEAR_MONTHLY_TABLES + f""\n{year_header}\n{TABLE_HEADER}"",
-        )
-        LOGGER.info(f""Updated wiki home page with year header for year: {year}"")
+    assert YEAR_MONTHLY_TABLES in wiki_home_content
+    wiki_home_content = wiki_home_content[
+        : wiki_home_content.find(YEAR_MONTHLY_TABLES) + len(YEAR_MONTHLY_TABLES)
+    ]
 
-    year_month_line = f""| [`{year_month}`](./{year_month}) |\n""
-    if year_month_line not in wiki_home_content:
-        assert TABLE_HEADER in wiki_home_content
-        wiki_home_content = wiki_home_content.replace(
-            TABLE_HEADER, TABLE_HEADER + year_month_line
-        )
-        LOGGER.info(f""Updated wiki home page with month: {year_month}"")
+    all_year_dirs = sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True)
+    for year_dir in all_year_dirs:
+        wiki_home_content += ""\n"" + YEAR_TABLE_HEADER.format(year=year_dir.name)
+
+        all_year_month_files = sorted(year_dir.glob(""*.md""), reverse=True)
+        for year_month_file in all_year_month_files:
+            year_month_file_content = year_month_file.read_text()
+            images = year_month_file_content.count(""Build manifest"")
+            builds = sum(
+                ""jupyter/base-notebook"" in line and ""aarch64"" not in line
+                for line in year_month_file_content.split(""\n"")
+            )
+            year_month = year_month_file.stem
+            wiki_home_content += (
+                f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} |\n""
+            )
 
     wiki_home_file.write_text(wiki_home_content)
+    LOGGER.info(""Updated Home page"")
 
 
 def update_monthly_wiki_page(
@@ -114,9 +121,9 @@ def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> No
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
         year_month = build_history_line[3:10]
-        update_home_wiki_page(wiki_dir, year_month)
         update_monthly_wiki_page(wiki_dir, year_month, build_history_line)
 
+    regenerate_home_wiki_page(wiki_dir)
     remove_old_manifests(wiki_dir)",No
Makefile,Makefile,1c32064b2e2fc8ea5057481a8f736d43dd6ebd4f,a41b6e80cef7c3729aebf9df2fb9ab73fc4f41a4,Fix args order in Makefile,"diff --git a/Makefile b/Makefile
index 9222d677..2ca28fd2 100644
--- a/Makefile
+++ b/Makefile
@@ -72,7 +72,7 @@ hook/%: VARIANT?=default
 hook/%: ## run post-build hooks for an image
 	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)"" && \
 	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)"" && \
-	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --variant ""$(VARIANT)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images","diff --git a/Makefile b/Makefile
index 9222d677..2ca28fd2 100644
--- a/Makefile
+++ b/Makefile
@@ -72,7 +72,7 @@ hook/%: VARIANT?=default
 hook/%: ## run post-build hooks for an image
 	python3 -m tagging.write_tags_file --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)"" && \
 	python3 -m tagging.write_manifest --short-image-name ""$(notdir $@)"" --hist-lines-dir /tmp/jupyter/hist_lines/ --manifests-dir /tmp/jupyter/manifests/ --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)"" && \
-	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --variant ""$(VARIANT)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)""
+	python3 -m tagging.apply_tags --short-image-name ""$(notdir $@)"" --tags-dir /tmp/jupyter/tags/ --platform ""$(shell uname -m)"" --registry ""$(REGISTRY)"" --owner ""$(OWNER)"" --variant ""$(VARIANT)""
 hook-all: $(foreach I, $(ALL_IMAGES), hook/$(I)) ## run post-build hooks for all images",Yes
.github/workflows/docker-tag-push.yml,.github/workflows/docker-tag-push.yml,67dd54966cff0bfcc5a6204924029983ea2f632a,1c32064b2e2fc8ea5057481a8f736d43dd6ebd4f,Fix args order when running python modules,"diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 887e2d2e..e4962a61 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -69,7 +69,7 @@ jobs:
           name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-tags
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
-        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --variant ${{ inputs.variant }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }} --variant ${{ inputs.variant }}
       # This step is needed to prevent pushing non-multi-arch ""latest"" tag
       - name: Remove the ""latest"" tag from the image 🗑️
         run: docker image rmi ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}:latest","diff --git a/.github/workflows/docker-tag-push.yml b/.github/workflows/docker-tag-push.yml
index 887e2d2e..e4962a61 100644
--- a/.github/workflows/docker-tag-push.yml
+++ b/.github/workflows/docker-tag-push.yml
@@ -69,7 +69,7 @@ jobs:
           name: ${{ inputs.image }}-${{ inputs.platform }}-${{ inputs.variant }}-tags
           path: /tmp/jupyter/tags/
       - name: Apply tags to the loaded image 🏷
-        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --variant ${{ inputs.variant }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }}
+        run: python3 -m tagging.apply_tags --short-image-name ${{ inputs.image }} --tags-dir /tmp/jupyter/tags/ --platform ${{ inputs.platform }} --registry ${{ env.REGISTRY }} --owner ${{ env.OWNER }} --variant ${{ inputs.variant }}
       # This step is needed to prevent pushing non-multi-arch ""latest"" tag
       - name: Remove the ""latest"" tag from the image 🗑️
         run: docker image rmi ${{ env.REGISTRY }}/${{ env.OWNER }}/${{ inputs.image }}:latest",Yes
tagging/merge_tags.py,tagging/merge_tags.py,67dd54966cff0bfcc5a6204924029983ea2f632a,1c32064b2e2fc8ea5057481a8f736d43dd6ebd4f,Fix args order when running python modules,"diff --git a/tagging/merge_tags.py b/tagging/merge_tags.py
index 06b18e70..d9a17b18 100755
--- a/tagging/merge_tags.py
+++ b/tagging/merge_tags.py
@@ -66,17 +66,17 @@ if __name__ == ""__main__"":
         required=True,
         help=""Short image name"",
     )
-    arg_parser.add_argument(
-        ""--variant"",
-        required=True,
-        help=""Variant tag prefix"",
-    )
     arg_parser.add_argument(
         ""--tags-dir"",
         required=True,
         type=Path,
         help=""Directory with saved tags file"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     args = arg_parser.parse_args()
 
     merge_tags(args.short_image_name, args.variant, args.tags_dir)","diff --git a/tagging/merge_tags.py b/tagging/merge_tags.py
index 06b18e70..d9a17b18 100755
--- a/tagging/merge_tags.py
+++ b/tagging/merge_tags.py
@@ -66,17 +66,17 @@ if __name__ == ""__main__"":
         required=True,
         help=""Short image name"",
     )
-    arg_parser.add_argument(
-        ""--variant"",
-        required=True,
-        help=""Variant tag prefix"",
-    )
     arg_parser.add_argument(
         ""--tags-dir"",
         required=True,
         type=Path,
         help=""Directory with saved tags file"",
     )
+    arg_parser.add_argument(
+        ""--variant"",
+        required=True,
+        help=""Variant tag prefix"",
+    )
     args = arg_parser.parse_args()
 
     merge_tags(args.short_image_name, args.variant, args.tags_dir)",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,72aea7469eb7e9a47f4ab8b7e2add4ed3bf66ebf,67dd54966cff0bfcc5a6204924029983ea2f632a,Update OracleDB Instant Client version (#2194),"diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 44ff2cd4..ce435b95 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -12,12 +12,12 @@ RUN apt-get update --yes && \
 
 # Oracle
 ARG INSTANTCLIENT_MAJOR_VERSION=23
-ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.4.0.24.05-1.el9.x86_64.rpm
-ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2340000
+ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.6.0.24.10-1.el9.x86_64.rpm
+ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2360000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools, and JDBC.
 # Note: You may need to change the URL to a newer version.
-# See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
+# See: https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html
 RUN mkdir ""/opt/oracle""
 WORKDIR ""/opt/oracle""
 # alien doesn't work well with sqlplus, so skipping it for now","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index 44ff2cd4..ce435b95 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -12,12 +12,12 @@ RUN apt-get update --yes && \
 
 # Oracle
 ARG INSTANTCLIENT_MAJOR_VERSION=23
-ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.4.0.24.05-1.el9.x86_64.rpm
-ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2340000
+ARG INSTANTCLIENT_BIN_SUFFIX=${INSTANTCLIENT_MAJOR_VERSION}.6.0.24.10-1.el9.x86_64.rpm
+ARG INSTANTCLIENT_URL=https://download.oracle.com/otn_software/linux/instantclient/2360000
 
 # Then install Oracle SQL Instant client, SQL+Plus, tools, and JDBC.
 # Note: You may need to change the URL to a newer version.
-# See: https://www.oracle.com/es/database/technologies/instant-client/linux-x86-64-downloads.html
+# See: https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html
 RUN mkdir ""/opt/oracle""
 WORKDIR ""/opt/oracle""
 # alien doesn't work well with sqlplus, so skipping it for now",Yes
docs/using/recipe_code/oracledb.dockerfile,docs/using/recipe_code/oracledb.dockerfile,2483ba812870e2645066332a24db3d8dd04f770d,72aea7469eb7e9a47f4ab8b7e2add4ed3bf66ebf,"Use Ububtu 24.04 image for OracleDB Instant Client (#2195)

* Use Ububtu 24.04 image for OracleDB Instant Client

* Package changed the name","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index ce435b95..c4ea3db5 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook:ubuntu-22.04
+FROM quay.io/jupyter/base-notebook
 
 USER root
 
@@ -7,7 +7,7 @@ RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends software-properties-common && \
     add-apt-repository universe && \
     apt-get update --yes && \
-    apt-get install --yes --no-install-recommends alien default-jre default-jdk openjdk-11-jdk libaio1 && \
+    apt-get install --yes --no-install-recommends alien default-jre default-jdk openjdk-11-jdk libaio1t64 && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
 # Oracle","diff --git a/docs/using/recipe_code/oracledb.dockerfile b/docs/using/recipe_code/oracledb.dockerfile
index ce435b95..c4ea3db5 100644
--- a/docs/using/recipe_code/oracledb.dockerfile
+++ b/docs/using/recipe_code/oracledb.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook:ubuntu-22.04
+FROM quay.io/jupyter/base-notebook
 
 USER root
 
@@ -7,7 +7,7 @@ RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends software-properties-common && \
     add-apt-repository universe && \
     apt-get update --yes && \
-    apt-get install --yes --no-install-recommends alien default-jre default-jdk openjdk-11-jdk libaio1 && \
+    apt-get install --yes --no-install-recommends alien default-jre default-jdk openjdk-11-jdk libaio1t64 && \
     apt-get clean && rm -rf /var/lib/apt/lists/*
 
 # Oracle",Yes
docs/using/recipe_code/microsoft_odbc.dockerfile,docs/using/recipe_code/microsoft_odbc.dockerfile,319c99c1281c156813f9f92c71e3c7c4be343eaa,2483ba812870e2645066332a24db3d8dd04f770d,"Use Ubuntu 24.04 image for Microsoft ODBC (#2196)

* Use Ubuntu 24.04 image for Microsoft ODBC

* Fix typo

* Don't use apt-key","diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index 8642fdf4..89bb69d1 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook:ubuntu-22.04
+FROM quay.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
@@ -11,7 +11,7 @@ ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
 
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends curl gnupg2 lsb-release && \
-    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
+    curl -fsSL ""https://packages.microsoft.com/keys/microsoft.asc"" | gpg --dearmor -o /usr/share/keyrings/microsoft-prod.gpg && \
     curl ""https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list"" > /etc/apt/sources.list.d/mssql-release.list && \
     apt-get update --yes && \
     ACCEPT_EULA=Y apt-get install --yes --no-install-recommends msodbcsql18 && \","diff --git a/docs/using/recipe_code/microsoft_odbc.dockerfile b/docs/using/recipe_code/microsoft_odbc.dockerfile
index 8642fdf4..89bb69d1 100644
--- a/docs/using/recipe_code/microsoft_odbc.dockerfile
+++ b/docs/using/recipe_code/microsoft_odbc.dockerfile
@@ -1,4 +1,4 @@
-FROM quay.io/jupyter/base-notebook:ubuntu-22.04
+FROM quay.io/jupyter/base-notebook
 
 # Fix: https://github.com/hadolint/hadolint/wiki/DL4006
 # Fix: https://github.com/koalaman/shellcheck/wiki/SC3014
@@ -11,7 +11,7 @@ ENV PATH=""/opt/mssql-tools18/bin:${PATH}""
 
 RUN apt-get update --yes && \
     apt-get install --yes --no-install-recommends curl gnupg2 lsb-release && \
-    curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - && \
+    curl -fsSL ""https://packages.microsoft.com/keys/microsoft.asc"" | gpg --dearmor -o /usr/share/keyrings/microsoft-prod.gpg && \
     curl ""https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list"" > /etc/apt/sources.list.d/mssql-release.list && \
     apt-get update --yes && \
     ACCEPT_EULA=Y apt-get install --yes --no-install-recommends msodbcsql18 && \",Yes
.github/ISSUE_TEMPLATE/bug_report.yml,.github/ISSUE_TEMPLATE/bug_report.yml,336a158857153110650dfce46139df6358b0c032,319c99c1281c156813f9f92c71e3c7c4be343eaa,Suggest that Host OS is Ubuntu 24.04 in bug report template,"diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 064028d4..a071a718 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -35,10 +35,10 @@ body:
 
   - type: input
     attributes:
-      label: Host OS system
+      label: Host OS
       placeholder: |
         Example:
-        Ubuntu 22.04
+        Ubuntu 24.04
     validations:
       required: true","diff --git a/.github/ISSUE_TEMPLATE/bug_report.yml b/.github/ISSUE_TEMPLATE/bug_report.yml
index 064028d4..a071a718 100644
--- a/.github/ISSUE_TEMPLATE/bug_report.yml
+++ b/.github/ISSUE_TEMPLATE/bug_report.yml
@@ -35,10 +35,10 @@ body:
 
   - type: input
     attributes:
-      label: Host OS system
+      label: Host OS
       placeholder: |
         Example:
-        Ubuntu 22.04
+        Ubuntu 24.04
     validations:
       required: true",Yes
examples/docker-compose/bin/letsencrypt.sh,examples/docker-compose/bin/letsencrypt.sh,7efbc39b9f9caa061da5e3063abf14367590314d,336a158857153110650dfce46139df6358b0c032,Use latest ubuntu in letsencrypt exaxmple,"diff --git a/examples/docker-compose/bin/letsencrypt.sh b/examples/docker-compose/bin/letsencrypt.sh
index ee976300..6b6eeefe 100755
--- a/examples/docker-compose/bin/letsencrypt.sh
+++ b/examples/docker-compose/bin/letsencrypt.sh
@@ -43,6 +43,6 @@ docker run -it --rm \
 # directory so that the FQDN doesn't have to be known later.
 docker run -it --rm \
     -v ""${SECRETS_VOLUME}"":/etc/letsencrypt \
-    ubuntu:22.04 \
+    ubuntu \
     bash -c ""ln -s /etc/letsencrypt/live/${FQDN}/* /etc/letsencrypt/ && \
         find /etc/letsencrypt -type d -exec chmod 755 {} +""","diff --git a/examples/docker-compose/bin/letsencrypt.sh b/examples/docker-compose/bin/letsencrypt.sh
index ee976300..6b6eeefe 100755
--- a/examples/docker-compose/bin/letsencrypt.sh
+++ b/examples/docker-compose/bin/letsencrypt.sh
@@ -43,6 +43,6 @@ docker run -it --rm \
 # directory so that the FQDN doesn't have to be known later.
 docker run -it --rm \
     -v ""${SECRETS_VOLUME}"":/etc/letsencrypt \
-    ubuntu:22.04 \
+    ubuntu \
     bash -c ""ln -s /etc/letsencrypt/live/${FQDN}/* /etc/letsencrypt/ && \
         find /etc/letsencrypt -type d -exec chmod 755 {} +""",Yes
.github/workflows/aarch64-setup.yml,.github/workflows/aarch64-setup.yml,c11078452beada1de433a24ecc74bd6f3f3b24b8,7efbc39b9f9caa061da5e3063abf14367590314d,Fix comment in aarch64-setup workflow,"diff --git a/.github/workflows/aarch64-setup.yml b/.github/workflows/aarch64-setup.yml
index 2519d846..bdaaf806 100644
--- a/.github/workflows/aarch64-setup.yml
+++ b/.github/workflows/aarch64-setup.yml
@@ -19,7 +19,8 @@ on:
 jobs:
   test-script:
     # The script itself is not aarch64-specific
-    # It is easier to test on ubuntu-22.04
+    # It is easier to test on x86_64
+    # Using `ubuntu-22.04` as this is what our aarch64 runners currently use
     runs-on: ubuntu-22.04
 
     steps:","diff --git a/.github/workflows/aarch64-setup.yml b/.github/workflows/aarch64-setup.yml
index 2519d846..bdaaf806 100644
--- a/.github/workflows/aarch64-setup.yml
+++ b/.github/workflows/aarch64-setup.yml
@@ -19,7 +19,8 @@ on:
 jobs:
   test-script:
     # The script itself is not aarch64-specific
-    # It is easier to test on ubuntu-22.04
+    # It is easier to test on x86_64
+    # Using `ubuntu-22.04` as this is what our aarch64 runners currently use
     runs-on: ubuntu-22.04
 
     steps:",Yes
.gitignore,.gitignore,af3191f853c64dffd50b18dd56954627e9eab830,c11078452beada1de433a24ecc74bd6f3f3b24b8,Update gitignore,"diff --git a/.gitignore b/.gitignore
index b0f3c848..2d29f388 100644
--- a/.gitignore
+++ b/.gitignore
@@ -94,6 +94,12 @@ ipython_config.py
 #   install all needed dependencies.
 #Pipfile.lock
 
+# UV
+#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
+#   This is especially recommended for binary packages to ensure reproducibility, and is more
+#   commonly ignored for libraries.
+#uv.lock
+
 # poetry
 #   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
 #   This is especially recommended for binary packages to ensure reproducibility, and is more
@@ -161,6 +167,9 @@ cython_debug/
 #  option (not recommended) you can uncomment the following to ignore the entire idea folder.
 #.idea/
 
+# PyPI configuration file
+.pypirc
+
 ##################################################################
 #             The content above is copied from                   #
 # https://github.com/github/gitignore/blob/main/Python.gitignore #","diff --git a/.gitignore b/.gitignore
index b0f3c848..2d29f388 100644
--- a/.gitignore
+++ b/.gitignore
@@ -94,6 +94,12 @@ ipython_config.py
 #   install all needed dependencies.
 #Pipfile.lock
 
+# UV
+#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
+#   This is especially recommended for binary packages to ensure reproducibility, and is more
+#   commonly ignored for libraries.
+#uv.lock
+
 # poetry
 #   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
 #   This is especially recommended for binary packages to ensure reproducibility, and is more
@@ -161,6 +167,9 @@ cython_debug/
 #  option (not recommended) you can uncomment the following to ignore the entire idea folder.
 #.idea/
 
+# PyPI configuration file
+.pypirc
+
 ##################################################################
 #             The content above is copied from                   #
 # https://github.com/github/gitignore/blob/main/Python.gitignore #",Yes
docs/conf.py,docs/conf.py,9ffeb238dc8e363b5bddd779442b4f32d06aff0d,af3191f853c64dffd50b18dd56954627e9eab830,Update sphinx config header,"diff --git a/docs/conf.py b/docs/conf.py
index 5cf59db1..f1bd390b 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -29,7 +29,7 @@ language = ""en""
 html_theme = ""alabaster""
 html_static_path = [""_static""]
 
-# The file above was generated using sphinx 7.2.6 with this command:
+# The file above was generated using sphinx 8.1.3 with this command:
 # sphinx-quickstart --project ""docker-stacks"" --author ""Project Jupyter"" -v ""latest"" -r ""latest"" -l en --no-sep --no-makefile --no-batchfile
 # These are custom options for this project","diff --git a/docs/conf.py b/docs/conf.py
index 5cf59db1..f1bd390b 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -29,7 +29,7 @@ language = ""en""
 html_theme = ""alabaster""
 html_static_path = [""_static""]
 
-# The file above was generated using sphinx 7.2.6 with this command:
+# The file above was generated using sphinx 8.1.3 with this command:
 # sphinx-quickstart --project ""docker-stacks"" --author ""Project Jupyter"" -v ""latest"" -r ""latest"" -l en --no-sep --no-makefile --no-batchfile
 # These are custom options for this project",Yes
tagging/update_wiki.py,tagging/update_wiki.py,af0493a30557814e0d827d56d40561f00b8c0746,9ffeb238dc8e363b5bddd779442b4f32d06aff0d,Add number of commits to wiki home page,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index aeaa12f6..ff3764e6 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -2,23 +2,51 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 import argparse
+import datetime
 import logging
 import shutil
 from pathlib import Path
 
-LOGGER = logging.getLogger(__name__)
+import plumbum
+from dateutil import relativedelta
 
+git = plumbum.local[""git""]
 
-def regenerate_home_wiki_page(wiki_dir: Path) -> None:
-    YEAR_MONTHLY_TABLES = ""<!-- YEAR_MONTHLY_TABLES -->\n""
+LOGGER = logging.getLogger(__name__)
 
-    YEAR_TABLE_HEADER = """"""\
+YEAR_TABLE_HEADER = """"""\
 ## {year}
 
-| Month                  | Builds | Images |
-| ---------------------- | ------ | ------ |
+| Month                  | Builds | Images | Commits |
+| ---------------------- | ------ | ------ | ------- |
 """"""
 
+
+def build_monthly_table_line(year_month_file: Path) -> str:
+    year_month_file_content = year_month_file.read_text()
+    images = year_month_file_content.count(""Build manifest"")
+    builds = sum(
+        ""jupyter/base-notebook"" in line and ""aarch64"" not in line
+        for line in year_month_file_content.split(""\n"")
+    )
+    year_month = year_month_file.stem
+    current_month = datetime.date(
+        year=int(year_month[:4]), month=int(year_month[5:]), day=1
+    )
+    next_month = current_month + relativedelta.relativedelta(months=1)
+    future = (
+        git[""log"", ""--oneline"", ""--since"", current_month, ""--until"", next_month]
+        & plumbum.BG
+    )
+    future.wait()
+    commits = len(future.stdout.splitlines())
+
+    return f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits: <7} |\n""
+
+
+def regenerate_home_wiki_page(wiki_dir: Path) -> None:
+    YEAR_MONTHLY_TABLES = ""<!-- YEAR_MONTHLY_TABLES -->\n""
+
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
 
@@ -27,22 +55,10 @@ def regenerate_home_wiki_page(wiki_dir: Path) -> None:
         : wiki_home_content.find(YEAR_MONTHLY_TABLES) + len(YEAR_MONTHLY_TABLES)
     ]
 
-    all_year_dirs = sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True)
-    for year_dir in all_year_dirs:
+    for year_dir in sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True):
         wiki_home_content += ""\n"" + YEAR_TABLE_HEADER.format(year=year_dir.name)
-
-        all_year_month_files = sorted(year_dir.glob(""*.md""), reverse=True)
-        for year_month_file in all_year_month_files:
-            year_month_file_content = year_month_file.read_text()
-            images = year_month_file_content.count(""Build manifest"")
-            builds = sum(
-                ""jupyter/base-notebook"" in line and ""aarch64"" not in line
-                for line in year_month_file_content.split(""\n"")
-            )
-            year_month = year_month_file.stem
-            wiki_home_content += (
-                f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} |\n""
-            )
+        for year_month_file in sorted(year_dir.glob(""*.md""), reverse=True):
+            wiki_home_content += build_monthly_table_line(year_month_file)
 
     wiki_home_file.write_text(wiki_home_content)
     LOGGER.info(""Updated Home page"")","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index aeaa12f6..ff3764e6 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -2,23 +2,51 @@
 # Copyright (c) Jupyter Development Team.
 # Distributed under the terms of the Modified BSD License.
 import argparse
+import datetime
 import logging
 import shutil
 from pathlib import Path
 
+import plumbum
+from dateutil import relativedelta
+
+git = plumbum.local[""git""]
+
 LOGGER = logging.getLogger(__name__)
 
+YEAR_TABLE_HEADER = """"""\
+## {year}
+
+| Month                  | Builds | Images | Commits |
+| ---------------------- | ------ | ------ | ------- |
+""""""
+
+
+def build_monthly_table_line(year_month_file: Path) -> str:
+    year_month_file_content = year_month_file.read_text()
+    images = year_month_file_content.count(""Build manifest"")
+    builds = sum(
+        ""jupyter/base-notebook"" in line and ""aarch64"" not in line
+        for line in year_month_file_content.split(""\n"")
+    )
+    year_month = year_month_file.stem
+    current_month = datetime.date(
+        year=int(year_month[:4]), month=int(year_month[5:]), day=1
+    )
+    next_month = current_month + relativedelta.relativedelta(months=1)
+    future = (
+        git[""log"", ""--oneline"", ""--since"", current_month, ""--until"", next_month]
+        & plumbum.BG
+    )
+    future.wait()
+    commits = len(future.stdout.splitlines())
+
+    return f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits: <7} |\n""
+
 
 def regenerate_home_wiki_page(wiki_dir: Path) -> None:
     YEAR_MONTHLY_TABLES = ""<!-- YEAR_MONTHLY_TABLES -->\n""
 
-    YEAR_TABLE_HEADER = """"""\
-## {year}
-
-| Month                  | Builds | Images |
-| ---------------------- | ------ | ------ |
-""""""
-
     wiki_home_file = wiki_dir / ""Home.md""
     wiki_home_content = wiki_home_file.read_text()
 
@@ -27,22 +55,10 @@ def regenerate_home_wiki_page(wiki_dir: Path) -> None:
         : wiki_home_content.find(YEAR_MONTHLY_TABLES) + len(YEAR_MONTHLY_TABLES)
     ]
 
-    all_year_dirs = sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True)
-    for year_dir in all_year_dirs:
+    for year_dir in sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True):
         wiki_home_content += ""\n"" + YEAR_TABLE_HEADER.format(year=year_dir.name)
-
-        all_year_month_files = sorted(year_dir.glob(""*.md""), reverse=True)
-        for year_month_file in all_year_month_files:
-            year_month_file_content = year_month_file.read_text()
-            images = year_month_file_content.count(""Build manifest"")
-            builds = sum(
-                ""jupyter/base-notebook"" in line and ""aarch64"" not in line
-                for line in year_month_file_content.split(""\n"")
-            )
-            year_month = year_month_file.stem
-            wiki_home_content += (
-                f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} |\n""
-            )
+        for year_month_file in sorted(year_dir.glob(""*.md""), reverse=True):
+            wiki_home_content += build_monthly_table_line(year_month_file)
 
     wiki_home_file.write_text(wiki_home_content)
     LOGGER.info(""Updated Home page"")",No
tagging/update_wiki.py,tagging/update_wiki.py,d812d6823439068cf3cb952af30f132299a54f36,af0493a30557814e0d827d56d40561f00b8c0746,Allow no new manfests or build history lines files if special flag is present during update_wiki,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index ff3764e6..597c38e4 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -118,11 +118,14 @@ def remove_old_manifests(wiki_dir: Path) -> None:
         LOGGER.info(f""Removed manifest: {file.relative_to(wiki_dir)}"")
 
 
-def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> None:
+def update_wiki(
+    wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path, allow_no_files: bool
+) -> None:
     LOGGER.info(""Updating wiki"")
 
     manifest_files = list(manifests_dir.rglob(""*.md""))
-    assert manifest_files, ""expected to have some manifest files""
+    if not allow_no_files:
+        assert manifest_files, ""expected to have some manifest files""
     for manifest_file in manifest_files:
         year_month = get_manifest_year_month(manifest_file)
         year = year_month[:4]
@@ -132,7 +135,10 @@ def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> No
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
 
     build_history_line_files = sorted(hist_lines_dir.rglob(""*.txt""))
-    assert build_history_line_files, ""expected to have some build history line files""
+    if not allow_no_files:
+        assert (
+            build_history_line_files
+        ), ""expected to have some build history line files""
     for build_history_line_file in build_history_line_files:
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
@@ -165,6 +171,13 @@ if __name__ == ""__main__"":
         type=Path,
         help=""Directory with manifest files"",
     )
+    arg_parser.add_argument(
+        ""--allow-no-files"",
+        action=""store_true"",
+        help=""Allow no manifest or history line files"",
+    )
     args = arg_parser.parse_args()
 
-    update_wiki(args.wiki_dir, args.hist_lines_dir, args.manifests_dir)
+    update_wiki(
+        args.wiki_dir, args.hist_lines_dir, args.manifests_dir, args.allow_no_files
+    )","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index ff3764e6..597c38e4 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -118,11 +118,14 @@ def remove_old_manifests(wiki_dir: Path) -> None:
         LOGGER.info(f""Removed manifest: {file.relative_to(wiki_dir)}"")
 
 
-def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> None:
+def update_wiki(
+    wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path, allow_no_files: bool
+) -> None:
     LOGGER.info(""Updating wiki"")
 
     manifest_files = list(manifests_dir.rglob(""*.md""))
-    assert manifest_files, ""expected to have some manifest files""
+    if not allow_no_files:
+        assert manifest_files, ""expected to have some manifest files""
     for manifest_file in manifest_files:
         year_month = get_manifest_year_month(manifest_file)
         year = year_month[:4]
@@ -132,7 +135,10 @@ def update_wiki(wiki_dir: Path, hist_lines_dir: Path, manifests_dir: Path) -> No
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")
 
     build_history_line_files = sorted(hist_lines_dir.rglob(""*.txt""))
-    assert build_history_line_files, ""expected to have some build history line files""
+    if not allow_no_files:
+        assert (
+            build_history_line_files
+        ), ""expected to have some build history line files""
     for build_history_line_file in build_history_line_files:
         build_history_line = build_history_line_file.read_text()
         assert build_history_line.startswith(""| `"")
@@ -165,6 +171,13 @@ if __name__ == ""__main__"":
         type=Path,
         help=""Directory with manifest files"",
     )
+    arg_parser.add_argument(
+        ""--allow-no-files"",
+        action=""store_true"",
+        help=""Allow no manifest or history line files"",
+    )
     args = arg_parser.parse_args()
 
-    update_wiki(args.wiki_dir, args.hist_lines_dir, args.manifests_dir)
+    update_wiki(
+        args.wiki_dir, args.hist_lines_dir, args.manifests_dir, args.allow_no_files
+    )",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,f44ddd6650b01424d878013fbeb1ec561018890d,d812d6823439068cf3cb952af30f132299a54f36,Add missing type stubs for mypy,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 0522c6bc..72e1ab07 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -47,6 +47,7 @@ repos:
             ""requests"",
             ""urllib3"",
             ""types-beautifulsoup4"",
+            ""types-python-dateutil"",
             ""types-requests"",
             ""types-tabulate"",
             ""types-urllib3"",","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 0522c6bc..72e1ab07 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -47,6 +47,7 @@ repos:
             ""requests"",
             ""urllib3"",
             ""types-beautifulsoup4"",
+            ""types-python-dateutil"",
             ""types-requests"",
             ""types-tabulate"",
             ""types-urllib3"",",Yes
requirements-dev.txt,requirements-dev.txt,c15d934a7125566db9ea883c1a6eafc2f3e32f0a,f44ddd6650b01424d878013fbeb1ec561018890d,Add python-dateutil to requirements.txt,"diff --git a/requirements-dev.txt b/requirements-dev.txt
index 3ab2be95..1f0faa75 100644
--- a/requirements-dev.txt
+++ b/requirements-dev.txt
@@ -6,5 +6,6 @@ pytest-retry
 # `pytest-xdist` is a plugin that provides the `--numprocesses` flag,
 # allowing us to run `pytest` tests in parallel
 pytest-xdist
+python-dateutil
 requests
 tabulate","diff --git a/requirements-dev.txt b/requirements-dev.txt
index 3ab2be95..1f0faa75 100644
--- a/requirements-dev.txt
+++ b/requirements-dev.txt
@@ -6,5 +6,6 @@ pytest-retry
 # `pytest-xdist` is a plugin that provides the `--numprocesses` flag,
 # allowing us to run `pytest` tests in parallel
 pytest-xdist
+python-dateutil
 requests
 tabulate",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,9cee159ec07a51268b10beb08643857af7542e7d,c15d934a7125566db9ea883c1a6eafc2f3e32f0a,Fetch full repo when running wiki update,"diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index b0abefc5..4403e6af 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -15,6 +15,8 @@ jobs:
     steps:
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index b0abefc5..4403e6af 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -15,6 +15,8 @@ jobs:
     steps:
       - name: Checkout Repo ⚡️
         uses: actions/checkout@v4
+        with:
+          fetch-depth: 0
       - name: Create dev environment 📦
         uses: ./.github/actions/create-dev-env",Yes
tagging/update_wiki.py,tagging/update_wiki.py,a61c9ae8a74e56a970c394b917d50058fc8fbb97,9cee159ec07a51268b10beb08643857af7542e7d,"Improve commits counting: inly count merge commits, calc between midnights UTC","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 597c38e4..69af5a47 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -34,10 +34,19 @@ def build_monthly_table_line(year_month_file: Path) -> str:
         year=int(year_month[:4]), month=int(year_month[5:]), day=1
     )
     next_month = current_month + relativedelta.relativedelta(months=1)
-    future = (
-        git[""log"", ""--oneline"", ""--since"", current_month, ""--until"", next_month]
-        & plumbum.BG
-    )
+    with plumbum.local.env(TZ=""UTC""):
+        future = (
+            git[
+                ""log"",
+                ""--oneline"",
+                ""--since"",
+                f""{current_month}.midnight"",
+                ""--until"",
+                f""{next_month}.midnight"",
+                ""--first-parent"",
+            ]
+            & plumbum.BG
+        )
     future.wait()
     commits = len(future.stdout.splitlines())","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 597c38e4..69af5a47 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -34,10 +34,19 @@ def build_monthly_table_line(year_month_file: Path) -> str:
         year=int(year_month[:4]), month=int(year_month[5:]), day=1
     )
     next_month = current_month + relativedelta.relativedelta(months=1)
-    future = (
-        git[""log"", ""--oneline"", ""--since"", current_month, ""--until"", next_month]
-        & plumbum.BG
-    )
+    with plumbum.local.env(TZ=""UTC""):
+        future = (
+            git[
+                ""log"",
+                ""--oneline"",
+                ""--since"",
+                f""{current_month}.midnight"",
+                ""--until"",
+                f""{next_month}.midnight"",
+                ""--first-parent"",
+            ]
+            & plumbum.BG
+        )
     future.wait()
     commits = len(future.stdout.splitlines())",Yes
tagging/update_wiki.py,tagging/update_wiki.py,ad4d4c6e6eea7c52ead60cb8bdaafc9eae135663,a61c9ae8a74e56a970c394b917d50058fc8fbb97,Add yearly total stats to update_wiki,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 69af5a47..ea83df6d 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -14,21 +14,17 @@ git = plumbum.local[""git""]
 
 LOGGER = logging.getLogger(__name__)
 
-YEAR_TABLE_HEADER = """"""\
-## {year}
-
-| Month                  | Builds | Images | Commits |
-| ---------------------- | ------ | ------ | ------- |
-""""""
 
-
-def build_monthly_table_line(year_month_file: Path) -> str:
+def calculate_monthly_stat(year_month_file: Path) -> tuple[int, int, int]:
     year_month_file_content = year_month_file.read_text()
-    images = year_month_file_content.count(""Build manifest"")
+
     builds = sum(
         ""jupyter/base-notebook"" in line and ""aarch64"" not in line
         for line in year_month_file_content.split(""\n"")
     )
+
+    images = year_month_file_content.count(""Build manifest"")
+
     year_month = year_month_file.stem
     current_month = datetime.date(
         year=int(year_month[:4]), month=int(year_month[5:]), day=1
@@ -50,7 +46,7 @@ def build_monthly_table_line(year_month_file: Path) -> str:
     future.wait()
     commits = len(future.stdout.splitlines())
 
-    return f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits: <7} |\n""
+    return builds, images, commits
 
 
 def regenerate_home_wiki_page(wiki_dir: Path) -> None:
@@ -64,10 +60,26 @@ def regenerate_home_wiki_page(wiki_dir: Path) -> None:
         : wiki_home_content.find(YEAR_MONTHLY_TABLES) + len(YEAR_MONTHLY_TABLES)
     ]
 
+    YEAR_TABLE_HEADER = """"""\
+## {year}
+
+| Month                  | Builds | Images | Commits |
+| ---------------------- | ------ | ------ | ------- |
+""""""
+
     for year_dir in sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True):
         wiki_home_content += ""\n"" + YEAR_TABLE_HEADER.format(year=year_dir.name)
+        year_builds, year_images, year_commits = 0, 0, 0
         for year_month_file in sorted(year_dir.glob(""*.md""), reverse=True):
-            wiki_home_content += build_monthly_table_line(year_month_file)
+            builds, images, commits = calculate_monthly_stat(year_month_file)
+            year_builds += builds
+            year_images += images
+            year_commits += commits
+            year_month = year_month_file.stem
+            monthly_line = f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits: <7} |\n""
+            wiki_home_content += monthly_line
+        year_total_line = f""| **Total**              | {year_builds: <6} | {year_images: <6} | {year_commits: <7} |\n""
+        wiki_home_content += year_total_line
 
     wiki_home_file.write_text(wiki_home_content)
     LOGGER.info(""Updated Home page"")","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index 69af5a47..ea83df6d 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -14,21 +14,17 @@ git = plumbum.local[""git""]
 
 LOGGER = logging.getLogger(__name__)
 
-YEAR_TABLE_HEADER = """"""\
-## {year}
 
-| Month                  | Builds | Images | Commits |
-| ---------------------- | ------ | ------ | ------- |
-""""""
-
-
-def build_monthly_table_line(year_month_file: Path) -> str:
+def calculate_monthly_stat(year_month_file: Path) -> tuple[int, int, int]:
     year_month_file_content = year_month_file.read_text()
-    images = year_month_file_content.count(""Build manifest"")
+
     builds = sum(
         ""jupyter/base-notebook"" in line and ""aarch64"" not in line
         for line in year_month_file_content.split(""\n"")
     )
+
+    images = year_month_file_content.count(""Build manifest"")
+
     year_month = year_month_file.stem
     current_month = datetime.date(
         year=int(year_month[:4]), month=int(year_month[5:]), day=1
@@ -50,7 +46,7 @@ def build_monthly_table_line(year_month_file: Path) -> str:
     future.wait()
     commits = len(future.stdout.splitlines())
 
-    return f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits: <7} |\n""
+    return builds, images, commits
 
 
 def regenerate_home_wiki_page(wiki_dir: Path) -> None:
@@ -64,10 +60,26 @@ def regenerate_home_wiki_page(wiki_dir: Path) -> None:
         : wiki_home_content.find(YEAR_MONTHLY_TABLES) + len(YEAR_MONTHLY_TABLES)
     ]
 
+    YEAR_TABLE_HEADER = """"""\
+## {year}
+
+| Month                  | Builds | Images | Commits |
+| ---------------------- | ------ | ------ | ------- |
+""""""
+
     for year_dir in sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True):
         wiki_home_content += ""\n"" + YEAR_TABLE_HEADER.format(year=year_dir.name)
+        year_builds, year_images, year_commits = 0, 0, 0
         for year_month_file in sorted(year_dir.glob(""*.md""), reverse=True):
-            wiki_home_content += build_monthly_table_line(year_month_file)
+            builds, images, commits = calculate_monthly_stat(year_month_file)
+            year_builds += builds
+            year_images += images
+            year_commits += commits
+            year_month = year_month_file.stem
+            monthly_line = f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits: <7} |\n""
+            wiki_home_content += monthly_line
+        year_total_line = f""| **Total**              | {year_builds: <6} | {year_images: <6} | {year_commits: <7} |\n""
+        wiki_home_content += year_total_line
 
     wiki_home_file.write_text(wiki_home_content)
     LOGGER.info(""Updated Home page"")",No
tagging/update_wiki.py,tagging/update_wiki.py,a6ef176ff3a798af0913260baed10b431066d227,ad4d4c6e6eea7c52ead60cb8bdaafc9eae135663,Make commits a url on wiki home page,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index ea83df6d..b5545fef 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -15,7 +15,9 @@ git = plumbum.local[""git""]
 LOGGER = logging.getLogger(__name__)
 
 
-def calculate_monthly_stat(year_month_file: Path) -> tuple[int, int, int]:
+def calculate_monthly_stat(
+    year_month_file: Path, year_month_date: datetime.date
+) -> tuple[int, int, int]:
     year_month_file_content = year_month_file.read_text()
 
     builds = sum(
@@ -25,20 +27,15 @@ def calculate_monthly_stat(year_month_file: Path) -> tuple[int, int, int]:
 
     images = year_month_file_content.count(""Build manifest"")
 
-    year_month = year_month_file.stem
-    current_month = datetime.date(
-        year=int(year_month[:4]), month=int(year_month[5:]), day=1
-    )
-    next_month = current_month + relativedelta.relativedelta(months=1)
     with plumbum.local.env(TZ=""UTC""):
         future = (
             git[
                 ""log"",
                 ""--oneline"",
                 ""--since"",
-                f""{current_month}.midnight"",
+                f""{year_month_date}.midnight"",
                 ""--until"",
-                f""{next_month}.midnight"",
+                f""{year_month_date + relativedelta.relativedelta(months=1)}.midnight"",
                 ""--first-parent"",
             ]
             & plumbum.BG
@@ -63,22 +60,39 @@ def regenerate_home_wiki_page(wiki_dir: Path) -> None:
     YEAR_TABLE_HEADER = """"""\
 ## {year}
 
-| Month                  | Builds | Images | Commits |
-| ---------------------- | ------ | ------ | ------- |
+| Month                  | Builds | Images | Commits                                                                                         |
+| ---------------------- | ------ | ------ | ----------------------------------------------------------------------------------------------- |
 """"""
 
+    GITHUB_COMMITS_URL = (
+        ""[{}](https://github.com/jupyter/docker-stacks/commits/main/?since={}&until={})""
+    )
+
     for year_dir in sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True):
         wiki_home_content += ""\n"" + YEAR_TABLE_HEADER.format(year=year_dir.name)
         year_builds, year_images, year_commits = 0, 0, 0
         for year_month_file in sorted(year_dir.glob(""*.md""), reverse=True):
-            builds, images, commits = calculate_monthly_stat(year_month_file)
+            year_month = year_month_file.stem
+            year_month_date = datetime.date(
+                year=int(year_month[:4]), month=int(year_month[5:]), day=1
+            )
+            builds, images, commits = calculate_monthly_stat(
+                year_month_file, year_month_date
+            )
             year_builds += builds
             year_images += images
             year_commits += commits
-            year_month = year_month_file.stem
-            monthly_line = f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits: <7} |\n""
+            commits_url = GITHUB_COMMITS_URL.format(
+                commits,
+                year_month_date,
+                year_month_date + relativedelta.relativedelta(day=31),
+            )
+            monthly_line = f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits_url: <95} |\n""
             wiki_home_content += monthly_line
-        year_total_line = f""| **Total**              | {year_builds: <6} | {year_images: <6} | {year_commits: <7} |\n""
+        year_commits_url = GITHUB_COMMITS_URL.format(
+            year_commits, f""{year_dir.name}-01-01"", f""{year_dir.name}-12-31""
+        )
+        year_total_line = f""| **Total**              | {year_builds: <6} | {year_images: <6} | {year_commits_url: <95} |\n""
         wiki_home_content += year_total_line
 
     wiki_home_file.write_text(wiki_home_content)","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index ea83df6d..b5545fef 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -15,7 +15,9 @@ git = plumbum.local[""git""]
 LOGGER = logging.getLogger(__name__)
 
 
-def calculate_monthly_stat(year_month_file: Path) -> tuple[int, int, int]:
+def calculate_monthly_stat(
+    year_month_file: Path, year_month_date: datetime.date
+) -> tuple[int, int, int]:
     year_month_file_content = year_month_file.read_text()
 
     builds = sum(
@@ -25,20 +27,15 @@ def calculate_monthly_stat(year_month_file: Path) -> tuple[int, int, int]:
 
     images = year_month_file_content.count(""Build manifest"")
 
-    year_month = year_month_file.stem
-    current_month = datetime.date(
-        year=int(year_month[:4]), month=int(year_month[5:]), day=1
-    )
-    next_month = current_month + relativedelta.relativedelta(months=1)
     with plumbum.local.env(TZ=""UTC""):
         future = (
             git[
                 ""log"",
                 ""--oneline"",
                 ""--since"",
-                f""{current_month}.midnight"",
+                f""{year_month_date}.midnight"",
                 ""--until"",
-                f""{next_month}.midnight"",
+                f""{year_month_date + relativedelta.relativedelta(months=1)}.midnight"",
                 ""--first-parent"",
             ]
             & plumbum.BG
@@ -63,22 +60,39 @@ def regenerate_home_wiki_page(wiki_dir: Path) -> None:
     YEAR_TABLE_HEADER = """"""\
 ## {year}
 
-| Month                  | Builds | Images | Commits |
-| ---------------------- | ------ | ------ | ------- |
+| Month                  | Builds | Images | Commits                                                                                         |
+| ---------------------- | ------ | ------ | ----------------------------------------------------------------------------------------------- |
 """"""
 
+    GITHUB_COMMITS_URL = (
+        ""[{}](https://github.com/jupyter/docker-stacks/commits/main/?since={}&until={})""
+    )
+
     for year_dir in sorted((wiki_dir / ""monthly-files"").glob(""*""), reverse=True):
         wiki_home_content += ""\n"" + YEAR_TABLE_HEADER.format(year=year_dir.name)
         year_builds, year_images, year_commits = 0, 0, 0
         for year_month_file in sorted(year_dir.glob(""*.md""), reverse=True):
-            builds, images, commits = calculate_monthly_stat(year_month_file)
+            year_month = year_month_file.stem
+            year_month_date = datetime.date(
+                year=int(year_month[:4]), month=int(year_month[5:]), day=1
+            )
+            builds, images, commits = calculate_monthly_stat(
+                year_month_file, year_month_date
+            )
             year_builds += builds
             year_images += images
             year_commits += commits
-            year_month = year_month_file.stem
-            monthly_line = f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits: <7} |\n""
+            commits_url = GITHUB_COMMITS_URL.format(
+                commits,
+                year_month_date,
+                year_month_date + relativedelta.relativedelta(day=31),
+            )
+            monthly_line = f""| [`{year_month}`](./{year_month}) | {builds: <6} | {images: <6} | {commits_url: <95} |\n""
             wiki_home_content += monthly_line
-        year_total_line = f""| **Total**              | {year_builds: <6} | {year_images: <6} | {year_commits: <7} |\n""
+        year_commits_url = GITHUB_COMMITS_URL.format(
+            year_commits, f""{year_dir.name}-01-01"", f""{year_dir.name}-12-31""
+        )
+        year_total_line = f""| **Total**              | {year_builds: <6} | {year_images: <6} | {year_commits_url: <95} |\n""
         wiki_home_content += year_total_line
 
     wiki_home_file.write_text(wiki_home_content)",Yes
tagging/update_wiki.py,tagging/update_wiki.py,7e4e18403a59aa7796c645224ede7c0981bc1464,a6ef176ff3a798af0913260baed10b431066d227,Create all necessary directories during wiki update,"diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index b5545fef..2688e2e5 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -111,6 +111,7 @@ def update_monthly_wiki_page(
     year = year_month[:4]
     monthly_page = wiki_dir / ""monthly-files"" / year / (year_month + "".md"")
     if not monthly_page.exists():
+        monthly_page.parent.mkdir(exist_ok=True)
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
         LOGGER.info(f""Created monthly page: {monthly_page.relative_to(wiki_dir)}"")
 
@@ -165,7 +166,7 @@ def update_wiki(
         year_month = get_manifest_year_month(manifest_file)
         year = year_month[:4]
         copy_to = wiki_dir / ""manifests"" / year / year_month / manifest_file.name
-        copy_to.parent.mkdir(exist_ok=True)
+        copy_to.parent.mkdir(parents=True, exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")","diff --git a/tagging/update_wiki.py b/tagging/update_wiki.py
index b5545fef..2688e2e5 100755
--- a/tagging/update_wiki.py
+++ b/tagging/update_wiki.py
@@ -111,6 +111,7 @@ def update_monthly_wiki_page(
     year = year_month[:4]
     monthly_page = wiki_dir / ""monthly-files"" / year / (year_month + "".md"")
     if not monthly_page.exists():
+        monthly_page.parent.mkdir(exist_ok=True)
         monthly_page.write_text(MONTHLY_PAGE_HEADER)
         LOGGER.info(f""Created monthly page: {monthly_page.relative_to(wiki_dir)}"")
 
@@ -165,7 +166,7 @@ def update_wiki(
         year_month = get_manifest_year_month(manifest_file)
         year = year_month[:4]
         copy_to = wiki_dir / ""manifests"" / year / year_month / manifest_file.name
-        copy_to.parent.mkdir(exist_ok=True)
+        copy_to.parent.mkdir(parents=True, exist_ok=True)
         shutil.copy(manifest_file, copy_to)
         LOGGER.info(f""Added manifest file: {copy_to.relative_to(wiki_dir)}"")",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,eda963af71ce3f85155330d9dd3625828a875e56,7e4e18403a59aa7796c645224ede7c0981bc1464,"[pre-commit.ci] pre-commit autoupdate (#2197)

updates:
- [github.com/asottile/pyupgrade: v3.19.0 → v3.19.1](https://github.com/asottile/pyupgrade/compare/v3.19.0...v3.19.1)
- [github.com/pre-commit/mirrors-mypy: v1.13.0 → v1.14.1](https://github.com/pre-commit/mirrors-mypy/compare/v1.13.0...v1.14.1)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 72e1ab07..31227662 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.19.0
+    rev: v3.19.1
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.13.0
+    rev: v1.14.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 72e1ab07..31227662 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -14,7 +14,7 @@
 repos:
   # Autoupdate: Python code
   - repo: https://github.com/asottile/pyupgrade
-    rev: v3.19.0
+    rev: v3.19.1
     hooks:
       - id: pyupgrade
         args: [--py39-plus]
@@ -35,7 +35,7 @@ repos:
 
   # Check python code static typing
   - repo: https://github.com/pre-commit/mirrors-mypy
-    rev: v1.13.0
+    rev: v1.14.1
     hooks:
       - id: mypy
         args: [--config, ./mypy.ini]",Yes
docs/conf.py,docs/conf.py,269093f23f5b0e48504c323fa1b8db506470970e,eda963af71ce3f85155330d9dd3625828a875e56,Update copyright year,"diff --git a/docs/conf.py b/docs/conf.py
index f1bd390b..6ddb83d3 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -7,7 +7,7 @@
 # https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information
 
 project = ""docker-stacks""
-copyright = ""2024, Project Jupyter""
+copyright = ""2025, Project Jupyter""
 author = ""Project Jupyter""
 
 version = ""latest""","diff --git a/docs/conf.py b/docs/conf.py
index f1bd390b..6ddb83d3 100644
--- a/docs/conf.py
+++ b/docs/conf.py
@@ -7,7 +7,7 @@
 # https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information
 
 project = ""docker-stacks""
-copyright = ""2024, Project Jupyter""
+copyright = ""2025, Project Jupyter""
 author = ""Project Jupyter""
 
 version = ""latest""",Yes
.github/workflows/docker-wiki-update.yml,.github/workflows/docker-wiki-update.yml,56599eb2ba5b311457f4d567485162bb300d59b2,269093f23f5b0e48504c323fa1b8db506470970e,"Bump stefanzweifel/git-auto-commit-action from 5.0.1 to 5.1.0 (#2199)

Bumps [stefanzweifel/git-auto-commit-action](https://github.com/stefanzweifel/git-auto-commit-action) from 5.0.1 to 5.1.0.
- [Release notes](https://github.com/stefanzweifel/git-auto-commit-action/releases)
- [Changelog](https://github.com/stefanzweifel/git-auto-commit-action/blob/master/CHANGELOG.md)
- [Commits](https://github.com/stefanzweifel/git-auto-commit-action/compare/8621497c8c39c72f3e2a999a26b4ca1b5058a842...e348103e9026cc0eee72ae06630dbe30c8bf7a79)

---
updated-dependencies:
- dependency-name: stefanzweifel/git-auto-commit-action
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 4403e6af..abc3e198 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -44,7 +44,7 @@ jobs:
 
       - name: Push Wiki to GitHub 📤
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: stefanzweifel/git-auto-commit-action@8621497c8c39c72f3e2a999a26b4ca1b5058a842 # v5.0.1
+        uses: stefanzweifel/git-auto-commit-action@e348103e9026cc0eee72ae06630dbe30c8bf7a79 # v5.1.0
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""
           repository: wiki/","diff --git a/.github/workflows/docker-wiki-update.yml b/.github/workflows/docker-wiki-update.yml
index 4403e6af..abc3e198 100644
--- a/.github/workflows/docker-wiki-update.yml
+++ b/.github/workflows/docker-wiki-update.yml
@@ -44,7 +44,7 @@ jobs:
 
       - name: Push Wiki to GitHub 📤
         if: env.PUSH_TO_REGISTRY == 'true'
-        uses: stefanzweifel/git-auto-commit-action@8621497c8c39c72f3e2a999a26b4ca1b5058a842 # v5.0.1
+        uses: stefanzweifel/git-auto-commit-action@e348103e9026cc0eee72ae06630dbe30c8bf7a79 # v5.1.0
         with:
           commit_message: ""Automated wiki publish for ${{ github.sha }}""
           repository: wiki/",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,b11a5699cab549de73cd91cad4cb996aaeeb4b25,56599eb2ba5b311457f4d567485162bb300d59b2,Use markdownlint-cli2,"diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 31227662..c52a2c88 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -123,11 +123,11 @@ repos:
       - id: flake8
 
   # Lint: Markdown
-  - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.43.0
+  - repo: https://github.com/DavidAnson/markdownlint-cli2
+    rev: v0.17.1
     hooks:
-      - id: markdownlint
-        args: [""--fix""]
+      - id: markdownlint-cli2
+        args: [--fix]
 
   # Strip output from Jupyter notebooks
   - repo: https://github.com/kynan/nbstripout","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index 31227662..c52a2c88 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -123,11 +123,11 @@ repos:
       - id: flake8
 
   # Lint: Markdown
-  - repo: https://github.com/igorshubovych/markdownlint-cli
-    rev: v0.43.0
+  - repo: https://github.com/DavidAnson/markdownlint-cli2
+    rev: v0.17.1
     hooks:
-      - id: markdownlint
-        args: [""--fix""]
+      - id: markdownlint-cli2
+        args: [--fix]
 
   # Strip output from Jupyter notebooks
   - repo: https://github.com/kynan/nbstripout",Yes
tests/package_helper.py,tests/package_helper.py,eeca94420ae9f3e6417f1f4f17fc0c4f9117981e,b11a5699cab549de73cd91cad4cb996aaeeb4b25,Ignore stderr in CondaPackageHelper::_execute_command,"diff --git a/tests/package_helper.py b/tests/package_helper.py
index 0c4f3ec3..6c5930b7 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -90,7 +90,7 @@ class CondaPackageHelper:
 
     def _execute_command(self, command: list[str]) -> str:
         """"""Execute a command on a running container""""""
-        rc = self.running_container.exec_run(command)
+        rc = self.running_container.exec_run(command, stderr=False)
         return rc.output.decode(""utf-8"")  # type: ignore
 
     @staticmethod","diff --git a/tests/package_helper.py b/tests/package_helper.py
index 0c4f3ec3..6c5930b7 100644
--- a/tests/package_helper.py
+++ b/tests/package_helper.py
@@ -90,7 +90,7 @@ class CondaPackageHelper:
 
     def _execute_command(self, command: list[str]) -> str:
         """"""Execute a command on a running container""""""
-        rc = self.running_container.exec_run(command)
+        rc = self.running_container.exec_run(command, stderr=False)
         return rc.output.decode(""utf-8"")  # type: ignore
 
     @staticmethod",Yes
images/minimal-notebook/setup-scripts/setup_julia.py,images/minimal-notebook/setup-scripts/setup_julia.py,0b16cf8dbff41db849390051ed008f1153eca193,eeca94420ae9f3e6417f1f4f17fc0c4f9117981e,Simplify unify_aarch64,"diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index e6221238..bf6cc62e 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -20,13 +20,9 @@ LOGGER = logging.getLogger(__name__)
 
 def unify_aarch64(platform: str) -> str:
     """"""
-    Renames arm64->aarch64 to support local builds on on aarch64 Macs
+    Renames arm64->aarch64 to support local builds on aarch64 Macs
     """"""
-    return {
-        ""aarch64"": ""aarch64"",
-        ""arm64"": ""aarch64"",
-        ""x86_64"": ""x86_64"",
-    }[platform]
+    return {""arm64"": ""aarch64""}.get(platform, platform)
 
 
 def get_latest_julia_url() -> tuple[str, str]:","diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index e6221238..bf6cc62e 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -20,13 +20,9 @@ LOGGER = logging.getLogger(__name__)
 
 def unify_aarch64(platform: str) -> str:
     """"""
-    Renames arm64->aarch64 to support local builds on on aarch64 Macs
+    Renames arm64->aarch64 to support local builds on aarch64 Macs
     """"""
-    return {
-        ""aarch64"": ""aarch64"",
-        ""arm64"": ""aarch64"",
-        ""x86_64"": ""x86_64"",
-    }[platform]
+    return {""arm64"": ""aarch64""}.get(platform, platform)
 
 
 def get_latest_julia_url() -> tuple[str, str]:",Yes
tagging/get_platform.py,tagging/get_platform.py,0b16cf8dbff41db849390051ed008f1153eca193,eeca94420ae9f3e6417f1f4f17fc0c4f9117981e,Simplify unify_aarch64,"diff --git a/tagging/get_platform.py b/tagging/get_platform.py
index cda791ab..76e5b88c 100644
--- a/tagging/get_platform.py
+++ b/tagging/get_platform.py
@@ -7,13 +7,9 @@ ALL_PLATFORMS = {""x86_64"", ""aarch64""}
 
 def unify_aarch64(platform: str) -> str:
     """"""
-    Renames arm64->aarch64 to support local builds on on aarch64 Macs
+    Renames arm64->aarch64 to support local builds on aarch64 Macs
     """"""
-    return {
-        ""aarch64"": ""aarch64"",
-        ""arm64"": ""aarch64"",
-        ""x86_64"": ""x86_64"",
-    }[platform]
+    return {""arm64"": ""aarch64""}.get(platform, platform)
 
 
 def get_platform() -> str:","diff --git a/tagging/get_platform.py b/tagging/get_platform.py
index cda791ab..76e5b88c 100644
--- a/tagging/get_platform.py
+++ b/tagging/get_platform.py
@@ -7,13 +7,9 @@ ALL_PLATFORMS = {""x86_64"", ""aarch64""}
 
 def unify_aarch64(platform: str) -> str:
     """"""
-    Renames arm64->aarch64 to support local builds on on aarch64 Macs
+    Renames arm64->aarch64 to support local builds on aarch64 Macs
     """"""
-    return {
-        ""aarch64"": ""aarch64"",
-        ""arm64"": ""aarch64"",
-        ""x86_64"": ""x86_64"",
-    }[platform]
+    return {""arm64"": ""aarch64""}.get(platform, platform)
 
 
 def get_platform() -> str:",Yes
images/base-notebook/jupyter_server_config.py,images/base-notebook/jupyter_server_config.py,368f8275e1644156630c524d78bb15afad84eaff,0b16cf8dbff41db849390051ed008f1153eca193,jupyter_server_config.py: Listen on all interfaces (ipv4 and ipv6),"diff --git a/images/base-notebook/jupyter_server_config.py b/images/base-notebook/jupyter_server_config.py
index c0cca3af..a8816034 100644
--- a/images/base-notebook/jupyter_server_config.py
+++ b/images/base-notebook/jupyter_server_config.py
@@ -9,7 +9,8 @@ from pathlib import Path
 from jupyter_core.paths import jupyter_data_dir
 
 c = get_config()  # noqa: F821
-c.ServerApp.ip = ""0.0.0.0""
+# Listen on all interfaces (ipv4 and ipv6)
+c.ServerApp.ip = """"
 c.ServerApp.open_browser = False
 
 # to output both image/svg+xml and application/pdf plot formats in the notebook file","diff --git a/images/base-notebook/jupyter_server_config.py b/images/base-notebook/jupyter_server_config.py
index c0cca3af..a8816034 100644
--- a/images/base-notebook/jupyter_server_config.py
+++ b/images/base-notebook/jupyter_server_config.py
@@ -9,7 +9,8 @@ from pathlib import Path
 from jupyter_core.paths import jupyter_data_dir
 
 c = get_config()  # noqa: F821
-c.ServerApp.ip = ""0.0.0.0""
+# Listen on all interfaces (ipv4 and ipv6)
+c.ServerApp.ip = """"
 c.ServerApp.open_browser = False
 
 # to output both image/svg+xml and application/pdf plot formats in the notebook file",Yes
images/minimal-notebook/setup-scripts/setup_julia.py,images/minimal-notebook/setup-scripts/setup_julia.py,dcecb315561968827336fae622b0c5e940ce4f0b,a85eb438012ef44909f8f3ee6a2248a8fa0d81d2,Do not use julia 1.11.3 as well,"diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index bf6cc62e..c431d778 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -43,11 +43,12 @@ def get_latest_julia_url() -> tuple[str, str]:
     triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
     file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
     LOGGER.info(f""Latest version: {file_info['version']} url: {file_info['url']}"")
-    if file_info[""version""] == ""1.11.2"":
+    BROKEN_VERSION = ""1.11.3""
+    if file_info[""version""] == BROKEN_VERSION:
         LOGGER.warning(
-            ""Not using Julia 1.11.2, because it hangs in GitHub self-hosted runners""
+            f""Not using Julia {BROKEN_VERSION}, because it hangs in GitHub self-hosted runners""
         )
-        return file_info[""url""].replace(""1.11.2"", ""1.11.1""), ""1.11.1""
+        return file_info[""url""].replace(BROKEN_VERSION, ""1.11.1""), ""1.11.1""
     return file_info[""url""], file_info[""version""]","diff --git a/images/minimal-notebook/setup-scripts/setup_julia.py b/images/minimal-notebook/setup-scripts/setup_julia.py
index bf6cc62e..c431d778 100755
--- a/images/minimal-notebook/setup-scripts/setup_julia.py
+++ b/images/minimal-notebook/setup-scripts/setup_julia.py
@@ -43,11 +43,12 @@ def get_latest_julia_url() -> tuple[str, str]:
     triplet = unify_aarch64(platform.machine()) + ""-linux-gnu""
     file_info = [vf for vf in latest_version_files if vf[""triplet""] == triplet][0]
     LOGGER.info(f""Latest version: {file_info['version']} url: {file_info['url']}"")
-    if file_info[""version""] == ""1.11.2"":
+    BROKEN_VERSION = ""1.11.3""
+    if file_info[""version""] == BROKEN_VERSION:
         LOGGER.warning(
-            ""Not using Julia 1.11.2, because it hangs in GitHub self-hosted runners""
+            f""Not using Julia {BROKEN_VERSION}, because it hangs in GitHub self-hosted runners""
         )
-        return file_info[""url""].replace(""1.11.2"", ""1.11.1""), ""1.11.1""
+        return file_info[""url""].replace(BROKEN_VERSION, ""1.11.1""), ""1.11.1""
     return file_info[""url""], file_info[""version""]",Yes
images/base-notebook/start-singleuser.py,images/base-notebook/start-singleuser.py,52f7f3b5d565ef1a6d06c4d16d75459eb37add6f,dcecb315561968827336fae622b0c5e940ce4f0b,"Don't override singleuser ip to 0.0.0.0 (#2203)

Co-authored-by: Ayaz Salikhov <mathbunnyru@users.noreply.github.com>","diff --git a/images/base-notebook/start-singleuser.py b/images/base-notebook/start-singleuser.py
index c80339f5..8fe0e9ef 100755
--- a/images/base-notebook/start-singleuser.py
+++ b/images/base-notebook/start-singleuser.py
@@ -8,9 +8,7 @@ import sys
 # Entrypoint is start.sh
 command = [""jupyterhub-singleuser""]
 
-# set default ip to 0.0.0.0
-if ""--ip="" not in os.environ.get(""NOTEBOOK_ARGS"", """"):
-    command.append(""--ip=0.0.0.0"")
+# JupyterHub singleuser arguments are set using environment variables
 
 # Append any optional NOTEBOOK_ARGS we were passed in.
 # This is supposed to be multiple args passed on to the notebook command,","diff --git a/images/base-notebook/start-singleuser.py b/images/base-notebook/start-singleuser.py
index c80339f5..8fe0e9ef 100755
--- a/images/base-notebook/start-singleuser.py
+++ b/images/base-notebook/start-singleuser.py
@@ -8,9 +8,7 @@ import sys
 # Entrypoint is start.sh
 command = [""jupyterhub-singleuser""]
 
-# set default ip to 0.0.0.0
-if ""--ip="" not in os.environ.get(""NOTEBOOK_ARGS"", """"):
-    command.append(""--ip=0.0.0.0"")
+# JupyterHub singleuser arguments are set using environment variables
 
 # Append any optional NOTEBOOK_ARGS we were passed in.
 # This is supposed to be multiple args passed on to the notebook command,",Yes
docs/maintaining/aarch64-runner.md,docs/maintaining/aarch64-runner.md,e9b04fd5da4a42d47eac1a6491dcb5377909121b,52f7f3b5d565ef1a6d06c4d16d75459eb37add6f,Fix oracle link redirect,"diff --git a/docs/maintaining/aarch64-runner.md b/docs/maintaining/aarch64-runner.md
index 3850760d..c6e129e3 100644
--- a/docs/maintaining/aarch64-runner.md
+++ b/docs/maintaining/aarch64-runner.md
@@ -6,7 +6,7 @@ Each runner is recommended to have at least _2 cores_ and _30 GB_ of disk space.
 
 Add a new runner:
 
-- To use [Oracle OCI](https://www.oracle.com/cloud-0/), create a compute instance `VM.Standard.A1.Flex`.
+- To use [Oracle OCI](https://www.oracle.com/cloud/), create a compute instance `VM.Standard.A1.Flex`.
 - To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-start-instance).
 
 Configure your runner:","diff --git a/docs/maintaining/aarch64-runner.md b/docs/maintaining/aarch64-runner.md
index 3850760d..c6e129e3 100644
--- a/docs/maintaining/aarch64-runner.md
+++ b/docs/maintaining/aarch64-runner.md
@@ -6,7 +6,7 @@ Each runner is recommended to have at least _2 cores_ and _30 GB_ of disk space.
 
 Add a new runner:
 
-- To use [Oracle OCI](https://www.oracle.com/cloud-0/), create a compute instance `VM.Standard.A1.Flex`.
+- To use [Oracle OCI](https://www.oracle.com/cloud/), create a compute instance `VM.Standard.A1.Flex`.
 - To use [Google Cloud](https://cloud.google.com), use [this instruction](https://cloud.google.com/compute/docs/instances/create-start-instance).
 
 Configure your runner:",Yes
.gitignore,.gitignore,34740dd9c6a05be95b4acfa002344734aa14f0e5,e9b04fd5da4a42d47eac1a6491dcb5377909121b,Update from Python.gitignore,"diff --git a/.gitignore b/.gitignore
index 2d29f388..813748c3 100644
--- a/.gitignore
+++ b/.gitignore
@@ -167,6 +167,9 @@ cython_debug/
 #  option (not recommended) you can uncomment the following to ignore the entire idea folder.
 #.idea/
 
+# Ruff stuff:
+.ruff_cache/
+
 # PyPI configuration file
 .pypirc","diff --git a/.gitignore b/.gitignore
index 2d29f388..813748c3 100644
--- a/.gitignore
+++ b/.gitignore
@@ -167,6 +167,9 @@ cython_debug/
 #  option (not recommended) you can uncomment the following to ignore the entire idea folder.
 #.idea/
 
+# Ruff stuff:
+.ruff_cache/
+
 # PyPI configuration file
 .pypirc",Yes
.pre-commit-config.yaml,.pre-commit-config.yaml,83600cfa5067e559b4868ab9fda73e6eaaa2691d,34740dd9c6a05be95b4acfa002344734aa14f0e5,"[pre-commit.ci] pre-commit autoupdate (#2207)

updates:
- [github.com/PyCQA/isort: 5.13.2 → 6.0.0](https://github.com/PyCQA/isort/compare/5.13.2...6.0.0)
- [github.com/psf/black: 24.10.0 → 25.1.0](https://github.com/psf/black/compare/24.10.0...25.1.0)
- [github.com/DavidAnson/markdownlint-cli2: v0.17.1 → v0.17.2](https://github.com/DavidAnson/markdownlint-cli2/compare/v0.17.1...v0.17.2)

Co-authored-by: pre-commit-ci[bot] <66853113+pre-commit-ci[bot]@users.noreply.github.com>","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index c52a2c88..57802ee1 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -21,14 +21,14 @@ repos:
 
   # Automatically sort python imports
   - repo: https://github.com/PyCQA/isort
-    rev: 5.13.2
+    rev: 6.0.0
     hooks:
       - id: isort
         args: [--profile, black]
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.10.0
+    rev: 25.1.0
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -124,7 +124,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/DavidAnson/markdownlint-cli2
-    rev: v0.17.1
+    rev: v0.17.2
     hooks:
       - id: markdownlint-cli2
         args: [--fix]","diff --git a/.pre-commit-config.yaml b/.pre-commit-config.yaml
index c52a2c88..57802ee1 100644
--- a/.pre-commit-config.yaml
+++ b/.pre-commit-config.yaml
@@ -21,14 +21,14 @@ repos:
 
   # Automatically sort python imports
   - repo: https://github.com/PyCQA/isort
-    rev: 5.13.2
+    rev: 6.0.0
     hooks:
       - id: isort
         args: [--profile, black]
 
   # Autoformat: Python code
   - repo: https://github.com/psf/black
-    rev: 24.10.0
+    rev: 25.1.0
     hooks:
       - id: black
         args: [--target-version=py39]
@@ -124,7 +124,7 @@ repos:
 
   # Lint: Markdown
   - repo: https://github.com/DavidAnson/markdownlint-cli2
-    rev: v0.17.1
+    rev: v0.17.2
     hooks:
       - id: markdownlint-cli2
         args: [--fix]",Yes
